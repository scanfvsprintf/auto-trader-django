======= é¡¹ç›®æ–‡ä»¶æ ‘ =======

ğŸ“‚ ./
    ğŸ“„ .env
    ğŸ“„ .env.example
    ğŸ“„ Må€¼å…³ç³»åˆ†æ.py
    ğŸ“„ Må€¼åˆ†ææŠ¥å‘Š.txt
    ğŸ“„ backtest.sh
    ğŸ“„ backtest_m.sh
    ğŸ“„ config.json
    ğŸ“„ m_value_csi300.csv
    ğŸ“„ manage.py
    ğŸ“„ requirements.txt
    ğŸ“„ restart.sh
    ğŸ“„ trade_report.html
    ğŸ“„ user.json
    ğŸ“„ uwsgi.ini
    ğŸ“„ äº’ç›¸å…³åˆ†æ.py
    ğŸ“„ äº’ç›¸å…³åˆ†æ.txt
    ğŸ“„ äº¤æ˜“å˜åŒ–.html
    ğŸ“„ å›æµ‹ç®€å•æ—¥å¿—.txt
    ğŸ“„ å›æµ‹ç®€å•æ—¥å¿—_v2.1.txt
    ğŸ“„ å›æµ‹ç®€å•æ—¥å¿—_v2.2.txt
    ğŸ“„ æå–æ—¥å¿—.py
    ğŸ“„ æ—¥å¿—åˆ†ææç¤ºè¯.txt
    ğŸ“„ æµ‹è¯•akshare.py
    ğŸ“„ æµ‹è¯•easytrader.py
    ğŸ“„ èµ„é‡‘å˜åŒ–å›¾.png
    ğŸ“‚ autoTrade/
        ğŸ“„ __init__.py
        ğŸ“„ asgi.py
        ğŸ“„ settings.py
        ğŸ“„ urls.py
        ğŸ“„ wsgi.py
    ğŸ“‚ common/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ config_loader.py
        ğŸ“„ tests.py
        ğŸ“„ views.py
        ğŸ“‚ models/
            ğŸ“„ __init__.py
            ğŸ“„ backtest_logs.py
            ğŸ“„ corporate_action.py
            ğŸ“„ daily_factor_values.py
            ğŸ“„ daily_quotes.py
            ğŸ“„ daily_trading_plan.py
            ğŸ“„ factor_definitions.py
            ğŸ“„ index_quotes_csi300.py
            ğŸ“„ positions.py
            ğŸ“„ stock_info.py
            ğŸ“„ strategy_parameters.py
            ğŸ“„ system_log.py
            ğŸ“„ trade_log.py
    ğŸ“‚ data_manager/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ models.py
        ğŸ“„ tests.py
        ğŸ“„ urls.py
        ğŸ“„ views.py
        ğŸ“‚ management/
            ğŸ“‚ commands/
                ğŸ“„ backfill_csi300_data.py
                ğŸ“„ calibrate_m_value_anchors.py
                ğŸ“„ full_update_stocks.py
                ğŸ“„ migrate_to_pg.py
                ğŸ“„ reset_sequences.py
        ğŸ“‚ service/
            ğŸ“„ corporate_action_service.py
            ğŸ“„ db_service.py
            ğŸ“„ email_handler.py
            ğŸ“„ email_service.py
            ğŸ“„ stock_service.py
    ğŸ“‚ selection_manager/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ models.py
        ğŸ“„ tests.py
        ğŸ“„ urls.py
        ğŸ“„ views.py
        ğŸ“‚ service/
            ğŸ“„ m_value_service.py
            ğŸ“„ ml.example
            ğŸ“„ selection_service copy.old_v4
            ğŸ“„ selection_service copy.py.old_v5
            ğŸ“„ selection_service.py
            ğŸ“„ selection_service.py.old
            ğŸ“„ selection_service.py.old_v2
            ğŸ“„ selection_service.py.old_v3
            ğŸ“„ selection_service.py.old_v6
            ğŸ“„ stock_value_service.py
        ğŸ“‚ management/
            ğŸ“‚ commands/
                ğŸ“„ generate_m_value_csv.py
                ğŸ“„ prepare_csi300_features.py
                ğŸ“„ prepare_stock_features.py
                ğŸ“„ train_csi300_model_test.py
                ğŸ“„ train_stock_model.py
        ğŸ“‚ ml_models/
            ğŸ“„ csi300_cnn_final_model.h5
            ğŸ“„ csi300_features_gen2.pkl
            ğŸ“„ csi300_features_lgbm.pkl
            ğŸ“„ csi300_lgbm_config.json
            ğŸ“„ csi300_lgbm_model.joblib
            ğŸ“„ csi300_model_config.json
            ğŸ“„ m_value_dataset.pkl
            ğŸ“„ m_value_lgbm_model.joblib
            ğŸ“„ m_value_model_config.json
            ğŸ“„ stock_features_dataset.pkl
            ğŸ“„ stock_lgbm_model.joblib
            ğŸ“„ stock_model_config.json
    ğŸ“‚ trade_manager/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ models.py
        ğŸ“„ tests.py
        ğŸ“„ urls.py
        ğŸ“„ views.py
        ğŸ“‚ management/
            ğŸ“‚ commands/
                ğŸ“„ run_backtest.py
                ğŸ“„ run_m_distribution_backtest.py
                ğŸ“„ run_scheduler.py
        ğŸ“‚ service/
            ğŸ“„ backtest_reporter.py
            ğŸ“„ before_fix_service.py
            ğŸ“„ db_utils.py
            ğŸ“„ decision_order_service.py
            ğŸ“„ decision_order_service_old.py
            ğŸ“„ m_distribution_backtest_service.py
            ğŸ“„ m_distribution_reporter.py
            ğŸ“„ monitor_exit_service.py
            ğŸ“„ position_monitor_logic.py
            ğŸ“„ real_trade_handler.py
            ğŸ“„ scheduler_service.py
            ğŸ“„ simulate_trade.py
            ğŸ“„ simulate_trade_handler.py
            ğŸ“„ simulate_trade_old.py
            ğŸ“„ trade_handler.py
    ğŸ“‚ logs/
        ğŸ“„ .__django.lock
        ğŸ“„ django.log

========================

======= Pythonæ–‡ä»¶å†…å®¹ =======

####Må€¼å…³ç³»åˆ†æ.py####
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# --- é…ç½®åŒº ---

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œä»¥é˜²å›¾è¡¨å’ŒæŠ¥å‘Šä¸­çš„ä¸­æ–‡ä¹±ç 
plt.rcParams['font.sans-serif'] = ['SimHei']  # 'SimHei' æ˜¯é»‘ä½“ï¼Œé€‚ç”¨äºWindows
# plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # é€‚ç”¨äº Mac
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# --- åŠŸèƒ½å‡½æ•°åŒº ---

def load_data(file_path):
    """
    åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨å¤„ç†å¸¸è§çš„ç¼–ç é—®é¢˜ (UTF-8, GBK)ã€‚
    """
    try:
        # ä¼˜å…ˆå°è¯•UTF-8ç¼–ç 
        df = pd.read_csv(file_path, parse_dates=['æ—¥æœŸ'])
        print("æ–‡ä»¶ä»¥ UTF-8 ç¼–ç æˆåŠŸåŠ è½½ã€‚")
    except UnicodeDecodeError:
        try:
            # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•GBKç¼–ç 
            df = pd.read_csv(file_path, parse_dates=['æ—¥æœŸ'], encoding='gbk')
            print("æ–‡ä»¶ä»¥ GBK ç¼–ç æˆåŠŸåŠ è½½ã€‚")
        except Exception as e:
            print(f"å°è¯•å¤šç§ç¼–ç åï¼Œè¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return None
    except Exception as e:
        print(f"è¯»å–æˆ–è§£ææ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None
        
    df = df.set_index('æ—¥æœŸ').sort_index()
    return df

def analyze_m_value_predictiveness(df, horizons=[1,5, 20, 60]):
    """
    åˆ†æMå€¼å¯¹æœªæ¥æ²ªæ·±300æŒ‡æ•°æ”¶ç›Šå’Œæ³¢åŠ¨æ€§çš„é¢„æµ‹èƒ½åŠ›ã€‚
    """
    # 1. è®¡ç®—æœªæ¥çš„Næ—¥æ¶¨è·Œå¹…
    for h in horizons:
        df[f'fwd_return_{h}d'] = (df['æ²ªæ·±300æ”¶ç›˜æŒ‡æ•°'].shift(-h) / df['æ²ªæ·±300æ”¶ç›˜æŒ‡æ•°']) - 1

    df.dropna(inplace=True)

    # 2. å¯¹Må€¼è¿›è¡Œåˆ†ç®±
    bins = np.arange(-1.0, 1.10, 0.1)
    # ç¡®ä¿æ ‡ç­¾å’Œbinsçš„é•¿åº¦åŒ¹é…
    labels = [f"[{i:.1f}, {i+0.1:.1f})" for i in bins[:-1]]
    df['m_bin'] = pd.cut(df['må€¼'], bins=bins, labels=labels, right=False, include_lowest=True)

    print("Må€¼åˆ†ç®±å®Œæˆï¼Œå¼€å§‹è¿›è¡Œåˆ†ç»„ç»Ÿè®¡...")

    # 3. æŒ‰Må€¼åˆ†ç®±è¿›è¡Œåˆ†ç»„ç»Ÿè®¡
    results = {}
    for h in horizons:
        agg_funcs = {
            f'fwd_return_{h}d': [
                ('å¹³å‡æ¶¨è·Œå¹…(%)', lambda x: x.mean() * 100),
                ('æ¶¨è·Œå¹…æ ‡å‡†å·®(%)', lambda x: x.std() * 100),
                ('æ ·æœ¬æ•°', 'count')
            ]
        }
        grouped_stats = df.groupby('m_bin').agg(agg_funcs)
        grouped_stats.columns = grouped_stats.columns.droplevel(0)
        results[h] = grouped_stats
    
    return results

def generate_text_report(results, file_path, df_info):
    """
    ç”Ÿæˆç»“æ„åŒ–çš„æ–‡æœ¬åˆ†ææŠ¥å‘Šã€‚
    """
    report_content = []
    report_content.append("="*80)
    report_content.append(" M(t) æŒ‡æ ‡æœ‰æ•ˆæ€§åˆ†ææŠ¥å‘Š")
    report_content.append("="*80)
    report_content.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_content.append(f"æ•°æ®æºæ–‡ä»¶: {file_path}")
    report_content.append(f"æ•°æ®æ—¶é—´èŒƒå›´: {df_info['start_date']} åˆ° {df_info['end_date']}")
    report_content.append(f"æ€»æ ·æœ¬æ•°: {df_info['total_samples']}")
    report_content.append("\n")

    for horizon, data in results.items():
        report_content.append("-" * 80)
        report_content.append(f" åˆ†æç»´åº¦ï¼šæœªæ¥ {horizon} äº¤æ˜“æ—¥å¸‚åœºè¡¨ç°")
        report_content.append("-" * 80)
        
        # æ·»åŠ æ•°æ®è¡¨
        report_content.append("ã€è¯¦ç»†æ•°æ®ç»Ÿè®¡ã€‘\n")
        report_content.append(data.to_string())
        report_content.append("\n")

        # æ·»åŠ è‡ªåŠ¨è§£è¯»
        report_content.append("ã€æ ¸å¿ƒæ´å¯Ÿè§£è¯»ã€‘\n")
        
        # 1. è¶‹åŠ¿æ€§åˆ†æ
        high_m_returns = data[data.index.str.startswith('[0.')]['å¹³å‡æ¶¨è·Œå¹…(%)']
        low_m_returns = data[data.index.str.startswith('[-')]['å¹³å‡æ¶¨è·Œå¹…(%)']
        
        if not high_m_returns.empty and not low_m_returns.empty:
            avg_high_return = high_m_returns.mean()
            avg_low_return = low_m_returns.mean()
            if avg_high_return > 0 and avg_low_return < 0 and avg_high_return > avg_low_return:
                report_content.append(f"  - è¶‹åŠ¿é¢„æµ‹æ€§: è¡¨ç°è‰¯å¥½ã€‚Må€¼ä¸ºæ­£æ—¶å¹³å‡æ”¶ç›Šä¸º {avg_high_return:.2f}%ï¼ŒMå€¼ä¸ºè´Ÿæ—¶å¹³å‡æ”¶ç›Šä¸º {avg_low_return:.2f}%ã€‚Må€¼è¶Šé«˜ï¼Œæœªæ¥æ”¶ç›ŠæœŸæœ›è¶Šé«˜ã€‚")
            else:
                report_content.append(f"  - è¶‹åŠ¿é¢„æµ‹æ€§: è¡¨ç°ä¸æ˜æ˜¾æˆ–å­˜åœ¨åå¸¸ã€‚Må€¼ä¸ºæ­£æ—¶å¹³å‡æ”¶ç›Š {avg_high_return:.2f}%ï¼ŒMå€¼ä¸ºè´Ÿæ—¶å¹³å‡æ”¶ç›Š {avg_low_return:.2f}%ã€‚")
        
        # 2. æ³¢åŠ¨æ€§/é£é™©åˆ†æ
        min_std_bin = data['æ¶¨è·Œå¹…æ ‡å‡†å·®(%)'].idxmin()
        min_std_val = data['æ¶¨è·Œå¹…æ ‡å‡†å·®(%)'].min()
        report_content.append(f"  - é£é™©æŒ‡ç¤ºæ€§: å¸‚åœºä¸ç¡®å®šæ€§æœ€ä½ï¼ˆæœ€å¯é¢„æµ‹ï¼‰çš„åŒºé—´å‡ºç°åœ¨ Må€¼ {min_std_bin}ï¼Œå…¶æœªæ¥æ¶¨è·Œå¹…æ ‡å‡†å·®ä»…ä¸º {min_std_val:.2f}%ã€‚")

        # 3. ç­–ç•¥å»ºè®®
        report_content.append("\nã€ç­–ç•¥åº”ç”¨å»ºè®®ã€‘\n")
        if avg_high_return > 0.5: # é˜ˆå€¼å¯è°ƒ
             report_content.append("  - å½“ M å€¼è¾ƒé«˜æ—¶ (å¦‚ > 0.3)ï¼Œæœªæ¥å¸‚åœºä¸Šæ¶¨æ¦‚ç‡è¾ƒå¤§ï¼Œé€‚åˆåŠ å¤§ã€è¶‹åŠ¿åŠ¨èƒ½ã€‘å’Œã€å¼ºåŠ¿çªç ´ã€‘ç­–ç•¥çš„æƒé‡ã€‚")
        if avg_low_return < -0.5: # é˜ˆå€¼å¯è°ƒ
             report_content.append("  - å½“ M å€¼è¾ƒä½æ—¶ (å¦‚ < -0.3)ï¼Œæœªæ¥å¸‚åœºä¸‹è·Œé£é™©è¾ƒé«˜ï¼Œé€‚åˆåŠ å¤§ã€è´¨é‡é˜²å¾¡ã€‘ç­–ç•¥çš„æƒé‡ã€‚")
        if '[-0.2, -0.1)' in min_std_bin or '[0.0, 0.1)' in min_std_bin or '[-0.1, 0.0)' in min_std_bin:
             report_content.append("  - å½“ M å€¼æ¥è¿‘ 0 æ—¶ï¼Œè‹¥æ³¢åŠ¨ç‡æ˜¾è‘—é™ä½ï¼Œè¡¨æ˜å¸‚åœºè¿›å…¥éœ‡è¡æœŸï¼Œé€‚åˆåŠ å¤§ã€å‡å€¼å›å½’ã€‘ç­–ç•¥çš„æƒé‡ã€‚")
        
        report_content.append("\n\n")

    report_filename = "Må€¼åˆ†ææŠ¥å‘Š.txt"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_content))
    
    print(f"åˆ†ææŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: {report_filename}")


def plot_analysis_results(results):
    """
    å°†åˆ†æç»“æœå¯è§†åŒ–ã€‚
    """
    for horizon, data in results.items():
        fig, ax1 = plt.subplots(figsize=(14, 7))

        x_labels = data.index.astype(str)
        mean_returns = data['å¹³å‡æ¶¨è·Œå¹…(%)']
        std_devs = data['æ¶¨è·Œå¹…æ ‡å‡†å·®(%)']
        counts = data['æ ·æœ¬æ•°']

        color = 'tab:blue'
        ax1.set_xlabel('Må€¼åŒºé—´', fontsize=12)
        ax1.set_ylabel(f'æœªæ¥{horizon}æ—¥å¹³å‡æ¶¨è·Œå¹… (%)', color=color, fontsize=12)
        bars = ax1.bar(x_labels, mean_returns, color=color, alpha=0.7)
        ax1.tick_params(axis='y', labelcolor=color)
        plt.setp(ax1.get_xticklabels(), rotation=45, ha="right")
        ax1.axhline(0, color='gray', linewidth=0.8, linestyle='--')

        for i, bar in enumerate(bars):
            yval = bar.get_height()
            # ä½¿ç”¨æ•´æ•°ç´¢å¼• i ä» counts ä¸­è·å–æ­£ç¡®çš„æ ·æœ¬æ•°å€¼
            count_val = counts.iloc[i]
            ax1.text(bar.get_x() + bar.get_width()/2.0, yval + np.sign(yval)*0.1, f"n={int(count_val)}", ha='center', va='bottom', fontsize=8)

        ax2 = ax1.twinx()
        color = 'tab:red'
        ax2.set_ylabel(f'æœªæ¥{horizon}æ—¥æ¶¨è·Œå¹…æ ‡å‡†å·® (%)', color=color, fontsize=12)
        ax2.plot(x_labels, std_devs, color=color, marker='o', linestyle='-')
        ax2.tick_params(axis='y', labelcolor=color)

        fig.tight_layout()
        plt.title(f'Må€¼åŒºé—´ä¸æœªæ¥ {horizon} äº¤æ˜“æ—¥å¸‚åœºè¡¨ç°å…³ç³»', fontsize=16)
        plt.grid(True, axis='y', linestyle='--', alpha=0.6)
        plt.show()

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    # 1. å®šä¹‰æ–‡ä»¶è·¯å¾„å’Œåˆ†æå‚æ•°
    csv_file_path = 'm_value_csi300.csv'  # <--- è¯·ç¡®ä¿è¿™æ˜¯æ‚¨çš„æ–‡ä»¶å
    analysis_horizons = [1,5, 20, 60]

    # 2. åŠ è½½æ•°æ®
    df_raw = load_data(csv_file_path)

    if df_raw is not None:
        # 3. æå–æ•°æ®ä¿¡æ¯ç”¨äºæŠ¥å‘Š
        df_info = {
            'start_date': df_raw.index.min().strftime('%Y-%m-%d'),
            'end_date': df_raw.index.max().strftime('%Y-%m-%d'),
            'total_samples': len(df_raw)
        }
        
        # 4. æ‰§è¡Œæ ¸å¿ƒåˆ†æ
        analysis_results = analyze_m_value_predictiveness(df_raw.copy(), horizons=analysis_horizons)
        
        # 5. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        generate_text_report(analysis_results, csv_file_path, df_info)
        
        # 6. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        plot_analysis_results(analysis_results)


####æ–‡ä»¶ç»“æŸ####

####manage.py####
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys
import dotenv

def main():
    """Run administrative tasks."""
    dotenv.load_dotenv()
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'autoTrade.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()

####æ–‡ä»¶ç»“æŸ####

####äº’ç›¸å…³åˆ†æ.py####
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

# è®¾ç½®matplotlibä»¥æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei']  # 'SimHei' æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„ä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# --- 1. åŠ è½½å’Œå‡†å¤‡æ•°æ® ---
def load_and_prepare_data(filepath):
    """åŠ è½½CSVæ•°æ®ï¼Œå¹¶è¿›è¡ŒåŸºæœ¬é¢„å¤„ç†"""
    df = pd.read_csv(filepath)
    
    # å°†'æ—¥æœŸ'åˆ—è½¬æ¢ä¸ºdatetimeå¯¹è±¡ï¼Œå¹¶è®¾ä¸ºç´¢å¼•
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
    df = df.set_index('æ—¥æœŸ')
    
    # æŒ‰æ—¥æœŸæ’åºï¼Œç¡®ä¿æ—¶é—´åºåˆ—æ˜¯è¿ç»­çš„
    df = df.sort_index()
    
    print("åŸå§‹æ•°æ®é¢„è§ˆï¼š")
    print(df.head())
    print("\n")
    
    return df

# --- 2. è®¡ç®—æ—¥æ”¶ç›Šç‡ ---
def calculate_returns(df):
    """
    è®¡ç®—æ—¥æ”¶ç›Šç‡ã€‚åœ¨é‡‘èåˆ†æä¸­ï¼Œåˆ†ææ”¶ç›Šç‡æ¯”åˆ†æåŸå§‹ä»·æ ¼æ›´å¸¸è§ã€‚
    è¿™æœ‰åŠ©äºåºåˆ—çš„å¹³ç¨³åŒ–ï¼Œå¹¶å…³æ³¨ç›¸å¯¹å˜åŒ–ã€‚
    """
    # # ä½¿ç”¨ .pct_change() è®¡ç®—ç™¾åˆ†æ¯”å˜åŒ–
    # df_returns = df.pct_change()
    
    # # må€¼æœ¬èº«å¯èƒ½å°±æ˜¯å˜åŒ–ç‡ï¼Œå¦‚æœmå€¼å·²ç»æ˜¯ç±»ä¼¼æ”¶ç›Šç‡çš„æŒ‡æ ‡ï¼Œå¯ä»¥è·³è¿‡å¯¹må€¼çš„å¤„ç†
    # # è¿™é‡Œæˆ‘ä»¬å‡è®¾må€¼ä¹Ÿéœ€è¦å¤„ç†ï¼Œå¦‚æœä¸éœ€è¦ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
    # # df_returns['må€¼'] = df['må€¼'] # å¦‚æœmå€¼æœ¬èº«å°±æ˜¯å˜åŒ–ç‡ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å€¼
    
    # # åˆ é™¤ç¬¬ä¸€è¡Œï¼Œå› ä¸ºå…¶æ²¡æœ‰å‰ä¸€å¤©çš„å€¼ï¼Œè®¡ç®—ç»“æœä¸ºNaN
    # df_returns = df_returns.dropna()
    df_processed = pd.DataFrame(index=df.index)
    
    # åªå¯¹ä»·æ ¼åºåˆ—è®¡ç®—ç™¾åˆ†æ¯”å˜åŒ–
    df_processed['æ²ªæ·±300æŒ‡æ•°_returns'] = df['æ²ªæ·±300æ”¶ç›˜æŒ‡æ•°'].pct_change()
    
    # ç›´æ¥ä½¿ç”¨må€¼ï¼Œå› ä¸ºå®ƒå¯èƒ½å·²ç»æ˜¯å˜åŒ–ç‡
    df_processed['må€¼'] = df['må€¼']
    
    # åˆ é™¤ç¬¬ä¸€è¡Œï¼Œå› ä¸ºæ”¶ç›Šç‡è®¡ç®—ç»“æœä¸ºNaN
    df_processed = df_processed.dropna()
    print("æ—¥æ”¶ç›Šç‡æ•°æ®é¢„è§ˆï¼š")
    print(df_processed.head())
    print("\n")
    
    return df_processed

# --- 3. äº’ç›¸å…³åˆ†ææ ¸å¿ƒå‡½æ•° ---
def cross_correlation_analysis(series1, series2, max_lag):
    """
    è®¡ç®—ä¸¤ä¸ªæ—¶é—´åºåˆ—åœ¨æŒ‡å®šæœ€å¤§æ»åèŒƒå›´å†…çš„äº’ç›¸å…³æ€§ã€‚
    
    å‚æ•°:
    series1 (pd.Series): ç¬¬ä¸€ä¸ªæ—¶é—´åºåˆ— (ä¾‹å¦‚ må€¼çš„å˜åŒ–)
    series2 (pd.Series): ç¬¬äºŒä¸ªæ—¶é—´åºåˆ— (ä¾‹å¦‚ æ²ªæ·±300çš„å˜åŒ–)
    max_lag (int): è¦æµ‹è¯•çš„æœ€å¤§æ­£è´Ÿæ»åå¤©æ•°
    
    è¿”å›:
    lags (list): æ»åå¤©æ•°åˆ—è¡¨
    corrs (list): å¯¹åº”çš„ç›¸å…³ç³»æ•°åˆ—è¡¨
    """
    lags = []
    corrs = []
    
    # éå†ä» -max_lag åˆ° +max_lag çš„æ‰€æœ‰æ»åæœŸ
    for lag in range(-max_lag, max_lag + 1):
        # å¯¹ series1 è¿›è¡Œç§»ä½æ“ä½œ
        # lag > 0: series1 å‘å‰ç§»åŠ¨ (ç”¨æœªæ¥çš„å€¼å¯¹é½ç°åœ¨çš„series2)ï¼Œä»£è¡¨series2é¢†å…ˆ
        # lag < 0: series1 å‘åç§»åŠ¨ (ç”¨è¿‡å»çš„å€¼å¯¹é½ç°åœ¨çš„series2)ï¼Œä»£è¡¨series1é¢†å…ˆ
        shifted_series1 = series1.shift(lag)
        
        # å°†ä¸¤ä¸ªåºåˆ—å¯¹é½ï¼Œå¹¶ç§»é™¤å› ç§»ä½äº§ç”Ÿçš„NaNå€¼
        # è¿™ä¼šç¡®ä¿æˆ‘ä»¬åªåœ¨ä¸¤ä¸ªåºåˆ—éƒ½æœ‰æ•°æ®çš„æ—¥æœŸä¸Šè®¡ç®—ç›¸å…³æ€§
        temp_df = pd.concat([shifted_series1, series2], axis=1)
        temp_df.columns = ['s1_shifted', 's2']
        temp_df = temp_df.dropna()
        
        if not temp_df.empty:
            # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
            corr, _ = pearsonr(temp_df['s1_shifted'], temp_df['s2'])
            lags.append(lag)
            corrs.append(corr)
            
    return lags, corrs

def plot_and_interpret(lags, corrs, series1_name, series2_name):
    """ç»˜åˆ¶äº’ç›¸å…³å›¾ï¼Œè§£è¯»ç»“æœï¼Œå¹¶ç”ŸæˆtxtæŠ¥å‘Š"""
    
    # æ‰¾åˆ°æœ€å¤§ç›¸å…³æ€§åŠå…¶å¯¹åº”çš„æ»åæœŸ
    max_corr = max(corrs)
    best_lag = lags[np.argmax(corrs)]
    
    # --- ç”Ÿæˆè§£è¯»æ–‡æœ¬ ---
    if best_lag > 0:
        interpretation_text = f"è§£è¯»: {series2_name} çš„å˜åŒ–è¶‹åŠ¿å¹³å‡é¢†å…ˆäº {series1_name} {best_lag} å¤©ã€‚"
    elif best_lag < 0:
        interpretation_text = f"è§£è¯»: {series1_name} çš„å˜åŒ–è¶‹åŠ¿å¹³å‡é¢†å…ˆäº {series2_name} {-best_lag} å¤©ã€‚"
    else:
        interpretation_text = f"è§£è¯»: {series1_name} å’Œ {series2_name} çš„å˜åŒ–è¶‹åŠ¿åŸºæœ¬åŒæ­¥ã€‚"
    # --- åœ¨æ§åˆ¶å°æ‰“å°ç»“æœ ---
    print("--- åˆ†æç»“æœ ---")
    print(f"æœ€å¤§ç›¸å…³ç³»æ•°ä¸º: {max_corr:.4f}")
    print(f"å¯¹åº”çš„æœ€ä½³æ»åæœŸä¸º: {best_lag} å¤©")
    print(interpretation_text)
    print("----------------\n")
    # --- ç”Ÿæˆå¹¶ä¿å­˜TXTæŠ¥å‘Š ---
    report_filename = 'äº’ç›¸å…³åˆ†æ.txt'
    report_content = f"""
äº’ç›¸å…³åˆ†ææŠ¥å‘Š
================================
åˆ†æå¯¹è±¡:
- åºåˆ—1: {series1_name}
- åºåˆ—2: {series2_name}
æ ¸å¿ƒå‘ç°:
--------------------------------
- æœ€å¤§ç›¸å…³ç³»æ•°: {max_corr:.4f}
- æœ€ä½³æ»åæœŸ: {best_lag} å¤©
ç»“è®º:
--------------------------------
{interpretation_text}
================================
æŠ¥å‘Šç”Ÿæˆäº: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    try:
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"åˆ†ææŠ¥å‘Šå·²æˆåŠŸä¿å­˜ä¸º: {report_filename}")
    except Exception as e:
        print(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
    # --- ç»˜åˆ¶äº’ç›¸å…³å›¾ ---
    plt.figure(figsize=(12, 6))
    # ä½¿ç”¨ä¿®æ”¹åçš„ä»£ç ï¼Œç§»é™¤ use_line_collection
    plt.stem(lags, corrs) 
    plt.axvline(best_lag, color='r', linestyle='--', label=f'æœ€ä½³æ»åæœŸ: {best_lag}å¤©')
    plt.title(f'{series1_name} ä¸ {series2_name} çš„äº’ç›¸å…³åˆ†æ')
    plt.xlabel('æ»åæœŸ (å¤©)')
    plt.ylabel('ç›¸å…³ç³»æ•°')
    plt.grid(True)
    plt.legend()
    plt.show()


# --- ä¸»ç¨‹åº ---
if __name__ == '__main__':

    # 1. åŠ è½½æ•°æ®
    df_raw = load_and_prepare_data('m_value_csi300.csv')
    
    # 2. è®¡ç®—æ”¶ç›Šç‡
    # æ³¨æ„ï¼šå¦‚æœä½ çš„'må€¼'æœ¬èº«å°±æ˜¯ä¸€ç§å˜åŒ–ç‡æˆ–æŒ‡æ ‡ï¼Œè€Œä¸æ˜¯ä»·æ ¼ï¼Œä½ å¯èƒ½ä¸éœ€è¦å¯¹å®ƒè®¡ç®—pct_change()
    # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ éœ€è¦è°ƒæ•´ calculate_returns å‡½æ•°
    df_returns = calculate_returns(df_raw)
    
    # 3. æ‰§è¡Œäº’ç›¸å…³åˆ†æ
    # æˆ‘ä»¬å°†åˆ†æ 'må€¼' ä¸ 'æ²ªæ·±300æ”¶ç›˜æŒ‡æ•°' çš„æ”¶ç›Šç‡ä¹‹é—´çš„å…³ç³»
    # è®¾ç½®ä¸€ä¸ªåˆç†çš„æœ€å¤§æ»åæœŸï¼Œæ¯”å¦‚30ä¸ªäº¤æ˜“æ—¥
    max_lag_days = 30
    
    # æ³¨æ„è¿™é‡Œçš„å‚æ•°é¡ºåºï¼š
    # series1æ˜¯må€¼ï¼Œseries2æ˜¯æ²ªæ·±300ã€‚
    # ç»“æœä¸­çš„æ­£æ»åæ„å‘³ç€æ²ªæ·±300é¢†å…ˆï¼Œè´Ÿæ»åæ„å‘³ç€må€¼é¢†å…ˆã€‚
    lags, corrs = cross_correlation_analysis(
        df_returns['må€¼'], 
        df_returns['æ²ªæ·±300æŒ‡æ•°_returns'], 
        max_lag_days
    )
    
    # 4. å¯è§†åŒ–å’Œè§£è¯»
    plot_and_interpret(lags, corrs, 'må€¼', 'æ²ªæ·±300æŒ‡æ•°')


####æ–‡ä»¶ç»“æŸ####

####æå–æ—¥å¿—.py####
import re
import html
import matplotlib.pyplot as plt
from collections import defaultdict
import os

# ==============================================================================
# é…ç½®åŒºåŸŸ
# ==============================================================================
LOG_FILE_PATH = 'å›æµ‹ç®€å•æ—¥å¿—.txt'
PLOT_OUTPUT_PATH = 'èµ„é‡‘å˜åŒ–å›¾.png'
HTML_REPORT_PATH = 'äº¤æ˜“å˜åŒ–.html'


# ==============================================================================
# 1. æ—¥å¿—è§£æ
# ==============================================================================
def parse_log_file(file_path):
    """
    è§£ææ—¥å¿—æ–‡ä»¶ï¼Œæå–ç»˜å›¾å’ŒæŠ¥å‘Šæ‰€éœ€çš„æ•°æ®ã€‚
    """
    # ç”¨äºå­˜å‚¨æ¯æ—¥èµ„äº§
    asset_dates = []
    asset_values = []
    
    # ç”¨äºå­˜å‚¨æ¯æ—¥çš„æ—¥å¿—å—
    daily_logs = []
    
    # ç”¨äºè®¡ç®—æ¯æ”¯è‚¡ç¥¨çš„ç›ˆäº
    # ç»“æ„: {'sz.002364': {'spent': 1000, 'received': 1100, 'dividends': 10, 'name': 'ä¸­æ’ç”µæ°”'}}
    stock_profits = defaultdict(lambda: {'spent': 0, 'received': 0, 'dividends': 0, 'name': ''})

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            current_day_block = None
            for line in f:
                line = line.strip()
                if not line:
                    continue

                # åŒ¹é…æ–°çš„ä¸€å¤©
                day_match = re.search(r"æ¨¡æ‹Ÿæ—¥: ([\d-]+)", line)
                if day_match:
                    if current_day_block:
                        daily_logs.append(current_day_block)
                    date_str = day_match.group(1)
                    current_day_block = {'date': date_str, 'logs': [line]}
                    continue
                
                if not current_day_block:
                    continue

                current_day_block['logs'].append(line)

                # åŒ¹é…æ€»èµ„äº§
                asset_match = re.search(r"æ€»èµ„äº§: ([\d.]+)", line)
                if asset_match:
                    asset_dates.append(current_day_block['date'])
                    asset_values.append(float(asset_match.group(1)))

                # åŒ¹é…ä¹°å…¥æ“ä½œ
                buy_match = re.search(r"ä¹°å…¥ (.+?)\((.+?)\).*?èŠ±è´¹: ([\d.]+)", line)
                if buy_match:
                    name, code, cost = buy_match.groups()
                    stock_profits[code]['spent'] += float(cost)
                    if not stock_profits[code]['name']: # é¦–æ¬¡è®°å½•è‚¡ç¥¨åç§°
                        stock_profits[code]['name'] = name

                # åŒ¹é…å–å‡ºæ“ä½œ
                sell_match = re.search(r"å–å‡º (.+?) .*?æ”¶å…¥: ([\d.]+)", line)
                if sell_match:
                    code, income = sell_match.groups()
                    stock_profits[code]['received'] += float(income)

                # åŒ¹é…åˆ†çº¢äº‹ä»¶
                dividend_match = re.search(r"æŒä»“ID \d+ \((.+?)\) è·å¾—åˆ†çº¢ ([\d.]+)", line)
                if dividend_match:
                    code, dividend = dividend_match.groups()
                    stock_profits[code]['dividends'] += float(dividend)


            if current_day_block: # æ·»åŠ æœ€åä¸€å¤©çš„æ•°æ®
                daily_logs.append(current_day_block)

    except FileNotFoundError:
        print(f"é”™è¯¯: æ—¥å¿—æ–‡ä»¶ '{file_path}' æœªæ‰¾åˆ°ã€‚")
        return None, None, None, None
    
    return asset_dates, asset_values, daily_logs, stock_profits

# ==============================================================================
# 2. ç”Ÿæˆèµ„é‡‘æ›²çº¿å›¾
# ==============================================================================
def generate_asset_plot(dates, assets, output_path):
    """
    ä½¿ç”¨matplotlibç”Ÿæˆèµ„é‡‘æ›²çº¿å›¾å¹¶ä¿å­˜ã€‚
    """
    if not dates or not assets:
        print("æ²¡æœ‰è¶³å¤Ÿçš„èµ„äº§æ•°æ®æ¥ç”Ÿæˆå›¾è¡¨ã€‚")
        return

    print("æ­£åœ¨ç”Ÿæˆèµ„é‡‘å˜åŒ–å›¾...")
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œä»¥é˜²ä¹±ç 
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False

    # åˆ›å»ºä¸€ä¸ªè¾ƒå¤§å°ºå¯¸çš„å›¾å½¢
    fig, ax = plt.subplots(figsize=(18, 9))

    ax.plot(dates, assets, marker='.', linestyle='-', color='b')

    # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
    ax.set_title('ç­–ç•¥å›æµ‹èµ„é‡‘æ›²çº¿', fontsize=20)
    ax.set_xlabel('æ¨¡æ‹Ÿæ—¥æœŸ', fontsize=14)
    ax.set_ylabel('æ€»èµ„äº§ (å…ƒ)', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.6)

    # è‡ªåŠ¨è°ƒæ•´xè½´æ ‡ç­¾ä»¥é¿å…é‡å 
    fig.autofmt_xdate(rotation=45)
    
    # æ ¼å¼åŒ–yè½´ä¸ºè´§å¸æ ¼å¼
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))

    # ç¡®ä¿å¸ƒå±€ç´§å‡‘ï¼Œæ‰€æœ‰å…ƒç´ éƒ½å¯è§
    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"èµ„é‡‘å˜åŒ–å›¾å·²æˆåŠŸä¿å­˜åˆ°: {output_path}")

# ==============================================================================
# 3. ç”ŸæˆHTMLæŠ¥å‘Š
# ==============================================================================
def generate_html_report(daily_logs, stock_profits, output_path):
    """
    ç”ŸæˆåŒ…å«é«˜äº®æ—¥å¿—å’Œç›ˆäºæ±‡æ€»çš„HTMLæŠ¥å‘Šã€‚
    """
    if not daily_logs or not stock_profits:
        print("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”ŸæˆHTMLæŠ¥å‘Šã€‚")
        return
        
    print("æ­£åœ¨ç”ŸæˆHTMLæŠ¥å‘Š...")

    # --- è®¡ç®—å¹¶æ’åºè‚¡ç¥¨ç›ˆäº ---
    profit_summary = []
    for code, data in stock_profits.items():
        total_profit = data['received'] + data['dividends'] - data['spent']
        profit_summary.append({
            'code': code,
            'name': data['name'] or 'æœªçŸ¥åç§°',
            'profit': total_profit
        })
    
    # ä»å¤§åˆ°å°æ’åº
    sorted_profits = sorted(profit_summary, key=lambda x: x['profit'], reverse=True)

    # --- æ„å»ºHTMLå†…å®¹ ---
    html_content = """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <title>å›æµ‹äº¤æ˜“æ—¥å¿—æŠ¥å‘Š</title>
        <style>
            body { font-family: 'Segoe UI', 'Microsoft YaHei', sans-serif; line-height: 1.6; margin: 20px; background-color: #f4f4f4; color: #333; }
            h1, h2 { color: #0056b3; border-bottom: 2px solid #0056b3; padding-bottom: 10px; }
            .container { max-width: 1200px; margin: auto; background: #fff; padding: 20px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
            .summary-table { width: 100%; border-collapse: collapse; margin-bottom: 30px; }
            .summary-table th, .summary-table td { border: 1px solid #ddd; padding: 12px; text-align: left; }
            .summary-table th { background-color: #007bff; color: white; }
            .summary-table tr:nth-child(even) { background-color: #f2f2f2; }
            .profit { color: #d9534f; } /* çº¢è‰² */
            .loss { color: #5cb85c; } /* ç»¿è‰² */
            .day-block { border: 1px solid #ccc; border-radius: 5px; margin-bottom: 20px; padding: 15px; background-color: #fafafa; }
            .day-block h3 { margin-top: 0; color: #555; }
            .log-entry { font-family: 'Courier New', Courier, monospace; white-space: pre-wrap; word-wrap: break-word; }
            .log-profit-sell { color: #d9534f; font-weight: bold; } /* æ­¢ç›ˆå–å‡º - çº¢è‰² */
            .log-stop-loss { color: #5cb85c; font-weight: bold; } /* æ­¢æŸå–å‡º - ç»¿è‰² */
        </style>
    </head>
    <body>
        <div class="container">
            <h1>å›æµ‹äº¤æ˜“æ—¥å¿—æŠ¥å‘Š</h1>
            
            <h2>å„è‚¡ç›ˆäºæ±‡æ€» (ä»é«˜åˆ°ä½)</h2>
            <table class="summary-table">
                <thead>
                    <tr>
                        <th>æ’å</th>
                        <th>è‚¡ç¥¨åç§°</th>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>æ€»ç›ˆäº (å…ƒ)</th>
                    </tr>
                </thead>
                <tbody>
    """

    # å¡«å……ç›ˆäºæ±‡æ€»è¡¨æ ¼
    for i, item in enumerate(sorted_profits):
        profit_class = 'profit' if item['profit'] >= 0 else 'loss'
        html_content += f"""
                    <tr>
                        <td>{i + 1}</td>
                        <td>{html.escape(item['name'])}</td>
                        <td>{html.escape(item['code'])}</td>
                        <td class="{profit_class}">{item['profit']:.2f}</td>
                    </tr>
        """
    
    html_content += """
                </tbody>
            </table>

            <h2>è¯¦ç»†æ—¥å¿—è®°å½•</h2>
    """

    # å¡«å……è¯¦ç»†æ—¥å¿—
    for day in daily_logs:
        html_content += f"""
            <div class="day-block">
                <h3>{html.escape(day['date'])}</h3>
                <div class="log-entry">
        """
        for log_line in day['logs']:
            escaped_line = html.escape(log_line)
            if 'è§¦å‘æ­¢ç›ˆ' in log_line or 'æ­¢ç›ˆå–å‡º' in log_line:
                html_content += f'<span class="log-profit-sell">{escaped_line}</span>\n'
            elif 'è§¦å‘æ­¢æŸ' in log_line or 'æ­¢æŸå–å‡º' in log_line:
                html_content += f'<span class="log-stop-loss">{escaped_line}</span>\n'
            else:
                html_content += f'{escaped_line}\n'
        html_content += """
                </div>
            </div>
        """

    html_content += """
        </div>
    </body>
    </html>
    """

    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    print(f"HTMLæŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°: {output_path}")

# ==============================================================================
# ä¸»æ‰§è¡Œå‡½æ•°
# ==============================================================================
def main():
    """ä¸»å‡½æ•°ï¼Œåè°ƒæ‰€æœ‰æ“ä½œã€‚"""
    print("å¼€å§‹å¤„ç†å›æµ‹æ—¥å¿—...")
    symbol=['==================== æ¨¡æ‹Ÿæ—¥','è§¦å‘','[å›æµ‹] å–å‡º',' [å›æµ‹] ä¹°å…¥','æ€»èµ„äº§: ','è·å¾—åˆ†çº¢','é£æ§ä»·æ ¼','M(t)','ç¡®å®šå”¯ä¸€ä¹°å…¥æ ‡çš„']
    log_prefix_pattern = re.compile(r"^[A-Z]+\s+[\d\-\s:,]+\s+\w+\s+\d+\s+\d+\s+(.*)")
 
    clean_log_content = []
    
    # ä½¿ç”¨ 'with' è¯­å¥èƒ½æ›´å¥½åœ°å¤„ç†æ–‡ä»¶ï¼Œå¹¶ä¸”æ›´å®‰å…¨
    # æ³¨æ„ï¼šå¦‚æœä½ çš„åŸå§‹æ—¥å¿—æ–‡ä»¶ä¸æ˜¯gbkç¼–ç ï¼Œè¯·ä¿®æ”¹è¿™é‡Œçš„ encoding
    try:
        with open('logs/django.log', "r", encoding="gbk") as f:
            for line in f:
                # æ£€æŸ¥è¯¥è¡Œæ˜¯å¦åŒ…å«æˆ‘ä»¬å…³å¿ƒçš„å…³é”®å­—
                should_keep = False
                for keyword in symbol:
                    if keyword in line:
                        should_keep = True
                        break
                
                if should_keep:
                    # å»æ‰è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
                    stripped_line = line.strip()
                    
                    # å°è¯•ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¹¶å»é™¤å‰ç¼€
                    match = log_prefix_pattern.match(stripped_line)
                    if match:
                        # å¦‚æœåŒ¹é…æˆåŠŸï¼Œåªå–æ‹¬å·é‡Œæ•è·çš„å†…å®¹ (æ ¸å¿ƒæ—¥å¿—)
                        clean_line = match.group(1)
                    else:
                        # å¦‚æœä¸åŒ¹é… (æ¯”å¦‚ "==== æ¨¡æ‹Ÿæ—¥..." è¿™ç§è¡Œ)ï¼Œå°±ä¿ç•™åŸæ ·
                        clean_line = stripped_line
                    
                    clean_log_content.append(clean_line)
    except FileNotFoundError:
        print("é”™è¯¯: åŸå§‹æ—¥å¿—æ–‡ä»¶ 'logs/django.log' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"è¯»å–åŸå§‹æ—¥å¿—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return
 
    # å°†å¤„ç†è¿‡çš„ã€å¹²å‡€çš„æ—¥å¿—å†…å®¹å†™å…¥åˆ°ç®€å•æ—¥å¿—æ–‡ä»¶ä¸­
    with open(LOG_FILE_PATH, 'w', encoding='utf-8') as f:
        f.write('\n'.join(clean_log_content))

    # 1. è§£ææ—¥å¿—
    asset_dates, asset_values, daily_logs, stock_profits = parse_log_file(LOG_FILE_PATH)

    if asset_dates is None: # å¦‚æœè§£æå¤±è´¥
        print("æ—¥å¿—å¤„ç†ç»ˆæ­¢ã€‚")
        return

    # 2. ç”Ÿæˆå›¾è¡¨
    generate_asset_plot(asset_dates, asset_values, PLOT_OUTPUT_PATH)

    # 3. ç”ŸæˆHTMLæŠ¥å‘Š
    generate_html_report(daily_logs, stock_profits, HTML_REPORT_PATH)
    
    print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print(f" - å›¾è¡¨æ–‡ä»¶: {os.path.abspath(PLOT_OUTPUT_PATH)}")
    print(f" - æŠ¥å‘Šæ–‡ä»¶: {os.path.abspath(HTML_REPORT_PATH)}")


if __name__ == '__main__':
    main()
main()
####æ–‡ä»¶ç»“æŸ####

####æµ‹è¯•akshare.py####
import akshare as ak
index_zh_a_hist_df = ak.index_zh_a_hist(symbol="000300", period="daily", start_date="20180101", end_date="20250815")
print(index_zh_a_hist_df)
####æ–‡ä»¶ç»“æŸ####

####æµ‹è¯•easytrader.py####
import easytrader
import json
f=open('config.json','r',encoding='utf-8')
t=""
for line in f:
    line = line.strip()
    t=t+line
    if not line:
        continue
f.close()
config=json.loads(t)
print(config)
user = easytrader.use('ht_client')
user.connect(config['easytrader']['client_path'])
user.prepare(config['easytrader']['user'])
user.refresh()
print(user.balance)
user.exit()
####æ–‡ä»¶ç»“æŸ####

####éå†æ–‡ä»¶.py####
import os

# --- é…ç½® ---
# è¦æ‰«æçš„æ ¹ç›®å½•ï¼Œ'.' è¡¨ç¤ºå½“å‰ç›®å½•
ROOT_DIR = '.'
# è¾“å‡ºæ–‡ä»¶å
OUTPUT_FILE = 'result.txt'
# è¦å¿½ç•¥çš„ç›®å½•ï¼ˆä½¿ç”¨é›†åˆä»¥æé«˜æŸ¥æ‰¾æ•ˆç‡ï¼‰
IGNORE_DIRS = {'.git', '__pycache__', 'venv', '.vscode', 'node_modules','migrations'}
# è¦å¿½ç•¥çš„æ–‡ä»¶
IGNORE_FILES = {'.DS_Store', OUTPUT_FILE,'éå†æ–‡ä»¶.py'} # ç¡®ä¿ä¸æŠŠè¾“å‡ºæ–‡ä»¶æœ¬èº«åŒ…å«è¿›å»

def generate_file_tree(root_dir, ignore_dirs, ignore_files):
    """ç”Ÿæˆé¡¹ç›®æ–‡ä»¶æ ‘ç»“æ„"""
    tree_lines = []
    for root, dirs, files in os.walk(root_dir, topdown=True):
        # åœ¨éå†å‰ï¼Œä»dirsåˆ—è¡¨ä¸­ç§»é™¤è¦å¿½ç•¥çš„ç›®å½•
        dirs[:] = [d for d in dirs if d not in ignore_dirs]
        
        # è®¡ç®—å½“å‰æ·±åº¦ï¼Œç”¨äºç”Ÿæˆå‰ç¼€
        level = root.replace(root_dir, '').count(os.sep)
        indent = ' ' * 4 * level
        
        # æ·»åŠ ç›®å½•ååˆ°æ ‘
        # os.path.basename(root) ç”¨äºè·å–å½“å‰ç›®å½•å
        tree_lines.append(f"{indent}ğŸ“‚ {os.path.basename(root)}/")

        # æ·»åŠ æ–‡ä»¶åˆ°æ ‘
        sub_indent = ' ' * 4 * (level + 1)
        for f in sorted(files): # å¯¹æ–‡ä»¶è¿›è¡Œæ’åº
            if f not in ignore_files:
                tree_lines.append(f"{sub_indent}ğŸ“„ {f}")
                
    return "\n".join(tree_lines)

def get_python_file_contents(root_dir, ignore_dirs):
    """è·å–æ‰€æœ‰.pyæ–‡ä»¶çš„å†…å®¹å¹¶æ ¼å¼åŒ–"""
    py_contents = []
    for root, dirs, files in os.walk(root_dir, topdown=True):
        # åŒæ ·ï¼Œå¿½ç•¥æŒ‡å®šç›®å½•
        dirs[:] = [d for d in dirs if d not in ignore_dirs]
        
        for file in sorted(files):
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè®©è¾“å‡ºæ›´æ¸…æ™°
                relative_path = os.path.relpath(file_path, root_dir)
                
                header = f"####{relative_path}####"
                footer = "####æ–‡ä»¶ç»“æŸ####"
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    py_contents.append(f"{header}\n{content}\n{footer}\n")
                except Exception as e:
                    py_contents.append(f"{header}\næ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {e}\n{footer}\n")
                    
    return "\n".join(py_contents)

def main():
    """ä¸»å‡½æ•°ï¼Œæ‰§è¡Œæ‰€æœ‰æ“ä½œ"""
    print("å¼€å§‹ç”Ÿæˆé¡¹ç›®æ–‡ä»¶æ ‘...")
    file_tree = generate_file_tree(ROOT_DIR, IGNORE_DIRS, IGNORE_FILES)
    
    print("å¼€å§‹è¯»å–æ‰€æœ‰.pyæ–‡ä»¶å†…å®¹...")
    python_contents = get_python_file_contents(ROOT_DIR, IGNORE_DIRS)
    
    print(f"æ­£åœ¨å°†ç»“æœå†™å…¥ {OUTPUT_FILE}...")
    
    # å°†æ‰€æœ‰å†…å®¹åˆå¹¶å†™å…¥æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write("======= é¡¹ç›®æ–‡ä»¶æ ‘ =======\n\n")
        f.write(file_tree)
        f.write("\n\n========================\n\n")
        f.write("======= Pythonæ–‡ä»¶å†…å®¹ =======\n\n")
        f.write(python_contents)
        
    print(f"âœ… æˆåŠŸï¼é¡¹ç›®ç»“æ„å’Œä»£ç å·²ä¿å­˜åˆ° {OUTPUT_FILE}")

if __name__ == '__main__':
    main()

####æ–‡ä»¶ç»“æŸ####

####autoTrade\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####autoTrade\asgi.py####
"""
ASGI config for autoTrade project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'autoTrade.settings')

application = get_asgi_application()

####æ–‡ä»¶ç»“æŸ####

####autoTrade\settings.py####
"""
Django settings for autoTrade project.

Generated by 'django-admin startproject' using Django 5.2.4.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""

from pathlib import Path
import os
import dotenv
# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent
dotenv.load_dotenv(os.path.join(BASE_DIR, '.env'))


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!

# SECURITY WARNING: don't run with debug turned on in production!

SECRET_KEY = os.getenv('SECRET_KEY', 'default-secret-key-for-dev')
ENVIRONMENT = os.getenv('ENVIRONMENT', 'development')
DEBUG = (ENVIRONMENT == 'development')
if ENVIRONMENT == 'production':
    # è¯·å°† 'your_domain.com' å’ŒæœåŠ¡å™¨çš„å…¬ç½‘/å†…ç½‘IPå¡«å…¥
    ALLOWED_HOSTS = ['your_domain.com', '1.15.100.196', '10.0.4.15','10.0.12.10','127.0.0.1','0.0.0.0']
else:
    ALLOWED_HOSTS = ['*']


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'data_manager',
    'selection_manager',
    'trade_manager',
    'common'
]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    #'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'autoTrade.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'autoTrade.wsgi.application'


# Database
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME', 'maindb'),
        'USER': os.getenv('DB_USER', 'xyx'),
        'PASSWORD': os.getenv('DB_PASSWORD', 'xyx123'),
        'HOST': os.getenv('DB_HOST', 'localhost'), # é»˜è®¤ä½¿ç”¨ localhost
        'PORT': os.getenv('DB_PORT', '5432'),
        'OPTIONS': {
            'keepalives': 1,
            'keepalives_idle': 60,
            'keepalives_interval': 10,
            'keepalives_count': 6,
        }
    },
    'local_sqlite': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': 'D:/project/mainDB.sqlite3', # æ³¨æ„ï¼šåœ¨Pythonå­—ç¬¦ä¸²ä¸­ï¼Œè·¯å¾„æœ€å¥½ä½¿ç”¨æ­£æ–œæ '/'
    }
}


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'Asia/Shanghai'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'


LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,  # ä¸è¦ç¦ç”¨å·²å­˜åœ¨çš„æ—¥å¿—å™¨ï¼Œå¦åˆ™ Django è‡ªå¸¦çš„æ—¥å¿—ä¼šå¤±æ•ˆ
    
    # 1. å®šä¹‰æ—¥å¿—æ ¼å¼
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
        'simple': {
            'format': '{levelname} {message}',
            'style': '{',
        },
    },
    
    # 2. å®šä¹‰å¤„ç†å™¨ (æ—¥å¿—å»å“ªé‡Œ)
    'handlers': {
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        'console': {
            'level': 'DEBUG',  # å¤„ç† DEBUG åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
            'class': 'logging.StreamHandler',
            'formatter': 'verbose', # ä½¿ç”¨ verbose æ ¼å¼
        },
        # è¾“å‡ºåˆ°æ–‡ä»¶
        'file': {
            'level': 'DEBUG',  # å¤„ç† INFO åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
            'class': 'concurrent_log_handler.ConcurrentRotatingFileHandler',
            'filename': os.path.join(BASE_DIR, 'logs/django.log'), # æ—¥å¿—æ–‡ä»¶è·¯å¾„
            'maxBytes': 1024 * 1024 * 10,  # 5 MB
            'backupCount': 5, # æœ€å¤šä¿ç•™ 5 ä¸ªå¤‡ä»½æ–‡ä»¶
            'formatter': 'verbose', # ä½¿ç”¨ verbose æ ¼å¼
        },
    },
    
    # 3. å®šä¹‰è®°å½•å™¨ (å“ªäº›æ—¥å¿—éœ€è¦å¤„ç†)
    'loggers': {
        # Django æ¡†æ¶è‡ªèº«çš„æ—¥å¿—
        'django': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': True,
        },
        # ä½ è‡ªå·±åº”ç”¨çš„æ—¥å¿—
        'data_manager': { # è¿™é‡Œä½¿ç”¨ä½ çš„ app åç§°
            'handlers': ['console','file'],
            'level': 'DEBUG', # åœ¨å¼€å‘æ—¶è®¾ä¸º DEBUGï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯
            'propagate': False, # ä¸å‘ä¸Šä¼ é€’ç»™ root logger
        },
        'selection_manager': { # è¿™é‡Œä½¿ç”¨ä½ çš„ app åç§°
            'handlers': ['console','file'],
            'level': 'DEBUG', # åœ¨å¼€å‘æ—¶è®¾ä¸º DEBUGï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯
            'propagate': False, # ä¸å‘ä¸Šä¼ é€’ç»™ root logger
        },
        'trade_manager': { # è¿™é‡Œä½¿ç”¨ä½ çš„ app åç§°
            'handlers': ['console','file'],
            'level': 'DEBUG', # åœ¨å¼€å‘æ—¶è®¾ä¸º DEBUGï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯
            'propagate': False, # ä¸å‘ä¸Šä¼ é€’ç»™ root logger
        },
        # ä½ å¯ä»¥ä¸ºä»»ä½•æ¨¡å—å®šä¹‰ logger
        'common': {
            'handlers': ['console', 'file'],
            'level': 'DEBUG',
            'propagate': False,
        },
        # --- æ–°å¢æ—¥å¿—æ¸…ç†é…ç½® ---
        'sqlalchemy.engine': {
            'handlers': ['console', 'file'],
            'level': 'WARNING',  # <-- åªæ˜¾ç¤º WARNING åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—ï¼Œè¿‡æ»¤æ‰SQLè¯­å¥
            'propagate': False,
        },
        'psycopg2': {
            'handlers': ['console', 'file'],
            'level': 'WARNING',  # <-- è¿‡æ»¤æ‰ psycopg2 çš„ä½çº§åˆ«æ—¥å¿—
            'propagate': False,
        },
        'apscheduler': {
            'handlers': ['console', 'file'],
            'level': 'WARNING', # <-- è¿‡æ»¤æ‰ apscheduler çš„ INFO æ—¥å¿—
            'propagate': False,
        }

    }
}
 
# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
LOGS_DIR = os.path.join(BASE_DIR, 'logs')
if not os.path.exists(LOGS_DIR):
    os.makedirs(LOGS_DIR)
####æ–‡ä»¶ç»“æŸ####

####autoTrade\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('dataManager/', include('data_manager.urls')),
    path('selectionManager/', include('selection_manager.urls')),
    path('tradeManager/', include('trade_manager.urls'))
]

####æ–‡ä»¶ç»“æŸ####

####autoTrade\wsgi.py####
"""
WSGI config for autoTrade project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'autoTrade.settings')

application = get_wsgi_application()

####æ–‡ä»¶ç»“æŸ####

####common\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####common\admin.py####
# common/admin.py

from django.contrib import admin
from .models import (
    StockInfo, DailyQuotes, FactorDefinitions, DailyFactorValues,
    StrategyParameters, DailyTradingPlan, Position, TradeLog,
    SystemLog, CorporateAction
)

# -----------------------------------------------------------------------------
# 1. åŸºç¡€æ•°æ®ç®¡ç† (è‚¡ç¥¨ä¿¡æ¯ã€è¡Œæƒ…ã€è‚¡æƒäº‹ä»¶)
# -----------------------------------------------------------------------------

@admin.register(StockInfo)
class StockInfoAdmin(admin.ModelAdmin):
    """è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ç®¡ç†"""
    list_display = ('stock_code', 'stock_name', 'listing_date', 'status', 'updated_at')
    search_fields = ('stock_code', 'stock_name')
    list_filter = ('status', 'listing_date')
    ordering = ('stock_code',)
    readonly_fields = ('created_at', 'updated_at')

@admin.register(DailyQuotes)
class DailyQuotesAdmin(admin.ModelAdmin):
    """æ—¥çº¿è¡Œæƒ…ç®¡ç†"""
    list_display = ('trade_date', 'stock_code', 'open', 'close', 'volume', 'turnover', 'hfq_close')
    search_fields = ('stock_code__stock_code', 'stock_code__stock_name')
    list_filter = ('trade_date',)
    ordering = ('-trade_date', 'stock_code')
    # å…³é”®æ€§èƒ½ä¼˜åŒ–ï¼šå¯¹äºæœ‰æˆåƒä¸Šä¸‡æ¡è®°å½•çš„å¤–é”®ï¼Œä½¿ç”¨ raw_id_fields æ›¿ä»£ä¸‹æ‹‰æ¡†
    raw_id_fields = ('stock_code',)
    readonly_fields = ('hfq_close',)
    list_per_page = 25 # è®¾ç½®æ¯é¡µæ˜¾ç¤ºæ¡æ•°

class CorporateActionAdmin(admin.ModelAdmin):
    """è‚¡æƒäº‹ä»¶ç®¡ç†"""
    list_display = ('ex_dividend_date', 'stock_code', 'event_type', 'dividend_per_share', 'shares_before', 'shares_after', 'rights_issue_price')
    # ä¿®æ­£ï¼šç›´æ¥æœç´¢æœ¬è¡¨çš„ stock_code å­—æ®µå³å¯
    search_fields = ('stock_code',) 
    list_filter = ('event_type', 'ex_dividend_date')
    ordering = ('-ex_dividend_date', 'stock_code')
    # raw_id_fields = ('stock_code',)

# -----------------------------------------------------------------------------
# 2. ç­–ç•¥ä¸å› å­å®šä¹‰ç®¡ç†
# -----------------------------------------------------------------------------

@admin.register(FactorDefinitions)
class FactorDefinitionsAdmin(admin.ModelAdmin):
    """å› å­å®šä¹‰ç®¡ç†"""
    list_display = ('factor_code', 'factor_name', 'direction', 'is_active', 'description')
    search_fields = ('factor_code', 'factor_name')
    list_filter = ('direction', 'is_active')
    ordering = ('factor_code',)

@admin.register(StrategyParameters)
class StrategyParametersAdmin(admin.ModelAdmin):
    """ç­–ç•¥å‚æ•°ç®¡ç†"""
    list_display = ('param_name', 'param_value', 'group_name', 'description')
    search_fields = ('param_name', 'group_name')
    list_filter = ('group_name',)
    ordering = ('group_name', 'param_name')
    # æ ¸å¿ƒåŠŸèƒ½ï¼šå…è®¸åœ¨åˆ—è¡¨é¡µç›´æ¥ç¼–è¾‘å‚æ•°å€¼ï¼Œéå¸¸æ–¹ä¾¿è°ƒå‚
    list_editable = ('param_value',)

@admin.register(DailyFactorValues)
class DailyFactorValuesAdmin(admin.ModelAdmin):
    """æ¯æ—¥å› å­å€¼ç®¡ç†"""
    list_display = ('trade_date', 'stock_code', 'factor_code', 'raw_value', 'norm_score')
    search_fields = ('stock_code__stock_code', 'factor_code__factor_code')
    list_filter = ('trade_date', 'factor_code')
    ordering = ('-trade_date', 'stock_code')
    # å…³é”®æ€§èƒ½ä¼˜åŒ–
    raw_id_fields = ('stock_code', 'factor_code')
    list_per_page = 25

# -----------------------------------------------------------------------------
# 3. äº¤æ˜“æµç¨‹ç®¡ç† (é¢„æ¡ˆã€æŒä»“ã€è®°å½•)
# -----------------------------------------------------------------------------

@admin.register(DailyTradingPlan)
class DailyTradingPlanAdmin(admin.ModelAdmin):
    """æ¯æ—¥äº¤æ˜“é¢„æ¡ˆç®¡ç†"""
    list_display = ('plan_date', 'stock_code', 'rank', 'final_score', 'miop', 'maop', 'status')
    search_fields = ('stock_code__stock_code',)
    list_filter = ('plan_date', 'status')
    ordering = ('-plan_date', 'rank')
    raw_id_fields = ('stock_code',)
    list_per_page = 20

@admin.register(Position)
class PositionAdmin(admin.ModelAdmin):
    """æŒä»“ä¿¡æ¯ç®¡ç†"""
    list_display = ('position_id', 'stock_code', 'entry_datetime', 'entry_price', 'quantity', 'current_stop_loss', 'current_take_profit', 'status')
    search_fields = ('stock_code__stock_code',)
    list_filter = ('status', 'entry_datetime')
    ordering = ('-entry_datetime',)
    raw_id_fields = ('stock_code',)

@admin.register(TradeLog)
class TradeLogAdmin(admin.ModelAdmin):
    """äº¤æ˜“è®°å½•ç®¡ç†"""
    list_display = ('trade_id', 'position', 'stock_code', 'trade_datetime', 'trade_type', 'price', 'quantity', 'reason', 'status')
    search_fields = ('stock_code__stock_code', 'position__position_id')
    list_filter = ('trade_type', 'status', 'reason', 'trade_datetime')
    ordering = ('-trade_datetime',)
    raw_id_fields = ('position', 'stock_code')
    list_per_page = 25

# -----------------------------------------------------------------------------
# 4. ç³»ç»Ÿä¸æ—¥å¿—ç®¡ç†
# -----------------------------------------------------------------------------

@admin.register(SystemLog)
class SystemLogAdmin(admin.ModelAdmin):
    """ç³»ç»Ÿæ—¥å¿—ç®¡ç†"""
    list_display = ('log_time', 'log_level', 'module_name', 'message_summary')
    list_filter = ('log_level', 'module_name', 'log_time')
    search_fields = ('message', 'module_name')
    ordering = ('-log_time',)
    # æ—¥å¿—åº”è¯¥æ˜¯ä¸å¯å˜çš„ï¼Œæ‰€ä»¥è®¾ä¸ºåªè¯»
    readonly_fields = ('log_time', 'log_level', 'module_name', 'message')
    list_per_page = 30

    def message_summary(self, obj):
        """åœ¨åˆ—è¡¨é¡µæ˜¾ç¤ºæˆªæ–­çš„æ—¥å¿—ä¿¡æ¯"""
        return (obj.message[:80] + '...') if len(obj.message) > 80 else obj.message
    message_summary.short_description = 'æ—¥å¿—æ‘˜è¦'

    def has_add_permission(self, request):
        # ç¦æ­¢åœ¨Adminåå°æ‰‹åŠ¨æ·»åŠ æ—¥å¿—
        return False

    def has_change_permission(self, request, obj=None):
        # ç¦æ­¢åœ¨Adminåå°ä¿®æ”¹æ—¥å¿—
        return False

####æ–‡ä»¶ç»“æŸ####

####common\apps.py####
from django.apps import AppConfig


class CommonConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'common'

####æ–‡ä»¶ç»“æŸ####

####common\config_loader.py####
# common/config_loader.py

import json
import os
import logging
from django.conf import settings

logger = logging.getLogger(__name__)

class ConfigLoader:
    _instance = None
    _config = None

    def __new__(cls):
        if not cls._instance:
            cls._instance = super(ConfigLoader, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if self._config is None:
            self._load_config()

    def _load_config(self):
        config_path = os.path.join(settings.BASE_DIR, 'config.json')
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self._config = json.load(f)
            logger.info("ConfigLoader: config.json åŠ è½½æˆåŠŸã€‚")
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.critical(f"ConfigLoader: æ— æ³•åŠ è½½æˆ–è§£æ config.json: {e}ã€‚ç³»ç»Ÿå°†æ— æ³•æ­£å¸¸è¿è¡Œã€‚")
            self._config = {} # è¿”å›ä¸€ä¸ªç©ºå­—å…¸ä»¥é¿å…åç»­è°ƒç”¨å‡ºé”™

    def get_config(self):
        """è·å–å®Œæ•´çš„é…ç½®å­—å…¸"""
        return self._config

    def get(self, key, default=None):
        """è·å–æŒ‡å®šé”®çš„é…ç½®å€¼"""
        return self._config.get(key, default)

# åˆ›å»ºä¸€ä¸ªå…¨å±€å®ä¾‹ï¼Œä¾›é¡¹ç›®å„å¤„è°ƒç”¨
config_loader = ConfigLoader()

####æ–‡ä»¶ç»“æŸ####

####common\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####common\views.py####
from django.shortcuts import render

# Create your views here.

####æ–‡ä»¶ç»“æŸ####

####common\models\__init__.py####
# my_strategy_app/__init__.py

from .stock_info import StockInfo
from .daily_quotes import DailyQuotes
from .factor_definitions import FactorDefinitions
from .daily_factor_values import DailyFactorValues
from .strategy_parameters import StrategyParameters
from .daily_trading_plan import DailyTradingPlan
from .positions import Position
from .trade_log import TradeLog
from .system_log import SystemLog
from .corporate_action import CorporateAction
from .backtest_logs import BacktestDailyLog,BacktestOperationLog
from .index_quotes_csi300 import IndexQuotesCsi300

__all__ = [
    'StockInfo',
    'DailyQuotes',
    'FactorDefinitions',
    'DailyFactorValues',
    'StrategyParameters',
    'DailyTradingPlan',
    'Position',
    'TradeLog',
    'SystemLog',
    'CorporateAction',
    'BacktestDailyLog',
    'BacktestOperationLog',
    "MDistributionBacktestLog",
    'IndexQuotesCsi300'
]

####æ–‡ä»¶ç»“æŸ####

####common\models\backtest_logs.py####
# ==============================================================================
# æè¿°: å®šä¹‰å›æµ‹æ—¥å¿—ç›¸å…³çš„æ–°æ¨¡å‹ã€‚
# ==============================================================================
from django.db import models

class BacktestDailyLog(models.Model):
    """
    å›æµ‹æ¯æ—¥æ—¥å¿—è¡¨
    
    è¯´æ˜: è®°å½•æ¯ä¸€æ¬¡å›æµ‹è¿è¡Œä¸­ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥ç»“æŸåçš„èµ„é‡‘ã€æŒä»“å’Œå¸‚åœºçŠ¶æ€ã€‚
    è¿™å¼ è¡¨ç”¨äºç”Ÿæˆèµ„é‡‘æ›²çº¿å›¾å’Œå…³é”®çš„å›æ’¤æŒ‡æ ‡ã€‚
    """
    backtest_run_id = models.CharField(
        max_length=50,
        db_index=True,
        help_text="å›æµ‹è¿è¡Œçš„å”¯ä¸€æ ‡è¯†ç¬¦, å¦‚ 'backtest_20231027_153000'"
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    total_assets = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="å½“æ—¥æ—¥ç»ˆæ€»èµ„äº§ (ç°é‡‘ + æŒä»“å¸‚å€¼)"
    )
    cash = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="å½“æ—¥æ—¥ç»ˆç°é‡‘ä½™é¢"
    )
    holdings_value = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="å½“æ—¥æ—¥ç»ˆæŒä»“å¸‚å€¼"
    )
    market_m_value = models.DecimalField(
        max_digits=18,
        decimal_places=10,
        null=True,
        blank=True,
        help_text="å½“æ—¥çš„å¸‚åœºçŠ¶æ€M(t)å€¼"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )

    class Meta:
        db_table = 'tb_trade_manager_backtest_daily_log'
        verbose_name = 'å›æµ‹æ¯æ—¥æ—¥å¿—'
        verbose_name_plural = verbose_name
        ordering = ['backtest_run_id', 'trade_date']
        # ä¸ºå¸¸ç”¨æŸ¥è¯¢æ·»åŠ ç´¢å¼•
        indexes = [
            models.Index(fields=['backtest_run_id', 'trade_date']),
        ]

class BacktestOperationLog(models.Model):
    """
    å›æµ‹æ“ä½œè®°å½•è¡¨
    
    è¯´æ˜: å¢é‡è®°å½•å›æµ‹è¿‡ç¨‹ä¸­çš„æ¯ä¸€æ¬¡ä¹°å…¥å’Œå–å‡ºæ“ä½œã€‚
    è¿™å¼ è¡¨ç”¨äºè®¡ç®—èƒœç‡ã€æ”¶ç›Šè´¡çŒ®ç­‰äº¤æ˜“å±‚é¢çš„æŒ‡æ ‡ã€‚
    """
    class Direction(models.TextChoices):
        BUY = 'BUY', 'ä¹°å…¥'
        SELL = 'SELL', 'å–å‡º'

    class ExitReason(models.TextChoices):
        TAKE_PROFIT = 'TAKE_PROFIT', 'æ­¢ç›ˆ'
        STOP_LOSS = 'STOP_LOSS', 'æ­¢æŸ'

    backtest_run_id = models.CharField(
        max_length=50,
        db_index=True,
        help_text="å›æµ‹è¿è¡Œçš„å”¯ä¸€æ ‡è¯†ç¬¦"
    )
    position_id_ref = models.BigIntegerField(
        db_index=True,
        help_text="å…³è”çš„æŒä»“ID (tb_positions.position_id)ï¼Œç”¨äºåæŸ¥"
    )
    stock_code = models.CharField(
        max_length=50,
        help_text="è‚¡ç¥¨ä»£ç , å¦‚ 'sh.600000'"
    )
    stock_name = models.CharField(
        max_length=50,
        help_text="è‚¡ç¥¨åç§°"
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“å‘ç”Ÿçš„æ—¥æœŸ"
    )
    direction = models.CharField(
        max_length=10,
        choices=Direction.choices,
        help_text="ä¹°å–æ–¹å‘"
    )
    exit_reason = models.CharField(
        max_length=20,
        choices=ExitReason.choices,
        null=True,
        blank=True,
        help_text="æ­¢ç›ˆ/æ­¢æŸæ–¹å‘ (ä»…å–å‡ºæ—¶æœ‰æ•ˆ)"
    )
    profit_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="è¯¥ç¬”äº¤æ˜“è®¾ç½®çš„æ­¢ç›ˆç‡"
    )
    loss_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="è¯¥ç¬”äº¤æ˜“è®¾ç½®çš„æ­¢æŸç‡"
    )
    buy_date_m_value = models.DecimalField(
        max_digits=18,
        decimal_places=10,
        null=True,
        blank=True,
        help_text="ä¹°å…¥å†³ç­–æ‰€ä¾æ®çš„T-1æ—¥å¸‚åœºM(t)å€¼"
    )
    factor_scores = models.TextField(
        help_text="ä¹°å…¥æ—¶å„å› å­å¾—åˆ†, æ ¼å¼: factor1:score1|factor2:score2"
    )
    price = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        help_text="æˆäº¤ä»·æ ¼"
    )
    quantity = models.BigIntegerField(
        help_text="æˆäº¤æ•°é‡"
    )
    amount = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="æˆäº¤æ€»é‡‘é¢"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )

    class Meta:
        db_table = 'tb_trade_manager_backtest_operation_log'
        verbose_name = 'å›æµ‹æ“ä½œè®°å½•'
        verbose_name_plural = verbose_name
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['backtest_run_id', 'stock_code']),
            models.Index(fields=['backtest_run_id', 'position_id_ref']),
        ]

class MDistributionBacktestLog(models.Model):
    """
    Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹çš„ä¸“ç”¨æ—¥å¿—è¡¨ã€‚
    
    è¯´æ˜: æ¯ä¸€æ¡è®°å½•ä»£è¡¨ä¸€æ¬¡å®Œæ•´çš„æ¨¡æ‹Ÿäº¤æ˜“ï¼ˆä»é¢„æ¡ˆç”Ÿæˆåˆ°æœ€ç»ˆå¹³ä»“ï¼‰ã€‚
    è¿™å¼ è¡¨æ˜¯Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æŠ¥å‘Šçš„å”¯ä¸€æ•°æ®æºã€‚
    """
    class ExitReason(models.TextChoices):
        TAKE_PROFIT = 'TAKE_PROFIT', 'æ­¢ç›ˆ'
        STOP_LOSS = 'STOP_LOSS', 'æ­¢æŸ'
        END_OF_PERIOD = 'END_OF_PERIOD', 'è¾¾åˆ°æœ€å¤§æŒæœ‰æœŸ'
    backtest_run_id = models.CharField(
        max_length=50,
        db_index=True,
        help_text="å›æµ‹è¿è¡Œçš„å”¯ä¸€æ ‡è¯†ç¬¦"
    )
    plan_date = models.DateField(
        help_text="é¢„æ¡ˆç”Ÿæˆæ—¥æœŸ (T-1æ—¥)"
    )
    stock_code = models.CharField(
        max_length=50,
        help_text="è‚¡ç¥¨ä»£ç "
    )
    stock_name = models.CharField(
        max_length=50,
        help_text="è‚¡ç¥¨åç§°"
    )
    m_value_at_plan = models.DecimalField(
        max_digits=18,
        decimal_places=10,
        help_text="é¢„æ¡ˆç”Ÿæˆæ—¥çš„å¸‚åœºM(t)å€¼"
    )
    strategy_dna = models.CharField(
        max_length=255,
        help_text="ç­–ç•¥DNAè´¡çŒ®åº¦, æ ¼å¼: MT:0.70|BO:0.20|MR:0.05|QD:0.05"
    )
    entry_date = models.DateField(
        help_text="æ¨¡æ‹Ÿå…¥åœºæ—¥æœŸ (Tæ—¥)"
    )
    entry_price = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        help_text="æ¨¡æ‹Ÿå…¥åœºä»·æ ¼ (Tæ—¥å¼€ç›˜ä»·)"
    )
    exit_date = models.DateField(
        help_text="æ¨¡æ‹Ÿå‡ºåœºæ—¥æœŸ"
    )
    exit_price = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        help_text="æ¨¡æ‹Ÿå‡ºåœºä»·æ ¼"
    )
    exit_reason = models.CharField(
        max_length=20,
        choices=ExitReason.choices,
        help_text="å¹³ä»“åŸå› "
    )
    holding_period = models.IntegerField(
        help_text="æŒæœ‰å¤©æ•°ï¼ˆäº¤æ˜“æ—¥ï¼‰"
    )
    # é¢„è®¾çš„æ­¢ç›ˆæ­¢æŸç‡ï¼Œç”¨äºè®¡ç®—æœŸæœ›æ”¶ç›Š
    preset_take_profit_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        help_text="æ ¹æ®ç­–ç•¥è®¡ç®—å‡ºçš„é¢„è®¾æ­¢ç›ˆç‡"
    )
    preset_stop_loss_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        help_text="æ ¹æ®ç­–ç•¥è®¡ç®—å‡ºçš„é¢„è®¾æ­¢æŸç‡"
    )
    # å®é™…æ”¶ç›Šç‡
    actual_return_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        help_text="è¯¥ç¬”äº¤æ˜“çš„å®é™…æ”¶ç›Šç‡ ( (exit_price / entry_price) - 1 )"
    )

    one_stratage_mode = models.CharField(
        max_length=10,
        null=True,
        blank=True,
        db_index=True, # ä¸ºGROUP BYå’ŒæŸ¥è¯¢ä¼˜åŒ–æ·»åŠ ç´¢å¼•
        help_text="å•ç­–ç•¥æ¨¡å¼ä¸‹ä½¿ç”¨çš„ç­–ç•¥å (MT, BO, QD, MR), ä¸ºç©ºåˆ™ä¸ºMåŠ¨æ€ç­–ç•¥"
    )

    created_at = models.DateTimeField(
        auto_now_add=True
    )
    class Meta:
        db_table = 'tb_m_distribution_backtest_log'
        verbose_name = 'Må€¼åˆ†å¸ƒå›æµ‹æ—¥å¿—'
        verbose_name_plural = verbose_name
        indexes = [
            models.Index(fields=['backtest_run_id', 'plan_date']),
            models.Index(fields=['backtest_run_id', 'one_stratage_mode'])
        ]
####æ–‡ä»¶ç»“æŸ####

####common\models\corporate_action.py####
from django.db import models

class CorporateAction(models.Model):
    """
    è‚¡æƒäº‹ä»¶è¡¨ (tb_corporate_actions)
    
    è¯´æ˜: å­˜å‚¨æ‰€æœ‰å½±å“è‚¡ä»·éäº¤æ˜“æ€§å˜åŠ¨çš„è‚¡æƒäº‹ä»¶ï¼Œæ˜¯ç›˜å‰æ ¡å‡†æ¨¡å—å’Œå›æµ‹å¼•æ“çš„æ ¸å¿ƒæ•°æ®æºã€‚
    
    ä¾‹å­:
    10é€5ï¼ševent_type='bonus', shares_before=10, shares_after=15
    10è½¬3ï¼ševent_type='transfer', shares_before=10, shares_after=13
    10é…3ï¼Œé…è‚¡ä»·8å…ƒï¼ševent_type='rights', shares_before=10, shares_after=13, rights_issue_price=8
    1æ‹†2ï¼ševent_type='split', shares_before=1, shares_after=2 (ç†è§£ä¸ºåœ¨1è‚¡åŸºç¡€ä¸Šå¢åŠ 1è‚¡)
    10å¹¶1ï¼ševent_type='split', shares_before=10, shares_after=1 (ç†è§£ä¸ºåœ¨10è‚¡åŸºç¡€ä¸Šå‡å°‘9è‚¡)
    æ´¾1å…ƒï¼ševent_type='dividend', dividend_per_share=0.1
    """

    # ä½¿ç”¨ Django æ¨èçš„ TextChoices æ¥å®šä¹‰äº‹ä»¶ç±»å‹çš„æšä¸¾
    class EventType(models.TextChoices):
        DIVIDEND = 'dividend', 'åˆ†çº¢'
        BONUS = 'bonus', 'é€è‚¡'
        TRANSFER = 'transfer', 'è½¬è‚¡'
        RIGHTS = 'rights', 'é…è‚¡'
        SPLIT = 'split', 'æ‹†è‚¡/å¹¶è‚¡'

    # å­—æ®µå®šä¹‰
    event_id = models.BigAutoField(
        primary_key=True,
        help_text="äº‹ä»¶å”¯ä¸€ID"
    )
    stock_code = models.CharField(
        max_length=50,
        null=False,
        blank=False,
        help_text="è‚¡ç¥¨ä»£ç , æ ¼å¼å¦‚ 'sh.600000'"
    )
    ex_dividend_date = models.DateField(
        null=False,
        db_index=True,
        help_text="é™¤æƒé™¤æ¯æ—¥ (ç­–ç•¥åˆ¤æ–­çš„åŸºå‡†æ—¥æœŸ)ï¼Œå¯¹äºé…è‚¡æ¥è¯´ï¼Œå®é™…ä¸ºè‚¡æƒç™»è®°æ—¥è€Œéé™¤æƒæ—¥"
    )
    record_date = models.DateField(
        null=True,
        blank=True,
        help_text="è‚¡æƒç™»è®°æ—¥"
    )
    notice_date = models.DateField(
        null=True,
        blank=True,
        help_text="å…¬å‘Šæ—¥æœŸ"
    )
    event_type = models.CharField(
        max_length=20,
        choices=EventType.choices,
        null=False,
        blank=False,
        help_text="äº‹ä»¶ç±»å‹ã€‚æšä¸¾: dividend(åˆ†çº¢), bonus(é€è‚¡), transfer(è½¬è‚¡),rights(é…è‚¡), split(æ‹†è‚¡/å¹¶è‚¡)"
    )
    dividend_per_share = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="æ¯è‚¡æ´¾æ¯(ç¨å‰, å…ƒï¼Œåˆ†çº¢ä¸“ç”¨)"
    )
    shares_before = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="åŸºå‡†è‚¡æ•° (å¦‚â€œ10é€5â€ï¼Œæ­¤å€¼ä¸º10ï¼Œé€è‚¡/è½¬è‚¡/æ‹†è‚¡/å¹¶è‚¡ä¸“ç”¨)"
    )
    shares_after = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="å˜åŠ¨è‚¡æ•° (å¦‚â€œ10é€5â€ï¼Œæ­¤å€¼ä¸º15ï¼Œé€è‚¡/è½¬è‚¡/æ‹†è‚¡/å¹¶è‚¡ä¸“ç”¨)"
    )
    rights_issue_price = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        null=True,
        blank=True,
        help_text="é…è‚¡ä»·æ ¼ï¼Œé…è‚¡ä¸“ç”¨"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        null=False,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )

    class Meta:
        # æ˜¾å¼æŒ‡å®šæ•°æ®åº“ä¸­çš„è¡¨å
        db_table = 'tb_corporate_actions'
        # åœ¨ Django Admin ä¸­æ˜¾ç¤ºçš„åç§°
        verbose_name = 'è‚¡æƒäº‹ä»¶'
        verbose_name_plural = 'è‚¡æƒäº‹ä»¶'
        # é»˜è®¤æ’åºè§„åˆ™
        ordering = ['-ex_dividend_date', 'stock_code']

    def __str__(self):
        # æä¾›ä¸€ä¸ªæ˜“äºé˜…è¯»çš„å¯¹è±¡è¡¨ç¤ºå½¢å¼
        return f"{self.stock_code} on {self.ex_dividend_date}: {self.get_event_type_display()}"


####æ–‡ä»¶ç»“æŸ####

####common\models\daily_factor_values.py####
from django.db import models
from .stock_info import StockInfo
from .factor_definitions import FactorDefinitions

class DailyFactorValues(models.Model):
    """
    2.2. æ¯æ—¥å› å­å€¼è¡¨ (tb_daily_factor_values)
    è¯´æ˜: (æ ¸å¿ƒè®¾è®¡) å­˜å‚¨æ¯åªè‚¡ç¥¨åœ¨æ¯ä¸ªäº¤æ˜“æ—¥è®¡ç®—å‡ºçš„æ‰€æœ‰å› å­åŸå§‹å€¼å’Œæ ‡å‡†åŒ–åˆ†å€¼ã€‚
    """
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.CASCADE, 
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    factor_code = models.ForeignKey(
        FactorDefinitions, 
        on_delete=models.CASCADE, 
        db_column='factor_code',
        help_text="å› å­ä»£ç "
    )
    raw_value = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        help_text="å› å­è®¡ç®—å‡ºçš„åŸå§‹å€¼"
    )
    norm_score = models.DecimalField(
        max_digits=10, 
        decimal_places=4, 
        null=True, 
        blank=True,
        help_text="ç»è¿‡norm()å‡½æ•°æ ‡å‡†åŒ–åçš„åˆ†å€¼ (-100åˆ°100)"
    )

    def __str__(self):
        return f"{self.stock_code} - {self.factor_code} on {self.trade_date}"

    class Meta:
        db_table = 'tb_daily_factor_values'
        # ä½¿ç”¨ unique_together å®ç°å¤åˆä¸»é”®çš„å”¯ä¸€æ€§çº¦æŸ
        unique_together = (('stock_code', 'trade_date', 'factor_code'),)
        verbose_name = 'æ¯æ—¥å› å­å€¼'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\daily_quotes.py####
from django.db import models
from .stock_info import StockInfo

class DailyQuotes(models.Model):
    """
    1.2. æ—¥çº¿è¡Œæƒ…è¡¨ (tb_daily_quotes)
    è¯´æ˜: å­˜å‚¨ä»æ•°æ®æºè·å–çš„æœ€åŸå§‹çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œæ˜¯æ‰€æœ‰è®¡ç®—çš„åŸºçŸ³ã€‚
    """
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.CASCADE, 
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    open = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒå¼€ç›˜ä»·"
    )
    high = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒæœ€é«˜ä»·"
    )
    low = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒæœ€ä½ä»·"
    )
    close = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒæ”¶ç›˜ä»·"
    )
    volume = models.BigIntegerField(
        help_text="æˆäº¤é‡ (è‚¡)"
    )
    turnover = models.DecimalField(
        max_digits=20, 
        decimal_places=2, 
        help_text="æˆäº¤é¢ (å…ƒ)"
    )
    adjust_factor = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        help_text="æˆªè‡³å½“æ—¥çš„åå¤æƒå› å­"
    )
    # (è¦æ±‚1) è®¡ç®—åˆ— hfq_close
    hfq_close = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        editable=False,
        help_text="åå¤æƒæ”¶ç›˜ä»·ï¼Œå…¬å¼: close * adjust_factor"
    )

    def save(self, *args, **kwargs):
        # åœ¨ä¿å­˜æ¨¡å‹å‰è®¡ç®— hfq_close çš„å€¼
        self.hfq_close = self.close * self.adjust_factor
        super().save(*args, **kwargs)

    def __str__(self):
        return f"{self.stock_code} on {self.trade_date}"

    class Meta:
        db_table = 'tb_daily_quotes'
        # ä½¿ç”¨ unique_together å®ç°å¤åˆä¸»é”®çš„å”¯ä¸€æ€§çº¦æŸ
        unique_together = (('stock_code', 'trade_date'),)
        verbose_name = 'æ—¥çº¿è¡Œæƒ…'
        verbose_name_plural = verbose_name
        indexes = [
            models.Index(fields=['trade_date'], name='dailyquotes_tradedate_idx'), # <--- åœ¨è¿™é‡Œæ·»åŠ 
        ]

####æ–‡ä»¶ç»“æŸ####

####common\models\daily_trading_plan.py####
from django.db import models
from .stock_info import StockInfo

class DailyTradingPlan(models.Model):
    """
    3.1. æ¯æ—¥äº¤æ˜“é¢„æ¡ˆè¡¨ (tb_daily_trading_plan)
    è¯´æ˜: å­˜å‚¨ T-1 æ—¥ç»ˆé€‰è‚¡æ¨¡å—ç”Ÿæˆçš„â€œæ¬¡æ—¥è§‚å¯Ÿæ± â€åŠç›¸å…³äº¤æ˜“é¢„æ¡ˆã€‚
    """
    class StatusChoices(models.TextChoices):
        PENDING = 'pending', 'å¾…æ‰§è¡Œ'
        EXECUTED = 'executed', 'å·²æ‰§è¡Œä¹°å…¥'
        CANCELLED = 'cancelled', 'å½“æ—¥æœªæ»¡è¶³æ¡ä»¶ä½œåºŸ'

    plan_date = models.DateField(
        help_text="é¢„æ¡ˆæ‰§è¡Œæ—¥æœŸ (Tæ—¥)"
    )
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.CASCADE, 
        db_column='stock_code',
        help_text="å€™é€‰è‚¡ç¥¨ä»£ç "
    )
    rank = models.IntegerField(
        help_text="ç»¼åˆå¾—åˆ†æ’å (1-10)"
    )
    final_score = models.DecimalField(
        max_digits=10, 
        decimal_places=4, 
        help_text="f(x)é€‰è‚¡ç»¼åˆå¾—åˆ†"
    )
    miop = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="æœ€ä½å¯æ¥å—å¼€ç›˜ä»· (Minimum Acceptable Open Price)"
    )
    maop = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="æœ€é«˜å¯æ¥å—å¼€ç›˜ä»· (Maximum Acceptable Open Price)"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices, 
        default=StatusChoices.PENDING,
        help_text="é¢„æ¡ˆçŠ¶æ€ã€‚æšä¸¾: pending(å¾…æ‰§è¡Œ), executed(å·²æ‰§è¡Œä¹°å…¥), cancelled(å½“æ—¥æœªæ»¡è¶³æ¡ä»¶ä½œåºŸ)"
    )
    strategy_dna = models.CharField(
        max_length=255,
        null=True,  # å…è®¸ä¸ºç©ºï¼Œç¡®ä¿å¯¹æ—§æ•°æ®å’Œç°æœ‰ä»£ç çš„å…¼å®¹æ€§
        blank=True, # å…è®¸ä¸ºç©º
        help_text="ç­–ç•¥DNAè´¡çŒ®åº¦, æ ¼å¼: MT:0.70|BO:0.20|MR:0.05|QD:0.05"
    )
    def __str__(self):
        return f"Plan for {self.stock_code} on {self.plan_date} (Rank: {self.rank})"

    class Meta:
        db_table = 'tb_daily_trading_plan'
        # ä½¿ç”¨ unique_together å®ç°å¤åˆä¸»é”®çš„å”¯ä¸€æ€§çº¦æŸ
        unique_together = (('plan_date', 'stock_code'),)
        verbose_name = 'æ¯æ—¥äº¤æ˜“é¢„æ¡ˆ'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\factor_definitions.py####
from django.db import models

class FactorDefinitions(models.Model):
    """
    2.1. å› å­å®šä¹‰è¡¨ (tb_factor_definitions)
    è¯´æ˜: (æ ¸å¿ƒè®¾è®¡) ç”¨äºå®šä¹‰æ‰€æœ‰ç­–ç•¥ä¸­ä½¿ç”¨çš„å› å­ï¼Œå®ç°å› å­çš„å¯æ’æ‹”ã€‚æ–°å¢å› å­åªéœ€åœ¨æ­¤è¡¨å¢åŠ ä¸€æ¡è®°å½•ã€‚
    """
    class DirectionChoices(models.TextChoices):
        POSITIVE = 'positive', 'æ­£å‘, å€¼è¶Šå¤§è¶Šå¥½'
        NEGATIVE = 'negative', 'è´Ÿå‘, å€¼è¶Šå°è¶Šå¥½'

    factor_code = models.CharField(
        max_length=50, 
        primary_key=True, 
        help_text="å› å­å”¯ä¸€è‹±æ–‡ä»£ç , å¦‚ 'MA20_SLOPE'"
    )
    factor_name = models.CharField(
        max_length=100, 
        help_text="å› å­ä¸­æ–‡åç§°, å¦‚ '20æ—¥å‡çº¿æ–œç‡'"
    )
    description = models.TextField(
        blank=True, 
        null=True, 
        help_text="è¯¦ç»†æè¿°å› å­çš„è®¡ç®—é€»è¾‘å’Œä¸šåŠ¡å«ä¹‰"
    )
    direction = models.CharField(
        max_length=10, 
        choices=DirectionChoices.choices,
        help_text="å› å­æ–¹å‘æ€§ã€‚æšä¸¾: positive(æ­£å‘, å€¼è¶Šå¤§è¶Šå¥½), negative(è´Ÿå‘, å€¼è¶Šå°è¶Šå¥½)"
    )
    is_active = models.BooleanField(
        default=True, 
        help_text="æ˜¯å¦å¯ç”¨è¯¥å› å­"
    )

    def __str__(self):
        return f"{self.factor_name} ({self.factor_code})"

    class Meta:
        db_table = 'tb_factor_definitions'
        verbose_name = 'å› å­å®šä¹‰'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\index_quotes_csi300.py####
# common/models/index_quotes_csi300.py
from django.db import models
from decimal import Decimal

class IndexQuotesCsi300(models.Model):
    """
    æ²ªæ·±300æŒ‡æ•°æ—¥çº¿è¡Œæƒ…è¡¨

    è¯´æ˜: å­˜å‚¨æ²ªæ·±300æŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œä½œä¸ºå¸‚åœºçŠ¶æ€å‡½æ•° M(t) çš„è®¡ç®—åŸºçŸ³ã€‚
    æ•°æ®é€šè¿‡ akshare çš„ index_zh_a_hist æ¥å£è·å–ã€‚
    """
    trade_date = models.DateField(
        primary_key=True,
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    open = models.DecimalField(
        max_digits=10, decimal_places=2, help_text="å¼€ç›˜ä»·"
    )
    close = models.DecimalField(
        max_digits=10, decimal_places=2, help_text="æ”¶ç›˜ä»·"
    )
    high = models.DecimalField(
        max_digits=10, decimal_places=2, help_text="æœ€é«˜ä»·"
    )
    low = models.DecimalField(
        max_digits=10, decimal_places=2, help_text="æœ€ä½ä»·"
    )
    volume = models.BigIntegerField(
        help_text="æˆäº¤é‡ (è‚¡)"
    )
    amount = models.DecimalField(
        max_digits=20, decimal_places=2, help_text="æˆäº¤é¢ (å…ƒ)"
    )
    amplitude = models.DecimalField(
        max_digits=8, decimal_places=4, help_text="æŒ¯å¹… (%)"
    )
    pct_change = models.DecimalField(
        max_digits=8, decimal_places=4, help_text="æ¶¨è·Œå¹… (%)"
    )
    change_amount = models.DecimalField(
        max_digits=10, decimal_places=2, help_text="æ¶¨è·Œé¢"
    )
    turnover_rate = models.DecimalField(
        max_digits=8, decimal_places=4, null=True, blank=True, help_text="æ¢æ‰‹ç‡ (%)"
    )

    class Meta:
        db_table = 'tb_index_quotes_csi300'
        verbose_name = 'æ²ªæ·±300æŒ‡æ•°è¡Œæƒ…'
        verbose_name_plural = verbose_name
        ordering = ['-trade_date']

    def __str__(self):
        return f"CSI300 on {self.trade_date}: {self.close}"

####æ–‡ä»¶ç»“æŸ####

####common\models\positions.py####
from django.db import models
from .stock_info import StockInfo

class Position(models.Model):
    """
    3.2. æŒä»“ä¿¡æ¯è¡¨ (tb_positions)
    è¯´æ˜: å­˜å‚¨å½“å‰æ‰€æœ‰æŒä»“çš„è¯¦ç»†ä¿¡æ¯ï¼Œæ˜¯ç›˜ä¸­ç›‘æ§æ¨¡å—çš„æ ¸å¿ƒæ•°æ®ä¾æ®ã€‚
    """
    class StatusChoices(models.TextChoices):
        OPEN = 'open', 'æŒä»“ä¸­'
        CLOSED = 'closed', 'å·²å¹³ä»“'

    position_id = models.BigAutoField(
        primary_key=True, 
        help_text="æŒä»“å”¯ä¸€ID"
    )
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.PROTECT, # ä¿æŠ¤ï¼Œé˜²æ­¢æ„å¤–åˆ é™¤å…³è”è‚¡ç¥¨ä¿¡æ¯
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    entry_datetime = models.DateTimeField(
        help_text="å»ºä»“æˆäº¤æ—¶é—´"
    )
    entry_price = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="å®é™…æˆäº¤å‡ä»· (AEP)"
    )
    quantity = models.BigIntegerField(
        help_text="æŒä»“æ•°é‡ (è‚¡)"
    )
    current_stop_loss = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="å½“å‰æ­¢æŸä»·"
    )
    current_take_profit = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="å½“å‰æ­¢ç›ˆä»·"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices, 
        default=StatusChoices.OPEN,
        help_text="æŒä»“çŠ¶æ€ã€‚æšä¸¾: open(æŒä»“ä¸­), closed(å·²å¹³ä»“)"
    )

    def __str__(self):
        return f"Position {self.position_id}: {self.quantity} of {self.stock_code}"

    class Meta:
        db_table = 'tb_positions'
        verbose_name = 'æŒä»“ä¿¡æ¯'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\stock_info.py####
from django.db import models
from django.utils import timezone

class StockInfo(models.Model):
    """
    1.1. è‚¡ç¥¨åŸºç¡€ä¿¡æ¯è¡¨ (tb_stock_info)
    è¯´æ˜: å­˜å‚¨æ‰€æœ‰Aè‚¡è‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯ï¼Œå¦‚ä»£ç ã€åç§°ã€ä¸Šå¸‚æ—¥æœŸç­‰ï¼Œä½œä¸ºå…¶ä»–æ•°æ®è¡¨çš„å…³è”åŸºç¡€ã€‚
    """
    class StatusChoices(models.TextChoices):
        LISTING = 'listing', 'ä¸Šå¸‚'
        DELISTED = 'delisted', 'é€€å¸‚'
        SUSPENDED = 'suspended', 'åœç‰Œ'

    stock_code = models.CharField(
        max_length=50, 
        primary_key=True, 
        help_text="è‚¡ç¥¨ä»£ç , æ ¼å¼å¦‚ 'sh.600000'"
    )
    stock_name = models.CharField(
        max_length=50, 
        help_text="è‚¡ç¥¨åç§°"
    )
    listing_date = models.DateField(
        help_text="ä¸Šå¸‚æ—¥æœŸ, ç”¨äºå‰”é™¤æ¬¡æ–°è‚¡"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices,
        help_text="è‚¡ç¥¨çŠ¶æ€ã€‚æšä¸¾: listing(ä¸Šå¸‚), delisted(é€€å¸‚), suspended(åœç‰Œ)"
    )
    created_at = models.DateTimeField(
        default=timezone.now, 
        editable=False,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        help_text="è®°å½•æ›´æ–°æ—¶é—´"
    )

    def __str__(self):
        return f"{self.stock_name}({self.stock_code})"

    class Meta:
        db_table = 'tb_stock_info'
        verbose_name = 'è‚¡ç¥¨åŸºç¡€ä¿¡æ¯'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\strategy_parameters.py####
from django.db import models

class StrategyParameters(models.Model):
    """
    2.3. ç­–ç•¥å‚æ•°è¡¨ (tb_strategy_parameters)
    è¯´æ˜: å­˜å‚¨æ‰€æœ‰ç­–ç•¥ä¸­å¯ä¼˜åŒ–çš„å‚æ•°ï¼Œå¦‚æƒé‡ã€ç³»æ•°ç­‰ï¼Œæ–¹ä¾¿å›æµ‹ä¸ä¼˜åŒ–æ¨¡å—è¿›è¡Œè¯»å–å’Œä¿®æ”¹ã€‚
    """
    param_name = models.CharField(
        max_length=50, 
        primary_key=True, 
        help_text="å‚æ•°å”¯ä¸€è‹±æ–‡å, å¦‚ 'w_trend', 'k_h1'"
    )
    param_value = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        help_text="å‚æ•°çš„æ•°å€¼"
    )
    group_name = models.CharField(
        max_length=50, 
        blank=True, 
        null=True, 
        help_text="å‚æ•°æ‰€å±åˆ†ç»„, å¦‚ 'WEIGHTS', 'STOP_LOSS'"
    )
    description = models.TextField(
        blank=True, 
        null=True, 
        help_text="å‚æ•°çš„è¯¦ç»†è¯´æ˜"
    )

    def __str__(self):
        return f"{self.param_name} = {self.param_value}"

    class Meta:
        db_table = 'tb_strategy_parameters'
        verbose_name = 'ç­–ç•¥å‚æ•°'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\system_log.py####
from django.db import models
from django.utils import timezone

class SystemLog(models.Model):
    """
    4.1. ç³»ç»Ÿæ—¥å¿—è¡¨ (tb_system_log)
    è¯´æ˜: è®°å½•ç³»ç»Ÿè¿è¡Œè¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯ã€è­¦å‘Šå’Œé”™è¯¯ï¼Œä¾¿äºç›‘æ§å’Œè°ƒè¯•ã€‚
    """
    class LogLevelChoices(models.TextChoices):
        INFO = 'INFO', 'INFO'
        WARNING = 'WARNING', 'WARNING'
        ERROR = 'ERROR', 'ERROR'
        CRITICAL = 'CRITICAL', 'CRITICAL'

    log_id = models.BigAutoField(
        primary_key=True, 
        help_text="æ—¥å¿—å”¯ä¸€ID"
    )
    log_time = models.DateTimeField(
        default=timezone.now, 
        editable=False,
        help_text="æ—¥å¿—è®°å½•æ—¶é—´"
    )
    log_level = models.CharField(
        max_length=10, 
        choices=LogLevelChoices.choices,
        help_text="æ—¥å¿—çº§åˆ«ã€‚æšä¸¾: INFO, WARNING, ERROR, CRITICAL"
    )
    module_name = models.CharField(
        max_length=50, 
        blank=True, 
        null=True,
        help_text="äº§ç”Ÿæ—¥å¿—çš„æ¨¡å—å, å¦‚ 'æ—¥ç»ˆé€‰è‚¡', 'å¼€ç›˜å†³ç­–'"
    )
    message = models.TextField(
        help_text="æ—¥å¿—å†…å®¹, å¦‚ 'æ— åˆé€‚ä¹°ç‚¹', 'ä¸‹å•APIè¯·æ±‚å¤±è´¥'"
    )

    def __str__(self):
        return f"[{self.log_time.strftime('%Y-%m-%d %H:%M:%S')}] [{self.log_level}] {self.message[:80]}"

    class Meta:
        db_table = 'tb_system_log'
        verbose_name = 'ç³»ç»Ÿæ—¥å¿—'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\trade_log.py####
from django.db import models
from .stock_info import StockInfo

class TradeLog(models.Model):
    """
    3.3. äº¤æ˜“è®°å½•è¡¨ (tb_trade_log)
    è¯´æ˜: è®°å½•æ¯ä¸€æ¬¡ä¹°å…¥å’Œå–å‡ºçš„è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºæˆæœ¬æ ¸ç®—ã€ä¸šç»©åˆ†æå’Œé—®é¢˜æ’æŸ¥ã€‚
    """
    class TradeTypeChoices(models.TextChoices):
        BUY = 'buy', 'ä¹°å…¥'
        SELL = 'sell', 'å–å‡º'

    class OrderTypeChoices(models.TextChoices):
        LIMIT = 'limit', 'é™ä»·'
        MARKET = 'market', 'å¸‚ä»·'

    class ReasonChoices(models.TextChoices):
        ENTRY = 'entry', 'ç­–ç•¥å…¥åœº'
        TAKE_PROFIT = 'take_profit', 'æ­¢ç›ˆ'
        STOP_LOSS = 'stop_loss', 'æ­¢æŸ'
        MANUAL = 'manual', 'äººå·¥å¹²é¢„'

    class StatusChoices(models.TextChoices):
        FILLED = 'filled', 'å·²æˆäº¤'
        FAILED = 'failed', 'å¤±è´¥'
        CANCELLED = 'cancelled', 'å·²æ’¤é”€'
        PENDING = 'pending','å¾…æ‰§è¡Œ'

    trade_id = models.BigAutoField(
        primary_key=True, 
        help_text="äº¤æ˜“å”¯ä¸€ID"
    )
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨å­—ç¬¦ä¸² 'positions.Position' æ¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
    # related_name='trade_logs' å…è®¸ä» Position å¯¹è±¡åå‘è®¿é—®å…¶æ‰€æœ‰äº¤æ˜“è®°å½•
    position = models.ForeignKey(
        'Position', 
        on_delete=models.CASCADE, # å¦‚æœæŒä»“è¢«åˆ é™¤ï¼Œå…³è”çš„äº¤æ˜“è®°å½•ä¹Ÿåº”åˆ é™¤
        related_name='trade_logs',
        help_text="å…³è”çš„æŒä»“ID (ä¹°å…¥æ—¶ç”Ÿæˆ, å–å‡ºæ—¶å¼•ç”¨)"
    )
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.PROTECT,
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    trade_datetime = models.DateTimeField(
        help_text="äº¤æ˜“æˆäº¤æ—¶é—´"
    )
    trade_type = models.CharField(
        max_length=10, 
        choices=TradeTypeChoices.choices,
        help_text="äº¤æ˜“ç±»å‹ã€‚æšä¸¾: buy(ä¹°å…¥), sell(å–å‡º)"
    )
    order_type = models.CharField(
        max_length=10, 
        choices=OrderTypeChoices.choices,
        help_text="è®¢å•ç±»å‹ã€‚æšä¸¾: limit(é™ä»·), market(å¸‚ä»·)"
    )
    price = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="æˆäº¤å‡ä»·"
    )
    quantity = models.BigIntegerField(
        help_text="æˆäº¤æ•°é‡"
    )
    commission = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä½£é‡‘"
    )
    stamp_duty = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        default=0,
        help_text="å°èŠ±ç¨ (ä»…å–å‡ºæ—¶æœ‰)"
    )
    reason = models.CharField(
        max_length=50, 
        choices=ReasonChoices.choices, 
        blank=True, 
        null=True,
        help_text="äº¤æ˜“åŸå› ã€‚æšä¸¾: entry(ç­–ç•¥å…¥åœº), take_profit(æ­¢ç›ˆ), stop_loss(æ­¢æŸ), manual(äººå·¥å¹²é¢„)"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices,
        help_text="è®¢å•çŠ¶æ€ã€‚æšä¸¾: filled(å·²æˆäº¤), failed(å¤±è´¥), cancelled(å·²æ’¤é”€),pending(å¾…æ‰§è¡Œ)"
    )

    external_order_id = models.CharField(
        max_length=50, 
        null=True, 
        blank=True, 
        db_index=True,
        help_text="å¤–éƒ¨äº¤æ˜“ç³»ç»Ÿçš„è®¢å•IDï¼Œå¦‚åˆ¸å•†çš„å§”æ‰˜ç¼–å·"
    )

    def __str__(self):
        return f"Trade {self.trade_id}: {self.trade_type.upper()} {self.quantity} of {self.stock_code}"

    class Meta:
        db_table = 'tb_trade_log'
        verbose_name = 'äº¤æ˜“è®°å½•'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####data_manager\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####data_manager\admin.py####
from django.contrib import admin

# Register your models here.

####æ–‡ä»¶ç»“æŸ####

####data_manager\apps.py####
from django.apps import AppConfig


class DataManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'data_manager'

####æ–‡ä»¶ç»“æŸ####

####data_manager\models.py####
from django.db import models

# Create your models here.

####æ–‡ä»¶ç»“æŸ####

####data_manager\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####data_manager\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include
from . import views
urlpatterns = [
    path('test', views.test_get),
    path('updateLocalStock', views.update_local_a_shares),
    path('syncCorporateActions', views.sync_corporate_actions),
    path('sendEmail', views.email_send),
    path('updateCSI300', views.update_csi300_index_data)
]

####æ–‡ä»¶ç»“æŸ####

####data_manager\views.py####
from django.http.response import JsonResponse
from django.shortcuts import render
from common.models import StockInfo
from data_manager.service.stock_service import StockService
from data_manager.service.corporate_action_service import CorporateActionService
from data_manager.service.email_service import EmailNotificationService
from django.views.decorators.http import require_http_methods
import json
from datetime import date,datetime
# Create your views here.
def test_get(request):
    result={}
    if request.method=='GET':
        result=  {'method':'get'}
    if request.method=='POST':
        result= {'methods':'post'}
    # service=StockService()
    # service.clear_all_data()
    # service.update_local_a_shares(start_date="2025-01-01",end_date="2025-08-04")
    # service.update_local_a_shares(start_date="2024-01-01",end_date="2024-12-31")
    # service.update_local_a_shares(start_date="2023-01-01",end_date="2023-12-31")
    # service.update_local_a_shares(start_date="2022-01-01",end_date="2022-12-31")
    # service.update_local_a_shares(start_date="2021-01-01",end_date="2021-12-31")
    return JsonResponse(result)

@require_http_methods(["POST"])
def update_local_a_shares(request):
    body= json.loads(request.body)
    service=StockService()
    service.update_local_a_shares(stock_codes=body['stockCodes'],start_date=body['startDate'],end_date=body['endDate'])
    return JsonResponse({"result":"success"})

@require_http_methods(["POST"])
def sync_corporate_actions(request):
    body= json.loads(request.body)
    service=CorporateActionService()
    service.sync_corporate_actions(start_date=body['startDate'],end_date=body['endDate'])
    return JsonResponse({"result":"success"})

@require_http_methods(["POST"])
def email_send(request):
    body= json.loads(request.body)
    service=EmailNotificationService(t_day=datetime.strptime(body['date'], "%Y-%m-%d").date())
    service.runEmailSend()
    return JsonResponse({"result":"success"})

def update_csi300_index_data(request):
    body= json.loads(request.body)
    service=StockService()
    service.update_csi300_index_data(start_date=body['startDate'],end_date=body['endDate'])
    return JsonResponse({"result":"success"})
####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\backfill_csi300_data.py####
# data_manager/management/commands/backfill_csi300_data.py
import logging
import time
from datetime import date, timedelta
import pandas as pd
import akshare as ak
from django.core.management.base import BaseCommand, CommandParser
from django.db import transaction
from decimal import Decimal

from common.models.index_quotes_csi300 import IndexQuotesCsi300

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'ä¸€æ¬¡æ€§å›å¡«æ²ªæ·±300æŒ‡æ•°çš„å†å²æ—¥çº¿æ•°æ®ã€‚'

    def add_arguments(self, parser: CommandParser):
        parser.add_argument(
            '--years',
            type=int,
            default=15,
            help='è¦å›å¡«çš„å†å²æ•°æ®å¹´æ•°ï¼Œé»˜è®¤ä¸º15å¹´ã€‚'
        )

    def handle(self, *args, **options):
        years_to_backfill = options['years']
        end_date = date.today()
        start_date = end_date - timedelta(days=years_to_backfill * 365)

        self.stdout.write(self.style.SUCCESS(f"===== å¼€å§‹å›å¡«æ²ªæ·±300æŒ‡æ•°å†å²æ•°æ® ====="))
        self.stdout.write(f"æ•°æ®èŒƒå›´: {start_date.strftime('%Y%m%d')} to {end_date.strftime('%Y%m%d')}")

        try:
            # 1. æ‹‰å–æ•°æ®
            self.stdout.write("æ­£åœ¨ä»akshareè·å–æ•°æ®...")
            df = ak.index_zh_a_hist(
                symbol="000300",
                period="daily",
                start_date=start_date.strftime('%Y%m%d'),
                end_date=end_date.strftime('%Y%m%d')
            )
            self.stdout.write(f"æˆåŠŸè·å– {len(df)} æ¡æ•°æ®ã€‚")

            if df.empty:
                self.stdout.write(self.style.WARNING("æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚"))
                return

            # 2. æ•°æ®æ¸…æ´—å’Œè½¬æ¢
            df.rename(columns={
                'æ—¥æœŸ': 'trade_date', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'pct_change', 'æ¶¨è·Œé¢': 'change_amount', 'æ¢æ‰‹ç‡': 'turnover_rate'
            }, inplace=True)
            
            # æˆäº¤é‡ä»â€œæ‰‹â€è½¬æ¢ä¸ºâ€œè‚¡â€
            df['volume'] = df['volume'] * 100
            df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce')


            # 3. æ‰¹é‡å…¥åº“
            records_to_create = []
            for _, row in df.iterrows():
                records_to_create.append(
                    IndexQuotesCsi300(
                        trade_date=row['trade_date'],
                        open=Decimal(str(row['open'])),
                        close=Decimal(str(row['close'])),
                        high=Decimal(str(row['high'])),
                        low=Decimal(str(row['low'])),
                        volume=int(row['volume']),
                        amount=Decimal(str(row['amount'])),
                        amplitude=Decimal(str(row['amplitude'])),
                        pct_change=Decimal(str(row['pct_change'])),
                        change_amount=Decimal(str(row['change_amount'])),
                        turnover_rate=Decimal(str(row['turnover_rate'])) if pd.notna(row['turnover_rate']) else None
                    )
                )
            
            self.stdout.write("æ­£åœ¨å°†æ•°æ®å†™å…¥æ•°æ®åº“ (update_or_create)...")
            # with transaction.atomic():
            #     for record in records_to_create:
            #         IndexQuotesCsi300.objects.update_or_create(
            #             trade_date=record.trade_date,
            #             defaults={
            #                 'open': record.open, 'close': record.close, 'high': record.high, 'low': record.low,
            #                 'volume': record.volume, 'amount': record.amount, 'amplitude': record.amplitude,
            #                 'pct_change': record.pct_change, 'change_amount': record.change_amount,
            #                 'turnover_rate': record.turnover_rate
            #             }
            #         )
            # ã€ç”¨è¿™æ®µä»£ç æ›¿æ¢ä¸Šé¢åˆ é™¤çš„éƒ¨åˆ†ã€‘
            self.stdout.write("æ­£åœ¨å°†æ•°æ®æ‰¹é‡å†™å…¥æ•°æ®åº“...")
            # å®šä¹‰éœ€è¦æ›´æ–°çš„å­—æ®µåˆ—è¡¨
            update_fields = [
                'open', 'close', 'high', 'low', 'volume', 'amount', 
                'amplitude', 'pct_change', 'change_amount', 'turnover_rate'
            ]
            # ä½¿ç”¨ bulk_create è¿›è¡Œæ‰¹é‡â€œæ›´æ–°æˆ–åˆ›å»ºâ€
            IndexQuotesCsi300.objects.bulk_create(
                records_to_create,
                batch_size=10000,  # æ¨èè®¾ç½®æ‰¹æ¬¡å¤§å°ï¼Œé˜²æ­¢å†…å­˜å ç”¨è¿‡é«˜
                update_conflicts=True,
                unique_fields=['trade_date'],  # å†²çªåˆ¤æ–­çš„å”¯ä¸€é”®
                update_fields=update_fields  # å‘ç”Ÿå†²çªæ—¶éœ€è¦æ›´æ–°çš„å­—æ®µ
            )
            
            self.stdout.write(self.style.SUCCESS("===== æ²ªæ·±300æ•°æ®å›å¡«æˆåŠŸï¼ ====="))

        except Exception as e:
            self.stdout.write(self.style.ERROR(f"å›å¡«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"))
            logger.error("å›å¡«æ²ªæ·±300æ•°æ®å¤±è´¥", exc_info=True)

####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\calibrate_m_value_anchors.py####
# data_manager/management/commands/calibrate_m_value_anchors.py
import logging
import pandas as pd
from django.core.management.base import BaseCommand, CommandParser
from django.db import transaction
from decimal import Decimal

from common.models import IndexQuotesCsi300, StrategyParameters

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'ä¸€æ¬¡æ€§æ ¡å‡†Må€¼è®¡ç®—æ‰€éœ€çš„å›ºå®šåˆ†ä½é”šç‚¹å‚æ•°ã€‚'

    def add_arguments(self, parser: CommandParser):
        parser.add_argument(
            '--start-date',
            type=str,
            default=None,  # æˆ–è€…è®¾ç½®ä¸º None
            help='ç”¨äºæ ¡å‡†çš„èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)ã€‚'
        )
        parser.add_argument(
            '--end-date',
            type=str,
            default=None,  # æˆ–è€…è®¾ç½®ä¸º None
            help='ç”¨äºæ ¡å‡†çš„æˆªæ­¢æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)ã€‚'
        )

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS("===== å¼€å§‹æ ¡å‡†Må€¼å›ºå®šåˆ†ä½é”šç‚¹ ====="))
        
        # 1. åŠ è½½æ•°æ®
        # df = pd.DataFrame.from_records(IndexQuotesCsi300.objects.all().values())
        start_date = options['start_date']
        end_date = options['end_date']
        queryset = IndexQuotesCsi300.objects.all()
        if start_date:
            queryset = queryset.filter(trade_date__gte=start_date)
        if end_date:
            queryset = queryset.filter(trade_date__lte=end_date)
        # å¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸€å¥æ—¥å¿—ï¼Œæ–¹ä¾¿ç¡®è®¤
        self.stdout.write(f"ä½¿ç”¨æ•°æ®èŒƒå›´: ä» {start_date or 'æœ€æ—©'} åˆ° {end_date or 'æœ€æ–°'}")
        df = pd.DataFrame.from_records(queryset.values())
        if df.empty:
            self.stdout.write(self.style.ERROR("æ•°æ®åº“ä¸­æ²¡æœ‰æ²ªæ·±300æŒ‡æ•°æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œ backfill_csi300_dataã€‚"))
            return
        
        df.set_index('trade_date', inplace=True)
        df.sort_index(inplace=True)
        columns_to_convert = ['open', 'high', 'low', 'close', 'turnover_rate']
        for col in columns_to_convert:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        # 2. è®¡ç®—å››ä¸ªåŸºç¡€æŒ‡æ ‡çš„å®Œæ•´å†å²åºåˆ—
        self.stdout.write("æ­£åœ¨è®¡ç®—åŸºç¡€æŒ‡æ ‡çš„å†å²åºåˆ—...")
        df['ma60'] = df['close'].rolling(60).mean()
        df['m1_trend'] = (df['close'] - df['ma60']) / df['ma60']
        df['m2_momentum'] = df['close'].pct_change(20)
        df['daily_return'] = df['close'].pct_change()
        df['m3_volatility'] = df['daily_return'].rolling(20).std()
        avg_turnover_20 = df['turnover_rate'].rolling(20).mean()
        avg_turnover_60 = df['turnover_rate'].rolling(60).mean()
        df['m4_turnover'] = avg_turnover_20 / avg_turnover_60
        
        indicators_df = df[['m1_trend', 'm2_momentum', 'm3_volatility', 'm4_turnover']].dropna()
        self.stdout.write(f"æŒ‡æ ‡å†å²è®¡ç®—å®Œæˆï¼Œæœ‰æ•ˆæ•°æ®ç‚¹: {len(indicators_df)}ã€‚")

        # 3. è®¡ç®—åˆ†ä½é”šç‚¹å¹¶å‡†å¤‡å‚æ•°
        params_to_update = {}
        quantiles = [0.10, 0.50, 0.90]
        indicator_map = {
            'm1_trend': 'trend',
            'm2_momentum': 'momentum',
            'm3_volatility': 'volatility',
            'm4_turnover': 'turnover'
        }

        for col, name in indicator_map.items():
            percentiles = indicators_df[col].quantile(quantiles)
            for q in quantiles:
                param_name = f"dynamic_m_csi300_anchor_{name}_p{int(q*100)}"
                param_value = Decimal(str(percentiles[q]))
                params_to_update[param_name] = param_value
                self.stdout.write(f"è®¡ç®—å‡ºé”šç‚¹: {param_name} = {param_value:.4f}")

        # 4. å†™å…¥æ•°æ®åº“
        self.stdout.write("æ­£åœ¨å°†é”šç‚¹å‚æ•°å†™å…¥æ•°æ®åº“...")
        with transaction.atomic():
            for name, value in params_to_update.items():
                StrategyParameters.objects.update_or_create(
                    param_name=name,
                    defaults={
                        'param_value': value,
                        'group_name': 'M_CSI300_ANCHORS',
                        'description': f'æ²ªæ·±300çš„Må€¼è®¡ç®—-æŒ‡æ ‡{name.split("_p")[0].split("_")[-1]}-é”šç‚¹P{name.split("_p")[-1]}'
                    }
                )
        
        self.stdout.write(self.style.SUCCESS(f"===== æˆåŠŸæ›´æ–° {len(params_to_update)} ä¸ªé”šç‚¹å‚æ•°ï¼ ====="))

####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\full_update_stocks.py####
# data_manager/management/commands/full_update_stocks.py

from django.core.management.base import BaseCommand
from data_manager.service.stock_service import StockService
from selection_manager.service.selection_service import SelectionService
import time
from datetime import date,datetime
class Command(BaseCommand):
    help = 'æ¸…ç©ºå¹¶é‡æ–°è·å–è¿‡å»äº”å¹´çš„å…¨éƒ¨Aè‚¡æ•°æ®'

    def handle(self, *args, **options):
        total_start_time = time.time()
        self.stdout.write(self.style.SUCCESS('===== å¼€å§‹æ‰§è¡Œå…¨é‡æ•°æ®æ›´æ–°ä»»åŠ¡ ====='))
        
        service = StockService()
        
        # 1. æ¸…ç©ºæ‰€æœ‰æ—§æ•°æ®
        self.stdout.write('æ­£åœ¨æ¸…ç©ºæ‰€æœ‰å†å²æ•°æ®...')
        #service.clear_all_data()
        self.stdout.write(self.style.SUCCESS('å†å²æ•°æ®å·²æ¸…ç©ºã€‚'))
        
        # 2. æŒ‰å¹´ä»½é¡ºåºè·å–æ•°æ®
        #service.clear_all_data()
        service.update_local_a_shares(start_date="2025-08-06",end_date="2025-08-08")
        service.update_local_a_shares(start_date="2018-01-01",end_date="2019-12-31")
        # service.update_local_a_shares(start_date="2023-01-01",end_date="2023-12-31")
        # service.update_local_a_shares(start_date="2022-01-01",end_date="2022-12-31")
        # service.update_local_a_shares(start_date="2021-01-01",end_date="2021-12-31")
        total_end_time = time.time()
        self.stdout.write(self.style.SUCCESS(f'\n===== æ‰€æœ‰å¹´ä»½æ•°æ®æ›´æ–°å®Œæ¯•ï¼æ€»è€—æ—¶: {(total_end_time - total_start_time) / 3600:.2f} å°æ—¶ ====='))
        self.stdout.write('å¼€å§‹é¢„çƒ­Må€¼...')
        service=SelectionService(datetime.strptime('2025-08-08', "%Y-%m-%d").date())
        service.run_selection()
        total_end_time_2 = time.time()

####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\migrate_to_pg.py####
# data_manager/management/commands/migrate_to_pg.py

from django.core.management.base import BaseCommand
from data_manager.service.db_service import DbMigrationService

class Command(BaseCommand):
    help = 'å°†æ•´ä¸ªSQLiteæ•°æ®åº“çš„ç»“æ„å’Œæ•°æ®è¿ç§»åˆ°PostgreSQL'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('å¼€å§‹æ‰§è¡Œæ•°æ®åº“è¿ç§»ä»»åŠ¡...'))
        
        try:
            service = DbMigrationService()
            service.migrate()
            self.stdout.write(self.style.SUCCESS('æ•°æ®åº“è¿ç§»ä»»åŠ¡å·²æˆåŠŸå®Œæˆã€‚'))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'æ•°æ®åº“è¿ç§»å¤±è´¥: {e}'))


####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\reset_sequences.py####
# data_manager/management/commands/reset_sequences.py (V2 - ä¿®æ­£ç‰ˆ)
import logging
from django.core.management.base import BaseCommand
from django.db import connection, models
from django.apps import apps

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'Resets PostgreSQL sequences for integer AutoFields to the max value of their primary key columns.'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('===== å¼€å§‹æ™ºèƒ½é‡ç½®æ•°æ®åº“åºåˆ— (ä»…å¤„ç†è‡ªå¢æ•´æ•°ä¸»é”®) ====='))
        
        all_models = apps.get_models()
        
        with connection.cursor() as cursor:
            for model in all_models:
                table_name = model._meta.db_table
                pk_field = model._meta.pk
                
                # --- æ ¸å¿ƒä¿®æ­£ï¼šå¢åŠ ç±»å‹æ£€æŸ¥ ---
                # 1. æ£€æŸ¥ä¸»é”®æ˜¯å¦å­˜åœ¨ä¸”æ˜¯å¦ä¸ºè‡ªå¢å­—æ®µ
                if not pk_field or not isinstance(pk_field, models.AutoField):
                    self.stdout.write(f'æ­£åœ¨å¤„ç†è¡¨: {table_name} ... ' + self.style.WARNING('è·³è¿‡ (ä¸»é”®éè‡ªå¢æ•´æ•°)'))
                    continue

                # 2. å¦‚æœæ˜¯è‡ªå¢å­—æ®µï¼Œå…¶å†…éƒ¨ç±»å‹ä¸€å®šæ˜¯æ•´æ•°ï¼Œå¯ä»¥å®‰å…¨å¤„ç†
                pk_name = pk_field.name
                sequence_name = f"{table_name}_{pk_name}_seq"
                
                self.stdout.write(f'æ­£åœ¨å¤„ç†è¡¨: {table_name} (åºåˆ—: {sequence_name}) ... ', ending='')
                
                try:
                    # SQL to get the max PK value.
                    # COALESCE is still useful for empty tables.
                    # The third argument 'false' in setval means the next value will be max_id + 1
                    # No change needed here as we've already filtered for integer PKs.
                    sql = f"""
                    SELECT setval('"{sequence_name}"', (SELECT COALESCE(MAX("{pk_name}"), 1) FROM "{table_name}"), false);
                    """
                    cursor.execute(sql)
                    self.stdout.write(self.style.SUCCESS('OK'))
                except Exception as e:
                    # æ•è·å…¶ä»–å¯èƒ½çš„é”™è¯¯ï¼Œä¾‹å¦‚åºåˆ—çœŸçš„ä¸å­˜åœ¨
                    if "does not exist" in str(e):
                        self.stdout.write(self.style.WARNING(f'è·³è¿‡ (åºåˆ—ä¸å­˜åœ¨)'))
                    else:
                        self.stdout.write(self.style.ERROR(f'å¤±è´¥: {e}'))
                        logger.error(f"é‡ç½®åºåˆ— {sequence_name} å¤±è´¥: {e}", exc_info=True)

        self.stdout.write(self.style.SUCCESS('\n===== æ•°æ®åº“åºåˆ—æ™ºèƒ½é‡ç½®å®Œæ¯• ====='))

####æ–‡ä»¶ç»“æŸ####

####data_manager\service\corporate_action_service.py####
import logging
import time
from datetime import datetime

import akshare
import pandas as pd
from django.db import transaction

# å¯¼å…¥æ‚¨çš„ Django models
# è¯·æ ¹æ®æ‚¨çš„é¡¹ç›®ç»“æ„è°ƒæ•´ä»¥ä¸‹å¯¼å…¥è·¯å¾„
from common.models.corporate_action import CorporateAction
from common.models.stock_info import StockInfo

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
class CorporateActionService:
    def _fetch_and_save_split_events(self,stock_codes_filter: list, start_date: str, end_date: str):
        """
        é¢„ç•™çš„æ‹†è‚¡/å¹¶è‚¡äº‹ä»¶å¤„ç†å‡½æ•°ã€‚
        """
        # logger.info(f"æ­£åœ¨æ£€æŸ¥æ‹†è‚¡/å¹¶è‚¡äº‹ä»¶ (å½“å‰ç‰ˆæœ¬æš‚æœªå®ç°)...")
        pass

    def sync_corporate_actions(self,start_date: str, end_date: str, stock_codes: list = None):
        """
        ä» Akshare é«˜æ•ˆåŒæ­¥æŒ‡å®šæ—¥æœŸèŒƒå›´å’Œè‚¡ç¥¨èŒƒå›´çš„è‚¡æƒäº‹ä»¶æ•°æ®ï¼Œå¹¶å­˜å…¥æ•°æ®åº“ã€‚
        """
        logger.info(f"å¼€å§‹åŒæ­¥è‚¡æƒäº‹ä»¶ï¼Œæ—¥æœŸèŒƒå›´: {start_date} to {end_date}ã€‚")
        if stock_codes:
            logger.info(f"ç›®æ ‡è‚¡ç¥¨: {len(stock_codes)} åªã€‚")
        else:
            logger.info("ç›®æ ‡è‚¡ç¥¨: å…¨éƒ¨Aè‚¡ã€‚")

        # 1. ä»»åŠ¡å¼€å§‹å‰ï¼Œä¸€æ¬¡æ€§æ¸…ç†æ•°æ®
        try:
            with transaction.atomic():
                qs = CorporateAction.objects.filter(
                    ex_dividend_date__gte=start_date,
                    ex_dividend_date__lte=end_date
                )
                if stock_codes:
                    qs = qs.filter(stock_code__in=stock_codes)
                
                deleted_count, _ = qs.delete()
                logger.info(f"æ•°æ®æ¸…ç†å®Œæˆã€‚åœ¨ {start_date} åˆ° {end_date} èŒƒå›´å†…å…±åˆ é™¤ {deleted_count} æ¡æ—§è®°å½•ã€‚")
        except Exception as e:
            logger.error(f"æ¸…ç†å†å²æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä»»åŠ¡ç»ˆæ­¢: {e}", exc_info=True)
            return

        all_stocks_map = {s.split('.')[-1]: s for s in StockInfo.objects.values_list('stock_code', flat=True)}
        ak_codes_filter = [c.split('.')[-1] for c in stock_codes] if stock_codes else None

        # 2. å¤„ç†åˆ†çº¢ã€é€è‚¡ã€è½¬è‚¡ (stock_fhps_em)
        try:
            logger.info("å¼€å§‹å¤„ç†åˆ†çº¢ã€é€è‚¡ã€è½¬è‚¡äº‹ä»¶...")
            fhps_dfs = []
            start_year = datetime.strptime(start_date, '%Y-%m-%d').year
            end_year = datetime.strptime(end_date, '%Y-%m-%d').year
            
            # â˜…â˜…â˜…â˜…â˜… ä¼˜åŒ–ç‚¹ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„å¹´ä»½èŒƒå›´ï¼Œè¦†ç›–è·¨å¹´é¢„æ¡ˆ â˜…â˜…â˜…â˜…â˜…
            report_suffixes = ["0331", "0630", "0930", "1231"]
            for year in range(start_year - 1, end_year + 1):
                for suffix in report_suffixes:
                    report_date = f"{year}{suffix}"
                    logger.info(f"æ­£åœ¨æ‹‰å–æŠ¥å‘ŠæœŸ {report_date} çš„åˆ†çº¢é€é…é¢„æ¡ˆ...")
                    try:
                        time.sleep(1)
                        fhps_df = akshare.stock_fhps_em(date=report_date)
                        if not fhps_df.empty:
                            fhps_dfs.append(fhps_df)
                    except Exception as e:
                        logger.warning(f"æ‹‰å–æŠ¥å‘ŠæœŸ {report_date} æ•°æ®å¤±è´¥æˆ–æ— æ•°æ®: {e}")
            
            if fhps_dfs:
                # ä½¿ç”¨ 'ä»£ç ' å’Œ 'é™¤æƒé™¤æ¯æ—¥' ä½œä¸ºè”åˆä¸»é”®å»é‡ï¼Œé˜²æ­¢åŒä¸€äº‹ä»¶å› åœ¨ä¸åŒæŠ¥å‘ŠæœŸæŠ«éœ²è€Œé‡å¤
                all_fhps_df = pd.concat(fhps_dfs, ignore_index=True).drop_duplicates(subset=['ä»£ç ', 'é™¤æƒé™¤æ¯æ—¥'])
                
                all_fhps_df['é™¤æƒé™¤æ¯æ—¥'] = pd.to_datetime(all_fhps_df['é™¤æƒé™¤æ¯æ—¥'], errors='coerce')
                all_fhps_df.dropna(subset=['é™¤æƒé™¤æ¯æ—¥'], inplace=True)
                
                mask = (all_fhps_df['é™¤æƒé™¤æ¯æ—¥'] >= pd.to_datetime(start_date)) & (all_fhps_df['é™¤æƒé™¤æ¯æ—¥'] <= pd.to_datetime(end_date))
                filtered_fhps_df = all_fhps_df[mask].copy()

                if ak_codes_filter:
                    filtered_fhps_df = filtered_fhps_df[filtered_fhps_df['ä»£ç '].isin(ak_codes_filter)]

                logger.info(f"å…±è·å–åˆ° {len(filtered_fhps_df)} æ¡ç¬¦åˆæ¡ä»¶çš„åˆ†çº¢é€è½¬è®°å½•ï¼Œå‡†å¤‡å…¥åº“...")

                with transaction.atomic():
                    for _, row in filtered_fhps_df.iterrows():
                        ak_code = row['ä»£ç ']
                        stock_code_prefixed = all_stocks_map.get(ak_code)
                        if not stock_code_prefixed:
                            continue

                        # åˆ†çº¢
                        if pd.notna(row['ç°é‡‘åˆ†çº¢-ç°é‡‘åˆ†çº¢æ¯”ä¾‹']) and row['ç°é‡‘åˆ†çº¢-ç°é‡‘åˆ†çº¢æ¯”ä¾‹'] > 0:
                            CorporateAction.objects.create(
                                stock_code=stock_code_prefixed,
                                ex_dividend_date=row['é™¤æƒé™¤æ¯æ—¥'].date(),
                                record_date=pd.to_datetime(row['è‚¡æƒç™»è®°æ—¥'], errors='coerce').date() if pd.notna(row['è‚¡æƒç™»è®°æ—¥']) else None,
                                notice_date=pd.to_datetime(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ'], errors='coerce').date() if pd.notna(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ']) else None,
                                event_type=CorporateAction.EventType.DIVIDEND,
                                dividend_per_share=row['ç°é‡‘åˆ†çº¢-ç°é‡‘åˆ†çº¢æ¯”ä¾‹'] / 10
                            )

                        # é€è‚¡
                        if pd.notna(row['é€è½¬è‚¡ä»½-é€è½¬æ¯”ä¾‹']) and row['é€è½¬è‚¡ä»½-é€è½¬æ¯”ä¾‹'] > 0:
                            CorporateAction.objects.create(
                                stock_code=stock_code_prefixed,
                                ex_dividend_date=row['é™¤æƒé™¤æ¯æ—¥'].date(),
                                record_date=pd.to_datetime(row['è‚¡æƒç™»è®°æ—¥'], errors='coerce').date() if pd.notna(row['è‚¡æƒç™»è®°æ—¥']) else None,
                                notice_date=pd.to_datetime(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ'], errors='coerce').date() if pd.notna(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ']) else None,
                                event_type=CorporateAction.EventType.BONUS,
                                shares_before=10,
                                shares_after=10 + row['é€è½¬è‚¡ä»½-é€è½¬æ¯”ä¾‹']
                            )

                        # è½¬è‚¡
                        if pd.notna(row['é€è½¬è‚¡ä»½-è½¬è‚¡æ¯”ä¾‹']) and row['é€è½¬è‚¡ä»½-è½¬è‚¡æ¯”ä¾‹'] > 0:
                            CorporateAction.objects.create(
                                stock_code=stock_code_prefixed,
                                ex_dividend_date=row['é™¤æƒé™¤æ¯æ—¥'].date(),
                                record_date=pd.to_datetime(row['è‚¡æƒç™»è®°æ—¥'], errors='coerce').date() if pd.notna(row['è‚¡æƒç™»è®°æ—¥']) else None,
                                notice_date=pd.to_datetime(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ'], errors='coerce').date() if pd.notna(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ']) else None,
                                event_type=CorporateAction.EventType.TRANSFER,
                                shares_before=10,
                                shares_after=10 + row['é€è½¬è‚¡ä»½-è½¬è‚¡æ¯”ä¾‹']
                            )
            logger.info("åˆ†çº¢ã€é€è‚¡ã€è½¬è‚¡äº‹ä»¶å¤„ç†å®Œæˆã€‚")
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†çº¢é€è½¬æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)

        # 3. å¤„ç†é…è‚¡ (stock_pg_em)
        try:
            logger.info("å¼€å§‹å¤„ç†é…è‚¡äº‹ä»¶...")
            time.sleep(1)
            all_pg_df = akshare.stock_pg_em()
            
            # Akshare è¿”å›çš„ 'è‚¡æƒç™»è®°æ—¥' å¯èƒ½åŒ…å«æ— æ•ˆæ—¥æœŸï¼Œéœ€è¦å¤„ç†
            all_pg_df['è‚¡æƒç™»è®°æ—¥'] = pd.to_datetime(all_pg_df['è‚¡æƒç™»è®°æ—¥'], errors='coerce')
            all_pg_df.dropna(subset=['è‚¡æƒç™»è®°æ—¥'], inplace=True)
 
            mask = (all_pg_df['è‚¡æƒç™»è®°æ—¥'] >= pd.to_datetime(start_date)) & (all_pg_df['è‚¡æƒç™»è®°æ—¥'] <= pd.to_datetime(end_date))
            filtered_pg_df = all_pg_df[mask].copy()
 
            if ak_codes_filter:
                filtered_pg_df = filtered_pg_df[filtered_pg_df['è‚¡ç¥¨ä»£ç '].isin(ak_codes_filter)]
            
            logger.info(f"å…±è·å–åˆ° {len(filtered_pg_df)} æ¡ç¬¦åˆæ¡ä»¶çš„é…è‚¡è®°å½•ï¼Œå‡†å¤‡å…¥åº“...")
 
            with transaction.atomic():
                for _, row in filtered_pg_df.iterrows():
                    ak_code = row['è‚¡ç¥¨ä»£ç ']
                    stock_code_prefixed = all_stocks_map.get(ak_code)
                    if not stock_code_prefixed:
                        continue
 
                    # --- ä¿®æ”¹å¼€å§‹ ---
                    # ä» '10é…3.0' è¿™æ ·çš„å­—ç¬¦ä¸²ä¸­è§£æå‡ºé…è‚¡æ¯”ä¾‹æ•°å€¼
                    rights_ratio_val = 0
                    rights_ratio_str = row['é…è‚¡æ¯”ä¾‹']
                    
                    # ç¡®ä¿ 'é…è‚¡æ¯”ä¾‹' æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ã€å¯è§£æçš„å­—ç¬¦ä¸²
                    if pd.notna(rights_ratio_str) and isinstance(rights_ratio_str, str) and 'é…' in rights_ratio_str:
                        try:
                            # æŒ‰ 'é…' åˆ†å‰²ï¼Œå–åé¢çš„éƒ¨åˆ†ï¼Œå¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                            ratio_str_part = rights_ratio_str.split('é…')[1]
                            rights_ratio_val = float(ratio_str_part)
                        except (IndexError, ValueError) as e:
                            logger.warning(f"æ— æ³•è§£æè‚¡ç¥¨ {ak_code} çš„é…è‚¡æ¯”ä¾‹ '{rights_ratio_str}'ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯: {e}")
                            continue # è·³è¿‡æ­¤æ¡è®°å½•
 
                    if rights_ratio_val > 0:
                        CorporateAction.objects.create(
                            stock_code=stock_code_prefixed,
                            # æ³¨æ„ï¼šé…è‚¡é€šå¸¸ä½¿ç”¨ 'è‚¡æƒç™»è®°æ—¥' ä½œä¸ºå…³é”®æ—¥æœŸï¼Œ'é™¤æƒæ—¥' åœ¨æ­¤æ¥å£ä¸­å¯èƒ½ä¸æä¾›
                            ex_dividend_date=row['è‚¡æƒç™»è®°æ—¥'].date(), 
                            record_date=row['è‚¡æƒç™»è®°æ—¥'].date(),
                            notice_date=None, # akshare.stock_pg_em() æœªæä¾›å…¬å‘Šæ—¥æœŸ
                            event_type=CorporateAction.EventType.RIGHTS,
                            shares_before=10, # é…è‚¡åŸºå‡†é€šå¸¸æ˜¯10è‚¡
                            shares_after=10 + rights_ratio_val, # ä½¿ç”¨è§£æåçš„æ•°å€¼
                            rights_issue_price=row['é…è‚¡ä»·']
                        )
                    # --- ä¿®æ”¹ç»“æŸ ---
 
            logger.info("é…è‚¡äº‹ä»¶å¤„ç†å®Œæˆã€‚")
        except KeyError as e:
            # æ•è· 'é…è‚¡æ¯”ä¾‹' ç­‰å­—æ®µä¸å­˜åœ¨çš„é”™è¯¯
            logger.error(f"å¤„ç†é…è‚¡æ•°æ®æ—¶å‘ç”Ÿå­—æ®µç¼ºå¤±é”™è¯¯: {e}ã€‚è¯·æ£€æŸ¥ Akshare è¿”å›çš„æ•°æ®åˆ—åæ˜¯å¦å·²å˜æ›´ã€‚", exc_info=True)
        except Exception as e:
            logger.error(f"å¤„ç†é…è‚¡æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)

        # 4. è°ƒç”¨é¢„ç•™çš„æ‹†è‚¡/å¹¶è‚¡å¤„ç†å‡½æ•°
        self._fetch_and_save_split_events(stock_codes, start_date, end_date)

        logger.info("æ‰€æœ‰è‚¡æƒäº‹ä»¶åŒæ­¥ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆã€‚")

####æ–‡ä»¶ç»“æŸ####

####data_manager\service\db_service.py####
# data_manager/service/db_service.py

import logging
import time
import pandas as pd
from sqlalchemy import create_engine, text
from django.apps import apps
from django.db import connections
from django.conf import settings
from collections import deque

logger = logging.getLogger(__name__)

class DbMigrationService:
    """
    ä¸€ä¸ªå¥å£®çš„æœåŠ¡ï¼Œç”¨äºå°†æ•°æ®ä»æºæ•°æ®åº“ï¼ˆSQLiteï¼‰è¿ç§»åˆ°ç›®æ ‡æ•°æ®åº“ï¼ˆPostgreSQLï¼‰ã€‚
    å®ƒèƒ½è‡ªåŠ¨å¤„ç†è¡¨ä¾èµ–å…³ç³»ï¼Œå¹¶ä½¿ç”¨åˆ†å—è¯»å†™æ¥å¤„ç†å¤§æ•°æ®è¡¨ã€‚
    """
    def __init__(self):
        # ä» Django settings è·å–ç›®æ ‡æ•°æ®åº“é…ç½®
        pg_config = settings.DATABASES['default']
        self.pg_uri = f"postgresql+psycopg2://{pg_config['USER']}:{pg_config['PASSWORD']}@{pg_config['HOST']}:{pg_config['PORT']}/{pg_config['NAME']}"
        
        # æºæ•°æ®åº“è·¯å¾„
        sqlite_path = settings.BASE_DIR / 'mainDB.sqlite3'
        self.sqlite_uri = f"sqlite:///{sqlite_path}"
        
        self.chunk_size = 50000  # æ¯æ¬¡å¤„ç†5ä¸‡è¡Œï¼Œé˜²æ­¢å†…å­˜æº¢å‡º

    def _get_migration_order(self) -> list:
        """
        é€šè¿‡æ‹“æ‰‘æ’åºåˆ†æ Django æ¨¡å‹ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç”Ÿæˆæ­£ç¡®çš„è¿ç§»é¡ºåºã€‚
        çˆ¶è¡¨ï¼ˆè¢«å¤–é”®å¼•ç”¨çš„è¡¨ï¼‰ä¼šæ’åœ¨å­è¡¨ï¼ˆæœ‰å¤–é”®çš„è¡¨ï¼‰å‰é¢ã€‚
        """
        all_models = apps.get_models()
        model_map = {model: model._meta.db_table for model in all_models}
        
        # æ„å»ºä¾èµ–å›¾å’Œå…¥åº¦è®¡æ•°
        dependencies = {model: set() for model in all_models}
        in_degree = {model: 0 for model in all_models}

        for model in all_models:
            for field in model._meta.get_fields():
                if field.is_relation and field.many_to_one and field.related_model in model_map:
                    # å¦‚æœ model ä¾èµ–äº related_model
                    related_model = field.related_model
                    if model in dependencies[related_model]:
                        continue
                    dependencies[related_model].add(model)
                    in_degree[model] += 1
        
        # æ‹“æ‰‘æ’åº
        queue = deque([model for model in all_models if in_degree[model] == 0])
        sorted_models = []
        
        while queue:
            model = queue.popleft()
            sorted_models.append(model)
            
            for dependent_model in dependencies[model]:
                in_degree[dependent_model] -= 1
                if in_degree[dependent_model] == 0:
                    queue.append(dependent_model)

        if len(sorted_models) != len(all_models):
            raise Exception("æ•°æ®åº“æ¨¡å‹å­˜åœ¨å¾ªç¯ä¾èµ–ï¼Œæ— æ³•è¿›è¡Œæ‹“æ‰‘æ’åºï¼")
            
        logger.info(f"è®¡ç®—å‡ºæ¨¡å‹è¿ç§»é¡ºåº: {[model._meta.db_table for model in sorted_models]}")
        return sorted_models

    def migrate(self):
        """
        æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“è¿ç§»æµç¨‹ã€‚
        """
        logger.info("===== å¼€å§‹æ•°æ®åº“è¿ç§»ï¼šSQLite -> PostgreSQL =====")
        start_total_time = time.time()

        try:
            migration_order = self._get_migration_order()
            
            source_engine = create_engine(self.sqlite_uri)
            target_engine = create_engine(self.pg_uri)

            with target_engine.connect() as pg_conn:
                for model in migration_order:
                    if not(model._meta.db_table =='tb_daily_factor_values' or model._meta.db_table =='tb_daily_trading_plan' or model._meta.db_table =='tb_trade_log'):
                        logger.info(f"è·³è¿‡è¡¨ {model}")
                        continue
                    else:
                        logger.info(f"æ‰§è¡Œè¡¨ {model}")
                    table_name = model._meta.db_table
                    logger.info(f"--- æ­£åœ¨è¿ç§»è¡¨: {table_name} ---")
                    start_table_time = time.time()

                    try:
                        # 1. æ¸…ç©ºç›®æ ‡è¡¨å¹¶é‡ç½®è‡ªå¢IDï¼Œä¿è¯å¹‚ç­‰æ€§
                        logger.info(f"æ¸…ç©ºç›®æ ‡è¡¨ {table_name}...")
                        # ä½¿ç”¨ text() æ¥ç¡®ä¿SQLè¯­å¥è¢«æ­£ç¡®å¤„ç†
                        truncate_sql = text(f'TRUNCATE TABLE public."{table_name}" RESTART IDENTITY CASCADE;')
                        pg_conn.execute(truncate_sql)
                        pg_conn.commit() # TRUNCATE éœ€è¦æ˜¾å¼æäº¤

                        # 2. åˆ†å—è¯»å–æºæ•°æ®å¹¶å†™å…¥ç›®æ ‡åº“
                        query = f'SELECT * FROM "{table_name}";'
                        total_rows = 0
                        for chunk_df in pd.read_sql_query(query, source_engine, chunksize=self.chunk_size):
                            
                            # ä¿®æ­£æ•°æ®ç±»å‹é—®é¢˜ï¼šPandasæœ‰æ—¶ä¼šå°†boolè½¬ä¸ºintï¼Œéœ€è¦è½¬å›æ¥
                            for col in chunk_df.columns:
                                model_field = model._meta.get_field(col)
                                if model_field.get_internal_type() == 'BooleanField':
                                    chunk_df[col] = chunk_df[col].astype(bool)

                            chunk_df.to_sql(
                                name=table_name,
                                con=target_engine,
                                if_exists='append',
                                index=False,
                                method='multi',
                                schema='public' # æ˜¾å¼æŒ‡å®š schema
                            )
                            total_rows += len(chunk_df)
                            logger.info(f"å·²è¿ç§» {total_rows} è¡Œ...")
                        
                        table_duration = time.time() - start_table_time
                        logger.info(f"è¡¨ {table_name} è¿ç§»å®Œæˆï¼Œå…± {total_rows} è¡Œï¼Œè€—æ—¶ {table_duration:.2f} ç§’ã€‚")

                    except Exception as e:
                        logger.error(f"è¿ç§»è¡¨ {table_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                        pg_conn.rollback() # å¦‚æœå‡ºé”™åˆ™å›æ»š
                        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä¸­æ–­æ•´ä¸ªè¿ç§»è¿‡ç¨‹

        except Exception as e:
            logger.critical(f"æ•°æ®åº“è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä»»åŠ¡ç»ˆæ­¢: {e}", exc_info=True)
            return

        total_duration = time.time() - start_total_time
        logger.info(f"===== æ•°æ®åº“è¿ç§»æˆåŠŸå®Œæˆï¼æ€»è€—æ—¶: {total_duration:.2f} ç§’ =====")


####æ–‡ä»¶ç»“æŸ####

####data_manager\service\email_handler.py####
# data_manager/service/email_handler.py

import smtplib
import logging
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.header import Header

logger = logging.getLogger(__name__)

class EmailHandler:
    """
    ä¸€ä¸ªé€šç”¨çš„é‚®ä»¶å‘é€å¤„ç†å™¨ã€‚
    å®ƒå°è£…äº†SMTPåè®®çš„ç»†èŠ‚ï¼Œåªå‘ä¸Šå±‚æä¾›ä¸€ä¸ªç®€å•çš„send_emailæ¥å£ã€‚
    æ‰€æœ‰é…ç½®é¡¹éƒ½åœ¨ç±»çš„èµ·å§‹åŒºåŸŸå®šä¹‰ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†ã€‚
    """

    # ==========================================================================
    # SMTP é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„é‚®ç®±æœåŠ¡å•†å¡«å……ä»¥ä¸‹ä¿¡æ¯
    # å¼ºçƒˆå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å®‰å…¨çš„é…ç½®ç®¡ç†æ–¹å¼ï¼Œè€Œéç¡¬ç¼–ç 
    # å¯¹äºå¤šæ•°é‚®ç®±ï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨â€œåº”ç”¨ä¸“ç”¨å¯†ç â€è€Œéæ‚¨çš„ç™»å½•å¯†ç 
    # ==========================================================================
    SMTP_SERVER = 'smtp.qq.com'  # ä¾‹å¦‚: 'smtp.qq.com' æˆ– 'smtp.gmail.com'
    SMTP_PORT = 465                   # SSLåŠ å¯†ç«¯å£é€šå¸¸ä¸º 465
    SMTP_USER = '876858298@qq.com' # æ‚¨çš„é‚®ç®±ç™»å½•è´¦å·
    SMTP_PASSWORD = 'eoyktuuifrmxbdba'  # æ‚¨çš„é‚®ç®±æˆæƒç æˆ–å¯†ç 
    SENDER_EMAIL = '876858298@qq.com' # å‘ä»¶äººé‚®ç®±åœ°å€
    SENDER_NAME = 'é‡åŒ–äº¤æ˜“é¢„æ¡ˆæ¨é€'          # å‘ä»¶äººæ˜¾ç¤ºåç§°
    # ==========================================================================

    def send_email(self, recipients: list[str], subject: str, html_content: str) -> bool:
        """
        å‘é€ä¸€å°HTMLæ ¼å¼çš„é‚®ä»¶ç»™ä¸€ä¸ªæˆ–å¤šä¸ªæ”¶ä»¶äººã€‚

        :param recipients: ç›®æ ‡é‚®ç®±åœ°å€çš„åˆ—è¡¨, e.g., ['user1@example.com', 'user2@example.com']
        :param subject: é‚®ä»¶ä¸»é¢˜
        :param html_content: é‚®ä»¶æ­£æ–‡ (HTMLæ ¼å¼)
        :return: True å¦‚æœå‘é€æˆåŠŸ, False å¦‚æœå¤±è´¥
        """
        if not all([self.SMTP_SERVER, self.SMTP_PORT, self.SMTP_USER, self.SMTP_PASSWORD, self.SENDER_EMAIL]):
            logger.critical("SMTPé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•å‘é€é‚®ä»¶ã€‚è¯·æ£€æŸ¥ EmailHandler ä¸­çš„é…ç½®é¡¹ã€‚")
            return False

        if not recipients:
            logger.warning("æ”¶ä»¶äººåˆ—è¡¨ä¸ºç©ºï¼Œé‚®ä»¶æœªå‘é€ã€‚")
            return False

        # åˆ›å»ºä¸€ä¸ªå¸¦é™„ä»¶çš„å®ä¾‹
        message = MIMEMultipart('alternative')
        message['From'] = f'"{Header(self.SENDER_NAME, "utf-8").encode()}" <{self.SENDER_EMAIL}>'
        message['To'] = ", ".join(recipients)
        message['Subject'] = Header(subject, 'utf-8')

        # é‚®ä»¶æ­£æ–‡å†…å®¹
        html_part = MIMEText(html_content, 'html', 'utf-8')
        message.attach(html_part)
        server = None  # åˆå§‹åŒ–serverå˜é‡
        try:
            logger.info(f"å‡†å¤‡é€šè¿‡ {self.SMTP_SERVER}:{self.SMTP_PORT} å‘é€é‚®ä»¶è‡³ {recipients}...")
            
            # 1. æ‰‹åŠ¨å»ºç«‹è¿æ¥
            server = smtplib.SMTP_SSL(self.SMTP_SERVER, self.SMTP_PORT)
            server.login(self.SMTP_USER, self.SMTP_PASSWORD)
            server.sendmail(self.SENDER_EMAIL, recipients, message.as_string())
            
            logger.info(f"é‚®ä»¶å‘é€æˆåŠŸï¼ä¸»é¢˜: '{subject}'")
            return True
            
        except smtplib.SMTPException as e:
            logger.error(f"å‘é€é‚®ä»¶æ—¶å‘ç”ŸSMTPé”™è¯¯: {e}", exc_info=True)
            return False
        except Exception as e:
            logger.error(f"å‘é€é‚®ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            return False
        finally:
            # 2. åœ¨finallyå—ä¸­ç¡®ä¿å…³é—­è¿æ¥
            if server:
                try:
                    # 3. å¯¹quit()å‘½ä»¤è¿›è¡Œç‹¬ç«‹çš„å¼‚å¸¸å¤„ç†
                    server.quit()
                except smtplib.SMTPResponseException as e:
                    # ä¼˜é›…åœ°å¤„ç†æœåŠ¡å™¨æå‰å…³é—­è¿æ¥çš„æƒ…å†µ
                    logger.warning(f"å…³é—­SMTPè¿æ¥æ—¶å‘ç”Ÿå“åº”å¼‚å¸¸ (é€šå¸¸æ— å®³): {e}")
                except Exception as e:
                    logger.error(f"å…³é—­SMTPè¿æ¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)


####æ–‡ä»¶ç»“æŸ####

####data_manager\service\email_service.py####
# data_manager/service/email_service.py

import logging
from datetime import date, timedelta
from decimal import Decimal

from django.utils import timezone
from django.db import transaction

# å†…éƒ¨æ¨¡å—å¯¼å…¥
from .email_handler import EmailHandler

# Djangoæ¨¡å‹å¯¼å…¥
from common.models import (
    DailyFactorValues, DailyTradingPlan, DailyQuotes, StockInfo,
    Position, TradeLog
)
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.simulate_trade_handler import SimulateTradeHandler
from trade_manager.service.simulate_trade import SimulateTradeService


logger = logging.getLogger(__name__)

class EmailNotificationService:
    """
    å°è£…äº†åœ¨Tæ—¥ç›˜å‰ï¼ˆå¦‚9:10ï¼‰å‘æŒ‡å®šé‚®ç®±æ¨é€T-1æ—¥é¢„æ¡ˆçš„ä¸šåŠ¡é€»è¾‘ã€‚
    """

    def __init__(self, t_day: date):
        """
        åˆå§‹åŒ–é‚®ä»¶é€šçŸ¥æœåŠ¡ã€‚
        :param t_day: Tæ—¥ï¼Œå³é¢„æ¡ˆæ‰§è¡Œæ—¥ã€‚
        """
        self.t_day = t_day
        try:
            # è·å–Tæ—¥ä¹‹å‰çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºT-1æ—¥
            self.t_minus_1_day = DailyQuotes.objects.filter(
                trade_date__lt=self.t_day
            ).latest('trade_date').trade_date
        except DailyQuotes.DoesNotExist:
            raise ValueError(f"æ— æ³•æ‰¾åˆ° {self.t_day} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥(T-1)ï¼ŒæœåŠ¡æ— æ³•åˆå§‹åŒ–ã€‚")

        self.email_handler = EmailHandler()
        # ä»EmailHandlerçš„é…ç½®ä¸­ç›´æ¥è¯»å–æ”¶ä»¶äººåˆ—è¡¨
        self.recipients = self.email_handler.recipients if hasattr(self.email_handler, 'recipients') else ['876858298@qq.com','850696281@qq.com','285173686@qq.com','2516937525@qq.com']


    def runEmailSend(self):
        """
        ä¸€é”®æ‰§è¡Œé‚®ä»¶å‘é€çš„ä¸»æ–¹æ³•ã€‚
        """
        logger.info(f"å¼€å§‹ä¸ºTæ—¥({self.t_day})ç”Ÿæˆé¢„æ¡ˆæ¨é€é‚®ä»¶...")
        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘å…ˆæ‰¾åˆ°çœŸæ­£éœ€è¦å¤„ç†çš„é¢„æ¡ˆæ—¥æœŸ
        plan_date_to_process = self._find_latest_pending_plan_date()
        if not plan_date_to_process:
            logger.warning(f"ä»Tæ—¥({self.t_day})å›æº¯ï¼Œæœªæ‰¾åˆ°ä»»ä½•å¾…å¤„ç†çš„äº¤æ˜“é¢„æ¡ˆï¼Œé‚®ä»¶å‘é€ä»»åŠ¡ç»ˆæ­¢ã€‚")
            return
        # 1. è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
        market_data = self._get_market_regime_data()
        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘å°†æ‰¾åˆ°çš„æ—¥æœŸä¼ é€’ç»™ä¸‹ä¸€æ­¥
        plan_details = self._get_trading_plan_details(plan_date_to_process)
        if not plan_details:
            logger.warning(f"é¢„æ¡ˆæ—¥({plan_date_to_process})çš„é¢„æ¡ˆè¯¦æƒ…ä¸ºç©ºï¼Œé‚®ä»¶å‘é€ä»»åŠ¡ç»ˆæ­¢ã€‚")
            return
        # 2. ç”ŸæˆHTMLå†…å®¹
        html_content = self._format_html_content(market_data, plan_details)
        # 3. å‘é€é‚®ä»¶
        subject = f"ã€äº¤æ˜“é¢„æ¡ˆã€‘{self.t_day.strftime('%Y-%m-%d')} ç›˜å‰ç¡®è®¤ (æ•°æ®æº: {plan_date_to_process.strftime('%Y-%m-%d')})"
        self.email_handler.send_email(self.recipients, subject, html_content)

    def _get_market_regime_data(self) -> dict:
        """è·å–æ˜¨æ—¥Må€¼åŠè¿‘10æ—¥Må€¼å†å²"""
        try:
            # è·å–T-1æ—¥åŠä¹‹å‰çš„10ä¸ªäº¤æ˜“æ—¥
            trade_dates = list(DailyQuotes.objects.filter(trade_date__lte=self.t_minus_1_day)
                               .values_list('trade_date', flat=True)
                               .distinct().order_by('-trade_date')[:10])
            trade_dates.reverse()

            m_values_qs = DailyFactorValues.objects.filter(
                stock_code_id=MARKET_INDICATOR_CODE,
                factor_code_id='dynamic_M_VALUE',
                trade_date__in=trade_dates
            ).order_by('-trade_date')

            m_values_map = {fv.trade_date: fv.raw_value for fv in m_values_qs}

            yesterday_m = m_values_map.get(self.t_minus_1_day, Decimal('NaN'))
            history_m = [{'date': d, 'value': m_values_map.get(d, Decimal('NaN'))} for d in trade_dates]

            return {'yesterday_m': yesterday_m, 'history_m': history_m}

        except Exception as e:
            logger.error(f"è·å–Må€¼æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            return {'yesterday_m': Decimal('NaN'), 'history_m': []}

    def _get_trading_plan_details(self, plan_date: date) -> list[dict]:
        """è·å–Tæ—¥äº¤æ˜“é¢„æ¡ˆåŠç›¸å…³çš„æ‰€æœ‰è¯¦ç»†ä¿¡æ¯"""
        plans = DailyTradingPlan.objects.filter(plan_date=plan_date, status=DailyTradingPlan.StatusChoices.PENDING).order_by('rank')
        if not plans.exists():
            return []

        detailed_plans = []
        for plan in plans:
            stock_code = plan.stock_code_id
            logger.debug(f"æ­£åœ¨å¤„ç†é¢„æ¡ˆè‚¡ç¥¨: {stock_code}")
            try:
                # è·å–æ­¢ç›ˆæ­¢æŸç‡
                rates = self._calculate_profit_loss_rates(stock_code)
                # è·å–å†å²è¡Œæƒ…
                history = self._get_stock_historical_data(stock_code)

                detailed_plans.append({
                    'plan': plan,
                    'stock_info': plan.stock_code, # StockInfo object
                    'rates': rates,
                    'history': history
                })
            except Exception as e:
                logger.error(f"å¤„ç†è‚¡ç¥¨ {stock_code} çš„é¢„æ¡ˆè¯¦æƒ…æ—¶å¤±è´¥: {e}", exc_info=True)
                continue # è·³è¿‡è¿™ä¸ªå‡ºé”™çš„è‚¡ç¥¨

        return detailed_plans

    def _calculate_profit_loss_rates(self, stock_code: str) -> dict:
        """
        é€šè¿‡åˆ›å»ºä¸´æ—¶æ•°æ®åº“è®°å½•æ¥å¤ç”¨ç°æœ‰æ­¢ç›ˆæ­¢æŸè®¡ç®—é€»è¾‘ã€‚
        æ•´ä¸ªè¿‡ç¨‹åœ¨å•ä¸ªæ•°æ®åº“äº‹åŠ¡ä¸­å®Œæˆï¼Œç¡®ä¿å®‰å…¨ã€‚
        """
        tp_rate, sl_rate = Decimal('NaN'), Decimal('NaN')
        try:
            # ã€æ–°å¢æ­¥éª¤1ã€‘: è·å–T-1æ—¥æ”¶ç›˜ä»·ä½œä¸ºåŸºå‡†
            try:
                t_minus_1_quote = DailyQuotes.objects.get(stock_code_id=stock_code, trade_date=self.t_minus_1_day)
                base_price = t_minus_1_quote.close
                if base_price <= 0:
                    raise ValueError("T-1æ—¥æ”¶ç›˜ä»·æ— æ•ˆ")
            except DailyQuotes.DoesNotExist:
                logger.error(f"æ— æ³•æ‰¾åˆ° {stock_code} åœ¨ {self.t_minus_1_day} çš„è¡Œæƒ…æ•°æ®ï¼Œæ— æ³•è®¡ç®—æ­¢ç›ˆæ­¢æŸç‡ã€‚")
                return {'tp_rate': tp_rate, 'sl_rate': sl_rate}
            except ValueError as e:
                logger.error(f"è‚¡ç¥¨ {stock_code} åœ¨ {self.t_minus_1_day} çš„æ”¶ç›˜ä»·ä¸åˆæ³•: {e}")
                return {'tp_rate': tp_rate, 'sl_rate': sl_rate}
            with transaction.atomic():
                # ã€ä¿®æ”¹æ­¥éª¤2ã€‘: ä½¿ç”¨è·å–åˆ°çš„base_priceåˆ›å»ºä¸´æ—¶è®°å½•
                temp_position = Position.objects.create(
                    stock_code_id=stock_code,
                    entry_price=base_price, # ä½¿ç”¨T-1æ”¶ç›˜ä»·
                    quantity=100,
                    entry_datetime=timezone.now(),
                    status=Position.StatusChoices.OPEN,
                    current_stop_loss=Decimal('0.00'),
                    current_take_profit=Decimal('0.00')
                )
                temp_trade_log = TradeLog.objects.create(
                    position=temp_position,
                    stock_code_id=stock_code,
                    trade_datetime=timezone.now(),
                    trade_type=TradeLog.TradeTypeChoices.BUY,
                    status=TradeLog.StatusChoices.FILLED,
                    price=base_price, # ä½¿ç”¨T-1æ”¶ç›˜ä»·
                    quantity=100,
                    commission=0,
                    stamp_duty=0
                )
                # è°ƒç”¨æœåŠ¡è¿›è¡Œè®¡ç®— (è¿™éƒ¨åˆ†ä¸å˜)
                dummy_sim_service = SimulateTradeService()
                dummy_handler = SimulateTradeHandler(dummy_sim_service)
                decision_service = DecisionOrderService(handler=dummy_handler, execution_date=self.t_day)
                decision_service.calculate_stop_profit_loss(trade_id=temp_trade_log.trade_id)
                temp_position.refresh_from_db()
                # ã€ä¿®æ”¹æ­¥éª¤3ã€‘: ä½¿ç”¨base_priceä½œä¸ºåˆ†æ¯è®¡ç®—æ¯”ç‡
                take_profit_price = temp_position.current_take_profit
                stop_loss_price = temp_position.current_stop_loss
                if take_profit_price > 0:
                    tp_rate = (take_profit_price / base_price) - 1
                if stop_loss_price > 0:
                    sl_rate = 1 - (stop_loss_price / base_price)
                # å›æ»šäº‹åŠ¡ï¼Œæ¸…é™¤ä¸´æ—¶æ•°æ® (è¿™éƒ¨åˆ†ä¸å˜)
                transaction.set_rollback(True)
        except Exception as e:
            logger.error(f"ä¸º {stock_code} è®¡ç®—æ­¢ç›ˆæ­¢æŸç‡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            transaction.set_rollback(True)
        logger.debug(f"{stock_code} (åŸºå‡†ä»·: {base_price:.2f}) -> TP Rate: {tp_rate:.4%}, SL Rate: {sl_rate:.4%}")
        return {'tp_rate': tp_rate, 'sl_rate': sl_rate}


    def _get_stock_historical_data(self, stock_code: str) -> list[dict]:
        """è·å–æŒ‡å®šè‚¡ç¥¨è¿‘10ä¸ªäº¤æ˜“æ—¥çš„å†å²è¡Œæƒ…"""
        trade_dates = list(DailyQuotes.objects.filter(trade_date__lte=self.t_minus_1_day)
                           .values_list('trade_date', flat=True)
                           .distinct().order_by('-trade_date')[:10])
        trade_dates.reverse()

        quotes = DailyQuotes.objects.filter(
            stock_code_id=stock_code,
            trade_date__in=trade_dates
        ).order_by('trade_date')

        history = []
        prev_close = None
        for quote in quotes:
            change_pct = Decimal('0.0')
            if prev_close and prev_close > 0:
                change_pct = (quote.close / prev_close) - 1
            
            history.append({
                'date': quote.trade_date,
                'open': quote.open,
                'high': quote.high,
                'low': quote.low,
                'close': quote.close,
                'hfq_close': quote.hfq_close,
                'change_pct': change_pct
            })
            prev_close = quote.close
        return history

    def _format_html_content(self, market_data: dict, plan_details: list[dict]) -> str:
        """å°†æ‰€æœ‰æ•°æ®æ ¼å¼åŒ–ä¸ºç¾è§‚çš„HTMLå­—ç¬¦ä¸²"""
        
        # --- CSSæ ·å¼ ---
        style = """
        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; line-height: 1.6; color: #333; background-color: #f8f9fa; margin: 0; padding: 20px; }
            .container { max-width: 800px; margin: auto; background: #fff; padding: 25px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
            h2 { color: #0056b3; border-bottom: 2px solid #0056b3; padding-bottom: 10px; margin-top: 30px; }
            h3 { color: #17a2b8; margin-top: 25px; }
            table { width: 100%; border-collapse: collapse; margin-top: 15px; font-size: 14px; }
            th, td { border: 1px solid #dee2e6; padding: 10px; text-align: left; }
            th { background-color: #e9ecef; font-weight: 600; }
            tr:nth-child(even) { background-color: #f8f9fa; }
            .summary { font-size: 16px; font-weight: bold; margin-bottom: 20px; }
            .red { color: #dc3545; }
            .green { color: #28a745; }
            .footer { margin-top: 30px; font-size: 12px; color: #6c757d; text-align: center; }
        </style>
        """

        # --- HTMLå¤´éƒ¨ ---
        html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <title>äº¤æ˜“é¢„æ¡ˆç¡®è®¤</title>
            {style}
        </head>
        <body>
            <div class="container">
                <h2>Tæ—¥ ({self.t_day.strftime('%Y-%m-%d')}) äº¤æ˜“é¢„æ¡ˆç›˜å‰ç¡®è®¤</h2>
        """

        # --- å¤§ç›˜æƒ…å†µ ---
        yesterday_m_str = f"{market_data['yesterday_m']:.4f}" if not market_data['yesterday_m'].is_nan() else "N/A"
        html += f"""
        <h3>[å¤§ç›˜æƒ…å†µ]</h3>
        <p class="summary">æ˜¨æ—¥Må€¼: <span class="{'red' if market_data.get('yesterday_m', 0) > 0 else 'green'}">{yesterday_m_str}</span></p>
        <table>
            <thead><tr><th>æ—¥æœŸ</th><th>Må€¼</th></tr></thead>
            <tbody>
        """
        for item in reversed(market_data['history_m']):
            m_val_str = f"{item['value']:.4f}" if not item['value'].is_nan() else "N/A"
            html += f"<tr><td>{item['date'].strftime('%Y-%m-%d')}</td><td>{m_val_str}</td></tr>"
        html += "</tbody></table>"

        # --- é€‰è‚¡é¢„æ¡ˆ ---
        html += "<h3>[é€‰è‚¡é¢„æ¡ˆ]</h3>"
        html += """
        <table>
            <thead>
                <tr>
                    <th>æ’å</th>
                    <th>è‚¡ç¥¨ä»£ç </th>
                    <th>è‚¡ç¥¨åç§°</th>
                    <th>å¯æ¥å—å¼€ç›˜åŒºé—´</th>
                    <th>é€‰è‚¡å¾—åˆ†</th>
                    <th>é¢„æœŸæ­¢ç›ˆç‡</th>
                    <th>é¢„æœŸæ­¢æŸç‡</th>
                </tr>
            </thead>
            <tbody>
        """
        for detail in plan_details:
            plan = detail['plan']
            stock_info = detail['stock_info']
            rates = detail['rates']
            tp_rate_str = f"{rates['tp_rate']:.2%}" if not rates['tp_rate'].is_nan() else "N/A"
            sl_rate_str = f"{rates['sl_rate']:.2%}" if not rates['sl_rate'].is_nan() else "N/A"
            html += f"""
            <tr>
                <td>{plan.rank}</td>
                <td>{stock_info.stock_code}</td>
                <td>{stock_info.stock_name}</td>
                <td>{plan.miop:.2f} - {plan.maop:.2f}</td>
                <td>{plan.final_score}</td>
                <td class="red">{tp_rate_str}</td>
                <td class="green">{sl_rate_str}</td>
            </tr>
            """
        html += "</tbody></table>"

        # --- å„è‚¡ç¥¨å†å²è¡Œæƒ… ---
        for detail in plan_details:
            stock_info = detail['stock_info']
            history = detail['history']
            html += f"<h4>{stock_info.stock_name} ({stock_info.stock_code}) - è¿‘10æ—¥è¡Œæƒ…</h4>"
            html += """
            <table>
                <thead>
                    <tr>
                        <th>æ—¥æœŸ</th>
                        <th>å¼€ç›˜ä»·</th>
                        <th>æœ€é«˜ä»·</th>
                        <th>æœ€ä½ä»·</th>
                        <th>æ”¶ç›˜ä»·</th>
                        <th>åå¤æƒæ”¶ç›˜</th>
                        <th>æ¶¨å¹…</th>
                    </tr>
                </thead>
                <tbody>
            """
            for item in reversed(history):
                color_class = 'red' if item['change_pct'] > 0 else ('green' if item['change_pct'] < 0 else '')
                html += f"""
                <tr>
                    <td>{item['date'].strftime('%Y-%m-%d')}</td>
                    <td>{item['open']:.2f}</td>
                    <td>{item['high']:.2f}</td>
                    <td>{item['low']:.2f}</td>
                    <td>{item['close']:.2f}</td>
                    <td>{item['hfq_close']:.4f}</td>
                    <td class="{color_class}">{item['change_pct']:.2%}</td>
                </tr>
                """
            html += "</tbody></table>"

        # --- HTMLå°¾éƒ¨ ---
        html += """
                <p class="footer">æœ¬é‚®ä»¶ç”±ç­–ç•¥äº¤æ˜“ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œè¯·åœ¨äº¤æ˜“å‰æœ€ç»ˆç¡®è®¤ã€‚</p>
            </div>
        </body>
        </html>
        """
        return html
    def _find_latest_pending_plan_date(self) -> date | None:
        """ä»Tæ—¥å¼€å§‹å‘å‰å›æº¯ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„ä¸€ä¸ªåŒ…å«å¾…æ‰§è¡Œé¢„æ¡ˆçš„æ—¥æœŸ"""
        # è®¾ç½®ä¸€ä¸ªåˆç†çš„å›æº¯ä¸Šé™ï¼Œä¾‹å¦‚14å¤©
        for i in range(14):
            check_date = self.t_day - timedelta(days=i)
            if DailyTradingPlan.objects.filter(
                plan_date=check_date,
                status=DailyTradingPlan.StatusChoices.PENDING
            ).exists():
                logger.info(f"æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆï¼Œé¢„æ¡ˆç”Ÿæˆæ—¥ä¸º: {check_date}")
                return check_date
        logger.warning(f"åœ¨è¿‡å»14å¤©å†…æœªæ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚")
        return None

####æ–‡ä»¶ç»“æŸ####

####data_manager\service\stock_service.py####
import logging
import datetime
from decimal import Decimal, ROUND_HALF_UP,InvalidOperation
import akshare as ak
import pandas as pd
from django.utils import timezone
from django.db import connection,transaction, DatabaseError

# å¯¼å…¥æ‚¨çš„Djangoæ¨¡å‹
from common.models.stock_info import StockInfo
from common.models.daily_quotes import DailyQuotes
from common.models.factor_definitions import FactorDefinitions
from common.models.daily_factor_values import DailyFactorValues
from common.models.strategy_parameters import StrategyParameters
from common.models.daily_trading_plan import DailyTradingPlan
from common.models.positions import Position
from common.models.trade_log import TradeLog
from common.models.system_log import SystemLog
from common.models.index_quotes_csi300 import IndexQuotesCsi300
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# è·å–loggerå®ä¾‹
logger = logging.getLogger(__name__)

# å®šä¹‰æ¨¡å—å¸¸é‡ï¼Œä¾¿äºç»´æŠ¤
MODULE_NAME = 'data_manager'

class StockService:
    """
    å°è£…äº†ä¸è‚¡ç¥¨æ•°æ®ç›¸å…³çš„æœåŠ¡ï¼ŒåŒ…æ‹¬ä»akshareæ›´æ–°æ•°æ®å’Œä»æœ¬åœ°æ•°æ®åº“æŸ¥è¯¢æ•°æ®ã€‚
  
    ä½¿ç”¨ç¤ºä¾‹ (åœ¨Django views.py æˆ– management commandä¸­):
  
    from .services.stock_service import StockService
  
    def my_view(request):
        service = StockService()
      
        # ç¤ºä¾‹1: æ›´æ–°æ‰€æœ‰Aè‚¡ä»Šå¤©çš„è¡Œæƒ…
        service.update_local_a_shares()
      
        # ç¤ºä¾‹2: æ›´æ–°æŒ‡å®šå‡ åªè‚¡ç¥¨æŸæ—¶é—´æ®µçš„è¡Œæƒ…
        codes = ['sh.600519', 'sz.000001']
        service.update_local_a_shares(stock_codes=codes, start_date='2023-01-01', end_date='2023-01-31')
      
        # ç¤ºä¾‹3: æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯
        stock_infos = service.query_stock_info(stock_codes=codes)
      
        # ç¤ºä¾‹4: æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨ä»Šå¤©çš„æ—¥çº¿è¡Œæƒ…
        daily_quotes = service.query_daily_quotes()
    """

    def _log_and_save(self, message: str, level: str = SystemLog.LogLevelChoices.INFO):
        """
        ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œç”¨äºåŒæ—¶å‘æ ‡å‡†loggerå’Œæ•°æ®åº“ç³»ç»Ÿæ—¥å¿—è¡¨å†™å…¥æ—¥å¿—ã€‚
        """
        log_map = {
            SystemLog.LogLevelChoices.INFO: logger.info,
            SystemLog.LogLevelChoices.WARNING: logger.warning,
            SystemLog.LogLevelChoices.ERROR: logger.error,
            SystemLog.LogLevelChoices.CRITICAL: logger.critical,
        }
      
        # æ‰“å°åˆ°æ ‡å‡†æ—¥å¿—
        log_function = log_map.get(level, logger.info)
        log_function(message)
      
        # ä¿å­˜åˆ°æ•°æ®åº“
        # try:
        #     SystemLog.objects.create(
        #         log_level=level,
        #         module_name=MODULE_NAME,
        #         message=message
        #     )
        # except Exception as e:
        #     logger.error(f"æ— æ³•å°†æ—¥å¿—å†™å…¥æ•°æ®åº“: {e}")

    def _save_quotes_df_to_db(self, quotes_df: pd.DataFrame):
        """
        è¾…åŠ©æ–¹æ³•ï¼šå°†ä¸€ä¸ªDataFrameçš„è¡Œæƒ…æ•°æ®é€šè¿‡ update_or_create æ‰¹é‡å­˜å…¥æ•°æ®åº“ã€‚
        æ­¤æ–¹æ³•å…·æœ‰å¹‚ç­‰æ€§ï¼Œé€‚ç”¨äºæ‰€æœ‰æ•°æ®ï¼Œæ— éœ€åŒºåˆ†å†å²å’Œå½“æ—¥ã€‚
        """
        if quotes_df.empty:
            return
 
        # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
        quotes_df.fillna(0, inplace=True)
        quotes_df = quotes_df[(quotes_df['å¼€ç›˜'] > 0) & (quotes_df['æ”¶ç›˜'] > 0) & (quotes_df['æœ€é«˜'] > 0) & (quotes_df['æœ€ä½'] > 0) & (quotes_df['æˆäº¤é‡'] >= 0)]
        if quotes_df.empty:
            self._log_and_save("æ•°æ®æ¸…æ´—åï¼Œå½“å‰æ‰¹æ¬¡æ— æœ‰æ•ˆæ•°æ®å¯å­˜å‚¨ã€‚", level=SystemLog.LogLevelChoices.INFO)
            return
            
        quotes_df['æ—¥æœŸ'] = pd.to_datetime(quotes_df['æ—¥æœŸ']).dt.date
        
        hfq_precision = Decimal('0.0000000001')
        records_to_process = len(quotes_df)
    
        try:
            # å°†æ•´ä¸ªæ‰¹æ¬¡çš„ update_or_create æ“ä½œæ”¾åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­ï¼Œä»¥æé«˜æ€§èƒ½
            with transaction.atomic():
                for _, row in quotes_df.iterrows():
                    try:
                        close_dec = Decimal(str(row['æ”¶ç›˜']))
                        factor_dec = Decimal(str(row['å¤æƒå› å­']))
                        hfq_close_dec = (close_dec * factor_dec).quantize(hfq_precision, rounding=ROUND_HALF_UP)
                        
                        # å¯¹æ¯ä¸€è¡Œæ•°æ®éƒ½æ‰§è¡Œ update_or_create
                        DailyQuotes.objects.update_or_create(
                            stock_code_id=row['stock_code'], 
                            trade_date=row['æ—¥æœŸ'],
                            defaults={
                                'open': Decimal(str(row['å¼€ç›˜'])), 
                                'high': Decimal(str(row['æœ€é«˜'])),
                                'low': Decimal(str(row['æœ€ä½'])), 
                                'close': close_dec,
                                'volume': int(row['æˆäº¤é‡']), 
                                'turnover': Decimal(str(row['æˆäº¤é¢'])),
                                'adjust_factor': factor_dec, 
                                'hfq_close': hfq_close_dec
                            }
                        )
                    except (InvalidOperation, TypeError) as conversion_error:
                        self._log_and_save(f"è·³è¿‡ä¸€æ¡æ•°æ®è½¬æ¢å¤±è´¥çš„è®°å½•: {row['stock_code']} on {row['æ—¥æœŸ']}. Error: {conversion_error}", level=SystemLog.LogLevelChoices.WARNING)
                        continue
            
            self._log_and_save(f"é€šè¿‡ update_or_create æˆåŠŸå¤„ç†äº† {records_to_process} æ¡æ—¥çº¿æ•°æ®ã€‚")
    
        except (DatabaseError, Exception) as e:
            self._log_and_save(f"æ•°æ®æ‰¹é‡å…¥åº“é˜¶æ®µ(update_or_create)å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", level=SystemLog.LogLevelChoices.ERROR)

    def update_local_a_shares(
        self, 
        stock_codes: list[str] = None, 
        start_date: str = None, 
        end_date: str = None
    ):

        """
        1. æ›´æ–°æœ¬åœ°Aè‚¡ä¿¡æ¯ (æœ€ç»ˆç‰ˆï¼šé«˜æ•ˆã€å¥å£®)
        """
        self._log_and_save(f"å¼€å§‹æ‰§è¡ŒAè‚¡æ•°æ®æ›´æ–°ä»»åŠ¡...")
        target_codes=[]
        # --- Part 1: æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ (tb_stock_info) ---
        try:
            self._log_and_save("æ­£åœ¨ä»äº¤æ˜“æ‰€å®˜æ–¹æ•°æ®æºè·å–å…¨é‡Aè‚¡åˆ—è¡¨...")
            
            # 1. é€šè¿‡é«˜æ•ˆã€å¯é çš„æ¥å£ä¸€æ¬¡æ€§è·å–æ‰€æœ‰Aè‚¡ä¿¡æ¯
            # ä¸Šæµ·ä¸»æ¿Aè‚¡
            sh_main_df = ak.stock_info_sh_name_code(symbol="ä¸»æ¿Aè‚¡").copy()
            # ä¸Šæµ·ç§‘åˆ›æ¿
            sh_star_df = ak.stock_info_sh_name_code(symbol="ç§‘åˆ›æ¿").copy()
            # æ·±åœ³Aè‚¡
            sz_a_df = ak.stock_info_sz_name_code(symbol="Aè‚¡åˆ—è¡¨").copy()
 
            # 2. æ•°æ®é¢„å¤„ç†å’Œåˆå¹¶
            # ç»Ÿä¸€åˆ—å
            sh_main_df.rename(columns={'è¯åˆ¸ç®€ç§°': 'stock_name', 'ä¸Šå¸‚æ—¥æœŸ': 'listing_date', 'è¯åˆ¸ä»£ç ': 'code'}, inplace=True)
            sh_star_df.rename(columns={'è¯åˆ¸ç®€ç§°': 'stock_name', 'ä¸Šå¸‚æ—¥æœŸ': 'listing_date', 'è¯åˆ¸ä»£ç ': 'code'}, inplace=True)
            sz_a_df.rename(columns={'Aè‚¡ç®€ç§°': 'stock_name', 'Aè‚¡ä¸Šå¸‚æ—¥æœŸ': 'listing_date', 'Aè‚¡ä»£ç ': 'code'}, inplace=True)
 
            # æ·»åŠ å¸‚åœºå‰ç¼€
            sh_main_df['code'] = 'sh.' + sh_main_df['code']
            sh_star_df['code'] = 'sh.' + sh_star_df['code']
            sz_a_df['code'] = 'sz.' + sz_a_df['code']
 
            # åˆå¹¶ä¸ºä¸€ä¸ªDataFrame
            all_stocks_df = pd.concat([
                sh_main_df[['code', 'stock_name', 'listing_date']],
                sh_star_df[['code', 'stock_name', 'listing_date']],
                sz_a_df[['code', 'stock_name', 'listing_date']]
            ], ignore_index=True)
 
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            all_stocks_df['listing_date'] = pd.to_datetime(all_stocks_df['listing_date']).dt.date
            
            self._log_and_save(f"æˆåŠŸè·å– {len(all_stocks_df)} æ¡Aè‚¡åŸºç¡€ä¿¡æ¯ã€‚")
 
            # 3. é«˜æ•ˆçš„æ‰¹é‡å…¥åº“æ“ä½œ
            with transaction.atomic():
                existing_stocks = StockInfo.objects.in_bulk(field_name='stock_code')
                
                to_create = []
                to_update = []
 
                for _, row in all_stocks_df.iterrows():
                    code = row['code']
                    stock_obj = existing_stocks.get(code)
                    
                    if not stock_obj:
                        # å¦‚æœè‚¡ç¥¨ä¸å­˜åœ¨ï¼Œåˆ™å‡†å¤‡æ–°å»º
                        to_create.append(
                            StockInfo(
                                stock_code=code,
                                stock_name=row['stock_name'],
                                listing_date=row['listing_date'],
                                status=StockInfo.StatusChoices.LISTING
                            )
                        )
                    elif stock_obj.stock_name != row['stock_name']:
                        # å¦‚æœè‚¡ç¥¨å­˜åœ¨ä½†åç§°æœ‰å˜ï¼Œåˆ™å‡†å¤‡æ›´æ–°
                        stock_obj.stock_name = row['stock_name']
                        to_update.append(stock_obj)
 
                # æ‰¹é‡åˆ›å»º
                if to_create:
                    StockInfo.objects.bulk_create(to_create, batch_size=500)
                    self._log_and_save(f"æ‰¹é‡æ–°å¢ {len(to_create)} æ¡è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ã€‚")
                
                # æ‰¹é‡æ›´æ–°
                if to_update:
                    StockInfo.objects.bulk_update(to_update, ['stock_name'], batch_size=500)
                    self._log_and_save(f"æ‰¹é‡æ›´æ–° {len(to_update)} æ¡è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ã€‚")
 
            # å¦‚æœæœªæŒ‡å®š stock_codesï¼Œåˆ™ä½¿ç”¨è·å–åˆ°çš„æ‰€æœ‰ä»£ç è¿›è¡Œä¸‹ä¸€æ­¥
            if not stock_codes or len(stock_codes)==0:
                stock_codes = all_stocks_df['code'].tolist()
            else:
                # å¦‚æœæŒ‡å®šäº†ï¼Œåˆ™åªå¤„ç†æŒ‡å®šçš„ä»£ç 
                stock_codes = [code for code in stock_codes if code in all_stocks_df['code'].values]
            target_codes = stock_codes if stock_codes else all_stocks_df['code'].tolist()
        except Exception as e:
            self._log_and_save(f"æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", level=SystemLog.LogLevelChoices.ERROR)
            return

        # --- Part 2: æ›´æ–°æ—¥çº¿è¡Œæƒ… (ä¸²è¡Œè·å–ã€å†…å­˜æ±‡æ€»ã€æ‰¹é‡å…¥åº“) ---
        self._log_and_save(f"å¼€å§‹ä¸º {len(target_codes)} åªè‚¡ç¥¨ä¸²è¡Œè·å–æ—¥çº¿è¡Œæƒ…...")
        today_str = datetime.date.today().strftime('%Y%m%d')
        start_date_str = datetime.datetime.strptime(start_date, '%Y-%m-%d').strftime('%Y%m%d') if start_date else today_str
        end_date_str = datetime.datetime.strptime(end_date, '%Y-%m-%d').strftime('%Y%m%d') if end_date else today_str
        # å®šä¹‰æ‰¹å¤„ç†å‚æ•°
        batch_size = 50  # æ¯æ‰¹å¤„ç†50åªè‚¡ç¥¨ï¼Œå¯ä»¥æ ¹æ®ä½ çš„æœºå™¨å†…å­˜è°ƒæ•´
        batch_quotes_list = []
        # æ”¹ä¸ºä¸²è¡Œå¾ªç¯
        for i, code in enumerate(target_codes):
            ak_code = code.split('.')[1]
            logger.info(f"è¿›åº¦: [{i+1}/{len(target_codes)}] æ­£åœ¨è·å– {code}...")
            try:
                df_normal = ak.stock_zh_a_hist(symbol=ak_code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="")
                time.sleep(1.6) # å¢åŠ ç¤¼è²Œæ€§å»¶æ—¶ï¼Œé™ä½è¢«å°é£é™©
                df_hfq = ak.stock_zh_a_hist(symbol=ak_code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="hfq")
                
                if df_normal.empty or df_hfq.empty:
                    continue
 
                df = pd.merge(df_normal, df_hfq[['æ—¥æœŸ', 'æ”¶ç›˜']], on='æ—¥æœŸ', suffixes=('', '_hfq'))
                df['å¤æƒå› å­'] = df.apply(lambda row: row['æ”¶ç›˜_hfq'] / row['æ”¶ç›˜'] if row['æ”¶ç›˜'] and row['æ”¶ç›˜'] != 0 else 0, axis=1)
                df['stock_code'] = code
                batch_quotes_list.append(df)
                
                time.sleep(1.4) # å¢åŠ ç¤¼è²Œæ€§å»¶æ—¶ï¼Œé™ä½è¢«å°é£é™©
 
            except Exception as e:
                self._log_and_save(f"è·å– {code} æ—¥çº¿è¡Œæƒ…å¤±è´¥: {e}", level=SystemLog.LogLevelChoices.WARNING)
                continue
 
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹å¤„ç†å¤§å°ï¼Œæˆ–è€…å·²ç»æ˜¯æœ€åä¸€åªè‚¡ç¥¨
            if (i + 1) % batch_size == 0 or (i + 1) == len(target_codes):
                if not batch_quotes_list:
                    continue # å¦‚æœè¿™ä¸ªæ‰¹æ¬¡æ˜¯ç©ºçš„ï¼Œå°±è·³è¿‡

                self._log_and_save(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}ï¼ŒåŒ…å« {len(batch_quotes_list)} åªè‚¡ç¥¨...")
                
                # 1. åˆå¹¶å½“å‰æ‰¹æ¬¡çš„æ•°æ®
                batch_master_df = pd.concat(batch_quotes_list, ignore_index=True)
                
                # 2. å°†è¿™ä¸ªæ‰¹æ¬¡çš„æ•°æ®å­˜å…¥æ•°æ®åº“
                self._save_quotes_df_to_db(batch_master_df)
                
                # 3. æ¸…ç©ºæ‰¹æ¬¡åˆ—è¡¨ï¼Œé‡Šæ”¾å†…å­˜ï¼Œä¸ºä¸‹ä¸€æ‰¹åšå‡†å¤‡
                batch_quotes_list = []
                self._log_and_save(f"æ‰¹æ¬¡ {i//batch_size + 1} å¤„ç†å®Œæ¯•ï¼Œå†…å­˜å·²é‡Šæ”¾ã€‚")
 
        self._log_and_save("Aè‚¡æ•°æ®æ›´æ–°ä»»åŠ¡å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ã€‚")

    def query_stock_info(self, stock_codes: list[str] = None) -> dict[str, StockInfo]:
        """
        2. æŸ¥è¯¢æœ¬åœ°Aè‚¡åŸºç¡€ä¿¡æ¯
        ç›´æ¥æŸ¥è¯¢ tb_stock_infoã€‚
        """
        queryset = StockInfo.objects.all()
        if stock_codes:
            queryset = queryset.filter(stock_code__in=stock_codes)
      
        return {stock.stock_code: stock for stock in queryset}

    def query_daily_quotes(
        self, 
        stock_codes: list[str] = None, 
        start_date: str = None, 
        end_date: str = None
    ) -> dict[str, list[DailyQuotes]]:
        """
        3. æŸ¥è¯¢æœ¬åœ°Aè‚¡äº¤æ˜“ä¿¡æ¯
        ç›´æ¥æŸ¥è¯¢ tb_daily_quotesã€‚
        """
        # è®¾ç½®é»˜è®¤æ—¥æœŸä¸ºä»Šå¤©
        today = datetime.date.today()
        start_date = start_date or today.strftime('%Y-%m-%d')
        end_date = end_date or today.strftime('%Y-%m-%d')

        # ä½¿ç”¨ select_related ä¼˜åŒ–æŸ¥è¯¢ï¼Œä¸€æ¬¡æ€§è·å–å…³è”çš„ StockInfo å¯¹è±¡
        # ä½¿ç”¨ order_by ç¡®ä¿æ•°æ®æŒ‰è‚¡ç¥¨å’Œæ—¥æœŸæ’åºï¼Œä¾¿äºåç»­åˆ†ç»„
        queryset = DailyQuotes.objects.select_related('stock_code').filter(
            trade_date__gte=start_date,
            trade_date__lte=end_date
        ).order_by('stock_code', 'trade_date')

        if stock_codes:
            queryset = queryset.filter(stock_code__in=stock_codes)
      
        # æ„å»ºè¾“å‡ºå­—å…¸
        result = {}
        for quote in queryset:
            # ä½¿ç”¨ stock_code_id é¿å…å†æ¬¡è®¿é—®æ•°æ®åº“
            # setdefault æ˜¯æ„å»ºè¿™ç§åˆ†ç»„å­—å…¸çš„ä¼˜é›…æ–¹å¼
            result.setdefault(quote.stock_code_id, []).append(quote)
          
        return result

    #æ¸…ç©ºæ‰€æœ‰æ•°æ®
    def clear_all_data(self):
        with connection.cursor() as cursor:
            cursor.execute(f"DELETE FROM tb_daily_factor_values;")
            cursor.execute(f"DELETE FROM tb_daily_quotes;")
            cursor.execute(f"DELETE FROM tb_daily_trading_plan;")
            cursor.execute(f"DELETE FROM tb_factor_definitions;")
            cursor.execute(f"DELETE FROM tb_positions;")
            cursor.execute(f"DELETE FROM tb_stock_info;")
            cursor.execute(f"DELETE FROM tb_strategy_parameters;")
            cursor.execute(f"DELETE FROM tb_system_log;")
            cursor.execute(f"DELETE FROM tb_trade_log;")
    def update_csi300_index_data(self, start_date: str, end_date: str):
        """
        è·å–å¹¶æ›´æ–°æ²ªæ·±300æŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ã€‚
        """
        self._log_and_save(f"å¼€å§‹æ›´æ–°æ²ªæ·±300æŒ‡æ•°æ•°æ®ï¼ŒèŒƒå›´: {start_date} to {end_date}ã€‚")
        try:
            df = ak.index_zh_a_hist(
                symbol="000300",
                period="daily",
                start_date=start_date.replace('-', ''),
                end_date=end_date.replace('-', '')
            )
            if df.empty:
                self._log_and_save(f"åœ¨ {start_date} to {end_date} æœŸé—´æœªè·å–åˆ°æ²ªæ·±300æŒ‡æ•°æ•°æ®ã€‚", level=SystemLog.LogLevelChoices.WARNING)
                return
            df.rename(columns={
                'æ—¥æœŸ': 'trade_date', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high', 'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume', 'æˆäº¤é¢': 'amount', 'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'pct_change', 'æ¶¨è·Œé¢': 'change_amount', 'æ¢æ‰‹ç‡': 'turnover_rate'
            }, inplace=True)
            
            df['volume'] = df['volume'] * 100
            df['turnover_rate'] = pd.to_numeric(df['turnover_rate'], errors='coerce')
            with transaction.atomic():
                for _, row in df.iterrows():
                    IndexQuotesCsi300.objects.update_or_create(
                        trade_date=row['trade_date'],
                        defaults={
                            'open': Decimal(str(row['open'])), 'close': Decimal(str(row['close'])),
                            'high': Decimal(str(row['high'])), 'low': Decimal(str(row['low'])),
                            'volume': int(row['volume']), 'amount': Decimal(str(row['amount'])),
                            'amplitude': Decimal(str(row['amplitude'])), 'pct_change': Decimal(str(row['pct_change'])),
                            'change_amount': Decimal(str(row['change_amount'])),
                            'turnover_rate': Decimal(str(row['turnover_rate'])) if pd.notna(row['turnover_rate']) else None
                        }
                    )
            self._log_and_save(f"æˆåŠŸæ›´æ–° {len(df)} æ¡æ²ªæ·±300æŒ‡æ•°æ•°æ®ã€‚")
        except Exception as e:
            self._log_and_save(f"æ›´æ–°æ²ªæ·±300æŒ‡æ•°æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}", level=SystemLog.LogLevelChoices.ERROR)
####æ–‡ä»¶ç»“æŸ####

####selection_manager\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####selection_manager\admin.py####
from django.contrib import admin

# Register your models here.

####æ–‡ä»¶ç»“æŸ####

####selection_manager\apps.py####
from django.apps import AppConfig


class SelectionManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'selection_manager'

####æ–‡ä»¶ç»“æŸ####

####selection_manager\models.py####
from django.db import models

# Create your models here.

####æ–‡ä»¶ç»“æŸ####

####selection_manager\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####selection_manager\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include
from . import views
urlpatterns = [
    path('initParam', views.init_strategy),
    path('runSelection',views.run_selection)
]

####æ–‡ä»¶ç»“æŸ####

####selection_manager\views.py####
from datetime import date,datetime
from django.shortcuts import render
from django.http.response import JsonResponse
from selection_manager.service.selection_service import SelectionService
import json
from django.views.decorators.http import require_http_methods
# Create your views here.
@require_http_methods(["GET"])
def init_strategy(request):
    SelectionService.initialize_strategy()
    result={}
    return JsonResponse(result)
@require_http_methods(["POST"])
def run_selection(request):
    if request.method=='POST':
        body= json.loads(request.body)
        selection_date=datetime.strptime(body['date'], "%Y-%m-%d").date()
        service=SelectionService(selection_date,mode=body['mode'])
        service.run_selection()
        return JsonResponse({
            'type':selection_date,
            'data':json.loads(request.body)
        })
    

####æ–‡ä»¶ç»“æŸ####

####selection_manager\service\m_value_service.py####
# selection_manager/service/m_value_service.py

import logging
import json
from pathlib import Path

import numpy as np
import pandas as pd
import pandas_ta as ta
import joblib
from django.conf import settings

logger = logging.getLogger(__name__)

# ==============================================================================
#  ç‹¬ç«‹çš„å› å­è®¡ç®—å™¨ (Decoupled Factor Calculator)
#  [é‡è¦] æ­¤ç±»ä»£ç ä¸ prepare_csi300_features.py ä¸­çš„å®Œå…¨ä¸€è‡´ï¼Œä»¥å®ç°è§£è€¦ã€‚
#  å¦‚æœå› å­é€»è¾‘æ›´æ–°ï¼Œéœ€è¦åŒæ­¥ä¿®æ”¹è¿™ä¸¤ä¸ªåœ°æ–¹ã€‚
# ==============================================================================
class FactorCalculator:
    """
    ä¸€ä¸ªç‹¬ç«‹çš„ã€è§£è€¦çš„å› å­è®¡ç®—å™¨ã€‚
    å®ƒåªæ¥æ”¶ä¸€ä¸ªæ ‡å‡†çš„OHLCVA DataFrameï¼Œå¹¶è®¡ç®—æ‰€æœ‰é¢„å®šä¹‰çš„å› å­ã€‚
    """
    def __init__(self, df: pd.DataFrame):
        if not all(col in df.columns for col in ['open', 'high', 'low', 'close', 'volume', 'amount']):
            raise ValueError("è¾“å…¥DataFrameå¿…é¡»åŒ…å« 'open', 'high', 'low', 'close', 'volume', 'amount' åˆ—")
        self.df = df.copy()
        ta.Imports["verbose"] = False

    def run(self, feature_names: list) -> pd.DataFrame:
        """
        æ ¹æ®ç»™å®šçš„ç‰¹å¾åç§°åˆ—è¡¨ï¼Œè¿è¡Œæ‰€æœ‰éœ€è¦çš„å› å­è®¡ç®—ã€‚
        """
        all_factors_df = pd.DataFrame(index=self.df.index)
        
        # [åŒæ­¥] ç¡®ä¿æ­¤å¤„çš„è®¡ç®—æ–¹æ³•åˆ—è¡¨ä¸ prepare_csi300_features.py å®Œå…¨ä¸€è‡´
        calculator_methods = {
            'dynamic_ADX_CONFIRM': self._calc_adx_confirm,
            'dynamic_v2_MA_SLOPE': self._calc_v2_ma_slope,
            'dynamic_v2_MA_SCORE': self._calc_v2_ma_score,
            'dynamic_v2_CPC_Factor': self._calc_v2_cpc_factor,
            'dynamic_v2_VPCF': self._calc_v2_vpcf,
            'dynamic_BREAKOUT_PWR': self._calc_breakout_pwr,
            'dynamic_VOLUME_SURGE': self._calc_volume_surge,
            'dynamic_MOM_ACCEL': self._calc_mom_accel,
            'dynamic_RSI_OS': self._calc_rsi_os,
            'dynamic_NEG_DEV': self._calc_neg_dev,
            'dynamic_BOLL_LB': self._calc_boll_lb,
            'dynamic_LOW_VOL': self._calc_low_vol,
            'dynamic_MAX_DD': self._calc_max_dd,
            'dynamic_DOWNSIDE_RISK': self._calc_downside_risk,
            'dynamic_MACD_SIGNAL': self._calc_macd_signal,
            'dynamic_BREAKOUT_DURATION': self._calc_breakout_duration,
            # --- æ–°å¢è€Må€¼ä½“ç³»å› å­ ---
            'dynamic_Old_D': self._calc_old_d,
            'dynamic_Old_I': self._calc_old_i,
            'dynamic_Old_M': self._calc_old_m,
        }

        for factor_name in feature_names:
            if factor_name in calculator_methods:
                factor_series = calculator_methods[factor_name]()
                all_factors_df[factor_name] = factor_series
            else:
                raise ValueError(f"é¢„æµ‹æ—¶å‘ç°æœªçŸ¥ç‰¹å¾ '{factor_name}'ï¼Œæ¨¡å‹å’Œæ•°æ®å‡†å¤‡è„šæœ¬å¯èƒ½ä¸ä¸€è‡´ã€‚")
        
        return all_factors_df

    # --- å› å­è®¡ç®—æ–¹æ³• (ä¸prepareæ–‡ä»¶å®Œå…¨ç›¸åŒ) ---
    def _calc_adx_confirm(self, length=14, adx_threshold=25):
        adx_df = self.df.ta.adx(length=length, high=self.df['high'], low=self.df['low'], close=self.df['close'])
        adx_col, dmp_col, dmn_col = f'ADX_{length}', f'DMP_{length}', f'DMN_{length}'
        condition = (adx_df[adx_col] > adx_threshold) & (adx_df[dmp_col] > adx_df[dmn_col])
        return adx_df[adx_col].where(condition, 0.0).rename('dynamic_ADX_CONFIRM')

    def _calc_v2_ma_slope(self, ma_period=20, ema_period=20):
        ma = self.df['close'].rolling(window=ma_period).mean()
        ma_roc = ma.pct_change(1)
        return ma_roc.ewm(span=ema_period, adjust=False).mean().rename('dynamic_v2_MA_SLOPE')

    def _calc_v2_ma_score(self, p1=5, p2=10, p3=20):
        close = self.df['close']
        ma5 = close.rolling(window=p1).mean()
        ma10 = close.rolling(window=p2).mean()
        ma20 = close.rolling(window=p3).mean()
        spread1 = (close - ma5) / ma5.replace(0, 1e-9)
        spread2 = (ma5 - ma10) / ma10.replace(0, 1e-9)
        spread3 = (ma10 - ma20) / ma20.replace(0, 1e-9)
        return ((spread1 + spread2 + spread3) / 3.0).rename('dynamic_v2_MA_SCORE')

    def _calc_v2_cpc_factor(self, ema_period=10):
        high, low, close = self.df['high'], self.df['low'], self.df['close']
        price_range = high - low
        dcp = (2 * close - high - low) / price_range.replace(0, 1e-9)
        return dcp.ewm(span=ema_period, adjust=False).mean().rename('dynamic_v2_CPC_Factor')

    def _calc_v2_vpcf(self, s=5, l=20, n_smooth=5):
        ma_close_s = self.df['close'].rolling(window=s).mean()
        price_momentum = ma_close_s.pct_change(1)
        ma_amount_s = self.df['amount'].rolling(window=s).mean()
        ma_amount_l = self.df['amount'].rolling(window=l).mean()
        volume_level = (ma_amount_s / ma_amount_l.replace(0, 1e-9)) - 1
        daily_score = price_momentum * volume_level
        return daily_score.ewm(span=n_smooth, adjust=False).mean().rename('dynamic_v2_VPCF')

    def _calc_breakout_pwr(self, lookback=60, atr_period=14):
        high_lookback = self.df['high'].rolling(window=lookback).max().shift(1)
        atr = self.df.ta.atr(length=atr_period, high=self.df['high'], low=self.df['low'], close=self.df['close'])
        return ((self.df['close'] - high_lookback) / atr.replace(0, 1e-9)).rename('dynamic_BREAKOUT_PWR')

    def _calc_volume_surge(self, lookback=20):
        avg_amount = self.df['amount'].rolling(window=lookback).mean().shift(1)
        return (self.df['amount'] / avg_amount.replace(0, 1e-9)).rename('dynamic_VOLUME_SURGE')

    def _calc_mom_accel(self, roc_period=5, shift_period=11):
        roc = self.df['close'].pct_change(roc_period)
        roc_shifted = roc.shift(shift_period)
        return ((roc / roc_shifted.replace(0, np.nan)) - 1).rename('dynamic_MOM_ACCEL')

    def _calc_rsi_os(self, length=14):
        return self.df.ta.rsi(close=self.df['close'], length=length).rename('dynamic_RSI_OS')

    def _calc_neg_dev(self, period=60):
        ma = self.df['close'].rolling(window=period).mean()
        return ((self.df['close'] - ma) / ma.replace(0, 1e-9)).rename('dynamic_NEG_DEV')

    def _calc_boll_lb(self, length=20, std=2.0):
        boll = self.df.ta.bbands(close=self.df['close'], length=length, std=std)
        lower_band = boll[f'BBL_{length}_{std}']
        upper_band = boll[f'BBU_{length}_{std}']
        band_width = upper_band - lower_band
        return ((self.df['close'] - lower_band) / band_width.replace(0, 1e-9)).rename('dynamic_BOLL_LB')

    def _calc_low_vol(self, period=20):
        returns = self.df['close'].pct_change()
        return returns.rolling(window=period).std().rename('dynamic_LOW_VOL')

    def _calc_max_dd(self, period=60):
        rolling_max = self.df['close'].rolling(window=period, min_periods=1).max()
        daily_dd = self.df['close'] / rolling_max - 1.0
        return daily_dd.rolling(window=period, min_periods=1).min().rename('dynamic_MAX_DD')

    def _calc_downside_risk(self, period=60):
        returns = self.df['close'].pct_change()
        downside_returns = returns.copy()
        downside_returns[downside_returns > 0] = 0
        return downside_returns.rolling(window=period).std().rename('dynamic_DOWNSIDE_RISK')

    # [åŒæ­¥] è¡¥å…¨ä¸ prepare_csi300_features.py ä¸€è‡´çš„å› å­
    def _calc_macd_signal(self, fast=12, slow=26, signal=9):
        macd_df = self.df.ta.macd(fast=fast, slow=slow, signal=signal)
        macd_line = macd_df[f'MACD_{fast}_{slow}_{signal}']
        signal_line = macd_df[f'MACDs_{fast}_{slow}_{signal}']
        factor = (macd_line - signal_line).where(macd_line > 0, 0)
        return factor.rename('dynamic_MACD_SIGNAL')
    
    def _calc_breakout_duration(self, lookback=20):
        high_lookback = self.df['close'].rolling(window=lookback).max().shift(1)
        is_breakout = self.df['close'] > high_lookback
        breakout_streaks = is_breakout.groupby((is_breakout != is_breakout.shift()).cumsum()).cumsum()
        return breakout_streaks.rename('dynamic_BREAKOUT_DURATION')
    

    def _calc_old_d(self, lookback_k=20, a_param=200.0):
        """
        è®¡ç®—è€Må€¼ä½“ç³»ä¸­çš„æ–¹å‘å‡½æ•° D(t)ã€‚
        D(t) = tanh(a * h(t,K))
        h(t,K) æ˜¯è¿‡å»Kå¤©ä¸åŒå‘¨æœŸçº¿æ€§å›å½’æ–œç‡çš„å‡å€¼ã€‚
        """
        from scipy.stats import linregress # ä»…åœ¨æ­¤æ–¹æ³•ä¸­éœ€è¦
        close_prices = self.df['close']
        g_values_list = []
        
        # ä¸ºäº†å‘é‡åŒ–è®¡ç®—ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰éœ€è¦å›å½’çš„çª—å£çš„DataFrame
        # å¯¹äºæ¯ä¸ªäº¤æ˜“æ—¥tï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ä»t-kåˆ°tçš„å›å½’ï¼Œkä»1åˆ°lookback_k
        for k in range(1, lookback_k + 1):
            # æˆªå– k+1 ä¸ªæ•°æ®ç‚¹
            windows = close_prices.rolling(window=k + 1)
            
            # ä½¿ç”¨applyå‡½æ•°å¯¹æ¯ä¸ªçª—å£è¿›è¡Œçº¿æ€§å›å½’
            # applyå‡½æ•°ä¼šæ¯”è¾ƒæ…¢ï¼Œä½†å¯¹äºè¿™ç§å¤æ‚çš„çª—å£è®¡ç®—æ˜¯å¿…è¦çš„
            # æ³¨æ„ï¼šlinregresséœ€è¦numpyæ•°ç»„
            slopes = windows.apply(lambda x: linregress(np.arange(len(x)), x).slope, raw=True)
            
            # è·å– t-k æ—¥çš„æ”¶ç›˜ä»·
            close_t_minus_k = close_prices.shift(k)
            
            # è®¡ç®— g(t,k)
            g_tk = slopes / close_t_minus_k.replace(0, 1e-9)
            g_values_list.append(g_tk)
        # å°†æ‰€æœ‰g(t,k)çš„å€¼åˆå¹¶æˆä¸€ä¸ªDataFrame
        g_df = pd.concat(g_values_list, axis=1)
        
        # è®¡ç®— h(t,K)ï¼Œå³å¯¹æ¯ä¸€è¡Œï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥ï¼‰çš„gå€¼æ±‚å‡å€¼
        h_t_k = g_df.mean(axis=1)
        
        # è®¡ç®— D(t)
        d_t = np.tanh(a_param * h_t_k)
        
        return d_t.rename('dynamic_Old_D')
    def _calc_old_i(self, adx_period=14, adx_threshold=20.0, b_param=0.075):
        """
        è®¡ç®—è€Må€¼ä½“ç³»ä¸­çš„å¼ºåº¦å‡½æ•° I(t)ã€‚
        I(t) = max(0, tanh(b * (ADX(t) - threshold)))
        """
        # pandas_taåº“å¯ä»¥éå¸¸é«˜æ•ˆåœ°è®¡ç®—ADX
        adx_df = self.df.ta.adx(length=adx_period, high=self.df['high'], low=self.df['low'], close=self.df['close'])
        adx_series = adx_df[f'ADX_{adx_period}']
        
        # è®¡ç®— I(t)
        raw_i = np.tanh(b_param * (adx_series - adx_threshold))
        i_t = raw_i.clip(lower=0) # ä½¿ç”¨clipå®ç°max(0, raw_i)
        
        return i_t.rename('dynamic_Old_I')
    def _calc_old_m(self):
        """
        è®¡ç®—è€Må€¼ OldM(t) = D(t) * I(t)ã€‚
        è¿™ä¸ªå› å­ä¾èµ–äº _calc_old_d å’Œ _calc_old_i çš„è®¡ç®—ç»“æœã€‚
        ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬ç›´æ¥åœ¨è¿™é‡Œè°ƒç”¨å®ƒä»¬ï¼Œè€Œä¸æ˜¯é‡å¤è®¡ç®—ã€‚
        """
        # ä¸ºäº†é¿å…é‡å¤è®¡ç®—ï¼Œæˆ‘ä»¬æ£€æŸ¥è¿™äº›åˆ—æ˜¯å¦å·²å­˜åœ¨äºä¸€ä¸ªä¸´æ—¶çš„DataFrameä¸­
        # ä½†åœ¨å½“å‰æ¶æ„ä¸‹ï¼Œæœ€ç®€å•çš„åšæ³•æ˜¯é‡æ–°è®¡ç®—ä¸€æ¬¡ï¼Œæˆ–è€…ä¿®æ”¹runæ–¹æ³•
        # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç›´æ¥è®¡ç®—ï¼Œå› ä¸ºå› å­è®¡ç®—æ˜¯ç‹¬ç«‹çš„
        d_t = self._calc_old_d()
        i_t = self._calc_old_i()
        
        m_t = d_t * i_t
        
        return m_t.rename('dynamic_Old_M')

# ==============================================================================
#  é‡æ„åçš„ M å€¼é¢„æµ‹æœåŠ¡ (Refactored M-Value Prediction Service)
# ==============================================================================
class MValueMLService:
    MODELS_DIR = settings.BASE_DIR / 'selection_manager' / 'ml_models'
    MODEL_FILE = MODELS_DIR / 'm_value_lgbm_model.joblib'
    CONFIG_FILE = MODELS_DIR / 'm_value_model_config.json'
    
    # å› å­è®¡ç®—æ‰€éœ€çš„æœ€é•¿å›æº¯æœŸï¼Œåº”å¤§äºæ‰€æœ‰å› å­ä¸­æœ€å¤§çš„lookback period
    # ä¾‹å¦‚ï¼Œneg_dev(60), max_dd(60)ç­‰ï¼Œç»™è¶³100å¤©buffer
    REQUIRED_LOOKBACK = 100

    def __init__(self):
        self._model = None
        self._config = None
        self._dependencies_loaded = False

    def _load_dependencies(self):
        """æ‡’åŠ è½½æ¨¡å‹å’Œé…ç½®æ–‡ä»¶"""
        if not self.MODEL_FILE.exists() or not self.CONFIG_FILE.exists():
            logger.error("Må€¼æ¨¡å‹æˆ–é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œ 'prepare_csi300_features' å’Œ 'train_csi300_model_test' å‘½ä»¤ã€‚")
            return
        try:
            self._model = joblib.load(self.MODEL_FILE)
            with open(self.CONFIG_FILE, 'r') as f:
                self._config = json.load(f)
            logger.info("æˆåŠŸåŠ è½½Må€¼é¢„æµ‹æ¨¡å‹ (LightGBM Regressor) åŠé…ç½®ã€‚")
        except Exception as e:
            logger.error(f"åŠ è½½Må€¼æ¨¡å‹ä¾èµ–æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            self._model, self._config = None, None
        self._dependencies_loaded = True

    def _prepare_input_data(self, csi300_df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¸ºå•æ¬¡é¢„æµ‹å‡†å¤‡ç‰¹å¾å‘é‡ã€‚
        """
        if len(csi300_df) < self.REQUIRED_LOOKBACK:
            raise ValueError(f"è¾“å…¥æ•°æ®é•¿åº¦ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {self.REQUIRED_LOOKBACK} å¤©ï¼Œå®é™… {len(csi300_df)} å¤©ã€‚")

        df = csi300_df.copy()
        
        # æ•°æ®æ¸…æ´—
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        #df.ffill(inplace=True).bfill(inplace=True)
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        # è®¡ç®—æ‰€æœ‰éœ€è¦çš„ç‰¹å¾
        feature_names = self._config['feature_names']
        calculator = FactorCalculator(df)
        features_df = calculator.run(feature_names)
        
        # æ£€æŸ¥è®¡ç®—åçš„ç‰¹å¾æ˜¯å¦æœ‰NaNï¼Œå¹¶è¿”å›æœ€åä¸€è¡Œçš„ç‰¹å¾å‘é‡
        latest_features = features_df.iloc[-1]
        if latest_features.isnull().any():
            # å°è¯•å‘å‰å¡«å……ï¼Œä»¥é˜²ä¸‡ä¸€
            latest_features = features_df.ffill().iloc[-1]
            if latest_features.isnull().any():
                 raise ValueError(f"è®¡ç®—å‡ºçš„æœ€æ–°ç‰¹å¾å‘é‡åŒ…å«NaNå€¼ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚NaNs in: {latest_features[latest_features.isnull()].index.tolist()}")

        return latest_features[feature_names] # ç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´

    def predict_csi300_next_day_trend(self, csi300_df: pd.DataFrame) -> float:
        """
        ä½¿ç”¨é‡æ„åçš„MLå›å½’æ¨¡å‹ç›´æ¥é¢„æµ‹Må€¼ã€‚
        Må€¼ç”±æ¨¡å‹ç›´æ¥è¾“å‡ºï¼Œå…¶èŒƒå›´åœ¨[-1, 1]ä¹‹é—´ã€‚
        """
        if not self._dependencies_loaded:
            self._load_dependencies()
        
        if self._model is None or self._config is None:
            logger.warning("Må€¼æ¨¡å‹æœªåŠ è½½ï¼Œè¿”å›ä¸­æ€§å€¼ 0.0")
            return 0.0

        try:
            # 1. å‡†å¤‡è¾“å…¥ç‰¹å¾å‘é‡
            feature_vector = self._prepare_input_data(csi300_df)
            
            # 2. æ¨¡å‹é¢„æµ‹
            # å›å½’æ¨¡å‹ç›´æ¥è¾“å‡ºé¢„æµ‹å€¼
            model_input = feature_vector.to_frame().T 
            m_value = self._model.predict(model_input)[0]
            
            # 3. è£å‰ªMå€¼ç¡®ä¿åœ¨[-1, 1]èŒƒå›´å†…ï¼Œä»¥é˜²æ¨¡å‹é¢„æµ‹ç•¥å¾®è¶…é™
            m_value = np.clip(m_value, -1.0, 1.0)
            
            logger.info(
                f"Må€¼é¢„æµ‹: æ¨¡å‹ç›´æ¥è¾“å‡º M-Value = {m_value:.4f}"
            )
            return float(m_value)
        
        except Exception as e:
            logger.error(f"é¢„æµ‹Må€¼è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            return 0.0

# åˆ›å»ºå…¨å±€å•ä¾‹ï¼Œä¾›ä¸‹æ¸¸æœåŠ¡å¯¼å…¥
m_value_service_instance = MValueMLService()

####æ–‡ä»¶ç»“æŸ####

####selection_manager\service\selection_service.py####
# ==============================================================================
# æ–‡ä»¶ 4/4: selection_manager/service/selection_service.py (é‡æ„ç‰ˆ)
# æè¿°: ç®€åŒ–åçš„é€‰è‚¡æœåŠ¡ï¼ŒèŒè´£åˆ†ç¦»ï¼Œè°ƒç”¨æ–°æœåŠ¡è·å–è¯„åˆ†ã€‚
# ==============================================================================
import logging
from datetime import date, timedelta
from decimal import Decimal

import pandas as pd
from django.db import transaction
from common.models import IndexQuotesCsi300
from common.models import (
    StockInfo, DailyQuotes, SystemLog, FactorDefinitions, DailyFactorValues,
    StrategyParameters, DailyTradingPlan
)
from .m_value_service import m_value_service_instance # å¤ç”¨Må€¼é¢„æµ‹æœåŠ¡
from .stock_value_service import StockValueService # å¼•å…¥æ–°çš„ä¸ªè‚¡è¯„åˆ†æœåŠ¡

logger = logging.getLogger(__name__)
MODULE_NAME = 'æœºå™¨å­¦ä¹ é€‰è‚¡ä¸é¢„æ¡ˆæ¨¡å—'
MARKET_INDICATOR_CODE = '_MARKET_REGIME_INDICATOR_'

class SelectionService:
    """
    [é‡æ„ç‰ˆ] T-1æ—¥æ”¶ç›˜åè¿è¡Œçš„ï¼ŒåŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹çš„é€‰è‚¡ä¸é¢„æ¡ˆç”ŸæˆæœåŠ¡ã€‚
    
    è¯¥æœåŠ¡ç°åœ¨å°†æ ¸å¿ƒçš„è‚¡ç¥¨è¯„åˆ†é€»è¾‘å§”æ‰˜ç»™ StockValueServiceï¼Œè‡ªèº«èŒè´£ç®€åŒ–ä¸ºï¼š
    1. è®¡ç®—å¸‚åœºçŠ¶æ€ M(t)ã€‚
    2. è°ƒç”¨ StockValueService è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ¨¡å‹è¯„åˆ†ã€‚
    3. åŸºäºæ¨¡å‹è¯„åˆ†ç”Ÿæˆäº¤æ˜“é¢„æ¡ˆã€‚
    4. ä¿å­˜ç»“æœã€‚
    """

    def __init__(self, trade_date: date, mode: str = 'realtime', one_strategy: str = None, preloaded_panels: dict = None):
        if mode not in ['realtime', 'backtest']:
            raise ValueError("æ¨¡å¼(mode)å¿…é¡»æ˜¯ 'realtime' æˆ– 'backtest'")

        try:
            latest_trade_date_obj = DailyQuotes.objects.filter(trade_date__lte=trade_date).latest('trade_date')
            self.trade_date = latest_trade_date_obj.trade_date
        except DailyQuotes.DoesNotExist:
            self.trade_date = trade_date
        
        self.mode = mode
        self.params = {}
        self.market_regime_M = 0.0
        self.stock_value_service = StockValueService() # å®ä¾‹åŒ–æ–°çš„æœåŠ¡
        self.preloaded_panels = preloaded_panels
        logger.debug(f"--- {MODULE_NAME} åˆå§‹åŒ– ---")
        logger.debug(f"äº¤æ˜“æ—¥æœŸ (T-1): {self.trade_date}, è¿è¡Œæ¨¡å¼: {self.mode}")

    def run_selection(self):
        """ä¸€é”®å¯åŠ¨å…¨æµç¨‹çš„å…¥å£æ–¹æ³•ã€‚"""
        self._log_to_db('INFO', f"æœºå™¨å­¦ä¹ é€‰è‚¡æµç¨‹å¯åŠ¨ã€‚æ¨¡å¼: {self.mode}, æ—¥æœŸ: {self.trade_date}")
        try:
            self._load_parameters()
            initial_stock_pool = self._initial_screening()
            if not initial_stock_pool:
                self._log_to_db('WARNING', "åˆæ­¥ç­›é€‰åæ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                return

            # 1. è®¡ç®—å¸‚åœºMå€¼
            self.market_regime_M = self._calculate_market_regime_M(initial_stock_pool)

            # 2. è°ƒç”¨æ–°æœåŠ¡è·å–æ‰€æœ‰è‚¡ç¥¨çš„æ¨¡å‹è¯„åˆ†
            logger.info("è°ƒç”¨StockValueServiceè·å–æ‰€æœ‰è‚¡ç¥¨çš„æ¨¡å‹è¯„åˆ†...")
            final_scores = self.stock_value_service.get_all_stock_scores(
                stock_pool=initial_stock_pool,
                trade_date=self.trade_date,
                m_value=self.market_regime_M,
                preloaded_panels=self.preloaded_panels
            )
            final_scores = final_scores.sort_values(ascending=False)

            if final_scores.empty:
                self._log_to_db('WARNING', "æ¨¡å‹æœªå¯¹ä»»ä½•è‚¡ç¥¨ç»™å‡ºæœ‰æ•ˆè¯„åˆ†ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                return
            if self.preloaded_panels:
                plan_panels = self.preloaded_panels
            else:
                # å¦‚æœæ˜¯å®æ—¶è¿è¡Œï¼Œæ²¡æœ‰é¢„åŠ è½½æ•°æ®ï¼Œéœ€è¦ä¸ºTopNè‚¡ç¥¨åŠ è½½æ•°æ®
                top_n_codes = final_scores.head(int(self.params.get('dynamic_top_n', 10))).index.tolist()
                plan_panels = self._load_panels_for_plan(top_n_codes)
            trading_plan = self._generate_trading_plan(final_scores, plan_panels)
            # 3. ç”Ÿæˆäº¤æ˜“é¢„æ¡ˆ
            #trading_plan = self._generate_trading_plan(final_scores)
            if trading_plan.empty:
                self._log_to_db('WARNING', "æœ€ç»ˆæœªç”Ÿæˆä»»ä½•äº¤æ˜“é¢„æ¡ˆã€‚")
                return

            # 4. ä¿å­˜ç»“æœ
            self._save_results(final_scores, trading_plan)

            success_msg = f"æœºå™¨å­¦ä¹ é€‰è‚¡æµç¨‹æˆåŠŸå®Œæˆã€‚M(t)={self.market_regime_M:.4f}, ç”Ÿæˆ {len(trading_plan)} æ¡äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.info(success_msg)
            self._log_to_db('INFO', success_msg)

        except Exception as e:
            error_msg = f"æœºå™¨å­¦ä¹ é€‰è‚¡æµç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
            logger.critical(error_msg, exc_info=True)
            self._log_to_db('CRITICAL', error_msg)
            raise

    def _load_parameters(self):
        """åŠ è½½ç­–ç•¥å‚æ•°"""
        logger.debug("åŠ è½½ç­–ç•¥å‚æ•°...")
        params_qs = StrategyParameters.objects.all()
        self.params = {p.param_name: float(p.param_value) for p in params_qs}
        
    def _initial_screening(self) -> list[str]:
        """åˆæ­¥ç­›é€‰è‚¡ç¥¨æ± ï¼Œé€»è¾‘ä¿æŒä¸å˜"""
        logger.debug("å¼€å§‹æ‰§è¡Œåˆæ­¥ç­›é€‰...")
        all_stocks = StockInfo.objects.filter(status=StockInfo.StatusChoices.LISTING)
        non_st_stocks = all_stocks.exclude(stock_code__contains='.688').exclude(stock_name__startswith='ST').exclude(stock_name__startswith='*ST')
        
        min_listing_days = self.params.get('dynamic_lookback_new_stock', 60)
        min_listing_date = self.trade_date - timedelta(days=int(min_listing_days))
        non_new_stocks = non_st_stocks.filter(listing_date__lt=min_listing_date)
        
        stock_pool_codes = list(non_new_stocks.values_list('stock_code', flat=True))
        
        lookback_days = 20
        start_date = self.trade_date - timedelta(days=lookback_days * 2)
        quotes = DailyQuotes.objects.filter(
            stock_code_id__in=stock_pool_codes,
            trade_date__gte=start_date,
            trade_date__lte=self.trade_date
        ).values('stock_code_id', 'turnover')

        if not quotes:
            return []

        quotes_df = pd.DataFrame.from_records(quotes)
        avg_turnover = quotes_df.groupby('stock_code_id')['turnover'].mean()
        
        min_liquidity = self.params.get('dynamic_min_liquidity', 100000000)
        liquid_stocks = avg_turnover[avg_turnover >= min_liquidity]
        
        final_stock_pool = list(liquid_stocks.index)
        logger.debug(f"åˆæ­¥ç­›é€‰åï¼Œæœ€ç»ˆå‰©ä½™ {len(final_stock_pool)} åªè‚¡ç¥¨è¿›å…¥ç²¾é€‰æ± ã€‚")
        return final_stock_pool

    def _calculate_market_regime_M(self, stock_pool: list[str]) -> float:
        """
        è®¡ç®—å¸‚åœºçŠ¶æ€å‡½æ•° M(t)
        """
        
        # =======================================================================
        # [MLé¢„æµ‹æ¥å£] - æœªæ¥åˆ‡æ¢åˆ°æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹Må€¼çš„å…¥å£
        # =======================================================================
        try:
            # 1. è·å–æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
            quotes_60_days_qs = IndexQuotesCsi300.objects.filter(
                trade_date__lte=self.trade_date
            ).order_by('-trade_date')[:100]
            
            if len(quotes_60_days_qs) < 100:
                logger.warning("æ²ªæ·±300æ•°æ®ä¸è¶³100å¤©ï¼Œæ— æ³•ä½¿ç”¨MLæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå°†å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•ã€‚")
            else:
                # [ä¿®å¤] ä»QuerySetç›´æ¥æ„å»ºDataFrame
                df_60_days_raw = pd.DataFrame.from_records(quotes_60_days_qs.values())
                
                # åè½¬é¡ºåºä½¿æ—¥æœŸä»æ—§åˆ°æ–°
                df_60_days = df_60_days_raw.iloc[::-1].reset_index(drop=True)
                
                # 2. è°ƒç”¨é¢„æµ‹æœåŠ¡ (m_value_serviceå†…éƒ¨ä¼šå¤„ç†ç±»å‹è½¬æ¢)
                ml_m_value = m_value_service_instance.predict_csi300_next_day_trend(df_60_days)
                
                # 3. ã€é‡è¦ã€‘å°†MLé¢„æµ‹ç»“æœå­˜å…¥ç¼“å­˜
                DailyFactorValues.objects.update_or_create(
                    stock_code_id=MARKET_INDICATOR_CODE,
                    trade_date=self.trade_date,
                    factor_code_id='dynamic_M_VALUE',
                    defaults={'raw_value': Decimal(str(ml_m_value)), 'norm_score': Decimal(str(ml_m_value))}
                )
                logger.info(f"å·²ä½¿ç”¨MLæ¨¡å‹é¢„æµ‹M(t) = {ml_m_value:.4f}")
                return ml_m_value
        except Exception as e:
            logger.error(f"è°ƒç”¨MLæ¨¡å‹é¢„æµ‹Må€¼æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)

    def _generate_trading_plan(self, final_scores: pd.Series, panels: dict) -> pd.DataFrame:
        """åŸºäºæ¨¡å‹è¯„åˆ†å’Œé¢æ¿æ•°æ®ç”Ÿæˆäº¤æ˜“é¢„æ¡ˆ"""
        logger.debug("åŸºäºæ¨¡å‹è¯„åˆ†ç”Ÿæˆäº¤æ˜“é¢„æ¡ˆ...")
        top_n = int(self.params.get('dynamic_top_n', 10))
        top_stocks_scores = final_scores.head(top_n)
        
        if top_stocks_scores.empty:
            return pd.DataFrame()
        top_stock_codes = top_stocks_scores.index.tolist()
        
        # --- [å…³é”®ä¿®æ­£] å¼€å§‹ ---
        # ä¸å†ä»æ•°æ®åº“åŠ è½½ï¼Œç›´æ¥ä½¿ç”¨ä¼ å…¥çš„panels
        if not panels or 'close' not in panels:
            logger.error("ç”Ÿæˆäº¤æ˜“é¢„æ¡ˆæ—¶æœªæä¾›æœ‰æ•ˆçš„é¢æ¿æ•°æ®ã€‚")
            return pd.DataFrame()
        # æ³¨æ„ï¼šMIOP/MAOPçš„è®¡ç®—åº”è¯¥åŸºäºä¸å¤æƒä»·æ ¼ï¼Œä½†ATRä¹Ÿéœ€è¦ä¸å¤æƒä»·æ ¼
        # æˆ‘ä»¬éœ€è¦ç¡®ä¿ä¼ å…¥çš„panelsåŒ…å«ä¸å¤æƒä»·æ ¼ã€‚
        # å‡è®¾å›æµ‹æ¡†æ¶ä¼ å…¥çš„panelså·²ç»æ˜¯å¤„ç†å¥½çš„ï¼ŒåŒ…å«äº†æ‰€éœ€åˆ—ã€‚
        # å¦‚æœæ²¡æœ‰ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œè¿›è¡Œå¤„ç†ï¼Œä½†ä¸ºäº†ä¿æŒä¸ä½ åŸè®¾è®¡ä¸€è‡´ï¼Œæˆ‘ä»¬å‡è®¾panelsæ˜¯OKçš„ã€‚
        # è¿™é‡Œçš„é€»è¾‘éœ€è¦å’Œä½ çš„å›æµ‹æ¡†æ¶ä¼ å…¥çš„æ•°æ®æ ¼å¼å¯¹é½ã€‚
        # å‡è®¾ä½ çš„å›æµ‹æ¡†æ¶ä¼ å…¥çš„panelsçš„ 'close', 'high', 'low' æ˜¯ä¸å¤æƒä»·ã€‚
        close_panel = panels['close']
        high_panel = panels['high']
        low_panel = panels['low']
        last_close_series = close_panel.iloc[-1].reindex(top_stock_codes)
        # ç®€å•çš„æ—¥å†…æ³¢å¹…ä½œä¸ºATR
        last_atr_series = (high_panel.iloc[-1] - low_panel.iloc[-1]).reindex(top_stock_codes)
        # --- [å…³é”®ä¿®æ­£] ç»“æŸ ---
        k_gap = self.params.get('k_gap', 0.5)
        k_drop = self.params.get('k_drop', 0.3)
        plans = []
        for stock_code, score in top_stocks_scores.items():
            close_price = last_close_series.get(stock_code)
            atr = last_atr_series.get(stock_code)
            if pd.isna(close_price) or pd.isna(atr):
                continue
            
            miop = Decimal(str(close_price)) - Decimal(str(k_drop)) * Decimal(str(atr))
            maop = Decimal(str(close_price)) + Decimal(str(k_gap)) * Decimal(str(atr))
            plans.append({
                'stock_code': stock_code,
                'rank': len(plans) + 1,
                'final_score': score,
                'miop': miop,
                'maop': maop,
            })
        
        return pd.DataFrame(plans)
    

    def _load_panels_for_plan(self, stock_codes: list) -> dict:
        """åœ¨å®æ—¶æ¨¡å¼ä¸‹ï¼Œä¸ºç”Ÿæˆäº¤æ˜“é¢„æ¡ˆåŠ è½½æ‰€éœ€çš„ä¸å¤æƒä»·æ ¼é¢æ¿"""
        if not stock_codes:
            return {}
        
        start_date = self.trade_date - timedelta(days=30) # ATRè®¡ç®—é€šå¸¸ä¸éœ€è¦å¾ˆé•¿å›æº¯
        quotes_qs = DailyQuotes.objects.filter(
            stock_code_id__in=stock_codes,
            trade_date__gte=start_date,
            trade_date__lte=self.trade_date
        ).values('trade_date', 'stock_code_id', 'close', 'high', 'low')
        if not quotes_qs:
            return {}
            
        df = pd.DataFrame.from_records(quotes_qs)
        panels = {}
        for col in ['close', 'high', 'low']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            panel = df.pivot(index='trade_date', columns='stock_code_id', values=col)
            panels[col] = panel
        return panels

    @transaction.atomic
    def _save_results(self, final_scores: pd.Series, trading_plan_df: pd.DataFrame):
        """ä¿å­˜æ¨¡å‹è¯„åˆ†å’Œäº¤æ˜“é¢„æ¡ˆ"""
        logger.debug("å¼€å§‹å°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“...")

        # 1. ä¿å­˜æ¨¡å‹è¯„åˆ†åˆ° DailyFactorValues
        factor_values_to_create = []
        for stock_code, score in final_scores.items():
            factor_values_to_create.append(
                DailyFactorValues(
                    stock_code_id=stock_code,
                    trade_date=self.trade_date,
                    factor_code_id='ML_STOCK_SCORE', # æ–°å› å­
                    raw_value=Decimal(str(score)),
                    norm_score=Decimal(str(score)) # è¯„åˆ†æœ¬èº«å°±æ˜¯æ ‡å‡†åŒ–çš„ï¼Œç›´æ¥å­˜
                )
            )
        
        # å…ˆåˆ é™¤å½“æ—¥æ—§çš„ML_STOCK_SCOREï¼Œå†æ‰¹é‡åˆ›å»º
        DailyFactorValues.objects.filter(
            trade_date=self.trade_date,
            factor_code_id='ML_STOCK_SCORE'
        ).delete()
        DailyFactorValues.objects.bulk_create(factor_values_to_create, batch_size=1000)
        logger.debug(f"å·²ä¿å­˜ {len(factor_values_to_create)} æ¡ä¸ªè‚¡æ¨¡å‹è¯„åˆ†ã€‚")

        # 2. ä¿å­˜äº¤æ˜“é¢„æ¡ˆ
        plan_date = self.trade_date + timedelta(days=1)
        DailyTradingPlan.objects.filter(plan_date=plan_date).delete()
        
        plans_to_create = []
        for _, row in trading_plan_df.iterrows():
            plans_to_create.append(
                DailyTradingPlan(
                    plan_date=plan_date, stock_code_id=row['stock_code'],
                    rank=row['rank'], final_score=Decimal(str(row['final_score'])),
                    miop=row['miop'].quantize(Decimal('0.01')),
                    maop=row['maop'].quantize(Decimal('0.01')),
                    status=DailyTradingPlan.StatusChoices.PENDING,
                    strategy_dna="ML_MODEL:1.00" # ç­–ç•¥DNAç°åœ¨å›ºå®šä¸ºæ¨¡å‹
                )
            )
        DailyTradingPlan.objects.bulk_create(plans_to_create)
        logger.debug(f"å·²ä¿å­˜ {len(plans_to_create)} æ¡äº¤æ˜“é¢„æ¡ˆã€‚")

    def _log_to_db(self, level, message):
        logger.info(message)
        # åœ¨å›æµ‹ç­‰é«˜æ€§èƒ½åœºæ™¯ä¸‹å¯ä»¥å…³é—­
        # SystemLog.objects.create(log_level=level, module_name=MODULE_NAME, message=message)
        pass


####æ–‡ä»¶ç»“æŸ####

####selection_manager\service\stock_value_service.py####
# ==============================================================================
# æ–‡ä»¶: selection_manager/service/stock_value_service.py (ç»ˆææ€§èƒ½ä¼˜åŒ–ç‰ˆ)
# æè¿°: æä¾›ä¸ªè‚¡æ¨¡å‹è¯„åˆ†çš„æœåŠ¡ï¼Œä½¿ç”¨å®Œå…¨å‘é‡åŒ–çš„å› å­è®¡ç®—å¼•æ“ã€‚
# ==============================================================================
import logging
import json
from pathlib import Path
from datetime import timedelta

import numpy as np
import pandas as pd
import joblib
from django.conf import settings
from scipy.stats import linregress

from common.models import DailyQuotes

logger = logging.getLogger(__name__)

# å› å­è®¡ç®—æ‰€éœ€çš„æœ€å¤§å›æº¯æœŸ
FACTOR_LOOKBACK_BUFFER = 100

# ==============================================================================
#  é«˜æ•ˆå‘é‡åŒ–å› å­è®¡ç®—å¼•æ“ (High-Performance Vectorized Factor Engine)
# ==============================================================================
class VectorizedFactorEngine:
    """
    ä¸€ä¸ªå®Œå…¨å‘é‡åŒ–çš„å› å­è®¡ç®—å¼•æ“ã€‚
    å®ƒæ¥æ”¶é¢æ¿æ•°æ®ï¼Œå¹¶ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„å› å­å€¼ã€‚
    """
    def __init__(self, panel_data: dict, feature_names: list):
        self.open = panel_data['open']
        self.high = panel_data['high']
        self.low = panel_data['low']
        self.close = panel_data['close']
        self.volume = panel_data['volume']
        self.amount = panel_data['amount']
        self.feature_names = feature_names
        self.epsilon = 1e-9
    def run(self) -> pd.DataFrame:
        calculator_methods = {
            'dynamic_ADX_CONFIRM': self._calc_adx_confirm,
            'dynamic_v2_MA_SLOPE': self._calc_v2_ma_slope,
            'dynamic_v2_MA_SCORE': self._calc_v2_ma_score,
            'dynamic_v2_CPC_Factor': self._calc_v2_cpc_factor,
            'dynamic_v2_VPCF': self._calc_v2_vpcf,
            'dynamic_BREAKOUT_PWR': self._calc_breakout_pwr,
            'dynamic_VOLUME_SURGE': self._calc_volume_surge,
            'dynamic_MOM_ACCEL': self._calc_mom_accel,
            'dynamic_RSI_OS': self._calc_rsi_os,
            'dynamic_NEG_DEV': self._calc_neg_dev,
            'dynamic_BOLL_LB': self._calc_boll_lb,
            'dynamic_LOW_VOL': self._calc_low_vol,
            'dynamic_MAX_DD': self._calc_max_dd,
            'dynamic_DOWNSIDE_RISK': self._calc_downside_risk,
            'dynamic_Old_D': self._calc_old_d,
            'dynamic_Old_I': self._calc_old_i,
            'dynamic_Old_M': self._calc_old_m,
        }
        all_factors = {}
        for factor_name in self.feature_names:
            if factor_name in calculator_methods:
                logger.debug(f"Vectorized calculation for: {factor_name}")
                all_factors[factor_name] = calculator_methods[factor_name]()
        return pd.DataFrame(all_factors)
    def _calculate_tr(self):
        """[å†…éƒ¨è¾…åŠ©å‡½æ•°] ç»Ÿä¸€è®¡ç®—çœŸå®æ³¢å¹… (True Range)"""
        tr1 = self.high - self.low
        tr2 = abs(self.high - self.close.shift(1))
        tr3 = abs(self.low - self.close.shift(1))
        return np.maximum(tr1, np.maximum(tr2, tr3))
    def _calc_adx_confirm(self, length=14, adx_threshold=25):
        move_up = self.high.diff()
        move_down = -self.low.diff()
        plus_dm = pd.DataFrame(np.where((move_up > move_down) & (move_up > 0), move_up, 0.0), index=self.high.index, columns=self.high.columns)
        minus_dm = pd.DataFrame(np.where((move_down > move_up) & (move_down > 0), move_down, 0.0), index=self.low.index, columns=self.low.columns)
        
        tr = self._calculate_tr() # è°ƒç”¨ç»Ÿä¸€çš„TRè®¡ç®—å‡½æ•°
        alpha = 1 / length
        atr = tr.ewm(alpha=alpha, adjust=False).mean()
        plus_di = 100 * (plus_dm.ewm(alpha=alpha, adjust=False).mean() / (atr + self.epsilon))
        minus_di = 100 * (minus_dm.ewm(alpha=alpha, adjust=False).mean() / (atr + self.epsilon))
        
        di_sum = plus_di + minus_di
        dx = 100 * (abs(plus_di - minus_di) / di_sum.replace(0, np.inf))
        adx = dx.ewm(alpha=alpha, adjust=False).mean()
        
        condition = (adx.iloc[-1] > adx_threshold) & (plus_di.iloc[-1] > minus_di.iloc[-1])
        return adx.iloc[-1].where(condition, 0.0)
    def _calc_v2_ma_slope(self, ma_period=20, ema_period=20):
        ma = self.close.rolling(window=ma_period).mean()
        ma_roc = ma.pct_change(1)
        return ma_roc.ewm(span=ema_period, adjust=False).mean().iloc[-1]
    def _calc_v2_ma_score(self, p1=5, p2=10, p3=20):
        ma5 = self.close.rolling(window=p1).mean()
        ma10 = self.close.rolling(window=p2).mean()
        ma20 = self.close.rolling(window=p3).mean()
        spread1 = (self.close - ma5) / (ma5 + self.epsilon)
        spread2 = (ma5 - ma10) / (ma10 + self.epsilon)
        spread3 = (ma10 - ma20) / (ma20 + self.epsilon)
        return ((spread1 + spread2 + spread3) / 3.0).iloc[-1]
    def _calc_v2_cpc_factor(self, ema_period=10):
        price_range = self.high - self.low
        dcp = (2 * self.close - self.high - self.low) / (price_range + self.epsilon)
        return dcp.ewm(span=ema_period, adjust=False).mean().iloc[-1]
    def _calc_v2_vpcf(self, s=5, l=20, n_smooth=5):
        ma_close_s = self.close.rolling(window=s).mean()
        price_momentum = ma_close_s.pct_change(1)
        ma_amount_s = self.amount.rolling(window=s).mean()
        ma_amount_l = self.amount.rolling(window=l).mean()
        volume_level = (ma_amount_s / (ma_amount_l + self.epsilon)) - 1
        daily_score = price_momentum * volume_level
        return daily_score.ewm(span=n_smooth, adjust=False).mean().iloc[-1]
    def _calc_breakout_pwr(self, lookback=60, atr_period=14):
        high_lookback = self.high.rolling(window=lookback).max().shift(1)
        
        tr = self._calculate_tr() # è°ƒç”¨ç»Ÿä¸€çš„TRè®¡ç®—å‡½æ•°
        atr = tr.ewm(alpha=1/atr_period, adjust=False).mean()
        
        return ((self.close - high_lookback) / (atr + self.epsilon)).iloc[-1]
    def _calc_volume_surge(self, lookback=20):
        avg_amount = self.amount.rolling(window=lookback).mean().shift(1)
        return (self.amount / (avg_amount + self.epsilon)).iloc[-1]
    def _calc_mom_accel(self, roc_period=5, shift_period=11):
        roc = self.close.pct_change(roc_period)
        roc_shifted = roc.shift(shift_period)
        # ä½¿ç”¨ where é¿å…åˆ†æ¯ä¸º0æ—¶äº§ç”Ÿ inf
        acceleration = (roc / roc_shifted).where(roc_shifted != 0, 1) - 1
        return acceleration.iloc[-1]
    def _calc_rsi_os(self, length=14):
        delta = self.close.diff()
        gain = delta.clip(lower=0)
        loss = -delta.clip(upper=0)
        avg_gain = gain.ewm(com=length - 1, adjust=False).mean()
        avg_loss = loss.ewm(com=length - 1, adjust=False).mean()
        rs = avg_gain / (avg_loss + self.epsilon)
        return (100 - (100 / (1 + rs))).iloc[-1]
    def _calc_neg_dev(self, period=60):
        ma = self.close.rolling(window=period).mean()
        return ((self.close - ma) / (ma + self.epsilon)).iloc[-1]
    def _calc_boll_lb(self, length=20, std=2.0):
        ma = self.close.rolling(window=length).mean()
        rolling_std = self.close.rolling(window=length).std()
        upper_band = ma + (rolling_std * std)
        lower_band = ma - (rolling_std * std)
        band_width = upper_band - lower_band
        return ((self.close - lower_band) / (band_width + self.epsilon)).iloc[-1]
    def _calc_low_vol(self, period=20):
        returns = self.close.pct_change()
        return returns.rolling(window=period).std().iloc[-1]
    def _calc_max_dd(self, period=60):
        rolling_max = self.close.rolling(window=period, min_periods=1).max()
        daily_dd = self.close / rolling_max - 1.0
        return daily_dd.rolling(window=period, min_periods=1).min().iloc[-1]
    def _calc_downside_risk(self, period=60):
        returns = self.close.pct_change()
        downside_returns = returns.clip(upper=0)
        return downside_returns.rolling(window=period).std().iloc[-1]
    def _calc_old_d(self, lookback_k=20, a_param=200.0):
        slopes = {}
        x_range = np.arange(lookback_k + 1)
        for stock_code in self.close.columns:
            series = self.close[stock_code].dropna()
            if len(series) < lookback_k + 1:
                slopes[stock_code] = np.nan
                continue
            
            y = series.iloc[-lookback_k-1:].values
            # å¢åŠ å¯¹yä¸­NaNå€¼çš„æ£€æŸ¥
            if np.isnan(y).any():
                slopes[stock_code] = np.nan
                continue
            slope, _, _, _, _ = linregress(x_range, y)
            denominator = series.iloc[-lookback_k-1]
            h_t_k = slope / (denominator + self.epsilon) if denominator != 0 else 0
            slopes[stock_code] = np.tanh(a_param * h_t_k)
        return pd.Series(slopes)
    def _calc_old_i(self, adx_period=14, adx_threshold=20.0, b_param=0.075):
        move_up = self.high.diff()
        move_down = -self.low.diff()
        plus_dm = pd.DataFrame(np.where((move_up > move_down) & (move_up > 0), move_up, 0.0), index=self.high.index, columns=self.high.columns)
        minus_dm = pd.DataFrame(np.where((move_down > move_up) & (move_down > 0), move_down, 0.0), index=self.low.index, columns=self.low.columns)
        
        tr = self._calculate_tr() # è°ƒç”¨ç»Ÿä¸€çš„TRè®¡ç®—å‡½æ•°
        alpha = 1 / adx_period
        atr = tr.ewm(alpha=alpha, adjust=False).mean()
        plus_di = 100 * (plus_dm.ewm(alpha=alpha, adjust=False).mean() / (atr + self.epsilon))
        minus_di = 100 * (minus_dm.ewm(alpha=alpha, adjust=False).mean() / (atr + self.epsilon))
        di_sum = plus_di + minus_di
        dx = 100 * (abs(plus_di - minus_di) / di_sum.replace(0, np.inf))
        adx = dx.ewm(alpha=alpha, adjust=False).mean().iloc[-1]
        
        raw_i = np.tanh(b_param * (adx - adx_threshold))
        return raw_i.clip(lower=0)
    def _calc_old_m(self):
        d_t = self._calc_old_d()
        i_t = self._calc_old_i()
        return d_t * i_t

# ==============================================================================
#  ä¸»æœåŠ¡ (Main Service)
# ==============================================================================
class StockValueService:
    MODELS_DIR = settings.BASE_DIR / 'selection_manager' / 'ml_models'
    MODEL_FILE = MODELS_DIR / 'stock_lgbm_model.joblib'
    CONFIG_FILE = MODELS_DIR / 'stock_model_config.json'

    def __init__(self):
        self._model = None
        self._config = None
        self._feature_names = []
        self._dependencies_loaded = False
        self._load_dependencies()

    def _load_dependencies(self):
        if not self.MODEL_FILE.exists() or not self.CONFIG_FILE.exists():
            logger.error("ä¸ªè‚¡è¯„åˆ†æ¨¡å‹æˆ–é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
            return
        try:
            self._model = joblib.load(self.MODEL_FILE)
            with open(self.CONFIG_FILE, 'r') as f:
                self._config = json.load(f)
            self._feature_names = self._config['feature_names']
            logger.info("æˆåŠŸåŠ è½½ä¸ªè‚¡è¯„åˆ†æ¨¡å‹åŠé…ç½®ã€‚")
            self._dependencies_loaded = True
        except Exception as e:
            logger.error(f"åŠ è½½ä¸ªè‚¡è¯„åˆ†æ¨¡å‹ä¾èµ–æ—¶å‡ºé”™: {e}", exc_info=True)

    def get_all_stock_scores(self, stock_pool: list, trade_date, m_value: float, preloaded_panels: dict = None) -> pd.Series:
        if not self._dependencies_loaded:
            logger.warning("æ¨¡å‹æœªåŠ è½½ï¼Œè¿”å›ç©ºè¯„åˆ†åˆ—è¡¨ã€‚")
            return pd.Series(dtype=float)
        panel_data = {}
        # --- [å…³é”®ä¿®æ­£] å¼€å§‹ ---
        if preloaded_panels:
            logger.debug("StockValueService æ£€æµ‹åˆ°é¢„åŠ è½½é¢æ¿æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨ã€‚")
            # ç›´æ¥ä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®ï¼Œä½†è¦ç¡®ä¿åˆ—åæ˜¯ 'amount'
            panel_data = preloaded_panels.copy()
            if 'turnover' in panel_data and 'amount' not in panel_data:
                panel_data['amount'] = panel_data.pop('turnover')
        else:
            logger.info("æœªæä¾›é¢„åŠ è½½é¢æ¿ï¼ŒStockValueService å°†ä»æ•°æ®åº“åŠ è½½æ•°æ®...")
            # 1. é«˜æ•ˆåŠ è½½æ•°æ® (å›é€€é€»è¾‘)
            start_date = trade_date - timedelta(days=FACTOR_LOOKBACK_BUFFER * 2)
            quotes_qs = DailyQuotes.objects.filter(
                stock_code_id__in=stock_pool,
                trade_date__gte=start_date,
                trade_date__lte=trade_date
            ).values('trade_date', 'stock_code_id', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close')
            
            if not quotes_qs:
                logger.warning("åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•è‚¡ç¥¨è¡Œæƒ…æ•°æ®ã€‚")
                return pd.Series(dtype=float)
            all_quotes_df = pd.DataFrame.from_records(quotes_qs)
            
            # 2. é¢„å¤„ç†ï¼šä»·æ ¼å¤æƒå’Œåˆ—åç»Ÿä¸€
            logger.info("æ­£åœ¨è¿›è¡Œä»·æ ¼åå¤æƒå¤„ç†...")
            numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']
            for col in numeric_cols:
                all_quotes_df[col] = pd.to_numeric(all_quotes_df[col], errors='coerce')
            
            all_quotes_df['adj_factor'] = all_quotes_df['hfq_close'] / (all_quotes_df['close'] + 1e-9)
            
            all_quotes_df['open'] = all_quotes_df['open'] * all_quotes_df['adj_factor']
            all_quotes_df['high'] = all_quotes_df['high'] * all_quotes_df['adj_factor']
            all_quotes_df['low'] = all_quotes_df['low'] * all_quotes_df['adj_factor']
            all_quotes_df['close'] = all_quotes_df['hfq_close']
            all_quotes_df.rename(columns={'turnover': 'amount'}, inplace=True)
            # 3. æ„å»ºé¢æ¿æ•°æ®
            logger.info("æ„å»ºé¢æ¿æ•°æ®...")
            for col in ['open', 'high', 'low', 'close', 'volume', 'amount']:
                panel = all_quotes_df.pivot(index='trade_date', columns='stock_code_id', values=col)
                full_date_range = pd.date_range(start=panel.index.min(), end=panel.index.max(), freq='B')
                panel = panel.reindex(full_date_range).ffill()
                panel_data[col] = panel
        # --- [å…³é”®ä¿®æ­£] ç»“æŸ ---
        # 4. ä½¿ç”¨å‘é‡åŒ–å¼•æ“è®¡ç®—æ‰€æœ‰ç‰¹å¾
        logger.info("å¯åŠ¨å‘é‡åŒ–å› å­è®¡ç®—å¼•æ“...")
        features_to_calc = [f for f in self._feature_names if f != 'market_m_value']
        engine = VectorizedFactorEngine(panel_data, features_to_calc)
        features_df = engine.run()

        # 4. å‡†å¤‡æ¨¡å‹è¾“å…¥
        logger.info("å‡†å¤‡æ¨¡å‹è¾“å…¥å¹¶è¿›è¡Œé¢„æµ‹...")
        features_df['market_m_value'] = m_value
        features_df.dropna(inplace=True)
        
        if features_df.empty:
            logger.warning("æ‰€æœ‰è‚¡ç¥¨åœ¨ç‰¹å¾è®¡ç®—åéƒ½å› NaNè¢«å‰”é™¤ã€‚")
            return pd.Series(dtype=float)

        # ä¿è¯ç‰¹å¾é¡ºåºå’Œæ•°æ®ç±»å‹
        model_input = features_df[self._feature_names].astype(float)
        
        # 5. ä¸€æ¬¡æ€§é¢„æµ‹æ‰€æœ‰è‚¡ç¥¨
        scores = self._model.predict(model_input)
        
        # 6. ç»„è£…æˆæœ€ç»ˆçš„Series
        final_scores = pd.Series(scores, index=model_input.index)
        
        logger.info(f"æˆåŠŸä¸º {len(final_scores)} åªè‚¡ç¥¨è®¡ç®—äº†æ¨¡å‹è¯„åˆ†ã€‚")
        return final_scores

####æ–‡ä»¶ç»“æŸ####

####selection_manager\management\commands\generate_m_value_csv.py####
# selection_manager/management/commands/generate_m_value_csv.py

import logging
import os
from decimal import Decimal

import pandas as pd
from django.conf import settings
from django.core.management.base import BaseCommand
from tqdm import tqdm

from common.models import IndexQuotesCsi300
from selection_manager.service.selection_service import SelectionService

# è·å–loggerå®ä¾‹
logger = logging.getLogger(__name__)

class Command(BaseCommand):
    """
    ä¸€ä¸ªDjangoç®¡ç†å‘½ä»¤ï¼Œç”¨äºè®¡ç®—æ²ªæ·±300æŒ‡æ•°ä»2010-08-19è‡³2025-08-18çš„
    å®Œæ•´å†å²Må€¼ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªCSVæ–‡ä»¶ä¾›åˆ†æè„šæœ¬ä½¿ç”¨ã€‚
    
    è¿è¡Œæ–¹å¼:
    python manage.py generate_m_value_csv
    """
    help = 'è®¡ç®—æ²ªæ·±300å†å²Må€¼å¹¶ç”Ÿæˆ m_value_csi300.csv æ–‡ä»¶'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('===== å¼€å§‹è®¡ç®—æ²ªæ·±300å†å²Må€¼ ====='))

        try:
            # 1. ä¸€æ¬¡æ€§ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰éœ€è¦çš„æ²ªæ·±300è¡Œæƒ…æ•°æ®
            self.stdout.write("æ­£åœ¨ä»æ•°æ®åº“åŠ è½½æ²ªæ·±300å†å²è¡Œæƒ…æ•°æ®...")
            quotes_qs = IndexQuotesCsi300.objects.all().order_by('trade_date').values('trade_date', 'close')
            if not quotes_qs:
                self.stdout.write(self.style.ERROR("é”™è¯¯ï¼šæ•°æ®åº“è¡¨ tb_index_quotes_csi300 ä¸­æ²¡æœ‰æ•°æ®ã€‚è¯·å…ˆå›å¡«æ•°æ®ã€‚"))
                return
            
            all_quotes_df = pd.DataFrame.from_records(quotes_qs)
            all_dates = all_quotes_df['trade_date'].tolist()
            self.stdout.write(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(all_dates)} ä¸ªäº¤æ˜“æ—¥ã€‚")

            # 2. åˆå§‹åŒ–SelectionServiceå¹¶åŠ è½½ä¸€æ¬¡å‚æ•°
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ—¥æœŸè¿›è¡Œåˆå§‹åŒ–ï¼Œåç»­åœ¨å¾ªç¯ä¸­æ›´æ–°æ—¥æœŸ
            service = SelectionService(trade_date=all_dates[0], mode='backtest')
            service._load_dynamic_parameters_and_defs()
            self.stdout.write("ç­–ç•¥æœåŠ¡å’Œå‚æ•°åˆå§‹åŒ–å®Œæˆã€‚")

            # 3. å¾ªç¯è®¡ç®—æ¯ä¸€å¤©çš„Må€¼
            results = []
            self.stdout.write("å¼€å§‹é€æ—¥è®¡ç®—Må€¼...")
            LOOKBACK_BUFFER = 100
            if len(all_dates) <= LOOKBACK_BUFFER:
                self.stdout.write(self.style.ERROR(f"é”™è¯¯ï¼šæ€»äº¤æ˜“æ—¥æ•° ({len(all_dates)}) ä¸è¶³ä»¥æ»¡è¶³ {LOOKBACK_BUFFER} å¤©çš„å›æº¯æœŸã€‚"))
                return
            # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡
            for current_date in tqdm(all_dates[LOOKBACK_BUFFER:], desc="è®¡ç®—Må€¼è¿›åº¦"):
                # æ›´æ–°æœåŠ¡çš„äº¤æ˜“æ—¥æœŸ
                service.trade_date = current_date
                
                # è°ƒç”¨æ ¸å¿ƒæ–¹æ³•è®¡ç®—Må€¼ï¼ŒæŒ‰è¦æ±‚ä¼ å…¥ç©ºstock_pool
                m_value = service._calculate_market_regime_M(stock_pool=[])
                
                # ä»å·²åŠ è½½çš„DataFrameä¸­è·å–æ”¶ç›˜ä»·
                close_price = all_quotes_df.loc[all_quotes_df['trade_date'] == current_date, 'close'].iloc[0]
                
                results.append({
                    'æ—¥æœŸ': current_date,
                    'må€¼': m_value,
                    'æ²ªæ·±300æ”¶ç›˜æŒ‡æ•°': float(close_price) # è½¬æ¢ä¸ºfloatä»¥ä¾¿pandaså¤„ç†
                })

            if not results:
                self.stdout.write(self.style.WARNING("è®¡ç®—å®Œæˆï¼Œä½†æ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœã€‚"))
                return

            # 4. å°†ç»“æœè½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜ä¸ºCSV
            self.stdout.write("æ‰€æœ‰Må€¼è®¡ç®—å®Œæˆï¼Œæ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶...")
            results_df = pd.DataFrame(results)
            
            # å®šä¹‰è¾“å‡ºè·¯å¾„ä¸ºé¡¹ç›®æ ¹ç›®å½•
            output_path = os.path.join(settings.BASE_DIR, 'm_value_csi300.csv')
            
            # ä¿å­˜æ–‡ä»¶ï¼Œä½¿ç”¨ utf-8-sig ç¼–ç ä»¥ç¡®ä¿Excelèƒ½æ­£ç¡®æ‰“å¼€
            results_df.to_csv(output_path, index=False, encoding='utf-8-sig', float_format='%.4f')

            self.stdout.write(self.style.SUCCESS(f"\n===== ä»»åŠ¡æˆåŠŸå®Œæˆï¼ ====="))
            self.stdout.write(f"æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")
            self.stdout.write(f"ç°åœ¨ä½ å¯ä»¥è¿è¡Œ [Må€¼å…³ç³»åˆ†æ.py] è„šæœ¬äº†ã€‚")

        except Exception as e:
            self.stdout.write(self.style.ERROR(f"ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"))
            logger.error("ç”ŸæˆMå€¼CSVæ–‡ä»¶å¤±è´¥", exc_info=True)


####æ–‡ä»¶ç»“æŸ####

####selection_manager\management\commands\prepare_csi300_features.py####
# selection_manager/management/commands/prepare_csi300_features.py

import logging
import pickle
import json
from pathlib import Path

import numpy as np
import pandas as pd
import pandas_ta as ta
from django.core.management.base import BaseCommand
from django.conf import settings
from tqdm import tqdm

from common.models import IndexQuotesCsi300

logger = logging.getLogger(__name__)

# ==============================================================================
#  ç‰¹å¾é…ç½®ä¸­å¿ƒ (Pluggable Feature Configuration)
# ==============================================================================
# é€šè¿‡ä¿®æ”¹æ­¤å­—å…¸çš„True/Falseå€¼ï¼Œå¯ä»¥æ§åˆ¶å“ªäº›ç‰¹å¾è¢«ç”¨äºè®­ç»ƒã€‚
# è¿™æ˜¯å®ç°â€œå¯æ’æ‹”â€è®¾è®¡çš„æ ¸å¿ƒã€‚
FEATURE_CONFIG = {
    # è¶‹åŠ¿åŠ¨èƒ½ (MT) ç»´åº¦
    'dynamic_ADX_CONFIRM': True,
    'dynamic_v2_MA_SLOPE': True,
    'dynamic_v2_MA_SCORE': True,
    'dynamic_v2_CPC_Factor': True,
    'dynamic_v2_VPCF': True,
    
    # å¼ºåŠ¿çªç ´ (BO) ç»´åº¦
    'dynamic_BREAKOUT_PWR': True,
    'dynamic_VOLUME_SURGE': True,
    'dynamic_MOM_ACCEL': True,

    # å‡å€¼å›å½’ (MR) ç»´åº¦
    'dynamic_RSI_OS': True,
    'dynamic_NEG_DEV': True,
    'dynamic_BOLL_LB': True,

    # è´¨é‡é˜²å¾¡ (QD) ç»´åº¦
    'dynamic_LOW_VOL': True,
    'dynamic_MAX_DD': True,
    'dynamic_DOWNSIDE_RISK': True,

    # æ–°å› å­
    'dynamic_MACD_SIGNAL': False,

    'dynamic_BREAKOUT_DURATION': False,

    # --- è€Må€¼ä½“ç³»å› å­ ---
    'dynamic_Old_D': True,
    'dynamic_Old_I': True,
    'dynamic_Old_M': True,
}

# ==============================================================================
#  ç‹¬ç«‹çš„å› å­è®¡ç®—å™¨ (Decoupled Factor Calculator)
# ==============================================================================
class FactorCalculator:
    """
    ä¸€ä¸ªç‹¬ç«‹çš„ã€è§£è€¦çš„å› å­è®¡ç®—å™¨ã€‚
    å®ƒåªæ¥æ”¶ä¸€ä¸ªæ ‡å‡†çš„OHLCVA DataFrameï¼Œå¹¶è®¡ç®—æ‰€æœ‰é¢„å®šä¹‰çš„å› å­ã€‚
    è¿™ä¸ªç±»å°†è¢«å¤åˆ¶åˆ° m_value_service.py ä¸­ä»¥ä¿æŒè§£è€¦ã€‚
    """
    def __init__(self, df: pd.DataFrame):
        if not all(col in df.columns for col in ['open', 'high', 'low', 'close', 'volume', 'amount']):
            raise ValueError("è¾“å…¥DataFrameå¿…é¡»åŒ…å« 'open', 'high', 'low', 'close', 'volume', 'amount' åˆ—")
        self.df = df.copy()
        # ç¡®ä¿ pandas_ta ä¸ä¼šæ‰“å°ä¸å¿…è¦çš„ä¿¡æ¯
        ta.Imports["verbose"] = False

    def run(self, config: dict) -> (pd.DataFrame, list):
        """
        æ ¹æ®é…ç½®è¿è¡Œæ‰€æœ‰å¯ç”¨çš„å› å­è®¡ç®—ã€‚
        è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰å› å­å€¼çš„DataFrameå’Œä½¿ç”¨çš„å› å­åˆ—è¡¨ã€‚
        """
        all_factors_df = pd.DataFrame(index=self.df.index)
        enabled_factors = []

        # è·å–æ‰€æœ‰å¯ç”¨çš„è®¡ç®—æ–¹æ³•
        calculator_methods = {
            'dynamic_ADX_CONFIRM': self._calc_adx_confirm,
            'dynamic_v2_MA_SLOPE': self._calc_v2_ma_slope,
            'dynamic_v2_MA_SCORE': self._calc_v2_ma_score,
            'dynamic_v2_CPC_Factor': self._calc_v2_cpc_factor,
            'dynamic_v2_VPCF': self._calc_v2_vpcf,
            'dynamic_BREAKOUT_PWR': self._calc_breakout_pwr,
            'dynamic_VOLUME_SURGE': self._calc_volume_surge,
            'dynamic_MOM_ACCEL': self._calc_mom_accel,
            'dynamic_RSI_OS': self._calc_rsi_os,
            'dynamic_NEG_DEV': self._calc_neg_dev,
            'dynamic_BOLL_LB': self._calc_boll_lb,
            'dynamic_LOW_VOL': self._calc_low_vol,
            'dynamic_MAX_DD': self._calc_max_dd,
            'dynamic_DOWNSIDE_RISK': self._calc_downside_risk,
            'dynamic_MACD_SIGNAL':self._calc_macd_signal,
            'dynamic_BREAKOUT_DURATION':self._calc_breakout_duration,
             # --- æ–°å¢è€Må€¼ä½“ç³»å› å­ ---
            'dynamic_Old_D': self._calc_old_d,
            'dynamic_Old_I': self._calc_old_i,
            'dynamic_Old_M': self._calc_old_m,
        }

        for factor_name, is_enabled in config.items():
            if is_enabled:
                if factor_name in calculator_methods:
                    logger.debug(f"Calculating factor: {factor_name}")
                    factor_series = calculator_methods[factor_name]()
                    all_factors_df[factor_name] = factor_series
                    enabled_factors.append(factor_name)
                else:
                    logger.warning(f"Factor '{factor_name}' is enabled in config but no calculation method found.")
        
        return all_factors_df, enabled_factors

    # --- è¶‹åŠ¿åŠ¨èƒ½ (MT) å› å­ ---
    def _calc_adx_confirm(self, length=14, adx_threshold=25):
        adx_df = self.df.ta.adx(length=length, high=self.df['high'], low=self.df['low'], close=self.df['close'])
        adx_col, dmp_col, dmn_col = f'ADX_{length}', f'DMP_{length}', f'DMN_{length}'
        condition = (adx_df[adx_col] > adx_threshold) & (adx_df[dmp_col] > adx_df[dmn_col])
        return adx_df[adx_col].where(condition, 0.0).rename('dynamic_ADX_CONFIRM')

    def _calc_v2_ma_slope(self, ma_period=20, ema_period=20):
        ma = self.df['close'].rolling(window=ma_period).mean()
        ma_roc = ma.pct_change(1)
        return ma_roc.ewm(span=ema_period, adjust=False).mean().rename('dynamic_v2_MA_SLOPE')

    def _calc_v2_ma_score(self, p1=5, p2=10, p3=20):
        close = self.df['close']
        ma5 = close.rolling(window=p1).mean()
        ma10 = close.rolling(window=p2).mean()
        ma20 = close.rolling(window=p3).mean()
        spread1 = (close - ma5) / ma5.replace(0, 1e-9)
        spread2 = (ma5 - ma10) / ma10.replace(0, 1e-9)
        spread3 = (ma10 - ma20) / ma20.replace(0, 1e-9)
        return ((spread1 + spread2 + spread3) / 3.0).rename('dynamic_v2_MA_SCORE')

    def _calc_v2_cpc_factor(self, ema_period=10):
        high, low, close = self.df['high'], self.df['low'], self.df['close']
        price_range = high - low
        dcp = (2 * close - high - low) / price_range.replace(0, 1e-9)
        return dcp.ewm(span=ema_period, adjust=False).mean().rename('dynamic_v2_CPC_Factor')

    def _calc_v2_vpcf(self, s=5, l=20, n_smooth=5):
        ma_close_s = self.df['close'].rolling(window=s).mean()
        price_momentum = ma_close_s.pct_change(1)
        ma_amount_s = self.df['amount'].rolling(window=s).mean()
        ma_amount_l = self.df['amount'].rolling(window=l).mean()
        volume_level = (ma_amount_s / ma_amount_l.replace(0, 1e-9)) - 1
        daily_score = price_momentum * volume_level
        return daily_score.ewm(span=n_smooth, adjust=False).mean().rename('dynamic_v2_VPCF')

    # --- å¼ºåŠ¿çªç ´ (BO) å› å­ ---
    def _calc_breakout_pwr(self, lookback=60, atr_period=14):
        high_lookback = self.df['high'].rolling(window=lookback).max().shift(1)
        atr = self.df.ta.atr(length=atr_period, high=self.df['high'], low=self.df['low'], close=self.df['close'])
        return ((self.df['close'] - high_lookback) / atr.replace(0, 1e-9)).rename('dynamic_BREAKOUT_PWR')

    def _calc_volume_surge(self, lookback=20):
        avg_amount = self.df['amount'].rolling(window=lookback).mean().shift(1)
        return (self.df['amount'] / avg_amount.replace(0, 1e-9)).rename('dynamic_VOLUME_SURGE')

    def _calc_mom_accel(self, roc_period=5, shift_period=11):
        roc = self.df['close'].pct_change(roc_period)
        roc_shifted = roc.shift(shift_period)
        return ((roc / roc_shifted.replace(0, np.nan)) - 1).rename('dynamic_MOM_ACCEL')

    # --- å‡å€¼å›å½’ (MR) å› å­ ---
    def _calc_rsi_os(self, length=14):
        return self.df.ta.rsi(close=self.df['close'], length=length).rename('dynamic_RSI_OS')

    def _calc_neg_dev(self, period=60):
        ma = self.df['close'].rolling(window=period).mean()
        return ((self.df['close'] - ma) / ma.replace(0, 1e-9)).rename('dynamic_NEG_DEV')

    def _calc_boll_lb(self, length=20, std=2.0):
        boll = self.df.ta.bbands(close=self.df['close'], length=length, std=std)
        lower_band = boll[f'BBL_{length}_{std}']
        upper_band = boll[f'BBU_{length}_{std}']
        band_width = upper_band - lower_band
        return ((self.df['close'] - lower_band) / band_width.replace(0, 1e-9)).rename('dynamic_BOLL_LB')

    # --- è´¨é‡é˜²å¾¡ (QD) å› å­ ---
    def _calc_low_vol(self, period=20):
        returns = self.df['close'].pct_change()
        return returns.rolling(window=period).std().rename('dynamic_LOW_VOL')

    def _calc_max_dd(self, period=60):
        rolling_max = self.df['close'].rolling(window=period, min_periods=1).max()
        daily_dd = self.df['close'] / rolling_max - 1.0
        return daily_dd.rolling(window=period, min_periods=1).min().rename('dynamic_MAX_DD')

    def _calc_downside_risk(self, period=60):
        returns = self.df['close'].pct_change()
        downside_returns = returns.copy()
        downside_returns[downside_returns > 0] = 0
        return downside_returns.rolling(window=period).std().rename('dynamic_DOWNSIDE_RISK')
    
    # --- æ–°å› å­ ---
    def _calc_macd_signal(self, fast=12, slow=26, signal=9):
        macd_df = self.df.ta.macd(fast=fast, slow=slow, signal=signal)
        macd_line = macd_df[f'MACD_{fast}_{slow}_{signal}']
        signal_line = macd_df[f'MACDs_{fast}_{slow}_{signal}']
        # å› å­å®šä¹‰ä¸ºï¼šMACDçº¿ä¸Šç©¿ä¿¡å·çº¿çš„å¼ºåº¦ï¼Œä¸”MACDçº¿åœ¨0è½´ä¹‹ä¸Š
        factor = (macd_line - signal_line).where(macd_line > 0, 0)
        return factor.rename('dynamic_MACD_SIGNAL')
    
    def _calc_breakout_duration(self, lookback=20):
        high_lookback = self.df['close'].rolling(window=lookback).max().shift(1)
        is_breakout = self.df['close'] > high_lookback
        
        # è®¡ç®—è¿ç»­ä¸ºTrueçš„å¤©æ•°
        breakout_streaks = is_breakout.groupby((is_breakout != is_breakout.shift()).cumsum()).cumsum()
        return breakout_streaks.rename('dynamic_BREAKOUT_DURATION')
    

    def _calc_old_d(self, lookback_k=20, a_param=200.0):
        """
        è®¡ç®—è€Må€¼ä½“ç³»ä¸­çš„æ–¹å‘å‡½æ•° D(t)ã€‚
        D(t) = tanh(a * h(t,K))
        h(t,K) æ˜¯è¿‡å»Kå¤©ä¸åŒå‘¨æœŸçº¿æ€§å›å½’æ–œç‡çš„å‡å€¼ã€‚
        """
        from scipy.stats import linregress # ä»…åœ¨æ­¤æ–¹æ³•ä¸­éœ€è¦
        close_prices = self.df['close']
        g_values_list = []
        
        # ä¸ºäº†å‘é‡åŒ–è®¡ç®—ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰éœ€è¦å›å½’çš„çª—å£çš„DataFrame
        # å¯¹äºæ¯ä¸ªäº¤æ˜“æ—¥tï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—ä»t-kåˆ°tçš„å›å½’ï¼Œkä»1åˆ°lookback_k
        for k in range(1, lookback_k + 1):
            # æˆªå– k+1 ä¸ªæ•°æ®ç‚¹
            windows = close_prices.rolling(window=k + 1)
            
            # ä½¿ç”¨applyå‡½æ•°å¯¹æ¯ä¸ªçª—å£è¿›è¡Œçº¿æ€§å›å½’
            # applyå‡½æ•°ä¼šæ¯”è¾ƒæ…¢ï¼Œä½†å¯¹äºè¿™ç§å¤æ‚çš„çª—å£è®¡ç®—æ˜¯å¿…è¦çš„
            # æ³¨æ„ï¼šlinregresséœ€è¦numpyæ•°ç»„
            slopes = windows.apply(lambda x: linregress(np.arange(len(x)), x).slope, raw=True)
            
            # è·å– t-k æ—¥çš„æ”¶ç›˜ä»·
            close_t_minus_k = close_prices.shift(k)
            
            # è®¡ç®— g(t,k)
            g_tk = slopes / close_t_minus_k.replace(0, 1e-9)
            g_values_list.append(g_tk)
        # å°†æ‰€æœ‰g(t,k)çš„å€¼åˆå¹¶æˆä¸€ä¸ªDataFrame
        g_df = pd.concat(g_values_list, axis=1)
        
        # è®¡ç®— h(t,K)ï¼Œå³å¯¹æ¯ä¸€è¡Œï¼ˆæ¯ä¸ªäº¤æ˜“æ—¥ï¼‰çš„gå€¼æ±‚å‡å€¼
        h_t_k = g_df.mean(axis=1)
        
        # è®¡ç®— D(t)
        d_t = np.tanh(a_param * h_t_k)
        
        return d_t.rename('dynamic_Old_D')
    def _calc_old_i(self, adx_period=14, adx_threshold=20.0, b_param=0.075):
        """
        è®¡ç®—è€Må€¼ä½“ç³»ä¸­çš„å¼ºåº¦å‡½æ•° I(t)ã€‚
        I(t) = max(0, tanh(b * (ADX(t) - threshold)))
        """
        # pandas_taåº“å¯ä»¥éå¸¸é«˜æ•ˆåœ°è®¡ç®—ADX
        adx_df = self.df.ta.adx(length=adx_period, high=self.df['high'], low=self.df['low'], close=self.df['close'])
        adx_series = adx_df[f'ADX_{adx_period}']
        
        # è®¡ç®— I(t)
        raw_i = np.tanh(b_param * (adx_series - adx_threshold))
        i_t = raw_i.clip(lower=0) # ä½¿ç”¨clipå®ç°max(0, raw_i)
        
        return i_t.rename('dynamic_Old_I')
    def _calc_old_m(self):
        """
        è®¡ç®—è€Må€¼ OldM(t) = D(t) * I(t)ã€‚
        è¿™ä¸ªå› å­ä¾èµ–äº _calc_old_d å’Œ _calc_old_i çš„è®¡ç®—ç»“æœã€‚
        ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬ç›´æ¥åœ¨è¿™é‡Œè°ƒç”¨å®ƒä»¬ï¼Œè€Œä¸æ˜¯é‡å¤è®¡ç®—ã€‚
        """
        # ä¸ºäº†é¿å…é‡å¤è®¡ç®—ï¼Œæˆ‘ä»¬æ£€æŸ¥è¿™äº›åˆ—æ˜¯å¦å·²å­˜åœ¨äºä¸€ä¸ªä¸´æ—¶çš„DataFrameä¸­
        # ä½†åœ¨å½“å‰æ¶æ„ä¸‹ï¼Œæœ€ç®€å•çš„åšæ³•æ˜¯é‡æ–°è®¡ç®—ä¸€æ¬¡ï¼Œæˆ–è€…ä¿®æ”¹runæ–¹æ³•
        # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç›´æ¥è®¡ç®—ï¼Œå› ä¸ºå› å­è®¡ç®—æ˜¯ç‹¬ç«‹çš„
        d_t = self._calc_old_d()
        i_t = self._calc_old_i()
        
        m_t = d_t * i_t
        
        return m_t.rename('dynamic_Old_M')




# ==============================================================================
#  ä¸»å‘½ä»¤ (Main Command)
# ==============================================================================
class Command(BaseCommand):
    help = '[M-Value Refactor] åŸºäºç²¾é€‰å› å­å’Œè¿ç»­å¤æ™®æ¯”ç‡æ ‡ç­¾ï¼Œä¸ºæ²ªæ·±300æŒ‡æ•°ç”Ÿæˆæœºå™¨å­¦ä¹ æ•°æ®é›†ã€‚'

    # --- è·¯å¾„å’Œé…ç½® ---
    MODELS_DIR = settings.BASE_DIR / 'selection_manager' / 'ml_models'
    DATASET_FILE = MODELS_DIR / 'm_value_dataset.pkl'
    MODEL_CONFIG_FILE = MODELS_DIR / 'm_value_model_config.json'

    # --- æ–°æ ‡ç­¾ä½“ç³»é…ç½® ---
    LABEL_LOOKFORWARD = 3      # å‘å‰çœ‹60ä¸ªäº¤æ˜“æ—¥è®¡ç®—å¤æ™®æ¯”ç‡
    RISK_FREE_RATE_ANNUAL = 0.02 # æ— é£é™©å¹´åˆ©ç‡ï¼Œè®¾ä¸º4%
    TANH_SCALING_FACTOR = 1    # tanhçš„ç¼©æ”¾å› å­aï¼Œä½¿å¾—å¤æ™®=1æ—¶æ¥è¿‘é¥±å’Œ

    def _get_continuous_m_labels(self, df: pd.DataFrame) -> pd.Series:
        """
        æ ¹æ®æœªæ¥60æ—¥å¹´åŒ–å¤æ™®æ¯”ç‡ï¼Œè®¡ç®—è¿ç»­çš„Må€¼æ ‡ç­¾ã€‚
        æ ‡ç­¾å…¬å¼: M = tanh(a * SharpeRatio)
        """
        self.stdout.write("æ­¥éª¤ 2/4: åº”ç”¨æ–°çš„è¿ç»­Må€¼æ ‡ç­¾ä½“ç³» (åŸºäºå¤æ™®æ¯”ç‡)...")
        
        # è®¡ç®—æ¯æ—¥æ”¶ç›Šç‡
        returns = df['close'].pct_change()
        
        # å°†å¹´åŒ–æ— é£é™©åˆ©ç‡è½¬æ¢ä¸ºæ—¥æ— é£é™©åˆ©ç‡
        # (1 + r_annual) = (1 + r_daily)^252  => r_daily = (1 + r_annual)^(1/252) - 1
        # ä¸€å¹´å¤§çº¦æœ‰252ä¸ªäº¤æ˜“æ—¥
        daily_risk_free_rate = (1 + self.RISK_FREE_RATE_ANNUAL)**(1/252) - 1
        
        # è®¡ç®—è¶…é¢æ”¶ç›Šç‡
        excess_returns = returns - daily_risk_free_rate
        
        # ä½¿ç”¨é«˜æ•ˆçš„å‘é‡åŒ–æ–¹æ³•è®¡ç®—æœªæ¥60å¤©çš„æ»šåŠ¨æŒ‡æ ‡
        # ä¸ºäº†è®¡ç®—æœªæ¥60å¤©ï¼Œæˆ‘ä»¬å°†æ•°æ®å‘å‰ç§»åŠ¨60å¤©ï¼Œç„¶åè®¡ç®—è¿‡å»60å¤©çš„æ»šåŠ¨å€¼
        # è¿™ç­‰ä»·äºåœ¨å½“å‰ç‚¹è®¡ç®—æœªæ¥60å¤©çš„æ•°æ®
        future_mean = excess_returns.shift(-self.LABEL_LOOKFORWARD).rolling(window=self.LABEL_LOOKFORWARD).mean()
        future_std = excess_returns.shift(-self.LABEL_LOOKFORWARD).rolling(window=self.LABEL_LOOKFORWARD).std()
        
        # è®¡ç®—å¹´åŒ–å¤æ™®æ¯”ç‡
        # å¹´åŒ–å› å­ = sqrt(252)
        # é¿å…é™¤ä»¥é›¶
        annualized_sharpe_ratio = (future_mean / future_std.replace(0, np.nan)) * np.sqrt(252)
        
        # åº”ç”¨tanhå‡½æ•°ç”Ÿæˆæœ€ç»ˆçš„Må€¼æ ‡ç­¾
        m_labels = np.tanh(self.TANH_SCALING_FACTOR * annualized_sharpe_ratio)
        m_labels_raw = np.tanh(self.TANH_SCALING_FACTOR * annualized_sharpe_ratio)
        m_labels_smoothed = m_labels_raw.rolling(window=5, min_periods=1).mean()
        self.stdout.write(f"æ ‡ç­¾è®¡ç®—å®Œæˆã€‚ç¼©æ”¾å› å­a={self.TANH_SCALING_FACTOR}, æ— é£é™©åˆ©ç‡(å¹´)={self.RISK_FREE_RATE_ANNUAL}")
        
        return m_labels_smoothed

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS("===== [M-Value Refactor] å¼€å§‹å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®é›† ====="))
        self.MODELS_DIR.mkdir(parents=True, exist_ok=True)

        # 1. åŠ è½½å¹¶å‡†å¤‡æ•°æ®
        self.stdout.write("æ­¥éª¤ 1/4: åŠ è½½æ²ªæ·±300è¡Œæƒ…æ•°æ®...")
        quotes_qs = IndexQuotesCsi300.objects.all().order_by('trade_date').values()
        df = pd.DataFrame.from_records(quotes_qs)
        df['trade_date'] = pd.to_datetime(df['trade_date'])
        df.set_index('trade_date', inplace=True)
        
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'amount']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        df.dropna(subset=numeric_cols, inplace=True)

        # 2. ç”Ÿæˆæ ‡ç­¾ (å·²é‡æ„ä¸ºè¿ç»­Må€¼)
        labels = self._get_continuous_m_labels(df)
        df['label'] = labels

        # 3. è®¡ç®—ç‰¹å¾
        self.stdout.write("æ­¥éª¤ 3/4: è®¡ç®—æ‰€æœ‰å·²å¯ç”¨çš„ç‰¹å¾...")
        calculator = FactorCalculator(df)
        features_df, enabled_features = calculator.run(FEATURE_CONFIG)
        
        # 4. å¯¹é½æ•°æ®å¹¶ä¿å­˜
        self.stdout.write("æ­¥éª¤ 4/4: å¯¹é½ç‰¹å¾å’Œæ ‡ç­¾ï¼Œå¹¶ä¿å­˜åˆ°æ–‡ä»¶...")
        
        # åˆå¹¶ç‰¹å¾å’Œæ ‡ç­¾
        final_df = pd.concat([features_df, df['label']], axis=1)
        
        # å‰”é™¤æ‰€æœ‰åŒ…å«NaNçš„è¡Œï¼ˆé€šå¸¸æ˜¯åºåˆ—å¼€å¤´å’Œç»“å°¾ï¼Œä»¥åŠæ ‡ç­¾è®¡ç®—çš„æœªæ¥çª—å£ï¼‰
        final_df.dropna(inplace=True)
        
        # åˆ†ç¦» X å’Œ y
        X = final_df[enabled_features]
        y = final_df['label'].astype(float) # æ ‡ç­¾ç°åœ¨æ˜¯æµ®ç‚¹æ•°
        
        self.stdout.write(f"æ•°æ®é›†å‡†å¤‡å®Œæˆã€‚æ€»æ ·æœ¬æ•°: {len(X)}")
        self.stdout.write("æ ‡ç­¾ï¼ˆMå€¼ï¼‰ç»Ÿè®¡ä¿¡æ¯:")
        self.stdout.write(str(y.describe()))
        
        # ä¿å­˜æ•°æ®é›†å’Œé…ç½®
        dataset = {
            'X': X,
            'y': y,
            'index': X.index,
            'feature_names': enabled_features,
            # 'label_map' ä¸å†éœ€è¦ï¼Œå› ä¸ºè¿™æ˜¯å›å½’ä»»åŠ¡
        }
        with open(self.DATASET_FILE, 'wb') as f:
            pickle.dump(dataset, f)
        
        self.stdout.write(self.style.SUCCESS(f"æ•°æ®é›†å·²æˆåŠŸä¿å­˜è‡³: {self.DATASET_FILE}"))
        
        # ä¿å­˜æ¨¡å‹é…ç½®ï¼Œä¸»è¦æ˜¯ç‰¹å¾åˆ—è¡¨ï¼Œä¾›é¢„æµ‹æ—¶ä½¿ç”¨
        model_config = {'feature_names': enabled_features}
        with open(self.MODEL_CONFIG_FILE, 'w') as f:
            json.dump(model_config, f, indent=4)
        self.stdout.write(self.style.SUCCESS(f"æ¨¡å‹é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {self.MODEL_CONFIG_FILE}"))
        self.stdout.write(self.style.SUCCESS("===== [M-Value Refactor] æ•°æ®å‡†å¤‡æµç¨‹ç»“æŸ ====="))

####æ–‡ä»¶ç»“æŸ####

####selection_manager\management\commands\prepare_stock_features.py####
# ==============================================================================
# æ–‡ä»¶ 1/4: selection_manager/management/commands/prepare_stock_features.py
# æè¿°: ä¸ºä¸ªè‚¡è¯„åˆ†æ¨¡å‹ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾æ•°æ®é›†ã€‚(å·²æ”¹é€ ä¸ºåˆ†æ‰¹å¤„ç†)
# ==============================================================================
import logging
import pickle
import json
import shutil # å¯¼å…¥shutilåº“ç”¨äºåˆ é™¤ç›®å½•
from pathlib import Path
from datetime import timedelta

import numpy as np
import pandas as pd
import pandas_ta as ta
from django.core.management.base import BaseCommand
from django.conf import settings
from tqdm import tqdm

from common.models import DailyQuotes, DailyFactorValues
from selection_manager.service.m_value_service import FactorCalculator # å¤ç”¨Må€¼æœåŠ¡ä¸­çš„å› å­è®¡ç®—å™¨
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE

logger = logging.getLogger(__name__)

# --- [é…ç½®åŒº] ---
# é€šè¿‡ä¿®æ”¹æ­¤å¤„çš„é…ç½®ï¼Œæ¥æ§åˆ¶æ•°æ®é›†çš„ç”Ÿæˆæ–¹å¼
LABEL_CONFIG = {
    'mode': 'return',  # 'return' (æœªæ¥æ”¶ç›Šç‡) æˆ– 'sharpe' (æœªæ¥å¤æ™®æ¯”ç‡)
    'lookforward_days': 3, # æ ‡ç­¾å‘å‰çœ‹çš„å¤©æ•° (N)
    'risk_free_rate_annual': 0.02, # å¹´åŒ–æ— é£é™©åˆ©ç‡ï¼Œä»…åœ¨ 'sharpe' æ¨¡å¼ä¸‹ä½¿ç”¨
    'tanh_scaling_factor': 4.0, # tanhç¼©æ”¾å› å­ï¼Œä»…åœ¨ 'sharpe' æ¨¡å¼ä¸‹ä½¿ç”¨
}

# å› å­è®¡ç®—æ‰€éœ€çš„æœ€å¤§å›æº¯æœŸï¼Œåº”å¤§äºæ‰€æœ‰å› å­ä¸­æœ€å¤§çš„lookback period
# ä¾‹å¦‚ï¼Œneg_dev(60), max_dd(60)ç­‰ï¼Œç»™è¶³100å¤©buffer
FACTOR_LOOKBACK_BUFFER = 100

# --- [æ–°å¢é…ç½®åŒº] ---
# åˆ†æ‰¹å¤„ç†çš„é…ç½®
BATCH_SIZE = 100 # æ¯æ¬¡å¤„ç†100åªè‚¡ç¥¨ï¼Œä»¥æ§åˆ¶å†…å­˜ä½¿ç”¨

class Command(BaseCommand):
    help = 'ä¸ºä¸ªè‚¡è¯„åˆ†æ¨¡å‹ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾æ•°æ®é›† (X, y)ã€‚é‡‡ç”¨åˆ†æ‰¹å¤„ç†ä»¥ä¼˜åŒ–å†…å­˜ã€‚'
    def add_arguments(self, parser):
        """æ·»åŠ å‘½ä»¤è¡Œå‚æ•°"""
        parser.add_argument(
            '--use-local-db',
            action='store_true',  # è¿™ä½¿å®ƒæˆä¸ºä¸€ä¸ªå¼€å…³ï¼Œå­˜åœ¨å³ä¸ºTrue
            help='å¦‚æœæŒ‡å®šï¼Œåˆ™å°†æ•°æ®æºåˆ‡æ¢è‡³ D:\\project\\mainDB.sqlite3 (éœ€åœ¨settings.pyä¸­é…ç½®å¥½local_sqlite)ã€‚'
        )
    # --- è·¯å¾„é…ç½® ---
    MODELS_DIR = settings.BASE_DIR / 'selection_manager' / 'ml_models'
    DATASET_FILE = MODELS_DIR / 'stock_features_dataset.pkl'
    MODEL_CONFIG_FILE = MODELS_DIR / 'stock_model_config.json' # ä¸ä¸ªè‚¡æ¨¡å‹å…±äº«é…ç½®
    
    # --- [æ–°å¢] ä¸´æ—¶æ–‡ä»¶å­˜å‚¨è·¯å¾„ ---
    TEMP_DATA_DIR = MODELS_DIR / 'temp_feature_batches'


    def handle(self, *args, **options):
        """
        ä¸»å¤„ç†å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªæ•°æ®é›†çš„ç”Ÿæˆæµç¨‹ã€‚
        æ”¹é€ åçš„æµç¨‹ï¼š
        1. å…¨å±€å‡†å¤‡ï¼šè·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç ã€Må€¼ã€å› å­åç­‰ä¸€æ¬¡æ€§æ•°æ®ã€‚
        2. åˆ†æ‰¹å¤„ç†ï¼šå°†è‚¡ç¥¨ä»£ç åˆ†æ‰¹ï¼Œå¯¹æ¯ä¸€æ‰¹æ¬¡æ‰§è¡Œâ€œåŠ è½½-è®¡ç®—-åˆå¹¶â€å¹¶å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ã€‚
        3. æœ€ç»ˆåˆå¹¶ï¼šå°†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶åˆå¹¶ä¸ºæœ€ç»ˆæ•°æ®é›†ã€‚
        4. æ¸…ç†ï¼šåˆ é™¤ä¸´æ—¶æ–‡ä»¶ã€‚
        """

        use_local_db = options['use_local_db']
        self.db_alias = 'local_sqlite' if use_local_db else 'default'
        
        db_source_message = f"D:\\project\\mainDB.sqlite3 (åˆ«å: {self.db_alias})" if use_local_db else f"é»˜è®¤æ•°æ®åº“ (åˆ«å: {self.db_alias})"
        self.stdout.write(self.style.SUCCESS(f"å½“å‰ä½¿ç”¨çš„æ•°æ®æº: {db_source_message}"))

        self.stdout.write(self.style.SUCCESS("===== å¼€å§‹ä¸ºä¸ªè‚¡è¯„åˆ†æ¨¡å‹å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®é›† (åˆ†æ‰¹å¤„ç†æ¨¡å¼) ====="))
        
        # --- [æ”¹é€ ] æ­¥éª¤ 0: å‡†å¤‡å·¥ä½œï¼Œåˆ›å»ºä¸´æ—¶ç›®å½• ---
        # å¦‚æœä¸´æ—¶ç›®å½•å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼Œç¡®ä¿ä¸€ä¸ªå¹²å‡€çš„å¼€å§‹
        if self.TEMP_DATA_DIR.exists():
            shutil.rmtree(self.TEMP_DATA_DIR)
        self.TEMP_DATA_DIR.mkdir(parents=True, exist_ok=True)
        self.stdout.write(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {self.TEMP_DATA_DIR}")

        try:
            # --- [æ”¹é€ ] æ­¥éª¤ 1: ä¸€æ¬¡æ€§åŠ è½½å…¨å±€/è½»é‡çº§æ•°æ® ---
            self.stdout.write("æ­¥éª¤ 1/5: åŠ è½½å…¨å±€æ•°æ® (è‚¡ç¥¨åˆ—è¡¨, Må€¼)...")
            all_stock_codes, m_values_series, start_date = self._load_global_data()
            if not all_stock_codes:
                self.stdout.write(self.style.ERROR("é”™è¯¯: æ•°æ®åº“ä¸­æ²¡æœ‰å¯ç”¨çš„è‚¡ç¥¨ä»£ç ã€‚"))
                return
            
            # ä»Må€¼æ¨¡å‹é…ç½®ä¸­è·å–æ‰€æœ‰éœ€è¦è®¡ç®—çš„å› å­åç§°
            feature_names = self._get_feature_names()

            # --- [æ”¹é€ ] æ­¥éª¤ 2: åˆ†æ‰¹ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾ï¼Œå¹¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ ---
            self.stdout.write(f"æ­¥éª¤ 2/5: å¼€å§‹åˆ†æ‰¹å¤„ç† {len(all_stock_codes)} åªè‚¡ç¥¨ï¼Œæ¯æ‰¹ {BATCH_SIZE} åª...")
            
            # å°†æ‰€æœ‰è‚¡ç¥¨ä»£ç åˆ†æ‰¹
            stock_batches = [all_stock_codes[i:i + BATCH_SIZE] for i in range(0, len(all_stock_codes), BATCH_SIZE)]
            
            # ä½¿ç”¨tqdmæ˜¾ç¤ºæ‰¹æ¬¡å¤„ç†è¿›åº¦
            batch_iterator = tqdm(enumerate(stock_batches), total=len(stock_batches), desc="å¤„ç†æ‰¹æ¬¡")
            
            intermediate_files = [] # ç”¨äºå­˜å‚¨ç”Ÿæˆçš„ä¸­é—´æ–‡ä»¶å

            for i, batch_codes in batch_iterator:
                batch_iterator.set_description(f"å¤„ç†æ‰¹æ¬¡ {i+1}/{len(stock_batches)}")
                self.stdout.write(f"\n  - [æ‰¹æ¬¡ {i+1}] å¼€å§‹åŠ è½½ {len(batch_codes)} åªè‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®...")
                # 2.1 åŠ è½½å½“å‰æ‰¹æ¬¡çš„è¡Œæƒ…æ•°æ®
                quotes_df = self._load_batch_quotes(batch_codes, start_date)
                if quotes_df.empty:
                    self.stdout.write(self.style.WARNING(f"è­¦å‘Š: æ‰¹æ¬¡ {i+1} æœªèƒ½åŠ è½½åˆ°ä»»ä½•æ•°æ®ï¼Œå·²è·³è¿‡ã€‚"))
                    continue
                self.stdout.write(f"  - [æ‰¹æ¬¡ {i+1}] è¡Œæƒ…æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(quotes_df)} æ¡è®°å½•ã€‚å¼€å§‹ç”Ÿæˆæ ‡ç­¾...")
                # 2.2 ä¸ºå½“å‰æ‰¹æ¬¡ç”Ÿæˆæ ‡ç­¾
                labels_df = self._generate_labels(quotes_df)
                self.stdout.write(f"  - [æ‰¹æ¬¡ {i+1}] æ ‡ç­¾ç”Ÿæˆå®Œæˆã€‚å¼€å§‹è®¡ç®—ç‰¹å¾...")
                # 2.3 ä¸ºå½“å‰æ‰¹æ¬¡è®¡ç®—å› å­ç‰¹å¾
                features_df = self._calculate_batch_features(quotes_df, feature_names)
                self.stdout.write(f"  - [æ‰¹æ¬¡ {i+1}] æ ‡ç­¾ç”Ÿæˆå®Œæˆã€‚å¼€å§‹è®¡ç®—ç‰¹å¾...")
                # 2.4 åˆå¹¶æ‰¹æ¬¡å†…çš„ç‰¹å¾ã€Må€¼å’Œæ ‡ç­¾
                # å°†Må€¼ä½œä¸ºä¸€ä¸ªç‰¹å¾åŠ å…¥
                features_df['market_m_value'] = features_df.index.get_level_values('trade_date').map(m_values_series)
                
                # åˆå¹¶æ‰¹æ¬¡æ•°æ®
                batch_final_df = features_df.join(labels_df, how='inner')
                batch_final_df.dropna(inplace=True)

                if batch_final_df.empty:
                    continue

                # 2.5 å°†å¤„ç†å¥½çš„æ‰¹æ¬¡æ•°æ®ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                temp_file_path = self.TEMP_DATA_DIR / f'batch_{i}.pkl'
                with open(temp_file_path, 'wb') as f:
                    pickle.dump(batch_final_df, f)
                intermediate_files.append(temp_file_path)

            if not intermediate_files:
                self.stdout.write(self.style.ERROR("é”™è¯¯: æ‰€æœ‰æ‰¹æ¬¡å¤„ç†åæœªç”Ÿæˆä»»ä½•æœ‰æ•ˆæ•°æ®ã€‚è¯·æ£€æŸ¥æ•°æ®èŒƒå›´æˆ–å› å­è®¡ç®—ã€‚"))
                return

            # --- [æ”¹é€ ] æ­¥éª¤ 3 & 4: åˆå¹¶æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ ---
            self.stdout.write(f"\næ­¥éª¤ 3/5 & 4/5: åˆå¹¶ {len(intermediate_files)} ä¸ªä¸­é—´æ–‡ä»¶...")
            all_dfs = []
            for file_path in tqdm(intermediate_files, desc="åˆå¹¶æ–‡ä»¶"):
                with open(file_path, 'rb') as f:
                    batch_df = pickle.load(f)
                    all_dfs.append(batch_df)
            
            final_df = pd.concat(all_dfs, ignore_index=False) # ignore_index=Falseä¿ç•™(date, code)å¤šçº§ç´¢å¼•

            # --- [æ— æ”¹åŠ¨] æ­¥éª¤ 5: ä¿å­˜æœ€ç»ˆæ•°æ®é›†å’Œé…ç½® ---
            self.stdout.write("æ­¥éª¤ 5/5: ä¿å­˜æœ€ç»ˆæ•°æ®é›†å’Œæ¨¡å‹é…ç½®æ–‡ä»¶...")
            # åœ¨æœ€ç»ˆåˆå¹¶åçš„DataFrameä¸­åŠ å…¥market_m_valueç‰¹å¾å
            if 'market_m_value' not in feature_names:
                feature_names.append('market_m_value')

            X = final_df[feature_names]
            y = final_df['label']

            self.stdout.write(f"æ•°æ®é›†å‡†å¤‡å®Œæˆã€‚æ€»æ ·æœ¬æ•°: {len(X)}")
            self.stdout.write("æ ‡ç­¾ (label) ç»Ÿè®¡ä¿¡æ¯:")
            self.stdout.write(str(y.describe()))

            dataset = {'X': X, 'y': y, 'index': X.index, 'feature_names': feature_names}
            with open(self.DATASET_FILE, 'wb') as f:
                pickle.dump(dataset, f)
            self.stdout.write(self.style.SUCCESS(f"æ•°æ®é›†å·²æˆåŠŸä¿å­˜è‡³: {self.DATASET_FILE}"))

            model_config = {'feature_names': feature_names}
            with open(self.MODEL_CONFIG_FILE, 'w') as f:
                json.dump(model_config, f, indent=4)
            self.stdout.write(self.style.SUCCESS(f"æ¨¡å‹é…ç½®æ–‡ä»¶å·²æˆåŠŸä¿å­˜è‡³: {self.MODEL_CONFIG_FILE}"))
            
        finally:
            # --- [æ–°å¢] æ¸…ç†æ­¥éª¤ ---
            # æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½å°è¯•åˆ é™¤ä¸´æ—¶ç›®å½•
            if self.TEMP_DATA_DIR.exists():
                shutil.rmtree(self.TEMP_DATA_DIR)
                self.stdout.write(self.style.SUCCESS(f"ä¸´æ—¶ç›®å½•å·²æ¸…ç†: {self.TEMP_DATA_DIR}"))
        
        self.stdout.write(self.style.SUCCESS("===== æ•°æ®å‡†å¤‡æµç¨‹ç»“æŸ ====="))

    def _load_global_data(self):
        """
        [æ–°å¢] ä¸€æ¬¡æ€§ä»æ•°æ®åº“åŠ è½½å…¨å±€å…±äº«ä¸”æ•°æ®é‡è¾ƒå°çš„æ•°æ®ã€‚
        - æ‰€æœ‰å”¯ä¸€çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ã€‚
        - å¸‚åœºMå€¼æ—¶é—´åºåˆ—ã€‚
        - è®¡ç®—å¹¶è¿”å›å…¨å±€çš„æ•°æ®èµ·å§‹æ—¥æœŸã€‚
        """
        # ç¡®å®šæ•°æ®åŠ è½½çš„èµ·å§‹æ—¥æœŸ
        first_quote = DailyQuotes.objects.order_by('trade_date').first()
        if not first_quote:
            return [], pd.Series(), None
        
        start_date = first_quote.trade_date + timedelta(days=FACTOR_LOOKBACK_BUFFER)
        self.stdout.write(f"å…¨å±€æ•°æ®åŠ è½½èµ·å§‹æ—¥æœŸ (å·²è€ƒè™‘å› å­è®¡ç®—ç¼“å†²): {start_date}")

        # åŠ è½½æ‰€æœ‰å”¯ä¸€çš„è‚¡ç¥¨ä»£ç 
        all_stock_codes = list(DailyQuotes.objects.using(self.db_alias).values_list('stock_code_id', flat=True).distinct())
        
        # åŠ è½½Må€¼
        m_values_qs = DailyFactorValues.objects.filter(
            stock_code_id=MARKET_INDICATOR_CODE,
            factor_code_id='dynamic_M_VALUE',
            trade_date__gte=start_date
        ).values('trade_date', 'raw_value')
        m_values_df = pd.DataFrame.from_records(m_values_qs)
        m_values_series = pd.Series()
        if not m_values_df.empty:
            m_values_series = m_values_df.set_index('trade_date')['raw_value'].astype(float)
        
        return all_stock_codes, m_values_series, start_date
    
    def _load_batch_quotes(self, batch_codes: list, start_date):
        """
        [æ–°å¢] ä»æ•°æ®åº“åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡è‚¡ç¥¨çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ã€‚
        """
        # åŠ è½½æŒ‡å®šè‚¡ç¥¨æ‰¹æ¬¡çš„æ—¥çº¿è¡Œæƒ…
        quotes_qs = DailyQuotes.objects.using(self.db_alias).filter(
            trade_date__gte=start_date,
            stock_code_id__in=batch_codes # æ ¸å¿ƒæ”¹åŠ¨ï¼šåªæŸ¥è¯¢å½“å‰æ‰¹æ¬¡çš„è‚¡ç¥¨
        ).values(
            'trade_date', 'stock_code_id', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close'
        )
        if not quotes_qs.exists():
            return pd.DataFrame()

        quotes_df = pd.DataFrame.from_records(quotes_qs)
        numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']
        for col in numeric_cols:
            quotes_df[col] = pd.to_numeric(quotes_df[col], errors='coerce')
        
        quotes_df['adj_factor'] = quotes_df['hfq_close'] / (quotes_df['close'] + 1e-9)
        
        # 3. è®¡ç®—åå¤æƒçš„ open, high, low
        quotes_df['hfq_open'] = quotes_df['open'] * quotes_df['adj_factor']
        quotes_df['hfq_high'] = quotes_df['high'] * quotes_df['adj_factor']
        quotes_df['hfq_low'] = quotes_df['low'] * quotes_df['adj_factor']
        
        # 4. ä¸ºäº†åç»­è®¡ç®—å™¨æ¥å£ç»Ÿä¸€ï¼Œé‡å‘½ååˆ—
        #    ç°åœ¨ 'open', 'high', 'low', 'close' éƒ½ä»£è¡¨åå¤æƒä»·æ ¼
        final_df = pd.DataFrame({
            'trade_date': quotes_df['trade_date'],
            'stock_code_id': quotes_df['stock_code_id'],
            'open': quotes_df['hfq_open'],
            'high': quotes_df['hfq_high'],
            'low': quotes_df['hfq_low'],
            'close': quotes_df['hfq_close'], # ç›´æ¥ä½¿ç”¨hfq_closeä½œä¸ºå¤æƒæ”¶ç›˜ä»·
            'volume': quotes_df['volume'],
            'amount': quotes_df['turnover'] # åŒæ—¶åœ¨è¿™é‡Œå®Œæˆturnoveråˆ°amountçš„é‡å‘½å
        })
        
        return final_df


    def _generate_labels(self, quotes_df: pd.DataFrame) -> pd.DataFrame:
        """
        [æ— æ”¹åŠ¨] æ ¹æ®é…ç½®ä¸ºç»™å®šçš„DataFrameç”Ÿæˆæ ‡ç­¾ã€‚
        æ­¤å‡½æ•°é€»è¾‘ä¸å˜ï¼Œç°åœ¨ä½œç”¨äºå°æ‰¹é‡çš„DataFrameï¼Œå› æ­¤å†…å­˜å‹å¥½ã€‚
        """
        df = quotes_df.set_index(['trade_date', 'stock_code_id'])['close'].unstack()
        df.replace(0, np.nan, inplace=True)
        if LABEL_CONFIG['mode'] == 'return':
            # è®¡ç®—æœªæ¥Næ—¥æ”¶ç›Šç‡
            future_price = df.shift(-LABEL_CONFIG['lookforward_days'])
            labels = (future_price / df) - 1
            labels=np.tanh(LABEL_CONFIG['tanh_scaling_factor'] * labels)
        elif LABEL_CONFIG['mode'] == 'sharpe':
            # è®¡ç®—æœªæ¥Næ—¥å¤æ™®æ¯”ç‡
            returns = df.pct_change(fill_method=None)
            daily_rf = (1 + LABEL_CONFIG['risk_free_rate_annual'])**(1/252) - 1
            excess_returns = returns - daily_rf
            
            future_mean = excess_returns.shift(-LABEL_CONFIG['lookforward_days']).rolling(window=LABEL_CONFIG['lookforward_days']).mean()
            future_std = excess_returns.shift(-LABEL_CONFIG['lookforward_days']).rolling(window=LABEL_CONFIG['lookforward_days']).std()
            
            annualized_sharpe = (future_mean / future_std.replace(0, np.nan)) * np.sqrt(252)
            labels = np.tanh(LABEL_CONFIG['tanh_scaling_factor'] * annualized_sharpe)
        else:
            raise ValueError(f"æœªçŸ¥çš„æ ‡ç­¾æ¨¡å¼: {LABEL_CONFIG['mode']}")

        return labels.stack().rename('label').to_frame()

    def _get_feature_names(self):
        """
        [æ–°å¢] å°è£…äº†è·å–å› å­åç§°åˆ—è¡¨çš„é€»è¾‘ï¼Œåªæ‰§è¡Œä¸€æ¬¡ã€‚
        """
        try:
            with open(settings.BASE_DIR / 'selection_manager' / 'ml_models' / 'm_value_model_config.json', 'r') as f:
                m_value_config = json.load(f)
            feature_names = m_value_config['feature_names']
            self.stdout.write("æˆåŠŸä»'m_value_model_config.json'åŠ è½½å› å­åˆ—è¡¨ã€‚")
        except FileNotFoundError:
            self.stdout.write(self.style.ERROR("é”™è¯¯: Må€¼æ¨¡å‹é…ç½®æ–‡ä»¶ 'm_value_model_config.json' ä¸å­˜åœ¨ã€‚"))
            # å¦‚æœMå€¼æ¨¡å‹ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨ä¸€ä¸ªé¢„å®šä¹‰çš„å› å­åˆ—è¡¨
            feature_names = [
                'dynamic_ADX_CONFIRM', 'dynamic_v2_MA_SLOPE', 'dynamic_v2_MA_SCORE',
                'dynamic_v2_CPC_Factor', 'dynamic_v2_VPCF', 'dynamic_BREAKOUT_PWR',
                'dynamic_VOLUME_SURGE', 'dynamic_MOM_ACCEL', 'dynamic_RSI_OS',
                'dynamic_NEG_DEV', 'dynamic_BOLL_LB', 'dynamic_LOW_VOL',
                'dynamic_MAX_DD', 'dynamic_DOWNSIDE_RISK', 'dynamic_Old_D',
                'dynamic_Old_I', 'dynamic_Old_M'
            ]
            self.stdout.write(self.style.WARNING(f"å°†ä½¿ç”¨é»˜è®¤çš„å› å­åˆ—è¡¨: {feature_names}"))
        return feature_names

    def _calculate_batch_features(self, quotes_df: pd.DataFrame, feature_names: list):
        """
        [åç§°å’Œç­¾åæœ‰æ”¹åŠ¨] å¯¹ä¸€ä¸ªæ‰¹æ¬¡çš„è‚¡ç¥¨è®¡ç®—æ‰€æœ‰å› å­ç‰¹å¾ã€‚
        åŸ_calculate_all_featuresï¼Œé€»è¾‘ä¸å˜ï¼Œä½†ç°åœ¨å¤„ç†çš„æ˜¯å°æ‰¹é‡çš„DataFrameã€‚
        """
        all_features_list = []
        stock_groups = quotes_df.groupby('stock_code_id')
        
        # è¿™é‡Œçš„tqdmç°åœ¨æ˜¾ç¤ºå•æ‰¹æ¬¡å†…çš„è‚¡ç¥¨è®¡ç®—è¿›åº¦ï¼Œå¯ä»¥ç¦ç”¨ä»¥å‡å°‘æ—¥å¿—è¾“å‡º
        for stock_code, group_df in stock_groups: # tqdm(stock_groups, desc="è®¡ç®—æ‰¹æ¬¡å†…å› å­", leave=False)
            #group_df = group_df.rename(columns={'turnover': 'amount'})
            group_df = group_df.set_index('trade_date').sort_index()
            
            # ç¡®ä¿æ•°æ®è¿ç»­ï¼Œå¡«å……ç¼ºå¤±çš„äº¤æ˜“æ—¥
            min_date, max_date = group_df.index.min(), group_df.index.max()
            if pd.isna(min_date) or pd.isna(max_date):
                continue
            full_date_range = pd.date_range(start=min_date, end=max_date, freq='B')
            group_df = group_df.reindex(full_date_range).ffill()
            
            if len(group_df) < FACTOR_LOOKBACK_BUFFER:
                continue

            # ä½¿ç”¨å¤ç”¨çš„å› å­è®¡ç®—å™¨
            calculator = FactorCalculator(group_df)
            stock_features_df = calculator.run(feature_names)
            stock_features_df['stock_code_id'] = stock_code
            all_features_list.append(stock_features_df)

        if not all_features_list:
            return pd.DataFrame()
            
        # åˆå¹¶æ‰¹æ¬¡ä¸­æ‰€æœ‰è‚¡ç¥¨çš„ç‰¹å¾
        final_features_df = pd.concat(all_features_list)
        final_features_df = final_features_df.reset_index().rename(columns={'index': 'trade_date'})
        final_features_df = final_features_df.set_index(['trade_date', 'stock_code_id'])
        
        return final_features_df


####æ–‡ä»¶ç»“æŸ####

####selection_manager\management\commands\train_csi300_model_test.py####
# selection_manager/management/commands/train_csi300_model_test.py

import logging
import pickle
import json

import numpy as np
import pandas as pd
import lightgbm as lgb
from django.core.management.base import BaseCommand
from django.conf import settings
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score
# ç§»é™¤åˆ†ç±»ç›¸å…³çš„å¯¼å…¥
# from sklearn.utils.class_weight import compute_sample_weight
import joblib
import optuna

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = '[M-Value Refactor] è®­ç»ƒLightGBMå›å½’æ¨¡å‹ä»¥ç›´æ¥é¢„æµ‹Må€¼ã€‚'

    # --- è·¯å¾„é…ç½® ---
    MODELS_DIR = settings.BASE_DIR / 'selection_manager' / 'ml_models'
    DATASET_FILE = MODELS_DIR / 'm_value_dataset.pkl'
    MODEL_FILE = MODELS_DIR / 'm_value_lgbm_model.joblib'
    MODEL_CONFIG_FILE = MODELS_DIR / 'm_value_model_config.json'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS("===== [M-Value Refactor] å¼€å§‹è®­ç»ƒLightGBMå›å½’æ¨¡å‹ ====="))

        # 1. åŠ è½½æ•°æ®é›†
        self.stdout.write(f"æ­¥éª¤ 1/4: ä» {self.DATASET_FILE} åŠ è½½æ•°æ®é›†...")
        try:
            with open(self.DATASET_FILE, 'rb') as f:
                dataset = pickle.load(f)
            X, y, feature_names = dataset['X'], dataset['y'], dataset['feature_names']
            # label_map ä¸å†å­˜åœ¨
        except FileNotFoundError:
            self.stdout.write(self.style.ERROR(f"é”™è¯¯: æ•°æ®é›†æ–‡ä»¶ {self.DATASET_FILE} ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œ 'prepare_csi300_features' å‘½ä»¤ã€‚"))
            return

        # 2. å®šä¹‰æ¨¡å‹å’Œäº¤å‰éªŒè¯
        self.stdout.write("æ­¥éª¤ 2/4: è®¾ç½®å›å½’æ¨¡å‹å‚æ•°å’Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯...")
        
        # LightGBM å›å½’æ¨¡å‹å‚æ•°
        lgbm_params = {
            # --- æ ¸å¿ƒå‚æ•° (å®šä¹‰æ¨¡å‹çš„åŸºæœ¬ä»»åŠ¡å’Œç±»å‹) ---
            'objective': 'regression',      # ç›®æ ‡å‡½æ•°: 'regression' (æˆ– 'regression_l1', 'regression_l2') è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ã€‚æ¨¡å‹çš„ç›®æ ‡æ˜¯æœ€å°åŒ–å‡æ–¹è¯¯å·®(L2æŸå¤±)ã€‚
            # 'num_class' å‚æ•°åœ¨å›å½’ä»»åŠ¡ä¸­ä¸éœ€è¦
            'boosting_type': 'gbdt',        # æå‡ç±»å‹: 'gbdt' (Gradient Boosting Decision Tree) æ˜¯æœ€ç»å…¸ã€æœ€å¸¸ç”¨çš„ç®—æ³•ã€‚
            'metric': 'rmse',               # è¯„ä¼°æŒ‡æ ‡: 'rmse' (Root Mean Squared Error, å‡æ–¹æ ¹è¯¯å·®) æ˜¯å›å½’é—®é¢˜ä¸­æœ€å¸¸ç”¨çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºç›‘æ§éªŒè¯é›†æ€§èƒ½å’Œæ—©åœã€‚
            
            # --- æ€§èƒ½ä¸é€Ÿåº¦ (å½±å“è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹å­¦ä¹ èƒ½åŠ›) ---
            'n_estimators': 5000,           # è¿­ä»£æ¬¡æ•° (æ ‘çš„æ•°é‡): æ¨¡å‹è¦æ„å»ºçš„æ ‘çš„æ€»æ•°ã€‚
                                            # æ”¹å¤§: å…è®¸æ¨¡å‹è¿›è¡Œæ›´å¤šè½®çš„å­¦ä¹ ï¼Œå¯èƒ½æ•æ‰æ›´å¤æ‚çš„æ¨¡å¼ï¼Œä½†å¢åŠ è®­ç»ƒæ—¶é—´ã€‚
                                            # æ”¹å°: è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œä½†å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆã€‚
                                            # åæœ: é€šå¸¸è®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„å€¼ï¼ˆå¦‚1000-10000ï¼‰ï¼Œå¹¶é…åˆæ—©åœä½¿ç”¨ï¼Œè®©æ¨¡å‹åœ¨éªŒè¯é›†æ€§èƒ½ä¸å†æå‡æ—¶è‡ªåŠ¨åœæ­¢ï¼Œä»è€Œæ‰¾åˆ°æœ€ä½³è¿­ä»£æ¬¡æ•°ã€‚
            'learning_rate': 0.01,          # å­¦ä¹ ç‡: æ§åˆ¶æ¯æ¬¡è¿­ä»£ï¼ˆæ¯æ£µæ ‘ï¼‰å¯¹æœ€ç»ˆç»“æœçš„è´¡çŒ®ç¨‹åº¦ã€‚
                                            # æ”¹å° (å¦‚0.005): æ¨¡å‹å­¦ä¹ å¾—æ›´æ…¢ã€æ›´ç²¾ç»†ï¼Œéœ€è¦æ›´å¤šçš„ 'n_estimators' æ‰èƒ½è¾¾åˆ°å¥½çš„æ•ˆæœï¼Œä½†é€šå¸¸èƒ½æ‰¾åˆ°æ³›åŒ–èƒ½åŠ›æ›´å¥½çš„æ¨¡å‹ã€‚
                                            # æ”¹å¤§ (å¦‚0.1): æ¨¡å‹å­¦ä¹ å¾—æ›´å¿«ï¼Œä½†å®¹æ˜“è·³è¿‡æœ€ä¼˜è§£ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚
                                            # åæœ: 'learning_rate' å’Œ 'n_estimators' å¼ºç›¸å…³ã€‚æ¨èç­–ç•¥æ˜¯ï¼šä½ 'learning_rate' (å¦‚ 0.01-0.05) + é«˜ 'n_estimators' + æ—©åœã€‚
            'n_jobs': -1,                   # å¹¶è¡Œçº¿ç¨‹æ•°: '-1' è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒï¼Œä»¥æœ€å¤§åŒ–è®­ç»ƒé€Ÿåº¦ã€‚
            'seed': 42,                     # éšæœºç§å­: ç”¨äºç¡®ä¿æ¯æ¬¡è®­ç»ƒçš„ç»“æœå¯å¤ç°ã€‚åªè¦ç§å­ä¸å˜ï¼Œæ•°æ®åˆ’åˆ†ã€ç‰¹å¾é€‰æ‹©ç­‰éšæœºè¿‡ç¨‹çš„ç»“æœå°±ä¼šå›ºå®šã€‚
            'verbose': -1,                  # æ—¥å¿—è¯¦ç»†ç¨‹åº¦: '-1' è¡¨ç¤ºä¸è¾“å‡ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯¦ç»†æ—¥å¿—ï¼Œä¿æŒæ§åˆ¶å°è¾“å‡ºå¹²å‡€ã€‚
            
            # --- æ§åˆ¶è¿‡æ‹Ÿåˆ (å…³é”®è°ƒä¼˜åŒºï¼Œé˜²æ­¢æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šè¡¨ç°å·®) ---
            'num_leaves': 31,               # æ¯æ£µæ ‘çš„æœ€å¤§å¶å­èŠ‚ç‚¹æ•°: æ§åˆ¶æ¨¡å‹å¤æ‚åº¦çš„æ ¸å¿ƒå‚æ•°ã€‚
                                            # æ”¹å¤§: å…è®¸æ ‘æ¨¡å‹å­¦ä¹ åˆ°æ›´å¤æ‚çš„è§„åˆ™ï¼Œå¯èƒ½æå‡è®­ç»ƒé›†è¡¨ç°ï¼Œä½†ææ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚
                                            # æ”¹å°: é™åˆ¶æ ‘çš„å¤æ‚åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œä½†è¿‡å°ä¼šä½¿æ¨¡å‹è¿‡äºç®€å•ï¼Œå¯¼è‡´æ¬ æ‹Ÿåˆã€‚
                                            # åæœ: å®ƒçš„å€¼åº”å°äº 2^max_depthã€‚'31' æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„ã€ç¨³å¥çš„é»˜è®¤å€¼ã€‚
            'max_depth': -1,                # æ ‘çš„æœ€å¤§æ·±åº¦: é™åˆ¶æ ‘å¯ä»¥ç”Ÿé•¿çš„æœ€å¤§å±‚æ•°ã€‚åœ¨LightGBMä¸­ï¼Œé€šå¸¸ä¼˜å…ˆç”¨ 'num_leaves' æ§åˆ¶å¤æ‚åº¦ï¼Œ'max_depth'è®¾ä¸º-1ï¼ˆä¸é™åˆ¶ï¼‰ã€‚
            'subsample': 0.8,               # æ ·æœ¬é‡‡æ ·æ¯”ä¾‹ (è¡Œé‡‡æ ·): æ¯æ¬¡è¿­ä»£æ—¶ï¼Œä»æ€»è®­ç»ƒæ•°æ®ä¸­éšæœºé‡‡æ ·çš„æ¯”ä¾‹ã€‚
                                            # æ”¹å° (å¦‚0.7): æ¯æ¬¡åªç”¨ä¸€éƒ¨åˆ†æ•°æ®è®­ç»ƒï¼Œå¢åŠ äº†æ¨¡å‹çš„éšæœºæ€§ï¼Œæœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚å€¼å¿…é¡»åœ¨ (0, 1.0] ä¹‹é—´ã€‚
            'colsample_bytree': 0.8,        # ç‰¹å¾é‡‡æ ·æ¯”ä¾‹ (åˆ—é‡‡æ ·): æ¯æ¬¡è¿­ä»£æ—¶ï¼Œä»æ€»ç‰¹å¾ä¸­éšæœºé€‰æ‹©çš„æ¯”ä¾‹ã€‚
                                            # æ”¹å° (å¦‚0.7): æ¯æ¬¡åªç”¨ä¸€éƒ¨åˆ†ç‰¹å¾æ¥å»ºæ ‘ï¼Œæœ‰åŠ©äºé˜²æ­¢æ¨¡å‹è¿‡åº¦ä¾èµ–å°‘æ•°å‡ ä¸ªå¼ºç‰¹å¾ï¼Œä»è€Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
            'reg_alpha': 0.1,               # L1 æ­£åˆ™åŒ–é¡¹: å¯¹æ¨¡å‹æƒé‡æ–½åŠ L1æƒ©ç½šã€‚
            'reg_lambda': 0.1,              # L2 æ­£åˆ™åŒ–é¡¹: å¯¹æ¨¡å‹æƒé‡æ–½åŠ L2æƒ©ç½šã€‚
        }

        # æ­¥éª¤ 3/4: ä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–å’ŒéªŒè¯
        self.stdout.write("æ­¥éª¤ 3/4: ä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–...")
        # å°†æ•°æ®çš„å20%ä½œä¸ºéªŒè¯é›†ï¼Œå‰80%ä½œä¸ºè®­ç»ƒé›†
        split_point = int(len(X) * 0.8)
        X_train, X_val = X.iloc[:split_point], X.iloc[split_point:]
        y_train, y_val = y.iloc[:split_point], y.iloc[split_point:]
        self.stdout.write(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}, éªŒè¯é›†å¤§å°: {len(X_val)}")
        
        # å›å½’ä»»åŠ¡ä¸éœ€è¦è®¡ç®—æ ·æœ¬æƒé‡
        # sample_weights = compute_sample_weight(...)

        # å®šä¹‰ Optuna çš„ç›®æ ‡å‡½æ•° (objective function)
        def objective(trial):
            # --- å®šä¹‰è¦æœç´¢çš„å‚æ•°ç©ºé—´ ---
            params_to_tune = {
                'num_leaves': trial.suggest_int('num_leaves', 10, 100),
                'max_depth': trial.suggest_int('max_depth', 3, 100),
                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 1.0, log=True),
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 1.0, log=True),
            }
            
            # åˆå¹¶åŸºç¡€å‚æ•°å’Œå½“å‰å°è¯•çš„å‚æ•°
            current_params = lgbm_params.copy()
            current_params.update(params_to_tune)
            
            # --- ä½¿ç”¨æ—¶åºäº¤å‰éªŒè¯è¿›è¡Œè¯„ä¼° ---
            tscv = TimeSeriesSplit(n_splits=5) 
            rmses = []
            for train_index, val_index in tscv.split(X):
                X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]
                y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]
                
                model = lgb.LGBMRegressor(**current_params)
                
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train_fold, y_train_fold)
                
                # åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹
                val_preds = model.predict(X_val_fold)
                
                # è®¡ç®—å‡æ–¹æ ¹è¯¯å·®
                rmse = np.sqrt(mean_squared_error(y_val_fold, val_preds))
                rmses.append(rmse)
                
            # è¿”å›æ‰€æœ‰æŠ˜å åˆ†æ•°çš„å¹³å‡å€¼ï¼ŒOptunaå°†æœ€å°åŒ–è¿™ä¸ªå¹³å‡å€¼
            return np.mean(rmses)

        # --- è¿è¡Œ Optuna ä¼˜åŒ– ---
        self.stdout.write("å¼€å§‹å‚æ•°æœç´¢ (n_trials=50)...")
        study = optuna.create_study(direction='minimize') # ç›®æ ‡æ˜¯æœ€å°åŒ– RMSE
        study.optimize(objective, n_trials=5) # å°è¯• 50 ç»„å‚æ•°ç»„åˆ
        
        # --- è·å–å¹¶æŠ¥å‘Šæœ€ä½³å‚æ•° ---
        best_params = lgbm_params.copy()
        best_params.update(study.best_params)
        self.stdout.write(self.style.SUCCESS(f"\næœç´¢å®Œæˆï¼æœ€ä½³éªŒè¯é›† RMSE: {study.best_value:.4f}"))
        self.stdout.write(self.style.SUCCESS(f"æ‰¾åˆ°çš„æœ€ä½³å‚æ•°: {study.best_params}"))
        
        # --- ä½¿ç”¨æœ€ä½³å‚æ•°åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼° ---
        self.stdout.write(self.style.SUCCESS("\n--- ä½¿ç”¨æœ€ä½³å‚æ•°åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼° ---"))
        best_model = lgb.LGBMRegressor(**best_params)
        best_model.fit(X_train, y_train,
                       eval_set=[(X_val, y_val)],
                       eval_metric='rmse',
                       callbacks=[lgb.early_stopping(100, verbose=False)])
        
        val_preds = best_model.predict(X_val)
        val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))
        val_r2 = r2_score(y_val, val_preds)
        self.stdout.write(f"æœ€ç»ˆéªŒè¯é›† RMSE: {val_rmse:.4f}")
        self.stdout.write(f"æœ€ç»ˆéªŒè¯é›† R^2 Score: {val_r2:.4f}")

        # æ­¥éª¤ 4/4: ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹å¹¶ä¿å­˜
        self.stdout.write("\næ­¥éª¤ 4/4: ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹å¹¶ä¿å­˜...")
        self.stdout.write("\n--- è®­ç»ƒæœ€ç»ˆæ¨¡å‹ (ä½¿ç”¨å…¨éƒ¨æ•°æ®å’Œæœ€ä½³å‚æ•°) ---")
        final_model = lgb.LGBMRegressor(**best_params)
        
        # å›å½’ä»»åŠ¡ä¸éœ€è¦æ ·æœ¬æƒé‡
        final_model.fit(X, y)
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(final_model, self.MODEL_FILE)
        self.stdout.write(self.style.SUCCESS(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³: {self.MODEL_FILE}"))
        
        # æ˜¾ç¤ºå¹¶ä¿å­˜ç‰¹å¾é‡è¦æ€§
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': final_model.feature_importances_
        }).sort_values('importance', ascending=False)
        self.stdout.write("\n--- ç‰¹å¾é‡è¦æ€§ ---")
        self.stdout.write(str(feature_importance_df.head(20)))
        
        # æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶ï¼ŒåŠ å…¥ç‰¹å¾é‡è¦æ€§
        try:
            with open(self.MODEL_CONFIG_FILE, 'r') as f:
                model_config = json.load(f)
            
            model_config['feature_importance'] = feature_importance_df.to_dict('records')
            model_config['best_params'] = {k: (v.isoformat() if isinstance(v, pd.Timestamp) else v) for k, v in study.best_params.items()}
            
            with open(self.MODEL_CONFIG_FILE, 'w') as f:
                json.dump(model_config, f, indent=4)
            self.stdout.write(self.style.SUCCESS(f"ç‰¹å¾é‡è¦æ€§å’Œæœ€ä½³å‚æ•°å·²æ›´æ–°è‡³: {self.MODEL_CONFIG_FILE}"))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}"))
            
        self.stdout.write(self.style.SUCCESS("===== [M-Value Refactor] æ¨¡å‹è®­ç»ƒæµç¨‹ç»“æŸï¼ ====="))

####æ–‡ä»¶ç»“æŸ####

####selection_manager\management\commands\train_stock_model.py####
# ==============================================================================
# æ–‡ä»¶ 2/4: selection_manager/management/commands/train_stock_model.py
# æè¿°: è®­ç»ƒä¸ªè‚¡è¯„åˆ†çš„LightGBMå›å½’æ¨¡å‹ã€‚
# ==============================================================================
import logging
import pickle
import json

import numpy as np
import pandas as pd
import lightgbm as lgb
from django.core.management.base import BaseCommand
from django.conf import settings
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import optuna

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'è®­ç»ƒä¸ªè‚¡è¯„åˆ†çš„LightGBMå›å½’æ¨¡å‹ã€‚'

    # --- è·¯å¾„é…ç½® ---
    MODELS_DIR = settings.BASE_DIR / 'selection_manager' / 'ml_models'
    DATASET_FILE = MODELS_DIR / 'stock_features_dataset.pkl'
    MODEL_FILE = MODELS_DIR / 'stock_lgbm_model.joblib'
    MODEL_CONFIG_FILE = MODELS_DIR / 'stock_model_config.json'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS("===== å¼€å§‹è®­ç»ƒä¸ªè‚¡è¯„åˆ†æ¨¡å‹ (LightGBM Regressor) ====="))

        # 1. åŠ è½½æ•°æ®é›†
        self.stdout.write(f"æ­¥éª¤ 1/4: ä» {self.DATASET_FILE} åŠ è½½æ•°æ®é›†...")
        try:
            with open(self.DATASET_FILE, 'rb') as f:
                dataset = pickle.load(f)
            X, y, feature_names = dataset['X'], dataset['y'], dataset['feature_names']
        except FileNotFoundError:
            self.stdout.write(self.style.ERROR(f"é”™è¯¯: æ•°æ®é›†æ–‡ä»¶ {self.DATASET_FILE} ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œ 'prepare_stock_features' å‘½ä»¤ã€‚"))
            return

        # 2. å®šä¹‰æ¨¡å‹å’Œäº¤å‰éªŒè¯
        self.stdout.write("æ­¥éª¤ 2/4: è®¾ç½®å›å½’æ¨¡å‹å‚æ•°å’Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯...")
        
        # LightGBM å›å½’æ¨¡å‹å‚æ•° (ä¸Må€¼æ¨¡å‹é£æ ¼ä¸€è‡´)
        lgbm_params = {
            'objective': 'regression_l1', # ä½¿ç”¨L1æŸå¤± (MAE)ï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’
            'boosting_type': 'gbdt',
            'metric': 'rmse',
            'n_estimators': 2000, # å‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œå› ä¸ºæ•°æ®é›†æ›´å¤§
            'learning_rate': 0.001,
            'n_jobs': -1,
            'seed': 42,
            'verbose': -1,
            'num_leaves': 63, # å…è®¸æ›´å¤æ‚çš„æ ‘
            'max_depth': -1,
            'subsample': 0.8,
            'colsample_bytree': 0.7,
            'reg_alpha': 0.2,
            'reg_lambda': 0.2,
        }

        # 3. ä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–å’ŒéªŒè¯
        self.stdout.write("æ­¥éª¤ 3/4: ä½¿ç”¨ Optuna è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–...")
        
        # ç”±äºæ•°æ®é›†å¯èƒ½éå¸¸å¤§ï¼Œæˆ‘ä»¬åªå–æœ€åä¸€éƒ¨åˆ†æ•°æ®è¿›è¡Œå¿«é€Ÿçš„è¶…å‚æ•°æœç´¢
        # ä¾‹å¦‚ï¼Œåªç”¨æœ€å20%çš„æ•°æ®è¿›è¡Œè°ƒä¼˜
        sample_frac_for_tuning = 0.2
        tuning_data_size = int(len(X) * sample_frac_for_tuning)
        X_tuning = X.iloc[-tuning_data_size:]
        y_tuning = y.iloc[-tuning_data_size:]
        self.stdout.write(f"ä¸ºåŠ é€Ÿè°ƒä¼˜ï¼Œä»…ä½¿ç”¨å {tuning_data_size} æ¡æ•°æ®è¿›è¡Œå‚æ•°æœç´¢ã€‚")

        def objective(trial):
            params_to_tune = {
                'num_leaves': trial.suggest_int('num_leaves', 20, 150),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),
            }
            current_params = lgbm_params.copy()
            current_params.update(params_to_tune)
            
            tscv = TimeSeriesSplit(n_splits=5)
            rmses = []
            for train_index, val_index in tscv.split(X_tuning):
                X_train_fold, X_val_fold = X_tuning.iloc[train_index], X_tuning.iloc[val_index]
                y_train_fold, y_val_fold = y_tuning.iloc[train_index], y_tuning.iloc[val_index]
                
                model = lgb.LGBMRegressor(**current_params)
                model.fit(X_train_fold, y_train_fold,
                          eval_set=[(X_val_fold, y_val_fold)],
                          callbacks=[lgb.early_stopping(50, verbose=False)])
                
                val_preds = model.predict(X_val_fold)
                rmse = np.sqrt(mean_squared_error(y_val_fold, val_preds))
                rmses.append(rmse)
            return np.mean(rmses)

        self.stdout.write("å¼€å§‹å‚æ•°æœç´¢ (n_trials=30)...")
        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=30) # å‡å°‘å°è¯•æ¬¡æ•°ä»¥é€‚åº”å¤§æ•°æ®é›†
        
        best_params = lgbm_params.copy()
        best_params.update(study.best_params)
        self.stdout.write(self.style.SUCCESS(f"\næœç´¢å®Œæˆï¼æœ€ä½³éªŒè¯é›† RMSE: {study.best_value:.4f}"))
        self.stdout.write(self.style.SUCCESS(f"æ‰¾åˆ°çš„æœ€ä½³å‚æ•°: {study.best_params}"))

        # æ­¥éª¤ 4/4: ä½¿ç”¨æœ€ä½³å‚æ•°åœ¨å…¨éƒ¨æ•°æ®ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹å¹¶ä¿å­˜
        self.stdout.write("\næ­¥éª¤ 4/4: ä½¿ç”¨æœ€ä½³å‚æ•°åœ¨å…¨éƒ¨æ•°æ®ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹å¹¶ä¿å­˜...")
        
        # ä½¿ç”¨æ—¶é—´åºåˆ—åˆ’åˆ†æ³•ï¼Œå°†æœ€å20%ä½œä¸ºéªŒè¯é›†æ¥å±•ç¤ºæœ€ç»ˆæ€§èƒ½
        split_point = int(len(X) * 0.8)
        X_train, X_val = X.iloc[:split_point], X.iloc[split_point:]
        y_train, y_val = y.iloc[:split_point], y.iloc[split_point:]

        final_model = lgb.LGBMRegressor(**best_params)
        final_model.fit(X_train, y_train,
                        eval_set=[(X_val, y_val)],
                        eval_metric='rmse',
                        callbacks=[lgb.early_stopping(100, verbose=True)])
        
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æœ€ç»ˆæ¨¡å‹
        val_preds = final_model.predict(X_val)
        val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))
        val_r2 = r2_score(y_val, val_preds)
        self.stdout.write(self.style.SUCCESS(f"\n--- æœ€ç»ˆæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½ ---"))
        self.stdout.write(f"RMSE: {val_rmse:.4f}")
        self.stdout.write(f"R^2 Score: {val_r2:.4f}")

        # ä¿å­˜æ¨¡å‹
        joblib.dump(final_model, self.MODEL_FILE)
        self.stdout.write(self.style.SUCCESS(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³: {self.MODEL_FILE}"))
        
        # æ˜¾ç¤ºå¹¶ä¿å­˜ç‰¹å¾é‡è¦æ€§
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': final_model.feature_importances_
        }).sort_values('importance', ascending=False)
        self.stdout.write("\n--- ç‰¹å¾é‡è¦æ€§ ---")
        self.stdout.write(str(feature_importance_df.head(20)))
        
        # æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶
        try:
            with open(self.MODEL_CONFIG_FILE, 'r') as f:
                model_config = json.load(f)
            
            model_config['feature_importance'] = feature_importance_df.to_dict('records')
            model_config['best_params'] = {k: v for k, v in study.best_params.items()}
            
            with open(self.MODEL_CONFIG_FILE, 'w') as f:
                json.dump(model_config, f, indent=4)
            self.stdout.write(self.style.SUCCESS(f"ç‰¹å¾é‡è¦æ€§å’Œæœ€ä½³å‚æ•°å·²æ›´æ–°è‡³: {self.MODEL_CONFIG_FILE}"))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}"))
            
        self.stdout.write(self.style.SUCCESS("===== ä¸ªè‚¡è¯„åˆ†æ¨¡å‹è®­ç»ƒæµç¨‹ç»“æŸï¼ ====="))

####æ–‡ä»¶ç»“æŸ####

####trade_manager\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####trade_manager\admin.py####
from django.contrib import admin

# Register your models here.

####æ–‡ä»¶ç»“æŸ####

####trade_manager\apps.py####
# trade_manager/apps.py

import os
import sys
from django.apps import AppConfig
import logging

logger = logging.getLogger(__name__)

class TradeManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'trade_manager'

    def ready(self):
        # # å…³é”®ä¿®æ­£ï¼šé€šè¿‡æ£€æŸ¥ç¯å¢ƒå˜é‡ RUN_MAIN æ¥é˜²æ­¢è°ƒåº¦å™¨åœ¨é‡è½½ä¸»è¿›ç¨‹ä¸­å¯åŠ¨ä¸¤æ¬¡
        # # è¿™ä¸ªç¯å¢ƒå˜é‡æ˜¯ Django çš„ autoreloader åœ¨å¯åŠ¨å­è¿›ç¨‹æ—¶è®¾ç½®çš„ã€‚
        # # æˆ‘ä»¬åªæƒ³åœ¨è¿è¡Œå®é™…åº”ç”¨çš„å­è¿›ç¨‹ä¸­å¯åŠ¨è°ƒåº¦å™¨ã€‚
        # if os.environ.get('RUN_MAIN'):
        #     logger.info("æ£€æµ‹åˆ° Django åº”ç”¨å·¥ä½œè¿›ç¨‹ï¼Œå‡†å¤‡åˆå§‹åŒ–è°ƒåº¦å™¨...")
        #     from .service import scheduler_service
        #     # ç¡®ä¿è°ƒåº¦å™¨åªå¯åŠ¨ä¸€æ¬¡
        #     if not scheduler_service.scheduler.running:
        #          scheduler_service.start()
        #     else:
        #          logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤å¯åŠ¨ã€‚")
        # else:
        #     logger.info("æ£€æµ‹åˆ° Django ç®¡ç†æˆ–é‡è½½ä¸»è¿›ç¨‹ï¼Œè·³è¿‡è°ƒåº¦å™¨åˆå§‹åŒ–ã€‚")
        return


####æ–‡ä»¶ç»“æŸ####

####trade_manager\models.py####
from django.db import models

# Create your models here.

####æ–‡ä»¶ç»“æŸ####

####trade_manager\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####trade_manager\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include
from . import views
urlpatterns = [
    path('beforeFixRun', views.before_fix_run),
    path('initParam',views.initialize_strategy_parameters),
    path('simulateTrade', views.simulate_trade)
]

####æ–‡ä»¶ç»“æŸ####

####trade_manager\views.py####
from datetime import date,datetime
from django.shortcuts import render
from django.http.response import JsonResponse
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.simulate_trade import SimulateTradeService
import json
from django.views.decorators.http import require_http_methods
# Create your views here.
@require_http_methods(["POST"])
def before_fix_run(request):
    if request.method=='POST':
        body= json.loads(request.body)
        selection_date=datetime.strptime(body['date'], "%Y-%m-%d").date()
        service=BeforeFixService(selection_date)
        service.run()
        return JsonResponse({
            'result':'æˆåŠŸ'
        })
@require_http_methods(["GET"])
def initialize_strategy_parameters(request):
    if request.method=='GET':
        DecisionOrderService.initialize_strategy_parameters()
        return JsonResponse({
            'result':'æˆåŠŸ'
        })

@require_http_methods(["POST"])
def simulate_trade(request):
    if request.method=='POST':
        body= json.loads(request.body)
        start_date=body['startDate']
        end_date=body['endDate']
        service=SimulateTradeService()
        result=service.run_backtest(start_date=start_date,end_date=end_date)
        return JsonResponse(result)
####æ–‡ä»¶ç»“æŸ####

####trade_manager\management\commands\run_backtest.py####
# ==============================================================================
# æ–‡ä»¶ 2/5: trade_manager/management/commands/run_backtest.py (æ–°å¢)
# æè¿°: ç”¨äºä»å‘½ä»¤è¡Œå¯åŠ¨å›æµ‹çš„ Command æ–‡ä»¶ã€‚
# ==============================================================================
from django.core.management.base import BaseCommand, CommandParser
from trade_manager.service.simulate_trade import SimulateTradeService
from decimal import Decimal

class Command(BaseCommand):
    help = 'è¿è¡Œä¸€ä¸ªå®Œæ•´çš„äº¤æ˜“ç­–ç•¥å›æµ‹'

    def add_arguments(self, parser: CommandParser):
        parser.add_argument(
            '--start',
            type=str,
            required=True,
            help='å›æµ‹èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)'
        )
        parser.add_argument(
            '--end',
            type=str,
            required=True,
            help='å›æµ‹ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)'
        )
        parser.add_argument(
            '--capital',
            type=Decimal,
            required=True,
            help='åˆå§‹èµ„é‡‘'
        )

    def handle(self, *args, **options):
        start_date = options['start']
        end_date = options['end']
        initial_capital = options['capital']

        self.stdout.write(self.style.SUCCESS(f'===== å¼€å§‹æ‰§è¡Œå›æµ‹ä»»åŠ¡ ====='))
        self.stdout.write(f'  - èµ·å§‹æ—¥æœŸ: {start_date}')
        self.stdout.write(f'  - ç»“æŸæ—¥æœŸ: {end_date}')
        self.stdout.write(f'  - åˆå§‹èµ„é‡‘: {initial_capital:.2f}')

        try:
            service = SimulateTradeService()
            # æ³¨æ„ï¼šæˆ‘ä»¬å°†æ‰€æœ‰å‚æ•°éƒ½ä¼ é€’ç»™ run_backtest æ–¹æ³•
            result = service.run_backtest(
                start_date=start_date,
                end_date=end_date,
                initial_capital=initial_capital
            )
            
            self.stdout.write(self.style.SUCCESS('\n===== å›æµ‹æ‰§è¡Œå®Œæ¯• ====='))
            self.stdout.write(f'æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡: {result}')

        except Exception as e:
            self.stdout.write(self.style.ERROR(f'å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}'))
            # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¯èƒ½éœ€è¦æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
            raise e


####æ–‡ä»¶ç»“æŸ####

####trade_manager\management\commands\run_m_distribution_backtest.py####
# trade_manager/management/commands/run_m_distribution_backtest.py

from django.core.management.base import BaseCommand, CommandParser
from trade_manager.service.m_distribution_backtest_service import MDistributionBacktestService

class Command(BaseCommand):
    help = 'è¿è¡Œä¸€ä¸ªæ–°çš„ã€åŸºäºMå€¼èƒœç‡åˆ†å¸ƒçš„å›æµ‹æ¨¡å—'

    def add_arguments(self, parser: CommandParser):
        parser.add_argument(
            '--start',
            type=str,
            required=True,
            help='å›æµ‹èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)'
        )
        parser.add_argument(
            '--end',
            type=str,
            required=True,
            help='å›æµ‹ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)'
        )

        parser.add_argument(
            '--single_strategy_mode',
            action='store_true', # è¿™ä¼šåˆ›å»ºä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œå¦‚æœå‘½ä»¤è¡ŒåŒ…å«æ­¤å‚æ•°ï¼Œåˆ™å…¶å€¼ä¸ºTrue
            help='å¼€å¯å•ç­–ç•¥Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æ¨¡å¼ï¼Œä¼šé¢å¤–ä¸ºæ¯ä¸ªç­–ç•¥ç‹¬ç«‹è¿è¡Œå›æµ‹ã€‚'
        )

    def handle(self, *args, **options):
        start_date = options['start']
        end_date = options['end']
        single_strategy_mode = options['single_strategy_mode']
        self.stdout.write(self.style.SUCCESS('===== å¼€å§‹æ‰§è¡ŒMå€¼èƒœç‡åˆ†å¸ƒå›æµ‹ ====='))
        self.stdout.write(f'  - èµ·å§‹æ—¥æœŸ: {start_date}')
        self.stdout.write(f'  - ç»“æŸæ—¥æœŸ: {end_date}')

        try:
            service = MDistributionBacktestService(start_date=start_date, end_date=end_date,single_strategy_mode=single_strategy_mode)
            service.run()
            
            self.stdout.write(self.style.SUCCESS('\n===== Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æ‰§è¡Œå®Œæ¯• ====='))

        except Exception as e:
            self.stdout.write(self.style.ERROR(f'å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}'))
            raise e


####æ–‡ä»¶ç»“æŸ####

####trade_manager\management\commands\run_scheduler.py####
# trade_manager/management/commands/run_scheduler.py

from django.core.management.base import BaseCommand
from trade_manager.service import scheduler_service
import logging
import time
logger = logging.getLogger(__name__)
class Command(BaseCommand):
    help = 'å¯åŠ¨è‡ªåŠ¨åŒ–äº¤æ˜“çš„ APScheduler è°ƒåº¦å™¨'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('æ­£åœ¨å¯åŠ¨è°ƒåº¦å™¨æœåŠ¡...'))
        scheduler_service.start()
        try:
            # è¿™æ˜¯å…³é”®ï¼šè®©ä¸»è¿›ç¨‹è¿›å…¥ä¸€ä¸ªæ— é™å¾ªç¯ï¼Œä»¥é˜²æ­¢è„šæœ¬é€€å‡º
            # è¿™æ ·åå°çš„è°ƒåº¦å™¨çº¿ç¨‹æ‰èƒ½ä¸€ç›´å­˜æ´»
            while True:
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œé™ä½CPUå ç”¨
        except (KeyboardInterrupt, SystemExit):
            # å½“æ¥æ”¶åˆ°é€€å‡ºä¿¡å·æ—¶ï¼ˆå¦‚Ctrl+Cæˆ–uWSGIçš„åœæ­¢å‘½ä»¤ï¼‰
            # ä¼˜é›…åœ°å…³é—­è°ƒåº¦å™¨
            logger.info("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å…³é—­è°ƒåº¦å™¨...")
            scheduler_service.scheduler.shutdown()
            logger.info("è°ƒåº¦å™¨å·²æˆåŠŸå…³é—­ã€‚")
            self.stdout.write(self.style.SUCCESS('è°ƒåº¦å™¨æœåŠ¡å·²ä¼˜é›…åœ°åœæ­¢ã€‚'))
        self.stdout.write(self.style.SUCCESS('è°ƒåº¦å™¨æœåŠ¡å·²åœæ­¢ã€‚'))


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\backtest_reporter.py####
# ==============================================================================
# æ–‡ä»¶ 3/5: trade_manager/service/backtest_reporter.py (æ–°å¢)
# æè¿°: è´Ÿè´£ç”Ÿæˆå’Œå‘é€å›æµ‹é‚®ä»¶æŠ¥å‘Šçš„æ¨¡å—ã€‚
# ==============================================================================
import base64
import io
import logging
from datetime import date
from decimal import Decimal
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

import pandas as pd
from django.db import connections

from common.models.backtest_logs import BacktestDailyLog, BacktestOperationLog
from common.models.positions import Position
from data_manager.service.email_handler import EmailHandler

logger = logging.getLogger(__name__)

class BacktestReporter:
    """
    å›æµ‹æŠ¥å‘Šç”Ÿæˆä¸å‘é€å™¨ã€‚
    """
    def __init__(self, schema_name: str, start_date: date, current_date: date, initial_capital: Decimal):
        self.schema_name = schema_name
        self.start_date = start_date
        self.current_date = current_date
        self.initial_capital = initial_capital
        self.email_handler = EmailHandler()
        self.recipients = ['876858298@qq.com','850696281@qq.com']#,'285173686@qq.com','850696281@qq.com'
    def _execute_query(self, query: str, params: list = None) -> list[dict]:
        """åœ¨æŒ‡å®š schema ä¸­æ‰§è¡ŒåŸç”Ÿ SQL æŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
        with connections['default'].cursor() as cursor:
            cursor.execute(f'SET search_path TO "{self.schema_name}", public;')
            cursor.execute(query, params or [])
            columns = [col[0] for col in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

    def _generate_report_data(self) -> dict:
        """å‡†å¤‡é‚®ä»¶æŠ¥å‘Šæ‰€éœ€çš„æ‰€æœ‰æ•°æ®"""
        data = {}

        # 1. å…³é”®æŒ‡æ ‡
        daily_logs = self._execute_query(
            f"SELECT trade_date, total_assets FROM {BacktestDailyLog._meta.db_table} ORDER BY trade_date"
        )
        df_daily = pd.DataFrame(daily_logs)
        df_daily['total_assets'] = df_daily['total_assets'].astype(float)
        
        # èƒœç‡
        sell_ops = self._execute_query(
            f"SELECT exit_reason FROM {BacktestOperationLog._meta.db_table} WHERE direction = 'SELL'"
        )
        if sell_ops:
            total_sells = len(sell_ops)
            profit_sells = sum(1 for op in sell_ops if op['exit_reason'] == 'TAKE_PROFIT')
            data['win_rate'] = profit_sells / total_sells if total_sells > 0 else 0.0
        else:
            data['win_rate'] = 0.0
        
        # æœ€å¤§å›æ’¤
        df_daily['peak'] = df_daily['total_assets'].cummax()
        df_daily['drawdown'] = (df_daily['total_assets'] - df_daily['peak']) / df_daily['peak']
        data['max_drawdown'] = df_daily['drawdown'].min() if not df_daily.empty else 0.0

        # å¹´åŒ–æ”¶ç›Šç‡
        final_assets = float(df_daily['total_assets'].iloc[-1]) if not df_daily.empty else float(self.initial_capital)
        days_passed = (self.current_date - self.start_date).days
        if days_passed > 0:
            data['annualized_return'] = ((final_assets / float(self.initial_capital)) ** (365.0 / days_passed)) - 1
        else:
            data['annualized_return'] = 0.0

        # 2. èµ„é‡‘æ›²çº¿å›¾æ•°æ®
        data['plot_data'] = self._execute_query(
            f"SELECT trade_date, total_assets, market_m_value FROM {BacktestDailyLog._meta.db_table} ORDER BY trade_date"
        )

        # 3. å½“å‰æŒä»“
        data['current_holdings'] = self._execute_query(
            f"""
            SELECT p.stock_code, si.stock_name, p.entry_price, p.quantity, 
                   p.current_take_profit, p.current_stop_loss, dq.close as current_price
            FROM {Position._meta.db_table} p
            JOIN public.tb_stock_info si ON p.stock_code = si.stock_code
            LEFT JOIN public.tb_daily_quotes dq ON p.stock_code = dq.stock_code AND dq.trade_date = %s
            WHERE p.status = 'open'
            """, [self.current_date]
        )
        for h in data['current_holdings']:
            entry_price = h['entry_price']
            if entry_price and entry_price > 0:
                # æ–°çš„è®¡ç®—æ–¹å¼ï¼šå°†æ­¢ç›ˆ/æ­¢æŸä»·è¡¨ç¤ºä¸ºæˆæœ¬ä»·çš„ç™¾åˆ†æ¯”
                h['profit_level_pct'] = h['current_take_profit'] / entry_price
                h['loss_level_pct'] = h['current_stop_loss'] / entry_price
            else:
                # å¤„ç† entry_price æ— æ•ˆçš„æƒ…å†µ
                h['profit_level_pct'] = Decimal('0.0')
                h['loss_level_pct'] = Decimal('0.0')

        # 4. æ”¶ç›Šæ’å
        all_ops = self._execute_query(f"SELECT stock_code, stock_name, direction, amount FROM {BacktestOperationLog._meta.db_table}")
        profits = {}
        for op in all_ops:
            key = (op['stock_code'], op['stock_name'])
            if op['direction'] == 'BUY':
                profits[key] = profits.get(key, 0) - op['amount']
            else: # SELL
                profits[key] = profits.get(key, 0) + op['amount']
        # æ€»æ”¶ç›Š = å·²å®ç°ç›ˆäº + æœªå®ç°ç›ˆäº
        #        = (å–å‡ºæ€»é¢ - ä¹°å…¥æ€»é¢) + (å½“å‰å¸‚å€¼ - æŒä»“æˆæœ¬)
        #        = (å–å‡ºæ€»é¢) - (å·²å¹³ä»“éƒ¨åˆ†çš„ä¹°å…¥æˆæœ¬) + (å½“å‰å¸‚å€¼)
        # ä¹‹å‰çš„å¾ªç¯å·²ç»è®¡ç®—äº† (å–å‡ºæ€»é¢ - å…¨éƒ¨ä¹°å…¥æˆæœ¬)ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€åŠ ä¸Šå½“å‰å¸‚å€¼å³å¯ã€‚
        for holding in data['current_holdings']:
            key = (holding['stock_code'], holding['stock_name'])
            
            # å¤„ç†å½“å¤©å¯èƒ½æ²¡æœ‰è¡Œæƒ…æ•°æ®çš„æƒ…å†µï¼Œè‹¥æ— å½“å‰ä»·åˆ™æŒ‰å…¥åœºä»·è®¡ç®—ï¼Œæµ®åŠ¨ç›ˆäºä¸º0
            current_price = holding['current_price'] or holding['entry_price']
            
            # è®¡ç®—å½“å‰æŒä»“çš„æ€»å¸‚å€¼
            current_market_value = holding['quantity'] * current_price
            
            # å°†å½“å‰å¸‚å€¼åŠ åˆ°è¯¥è‚¡ç¥¨çš„ç´¯è®¡æ”¶ç›Šä¸­
            profits[key] = profits.get(key, 0) + current_market_value
        profit_list = [{'stock_code': k[0], 'stock_name': k[1], 'profit': v} for k, v in profits.items()]
        data['profit_ranking'] = sorted(profit_list, key=lambda x: x['profit'], reverse=True)

        return data

    def _generate_plot_base64(self, plot_data: list[dict]) -> str:
        if not plot_data:
            return ""
        
        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False
        except Exception as e:
            pass
        
        try:
            df = pd.DataFrame(plot_data)
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df['trade_date'] = pd.to_datetime(df['trade_date'])
            df['total_assets'] = pd.to_numeric(df['total_assets'])
            df['market_m_value'] = pd.to_numeric(df['market_m_value'])

            if df.empty:
                return ""

            plt.style.use('seaborn-v0_8-whitegrid')
            fig, ax1 = plt.subplots(figsize=(14, 7))

            # ç»˜åˆ¶ä¸»æ›²çº¿
            ax1.plot(df['trade_date'], df['total_assets'], color='dodgerblue', label='money', linewidth=2)
            ax1.set_xlabel('date', fontsize=12)
            ax1.set_ylabel('money', color='dodgerblue', fontsize=12)
            ax1.tick_params(axis='y', labelcolor='dodgerblue')
            ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))

            # ç»˜åˆ¶å‰¯åæ ‡è½´æ›²çº¿
            ax2 = ax1.twinx()
            ax2.plot(df['trade_date'], df['market_m_value'], color='coral', linestyle='--', label='M', alpha=0.7)
            ax2.set_ylabel('M', color='coral', fontsize=12)
            ax2.tick_params(axis='y', labelcolor='coral')
            ax2.axhline(0, color='grey', linestyle=':', linewidth=1)

            # ======================= ä¸»è¦ä¿®æ”¹ç‚¹ =======================
            # 1. æ›´å¥å£®å’Œç®€åŒ–çš„Xè½´åˆ»åº¦é€»è¾‘
            num_days = (df['trade_date'].max() - df['trade_date'].min()).days
            
            if num_days <= 60:  # 2ä¸ªæœˆä»¥å†…ï¼ŒæŒ‰å‘¨æ˜¾ç¤º
                locator = mdates.WeekdayLocator(byweekday=mdates.MO)
                formatter = mdates.DateFormatter('%m-%d')
            elif num_days <= 365 * 2: # 2å¹´ä»¥å†…ï¼ŒæŒ‰å­£åº¦æ˜¾ç¤º
                locator = mdates.MonthLocator(interval=3)
                formatter = mdates.DateFormatter('%Y-%m')
            elif num_days <= 365 * 5: # 5å¹´ä»¥å†…ï¼ŒæŒ‰åŠå¹´æ˜¾ç¤º
                locator = mdates.MonthLocator(interval=6)
                formatter = mdates.DateFormatter('%Y-%m')
            else:  # è¶…è¿‡5å¹´ï¼ŒæŒ‰å¹´æ˜¾ç¤º
                locator = mdates.YearLocator()
                formatter = mdates.DateFormatter('%Y')
            
            ax1.xaxis.set_major_locator(locator)
            ax1.xaxis.set_major_formatter(formatter)

            # 2. ç§»é™¤ fig.autofmt_xdate()ï¼Œå¹¶æ‰‹åŠ¨è®¾ç½®æ ‡ç­¾æ—‹è½¬ï¼Œé¿å…å†²çª
            plt.setp(ax1.get_xticklabels(), rotation=30, ha='right')
            # ========================================================

            fig.suptitle('Money-M(t)', fontsize=16, weight='bold')
            fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))
            
            # ä½¿ç”¨ tight_layout æ›¿ä»£
            plt.tight_layout(rect=[0, 0, 1, 0.96])

            # ä¿å­˜å›¾åƒåˆ°å†…å­˜
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100)
            plt.close(fig)
            buf.seek(0)
            return base64.b64encode(buf.getvalue()).decode('utf-8')
        finally:
            pass



    def _format_html_content(self, data: dict, plot_base64: str) -> str:
        
        # ======================= ä¿®å¤é¢œè‰²é€»è¾‘ =======================
        # ä¿®å¤ï¼šç›ˆåˆ© (value > 0) ä¸ºç»¿è‰²ï¼ŒäºæŸ (value < 0) ä¸ºçº¢è‰²
        def get_row_style(value):
            if value > 0:
                return 'style="background-color: #e9f5e9; color: #1e7e34;"'  # ç»¿è‰²èƒŒæ™¯ï¼Œæ·±ç»¿è‰²æ–‡å­—
            elif value < 0:
                return 'style="background-color: #fdeaea; color: #c82333;"'  # çº¢è‰²èƒŒæ™¯ï¼Œæ·±çº¢è‰²æ–‡å­—
            else:
                return '' # ä¸­æ€§
        # ==========================================================
        # Part 1: Key Metrics
        html = f"""
        <h2>å…³é”®æŒ‡æ ‡ (æˆªè‡³ {self.current_date.strftime('%Y-%m-%d')})</h2>
        <table class="summary-table">
            <tr>
                <th>èƒœç‡</th><td>{data['win_rate']:.2%}</td>
                <th>æœ€å¤§å›æ’¤</th><td style="color: #c82333;">{data['max_drawdown']:.2%}</td>
                <th>å¹´åŒ–æ”¶ç›Šç‡</th><td>{data['annualized_return']:.2%}</td>
            </tr>
        </table>
        """
        # Part 2: Plot
        html += f"""
        <h2>èµ„é‡‘ä¸Må€¼å˜åŒ–è¶‹åŠ¿</h2>
        <div style="text-align: center;">
            <img src="data:image/png;base64,{plot_base64}" alt="Performance Chart" style="max-width: 100%;">
        </div>
        """
        # Part 3: Current Holdings
        html += "<h2>å½“å‰æŒä»“æƒ…å†µ</h2>"
        if data['current_holdings']:
            html += """
            <table class="data-table">
                <thead><tr><th>è‚¡ç¥¨ä»£ç </th><th>è‚¡ç¥¨åç§°</th><th>å…¥åœºä»·</th><th>å½“å‰ä»·</th><th>æµ®åŠ¨ç›ˆäº</th><th>æ­¢ç›ˆä»·æ ¼</th><th>æ­¢æŸä»·æ ¼</th><th>æ­¢ç›ˆçº¿ä½ç½®</th><th>æ­¢æŸçº¿ä½ç½®</th></tr></thead>
                <tbody>
            """
            for h in data['current_holdings']:
                current_price = h['current_price'] or h['entry_price']
                profit_loss = current_price - h['entry_price']
                profit_loss_rate = (current_price / h['entry_price'] - 1) if h['entry_price'] else 0
                style = get_row_style(profit_loss)
                profit_level_str = f"{h['profit_level_pct']:.2%}"
                loss_level_str = f"{h['loss_level_pct']:.2%}"
                html += f"""
                <tr {style}>
                    <td>{h['stock_code']}</td>
                    <td>{h['stock_name']}</td>
                    <td>{h['entry_price']:.2f}</td>
                    <td>{current_price:.2f}</td>
                    <td>{profit_loss_rate:.2%}</td>
                    <td>{h['current_take_profit']:.2f}</td>
                    <td>{h['current_stop_loss']:.2f}</td>
                    <td style="color: #c82333;">{profit_level_str}</td>
                    <td style="color: #1e7e34;">{loss_level_str}</td>
                </tr>
                """
            html += "</tbody></table>"
        else:
            html += "<p>å½“å‰æ— æŒä»“ã€‚</p>"
        # Part 4: Profit Ranking
        html += "<h2>å„è‚¡ç´¯è®¡æ”¶ç›Šæ’å</h2>"
        if data['profit_ranking']:
            html += """
            <table class="data-table">
                <thead><tr><th>æ’å</th><th>è‚¡ç¥¨ä»£ç </th><th>è‚¡ç¥¨åç§°</th><th>ç´¯è®¡æ”¶ç›Š(å…ƒ)</th></tr></thead>
                <tbody>
            """
            for i, p in enumerate(data['profit_ranking'], 1):
                # è¿™é‡Œå¤ç”¨ä¸Šé¢ä¿®æ”¹å¥½çš„é¢œè‰²é€»è¾‘
                style = get_row_style(p['profit'])
                html += f"""
                <tr {style}>
                    <td>{i}</td>
                    <td>{p['stock_code']}</td>
                    <td>{p['stock_name']}</td>
                    <td>{p['profit']:,.2f}</td>
                </tr>
                """
            html += "</tbody></table>"
        else:
            html += "<p>æš‚æ— å·²å¹³ä»“çš„äº¤æ˜“ã€‚</p>"
        # Final HTML structure (ä¿æŒä¸å˜)
        final_html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <title>å›æµ‹æŠ¥å‘Š</title>
            <style>
                body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; margin: 20px; background-color: #f4f7f6; color: #333; }}
                h2 {{ color: #0056b3; border-bottom: 2px solid #e0e0e0; padding-bottom: 8px; margin-top: 30px; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 15px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }}
                th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #ddd; }}
                th {{ background-color: #f8f9fa; }}
                .summary-table th {{ width: 15%; background-color: #e9ecef; }}
                .summary-table td {{ font-weight: bold; font-size: 1.1em; }}
                .data-table tbody tr:hover {{ background-color: #f1f1f1; }}
            </style>
        </head>
        <body>
            <h1>å›æµ‹è¿›åº¦æŠ¥å‘Š: {self.start_date}~{self.current_date}å›æµ‹</h1>
            {html}
        </body>
        </html>
        """
        return final_html

    def send_report(self):
        """ç”Ÿæˆå¹¶å‘é€æŠ¥å‘Šé‚®ä»¶"""
        logger.info(f"[{self.schema_name}] æ­£åœ¨ç”Ÿæˆæˆªè‡³ {self.current_date} çš„å›æµ‹æŠ¥å‘Š...")
        try:
            report_data = self._generate_report_data()
            plot_base64 = self._generate_plot_base64(report_data.get('plot_data', []))
            html_content = self._format_html_content(report_data, plot_base64)
            subject = f"å›æµ‹æŠ¥å‘Š ({self.start_date}~{self.current_date}) - {self.current_date.strftime('%Y-%m-%d')}"
            
            self.email_handler.send_email(
                recipients=self.recipients,
                subject=subject,
                html_content=html_content
            )
            logger.info(f"[{self.start_date}~{self.current_date}] å›æµ‹æŠ¥å‘Šé‚®ä»¶å·²æˆåŠŸå‘é€ã€‚")
        except Exception as e:
            logger.error(f"[{self.start_date}~{self.current_date}] ç”Ÿæˆæˆ–å‘é€å›æµ‹æŠ¥å‘Šæ—¶å¤±è´¥: {e}", exc_info=True)


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\before_fix_service.py####
# trade_manager/service/before_fix_service.py

import logging
from datetime import date, timedelta, datetime
from decimal import Decimal, ROUND_HALF_UP
from django.utils import timezone
from django.db import transaction
from django.db.models import Q

# å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å‹
from common.models import (
    CorporateAction,
    DailyTradingPlan,
    Position,
    DailyQuotes,
    SystemLog
)

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


class BeforeFixService:
    """
    Tæ—¥å¼€ç›˜å‰æ ¡å‡†ä¸é¢„æ¡ˆä¿®æ­£æœåŠ¡ã€‚

    èŒè´£:
    1. æ£€æŸ¥å½“å¤©æ˜¯å¦å·²æˆåŠŸæ‰§è¡Œè¿‡ï¼Œé˜²æ­¢é‡å¤è¿è¡Œã€‚
    2. è·å–Tæ—¥çš„é™¤æƒé™¤æ¯äº‹ä»¶ã€‚
    3. è®¡ç®—å—å½±å“è‚¡ç¥¨çš„ä»·æ ¼è°ƒæ•´æ¯”ç‡ã€‚
    4. æ ¹æ®æ¯”ç‡ä¿®æ­£â€œæ¯æ—¥äº¤æ˜“é¢„æ¡ˆâ€ä¸­çš„MIOPå’ŒMAOPã€‚
    5. æ ¹æ®æ¯”ç‡ä¿®æ­£â€œæŒä»“ä¿¡æ¯â€ä¸­çš„æ­¢ç›ˆæ­¢æŸä»·ã€‚
    6. å¯¹è¿‘æœŸå‘ç”Ÿé…è‚¡çš„è‚¡ç¥¨è¿›è¡Œç‰¹æ®Šé£é™©å¤„ç†ã€‚
    """
    MODULE_NAME = 'ç›˜å‰æ ¡å‡†ä¸é¢„æ¡ˆä¿®æ­£'
    # å¯é…ç½®å‚æ•°
    MAX_PLAN_LOOKBACK_DAYS = 14  # æŸ¥æ‰¾äº¤æ˜“é¢„æ¡ˆçš„æœ€å¤§å›æº¯å¤©æ•°
    RIGHTS_ISSUE_LOOKBACK_DAYS = 30 # é…è‚¡äº‹ä»¶ç‰¹æ®Šå¤„ç†çš„å›æº¯äº¤æ˜“æ—¥æ•°

    def __init__(self, execution_date: date = None):
        """
        åˆå§‹åŒ–æœåŠ¡ã€‚
        :param execution_date: Tæ—¥ï¼Œå³æ‰§è¡Œæ ¡å‡†çš„æ—¥æœŸã€‚å¦‚æœä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºå½“å¤©ã€‚
        """
        self.t_day = execution_date if execution_date else date.today()
        self.t_minus_1_day = None
        self.adjustment_ratios = {} # å­˜å‚¨ {stock_code: ratio}
        logger.debug(f"[{self.MODULE_NAME}] æœåŠ¡åˆå§‹åŒ–ï¼Œç›®æ ‡Tæ—¥: {self.t_day}")

    def _log_to_db(self, level: str, message: str):
        """è¾…åŠ©æ–¹æ³•ï¼šå°†æ—¥å¿—å†™å…¥æ•°æ®åº“"""
        try:
            SystemLog.objects.create(
                log_level=level,
                module_name=self.MODULE_NAME,
                message=message
            )
        except Exception as e:
            logger.error(f"æ— æ³•å°†æ—¥å¿—å†™å…¥æ•°æ®åº“: {e}")

    def _is_trading_day(self, check_date: date) -> bool:
        """æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
        is_trade_day = DailyQuotes.objects.filter(trade_date=check_date).exists()
        logger.info(f"æ£€æŸ¥æ—¥æœŸ {check_date} æ˜¯å¦ä¸ºäº¤æ˜“æ—¥: {'æ˜¯' if is_trade_day else 'å¦'}")
        return is_trade_day

    def _get_last_trading_day(self, from_date: date) -> date | None:
        """è·å–æŒ‡å®šæ—¥æœŸä¹‹å‰çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥"""
        last_day = DailyQuotes.objects.filter(
            trade_date__lt=from_date
        ).order_by('-trade_date').values_list('trade_date', flat=True).first()
        
        if last_day:
            logger.info(f"{from_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ (T-1) æ˜¯: {last_day}")
        else:
            logger.warning(f"æ— æ³•æ‰¾åˆ° {from_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ã€‚")
        return last_day

    def _find_latest_pending_plan_date(self) -> date | None:
        """ä»Tæ—¥å¼€å§‹å‘å‰å›æº¯ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„ä¸€ä¸ªåŒ…å«å¾…æ‰§è¡Œé¢„æ¡ˆçš„æ—¥æœŸ"""
        for i in range(self.MAX_PLAN_LOOKBACK_DAYS):
            check_date = self.t_day - timedelta(days=i)
            if DailyTradingPlan.objects.filter(
                plan_date=check_date,
                status=DailyTradingPlan.StatusChoices.PENDING
            ).exists():
                logger.info(f"æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆï¼Œé¢„æ¡ˆæ—¥æœŸä¸º: {check_date}")
                return check_date
        logger.warning(f"åœ¨è¿‡å» {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…æœªæ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚")
        return None

    def _calculate_adjustment_ratios(self, events: list[CorporateAction]) -> tuple[Decimal, Decimal]:
        """
        æ ¸å¿ƒç®—æ³•ï¼šæ ¹æ®äº‹ä»¶åˆ—è¡¨è®¡ç®—é™¤æƒé™¤æ¯å‚è€ƒä»·ã€‚
        å¤„ç†é¡ºåºï¼š1.é™¤æ¯ -> 2.é€/è½¬è‚¡ -> 3.é…è‚¡
        """
        price_ratio = Decimal('1.0')
        quantity_ratio = Decimal('1.0')


        
        # æŒ‰äº‹ä»¶ç±»å‹ä¼˜å…ˆçº§æ’åº
        event_priority = {
            CorporateAction.EventType.DIVIDEND: 1,
            CorporateAction.EventType.BONUS: 2,
            CorporateAction.EventType.TRANSFER: 2,
            CorporateAction.EventType.SPLIT: 2
            #CorporateAction.EventType.RIGHTS: 3,
        }
        sorted_events = sorted(events, key=lambda e: event_priority.get(e.event_type, 99))

        for event in sorted_events:
            # é€è‚¡/è½¬å¢è‚¡/å¹¶è‚¡/æ‹†è‚¡ (é™¤æƒ)
            if event.event_type in [CorporateAction.EventType.BONUS, CorporateAction.EventType.TRANSFER, CorporateAction.EventType.SPLIT]:
                if event.shares_before and event.shares_after and event.shares_after > 0:
                    # ä»·æ ¼æ¯”ç‡ = æ—§è‚¡æ•° / æ–°è‚¡æ•°
                    price_ratio *= (event.shares_before / event.shares_after)
                    # æ•°é‡æ¯”ç‡ = æ–°è‚¡æ•° / æ—§è‚¡æ•°
                    quantity_ratio *= (event.shares_after / event.shares_before)
        
        return price_ratio, quantity_ratio

    @transaction.atomic
    def run(self):
        """æ‰§è¡Œç›˜å‰æ ¡å‡†ä¸ä¿®æ­£çš„ä¸»æµç¨‹"""

        self.t_minus_1_day = self._get_last_trading_day(self.t_day)
        if not self.t_minus_1_day:
            logger.error(f"æ— æ³•ç¡®å®šT-1æ—¥ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
            return

        # a. è·å–Tæ—¥æ‰€æœ‰é™¤æƒé™¤æ¯ä¿¡æ¯
        events_on_t_day = CorporateAction.objects.filter(ex_dividend_date=self.t_day)
        if not events_on_t_day.exists():
            logger.debug(f"Tæ—¥ ({self.t_day}) æ— é™¤æƒé™¤æ¯äº‹ä»¶ï¼Œæ— éœ€æ ¡å‡†ã€‚")
            return

        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„äº‹ä»¶
        events_by_stock = {}
        for event in events_on_t_day:
            if event.event_type != CorporateAction.EventType.RIGHTS:
                 events_by_stock.setdefault(event.stock_code, []).append(event)
        
        affected_codes = list(events_by_stock.keys())
        if not affected_codes:
            logger.info("Tæ—¥åªæœ‰é…è‚¡äº‹ä»¶ï¼Œå¸¸è§„æ ¡å‡†æµç¨‹è·³è¿‡ã€‚")
            self._handle_rights_issue_special_case() # ä»ç„¶è¦å¤„ç†é…è‚¡çš„ç‰¹æ®Šæƒ…å†µ
            return
        logger.info(f"Tæ—¥å…±æœ‰ {len(affected_codes)} åªè‚¡ç¥¨å‘ç”Ÿè‚¡æƒäº‹ä»¶ã€‚")

        # è·å–è¿™äº›è‚¡ç¥¨åœ¨T-1æ—¥çš„æ”¶ç›˜ä»·
        quotes_qs = DailyQuotes.objects.filter(
            trade_date=self.t_minus_1_day,
            stock_code_id__in=affected_codes
        )
        # ä½¿ç”¨å­—å…¸æ¨å¯¼å¼æ„å»ºæˆ‘ä»¬éœ€è¦çš„æ˜ å°„å…³ç³»
        quotes_t_minus_1 = {quote.stock_code_id: quote for quote in quotes_qs}
        self.adjustment_ratios = {} 
        # b. è®¡ç®—ä»·æ ¼è°ƒæ•´æ¯”ç‡
        for stock_code, events in events_by_stock.items():
            if stock_code not in quotes_t_minus_1:
                logger.warning(f"è‚¡ç¥¨ {stock_code} åœ¨T-1æ—¥({self.t_minus_1_day})æ— è¡Œæƒ…æ•°æ®ï¼ˆå¯èƒ½åœç‰Œï¼‰ï¼Œè·³è¿‡æ ¡å‡†ã€‚")
                continue
            
            close_t_minus_1 = quotes_t_minus_1[stock_code].close
            if close_t_minus_1 <= 0:
                logger.warning(f"è‚¡ç¥¨ {stock_code} åœ¨T-1æ—¥æ”¶ç›˜ä»·ä¸º0æˆ–è´Ÿæ•°ï¼Œä¸åˆç†ï¼Œè·³è¿‡æ ¡å‡†ã€‚")
                continue
            # 1. è®¡ç®—é€/è½¬/æ‹†/å¹¶è‚¡çš„æ¯”ç‡
            price_ratio_st, quantity_ratio_st = self._calculate_adjustment_ratios(events)
            # 2. è®¡ç®—åˆ†çº¢çš„ä»·æ ¼å½±å“
            total_dividend = sum(e.dividend_per_share for e in events if e.event_type == CorporateAction.EventType.DIVIDEND and e.dividend_per_share)
            
            price_ratio_div = Decimal('1.0')
            if total_dividend > 0:
                # åˆ†çº¢çš„ä»·æ ¼è°ƒæ•´æ¯”ç‡ = (æ”¶ç›˜ä»· - åˆ†çº¢) / æ”¶ç›˜ä»·
                price_ratio_div = (close_t_minus_1 - total_dividend) / close_t_minus_1
            # 3. åˆå¹¶æ€»æ¯”ç‡
            final_price_ratio = price_ratio_st * price_ratio_div
            final_quantity_ratio = quantity_ratio_st # åˆ†çº¢ä¸å½±å“æ•°é‡
            self.adjustment_ratios[stock_code] = (final_price_ratio, final_quantity_ratio)
            
            logger.info(f"è‚¡ç¥¨ {stock_code}: T-1æ”¶ç›˜ä»·={close_t_minus_1}, "
                        f"ä»·æ ¼è°ƒæ•´æ¯”ç‡={final_price_ratio:.6f}, "
                        f"æ•°é‡è°ƒæ•´æ¯”ç‡={final_quantity_ratio:.6f}")

        # c. ä¿®æ­£äº¤æ˜“é¢„æ¡ˆ
        self._process_trading_plans()

        # d. ä¿®æ­£æŒä»“é£æ§
        self._process_positions()

        # e. é…è‚¡äº‹ä»¶ç‰¹æ®Šå¤„ç†
        self._handle_rights_issue_special_case()

        logger.info(f"[{self.MODULE_NAME}] ä»»åŠ¡æˆåŠŸå®Œæˆã€‚å…±å¤„ç† {len(self.adjustment_ratios)} åªè‚¡ç¥¨çš„å¸¸è§„æ ¡å‡†ã€‚")

    def _process_trading_plans(self):
        """ä¿®æ­£äº¤æ˜“é¢„æ¡ˆä¸­çš„MIOPå’ŒMAOP"""
        plan_date_to_fix = self._find_latest_pending_plan_date()
        if not plan_date_to_fix:
            return

        plans_to_fix = DailyTradingPlan.objects.filter(
            plan_date=plan_date_to_fix,
            status=DailyTradingPlan.StatusChoices.PENDING,
            stock_code__in=self.adjustment_ratios.keys()
        )

        plans_to_update = []
        for plan in plans_to_fix:
            price_ratio, _ = self.adjustment_ratios[plan.stock_code_id]
            original_miop = plan.miop
            original_maop = plan.maop
            
            plan.miop = (original_miop * price_ratio).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            plan.maop = (original_maop * price_ratio).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            
            plans_to_update.append(plan)
            logger.info(f"äº¤æ˜“é¢„æ¡ˆä¿®æ­£: {plan.stock_code_id}, MIOP: {original_miop}->{plan.miop}, MAOP: {original_maop}->{plan.maop}")

        if plans_to_update:
            DailyTradingPlan.objects.bulk_update(plans_to_update, ['miop', 'maop'])
            logger.info(f"æˆåŠŸæ‰¹é‡æ›´æ–° {len(plans_to_update)} æ¡äº¤æ˜“é¢„æ¡ˆã€‚")

    def _process_positions(self):
        """ä¿®æ­£æŒä»“ä¸­çš„æ­¢ç›ˆæ­¢æŸä»·"""
        positions_to_fix = Position.objects.filter(
            status=Position.StatusChoices.OPEN,
            stock_code__in=self.adjustment_ratios.keys()
        )

        positions_to_update = []
        update_fields = ['entry_price', 'quantity', 'current_stop_loss', 'current_take_profit']
        for pos in positions_to_fix:
            price_ratio, quantity_ratio = self.adjustment_ratios[pos.stock_code_id]
            
            original_ep = pos.entry_price
            original_qty = pos.quantity
            original_sl = pos.current_stop_loss
            original_tp = pos.current_take_profit
            # ã€æ–°å¢ã€‘è°ƒæ•´æˆæœ¬ä»·
            pos.entry_price = (original_ep * price_ratio).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            
            # ã€æ–°å¢ã€‘è°ƒæ•´æŒä»“æ•°é‡ï¼Œå¹¶å–æ•´åˆ°è‚¡
            pos.quantity = int((Decimal(str(original_qty)) * quantity_ratio).to_integral_value(rounding=ROUND_HALF_UP))
            # ã€ä¿®æ”¹ã€‘è°ƒæ•´æ­¢ç›ˆæ­¢æŸä»·
            pos.current_stop_loss = (original_sl * price_ratio).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            pos.current_take_profit = (original_tp * price_ratio).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            
            positions_to_update.append(pos)
            logger.info(f"æŒä»“é£æ§ä¿®æ­£: {pos.stock_code_id}, "
                        f"æˆæœ¬ä»·: {original_ep:.2f} -> {pos.entry_price:.2f}, "
                        f"æ•°é‡: {original_qty} -> {pos.quantity}, "
                        f"æ­¢æŸ: {original_sl:.2f} -> {pos.current_stop_loss:.2f}, "
                        f"æ­¢ç›ˆ: {original_tp:.2f} -> {pos.current_take_profit:.2f}")

        if positions_to_update:
            Position.objects.bulk_update(positions_to_update, ['current_stop_loss', 'current_take_profit'])
            logger.info(f"æˆåŠŸæ‰¹é‡æ›´æ–° {len(positions_to_update)} æ¡æŒä»“è®°å½•ã€‚")

    def _handle_rights_issue_special_case(self):
        """å¤„ç†30ä¸ªäº¤æ˜“æ—¥å†…æœ‰é…è‚¡äº‹ä»¶çš„è‚¡ç¥¨"""
        # 1. è·å–è¿‡å»30ä¸ªäº¤æ˜“æ—¥çš„æ—¥æœŸåˆ—è¡¨
        recent_trading_days = list(
            DailyQuotes.objects.filter(trade_date__lte=self.t_day)
            .order_by('-trade_date')
            .values_list('trade_date', flat=True)[:self.RIGHTS_ISSUE_LOOKBACK_DAYS]
        )
        if not recent_trading_days:
            logger.warning("æ— æ³•è·å–æœ€è¿‘äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè·³è¿‡é…è‚¡ç‰¹æ®Šå¤„ç†ã€‚")
            return

        # 2. æŸ¥æ‰¾åœ¨æ­¤æœŸé—´å‘ç”Ÿé…è‚¡çš„è‚¡ç¥¨
        rights_issue_stocks = list(
            CorporateAction.objects.filter(
                event_type=CorporateAction.EventType.RIGHTS,
                ex_dividend_date__in=recent_trading_days
            ).values_list('stock_code', flat=True).distinct()
        )
        if not rights_issue_stocks:
            logger.info("è¿‘æœŸæ— é…è‚¡äº‹ä»¶ï¼Œæ— éœ€ç‰¹æ®Šå¤„ç†ã€‚")
            return
        
        logger.warning(f"æ£€æµ‹åˆ° {len(rights_issue_stocks)} åªè‚¡ç¥¨è¿‘æœŸæœ‰é…è‚¡äº‹ä»¶: {rights_issue_stocks}ï¼Œå°†è¿›è¡Œé£é™©å‰”é™¤ã€‚")

        # 3. å¤„ç†äº¤æ˜“é¢„æ¡ˆ
        plan_date_to_fix = self._find_latest_pending_plan_date()
        if plan_date_to_fix:
            plans_to_void = DailyTradingPlan.objects.filter(
                plan_date=plan_date_to_fix,
                status=DailyTradingPlan.StatusChoices.PENDING,
                stock_code__in=rights_issue_stocks
            )
            plans_to_update = []
            for plan in plans_to_void:
                plan.miop = Decimal('99999.00')
                plan.maop = Decimal('0.00')
                plans_to_update.append(plan)
            
            if plans_to_update:
                DailyTradingPlan.objects.bulk_update(plans_to_update, ['miop', 'maop'])
                logger.info(f"é…è‚¡é£é™©å¤„ç†ï¼šå°† {len(plans_to_update)} æ¡äº¤æ˜“é¢„æ¡ˆçš„MIOP/MAOPç½®ä¸ºæ— æ•ˆã€‚")

        # 4. å¤„ç†æŒä»“
        positions_to_void = Position.objects.filter(
            status=Position.StatusChoices.OPEN,
            stock_code__in=rights_issue_stocks
        )
        positions_to_update = []
        for pos in positions_to_void:
            pos.current_take_profit = Decimal('0.00')
            pos.current_stop_loss = Decimal('99999.00')
            positions_to_update.append(pos)
        
        if positions_to_update:
            Position.objects.bulk_update(positions_to_update, ['current_take_profit', 'current_stop_loss'])
            logger.info(f"é…è‚¡é£é™©å¤„ç†ï¼šå°† {len(positions_to_update)} æ¡æŒä»“çš„æ­¢ç›ˆ/æ­¢æŸç½®ä¸ºç´§æ€¥é€€å‡ºçŠ¶æ€ã€‚")


# --- å¦‚ä½•åœ¨é¡¹ç›®ä¸­ä½¿ç”¨è¿™ä¸ªæœåŠ¡ ---
# ä½ å¯ä»¥åœ¨ä¸€ä¸ªDjango Management Commandæˆ–è€…å®šæ—¶ä»»åŠ¡ï¼ˆå¦‚Celeryï¼‰ä¸­è°ƒç”¨å®ƒ
#
# from trade_manager.service.before_fix_service import BeforeFixService
#
# def run_daily_premarket_fix():
#     # é»˜è®¤ä½¿ç”¨å½“å¤©æ—¥æœŸ
#     service = BeforeFixService()
#     service.run()
#
# def run_backtest_premarket_fix(some_date):
#     # ä¼ å…¥æŒ‡å®šæ—¥æœŸè¿›è¡Œå›æµ‹
#     service = BeforeFixService(execution_date=some_date)
#     service.run()


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\db_utils.py####
# trade_manager/service/db_utils.py

import contextlib
import logging
import threading
from django.db import connections
from django.db.backends.signals import connection_created

logger = logging.getLogger(__name__)

# ä½¿ç”¨çº¿ç¨‹å±€éƒ¨å­˜å‚¨æ¥å®‰å…¨åœ°åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­ä¼ é€’ schema åç§°
_db_context = threading.local()

def backtest_schema_handler(sender, connection, **kwargs):
    """
    Django `connection_created` ä¿¡å·çš„å¤„ç†å™¨ã€‚
    å½“ä¸€ä¸ªæ–°çš„æ•°æ®åº“è¿æ¥è¢«åˆ›å»ºæ—¶ï¼Œæ­¤å‡½æ•°ä¼šè¢«è°ƒç”¨ã€‚
    å®ƒä¼šæ£€æŸ¥å½“å‰çº¿ç¨‹æ˜¯å¦åœ¨ `use_backtest_schema` ä¸Šä¸‹æ–‡ä¸­ï¼Œ
    å¦‚æœæ˜¯ï¼Œåˆ™ç«‹å³ä¸ºè¿™ä¸ªæ–°è¿æ¥è®¾ç½®æ­£ç¡®çš„ search_pathã€‚
    """
    if hasattr(_db_context, 'schema_name') and _db_context.schema_name:
        schema_name = _db_context.schema_name
        logger.debug(f"æ–°æ•°æ®åº“è¿æ¥åˆ›å»ºï¼Œä¸ºå…¶è®¾ç½® search_path -> {schema_name}, public")
        with connection.cursor() as cursor:
            # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢SQLæ³¨å…¥
            cursor.execute("SET search_path TO %s, public;", [schema_name])

# å°†ä¿¡å·å¤„ç†å™¨è¿æ¥åˆ° `connection_created` ä¿¡å·
# dispatch_uid ç¡®ä¿å³ä½¿ä»£ç è¢«å¤šæ¬¡å¯¼å…¥ï¼Œä¿¡å·å¤„ç†å™¨ä¹Ÿåªè¿æ¥ä¸€æ¬¡
connection_created.connect(backtest_schema_handler, dispatch_uid="set_backtest_search_path")

@contextlib.contextmanager
def use_backtest_schema(schema_name: str):
    """
    ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºåœ¨ç‰¹å®šä»£ç å—å†…å°†æ‰€æœ‰æ•°æ®åº“æ“ä½œé‡å®šå‘åˆ°æŒ‡å®šçš„ schemaã€‚

    ç”¨æ³•:
    with use_backtest_schema('my_backtest_schema'):
        # æ­¤å¤„æ‰€æœ‰çš„ Django ORM æ“ä½œéƒ½ä¼šåœ¨ 'my_backtest_schema' ä¸­è¿›è¡Œ
        MyModel.objects.create(...)
    """
    # è¿›å…¥ with å—æ—¶ï¼Œè®¾ç½®çº¿ç¨‹å±€éƒ¨å˜é‡
    _db_context.schema_name = schema_name
    # å¼ºåˆ¶å…³é—­å½“å‰çº¿ç¨‹çš„ç°æœ‰è¿æ¥ï¼Œä»¥ç¡®ä¿ä¸‹ä¸€ä¸ªæŸ¥è¯¢ä¼šåˆ›å»ºä¸€ä¸ªæ–°è¿æ¥ï¼Œä»è€Œè§¦å‘ä¿¡å·å¤„ç†å™¨
    connections['default'].close()
    try:
        # å°†æ§åˆ¶æƒäº¤è¿˜ç»™ with å—å†…çš„ä»£ç 
        yield
    finally:
        # é€€å‡º with å—æ—¶ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¼‚å¸¸ï¼‰ï¼Œæ¸…ç†çº¿ç¨‹å±€éƒ¨å˜é‡
        if hasattr(_db_context, 'schema_name'):
            del _db_context.schema_name
        # å†æ¬¡å…³é—­è¿æ¥ï¼Œä»¥ä¾¿åç»­æ“ä½œèƒ½æ¢å¤åˆ°é»˜è®¤çš„ search_path
        connections['default'].close()
        logger.debug("å·²é€€å‡ºå›æµ‹ schema ä¸Šä¸‹æ–‡ï¼Œæ¢å¤é»˜è®¤ search_pathã€‚")


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\decision_order_service.py####
# trade_manager/service/decision_order_service.py
# ç‰ˆæœ¬: 2.0 - M(t)é©±åŠ¨çš„åŠ¨æ€é£é™©ç®¡ç†
# æè¿°: æ­¤ç‰ˆæœ¬é‡æ„äº†æ­¢ç›ˆæ­¢æŸè®¡ç®—é€»è¾‘ï¼Œä½¿å…¶ä¸åŠ¨æ€é€‰è‚¡ç­–ç•¥çš„å¸‚åœºçŠ¶æ€åˆ¤æ–­(M(t))ä¿æŒä¸€è‡´ã€‚
#       è§£å†³äº†æ—§ç‰ˆåœ¨éè¶‹åŠ¿è¡Œæƒ…ä¸­æ­¢æŸä»·å¯èƒ½é«˜äºæ­¢ç›ˆä»·çš„ä¸¥é‡é€»è¾‘é—®é¢˜ã€‚

import logging
from datetime import date, timedelta
from decimal import Decimal, ROUND_HALF_UP
import pandas as pd
import pandas_ta as ta

from django.db import transaction
from django.utils import timezone

from common.models import (
    DailyTradingPlan,
    Position,
    TradeLog,
    StrategyParameters,
    DailyQuotes,
    SystemLog,
    DailyFactorValues  # æ–°å¢å¯¼å…¥
)
from .trade_handler import ITradeHandler
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE # æ–°å¢å¯¼å…¥

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class DecisionOrderService:
    """
    å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å— (V2.0 - åŠ¨æ€é£é™©ç‰ˆ)ã€‚

    è¯¥æœåŠ¡è´Ÿè´£åœ¨Tæ—¥å¼€ç›˜åçš„é»„é‡‘æ—¶é—´å†…ï¼Œæ ¹æ®é¢„æ¡ˆã€å®é™…å¼€ç›˜ä»·å’Œè´¦æˆ·çŠ¶æ€ï¼Œ
    åšå‡ºæœ€ç»ˆçš„ä¹°å…¥å†³ç­–ï¼Œå¹¶æ‰§è¡Œä¸‹å•ã€‚å…¶æ ¸å¿ƒç‰¹è‰²æ˜¯ï¼Œåœ¨è®¢å•æˆäº¤åï¼Œ
    èƒ½å¤Ÿæ ¹æ®T-1æ—¥çš„å¸‚åœºçŠ¶æ€M(t)ï¼Œä¸ºæ–°æŒä»“è®¡ç®—åŠ¨æ€çš„ã€è‡ªé€‚åº”çš„æ­¢ç›ˆæ­¢æŸä»·ã€‚
    """
    MODULE_NAME = 'å¼€ç›˜å†³ç­–ä¸ä¸‹å•(åŠ¨æ€é£é™©ç‰ˆ)'
    MAX_PLAN_LOOKBACK_DAYS = 14

    def __init__(self, handler: ITradeHandler, execution_date: date = None):
        """
        åˆå§‹åŒ–æœåŠ¡ã€‚

        :param handler: ä¸€ä¸ªå®ç°äº† ITradeHandler æ¥å£çš„å®ä¾‹ï¼Œç”¨äºä¸äº¤æ˜“ç¯å¢ƒäº¤äº’ã€‚
        :param execution_date: Tæ—¥ï¼Œå³æ‰§è¡Œå†³ç­–çš„æ—¥æœŸã€‚å¦‚æœä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºå½“å¤©ã€‚
        """
        if not isinstance(handler, ITradeHandler):
            raise TypeError("ä¼ å…¥çš„ handler å¿…é¡»æ˜¯ ITradeHandler çš„ä¸€ä¸ªå®ä¾‹ã€‚")
      
        self.handler = handler
        self.execution_date = execution_date if execution_date else date.today()
        self.params = self._load_strategy_parameters()
      
        # æ–°å¢ï¼šç”¨äºå­˜å‚¨å½“æ—¥åŠ¨æ€è®¡ç®—ç»“æœçš„å®ä¾‹å˜é‡
        self.current_max_positions = 0
        self.final_nominal_principal = Decimal('0.0')
 
        # ã€å…¨æ–°ã€‘è°ƒç”¨æ–°çš„åˆå§‹åŒ–å¼•æ“
        self._initialize_position_sizing_engine()
      
        logger.debug(f"[{self.MODULE_NAME}] æœåŠ¡åˆå§‹åŒ–ã€‚æ‰§è¡ŒTæ—¥: {self.execution_date}")
        logger.debug(f"ç­–ç•¥å‚æ•°åŠ è½½æˆåŠŸ: {len(self.params)}ä¸ª")
        logger.debug(f"å½“æ—¥åŠ¨æ€æœ€å¤§æŒä»“æ•°: {self.current_max_positions}")
        logger.debug(f"å½“æ—¥åŠ¨æ€å•ä½åä¹‰æœ¬é‡‘: {self.final_nominal_principal:.2f}")

    def _initialize_position_sizing_engine(self):
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        åœ¨æœåŠ¡åˆå§‹åŒ–æ—¶ï¼Œå®Œæˆæ‰€æœ‰åŸºäºT-1æ—¥M(t)çš„ä»“ä½ sizing è®¡ç®—ã€‚
        """
        try:
            # 1. è·å–T-1äº¤æ˜“æ—¥
            t_minus_1_date = DailyQuotes.objects.filter(trade_date__lt=self.execution_date).latest('trade_date').trade_date
        except DailyQuotes.DoesNotExist:
            logger.error(f"æ— æ³•æ‰¾åˆ° {self.execution_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ŒåŠ¨æ€ä»“ä½ç®¡ç†æ— æ³•å¯åŠ¨ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ã€‚")
            self.current_max_positions = self.params.get('MIN_POSITIONS_COUNT', 1)
            self.final_nominal_principal = Decimal('0.0') # å¯¼è‡´æ— æ³•ä¹°å…¥
            return
 
        # 2. è·å–T-1æ—¥çš„å¸‚åœºçŠ¶æ€M(t)
        market_regime_M = self._get_market_regime_M(t_minus_1_date)
        market_regime_S = self._get_market_regime_S(t_minus_1_date)
        logger.info(f"è·å–åˆ° T-1 ({t_minus_1_date}) çš„ M(t) = {market_regime_M:.4f}")
 
        # 3. è®¡ç®—å½“æ—¥åŠ¨æ€æœ€å¤§æŒä»“æ•°
        self.current_max_positions = self._calculate_dynamic_max_positions(market_regime_M)
        
        # 4. è®¡ç®—å½“æ—¥åŠ¨æ€å•ä½åä¹‰æœ¬é‡‘
        self.final_nominal_principal = self._calculate_dynamic_nominal_principal(market_regime_M, t_minus_1_date)
 
    def _get_market_regime_M(self, t_minus_1_date: date) -> Decimal:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        ä»æ•°æ®åº“è·å–æŒ‡å®šæ—¥æœŸçš„ M(t) å€¼ã€‚
        """
        try:
            m_value_record = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                trade_date=t_minus_1_date,
                factor_code_id='dynamic_M_VALUE'
            )
            return m_value_record.raw_value
        except DailyFactorValues.DoesNotExist:
            logger.error(f"ä¸¥é‡è­¦å‘Š: æ— æ³•åœ¨ {t_minus_1_date} æ‰¾åˆ°å¸‚åœºçŠ¶æ€M(t)å€¼ï¼å°†ä½¿ç”¨æœ€ä¿å®ˆçš„ä¸­æ€§å€¼0.0è¿›è¡Œè®¡ç®—ã€‚")
            return Decimal('0.0')
        
    def _get_market_regime_S(self, t_minus_1_date: date) -> Decimal:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        ä»æ•°æ®åº“è·å–æŒ‡å®šæ—¥æœŸçš„ S(t) å€¼ã€‚
        """
        try:
            m_value_record = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                trade_date=t_minus_1_date,
                factor_code_id='dynamic_S_VALUE'
            )
            return m_value_record.raw_value
        except DailyFactorValues.DoesNotExist:
            logger.error(f"ä¸¥é‡è­¦å‘Š: æ— æ³•åœ¨ {t_minus_1_date} æ‰¾åˆ°å¸‚åœºçŠ¶æ€S(t)å€¼ï¼å°†ä½¿ç”¨æœ€ä¿å®ˆçš„ä¸­æ€§å€¼0.0è¿›è¡Œè®¡ç®—ã€‚")
            return Decimal('0.0')
 
    def _calculate_dynamic_max_positions(self, M_t: Decimal) -> int:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        æ ¹æ®M(t)è®¡ç®—åŠ¨æ€æœ€å¤§æŒä»“æ•° Current_Max_Positionsã€‚
        """
        S_min_pos = self.params['RISK_ADJ_POS_FLOOR_PCT']
        
        # i. è®¡ç®—æ€»ä»“ä½æ•°é£é™©ç¼©æ”¾å› å­ S_pos(M(t))
        S_pos = S_min_pos + (1 - S_min_pos) * (M_t + 1) / 2
        
        # ii. è®¡ç®—ç†è®ºæœ€å¤§ä»“ä½æ•°
        base_max_pos = self.params['ORIGINAL_MAX_POSITIONS']
        theoretical_max = Decimal(base_max_pos) * S_pos
        
        # iii. å–æ•´å¹¶åº”ç”¨ä¸‹é™
        min_pos_count = self.params['MIN_POSITIONS_COUNT']
        current_max_positions = max(min_pos_count, int(theoretical_max.to_integral_value(rounding='ROUND_FLOOR')))
        current_max_positions=base_max_pos
        logger.debug(f"åŠ¨æ€æŒä»“æ•°è®¡ç®—: S_pos={S_pos:.4f}, ç†è´¢æŒä»“={theoretical_max:.2f}, æœ€ç»ˆå–æ•´={current_max_positions}")
        return current_max_positions
 
    def _calculate_dynamic_nominal_principal(self, M_t: Decimal, t_minus_1_date: date) -> Decimal:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        æ ¹æ®M(t)è®¡ç®—åŠ¨æ€å•ä½åä¹‰æœ¬é‡‘ Final_Nominal_Principalã€‚
        """
        # i. è·å–å½“å‰æ€»èµ„äº§
        cash_balance = self.handler.get_available_balance()
        positions_market_value = Decimal('0.0')
        open_positions = Position.objects.filter(status=Position.StatusChoices.OPEN)
        if open_positions.exists():
            for pos in open_positions:
                try:
                    quote = DailyQuotes.objects.get(stock_code_id=pos.stock_code_id, trade_date=t_minus_1_date)
                    positions_market_value += quote.close * pos.quantity
                except DailyQuotes.DoesNotExist:
                    positions_market_value += pos.entry_price * pos.quantity
        
        total_assets = cash_balance + positions_market_value
        logger.debug(f"æ€»èµ„äº§è®¡ç®—: ç°é‡‘{cash_balance:.2f} + æŒä»“å¸‚å€¼{positions_market_value:.2f} = {total_assets:.2f}")
 
        # ii. è®¡ç®—åŸºå‡†å•ä½åä¹‰æœ¬é‡‘
        base_max_pos = self.params['ORIGINAL_MAX_POSITIONS']
        if base_max_pos <= 0: return Decimal('0.0')
        baseline_unit_principal = total_assets / Decimal(base_max_pos)
        
        # iii. è®¡ç®—å•ä½åä¹‰æœ¬é‡‘é£é™©ç¼©æ”¾å› å­ S_cap(M(t))
        S_min_cap = self.params['RISK_ADJ_CAPITAL_FLOOR_PCT']
        S_cap = S_min_cap + (1 - S_min_cap) * (M_t + 1) / 2
        # if M_t > Decimal('0.5'):
        #     S_cap = Decimal('1.0')
        # elif M_t > Decimal('0.0'):
        #     S_cap = Decimal('0.5')
        # else:
        #     S_cap = Decimal('0.0')
        epsilon = Decimal(1e-9)
        if abs(M_t) < epsilon:
            S_cap=Decimal('0.0')
        elif M_t<Decimal('0.0'):
            S_cap=Decimal('0.0')
        else:
            S_cap=min(M_t*2,Decimal('1.0'))
            #Decimal('1.0')
        
        #S_cap=Decimal('1.0')
        # iv. è®¡ç®—åŠ¨æ€è°ƒæ•´åçš„åä¹‰æœ¬é‡‘
        adjusted_unit_principal = baseline_unit_principal * S_cap
        
        logger.debug(f"åŠ¨æ€åä¹‰æœ¬é‡‘è®¡ç®—: åŸºå‡†æœ¬é‡‘={baseline_unit_principal:.2f}, S_cap={S_cap:.4f}, è°ƒæ•´åæœ¬é‡‘={adjusted_unit_principal:.2f}")
        
        # v. ç¡®å®šæœ€ç»ˆä¸‹å•åä¹‰æœ¬é‡‘ - æ³¨æ„ï¼šä¸å¯ç”¨ç°é‡‘çš„æ¯”è¾ƒå°†åœ¨ä¸‹å•æ—¶è¿›è¡Œ
        return adjusted_unit_principal

    def _log_to_db(self, level: str, message: str):
        """è¾…åŠ©æ–¹æ³•ï¼šå°†æ—¥å¿—å†™å…¥æ•°æ®åº“"""
        # åœ¨é«˜é¢‘å›æµ‹ä¸­å¯ä»¥æ³¨é‡Šæ‰æ­¤æ–¹æ³•ä»¥æé«˜æ€§èƒ½
        # SystemLog.objects.create(
        #     log_level=level,
        #     module_name=self.MODULE_NAME,
        #     message=message
        # )
        pass
    def _find_relevant_plan_date(self) -> date | None:
        # 1. è®¡ç®—æŸ¥è¯¢çš„èµ·å§‹æ—¥æœŸ
        start_date = self.execution_date - timedelta(days=self.MAX_PLAN_LOOKBACK_DAYS - 1)
        
        # 2. æ‰§è¡Œä¸€æ¬¡æ•°æ®åº“æŸ¥è¯¢
        latest_plan = DailyTradingPlan.objects.filter(
            plan_date__gte=start_date,  # gte = greater than or equal to (å¤§äºç­‰äº)
            plan_date__lte=self.execution_date, # lte = less than or equal to (å°äºç­‰äº)
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('-plan_date').first() # æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼Œå¹¶å–ç¬¬ä¸€ä¸ª
    
        # 3. å¤„ç†æŸ¥è¯¢ç»“æœ
        if latest_plan:
            found_date = latest_plan.plan_date
            if found_date != self.execution_date:
                logger.info(f"æ‰§è¡Œæ—¥ {self.execution_date} æ— é¢„æ¡ˆï¼Œå›æº¯æ‰¾åˆ°å¾…æ‰§è¡Œé¢„æ¡ˆï¼Œå…¶ç”Ÿæˆæ—¥æœŸä¸º: {found_date}")
            else:
                logger.debug(f"æ‰¾åˆ°å½“å¤© {found_date} çš„å¾…æ‰§è¡Œé¢„æ¡ˆã€‚")
            return found_date
        
        # å¦‚æœæŸ¥è¯¢ç»“æœä¸ºç©º
        logger.warning(f"åœ¨è¿‡å» {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…ï¼ˆä» {self.execution_date} å¼€å§‹å›æº¯ï¼‰æœªæ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚")
        return None
    def _load_strategy_parameters(self) -> dict:
        """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç­–ç•¥å‚æ•°åˆ°å†…å­˜"""
        params = {}
        # å®šä¹‰éœ€è¦åŠ è½½çš„å‚æ•°åŠå…¶é»˜è®¤å€¼
        # æ³¨æ„ï¼šè¿™é‡Œçš„é”®ååº”ä¸ initialize_strategy_parameters ä¸­å®šä¹‰çš„å®Œå…¨ä¸€è‡´
        required_params = {
            # é€šç”¨å‚æ•°
            #'MAX_POSITIONS': '3',
            'MAX_CAPITAL_PER_POSITION': '20000.00',
            'k_slip': '0.002',
            'lookback_atr': '14',
            # æ–°ç‰ˆåŠ¨æ€é£é™©å‚æ•°
            'risk_adj_tp_pct_min': '0.15',
            'risk_adj_tp_pct_max': '0.15',
            'risk_adj_sl_atr_min': '2',
            'risk_adj_sl_atr_max': '2',
            'risk_adj_max_loss_pct': '0.1',
            # å…¨æ–°åŠ¨æ€ä»“ä½å‚æ•°
            'ORIGINAL_MAX_POSITIONS': '5',
            'MIN_POSITIONS_COUNT': '1',
            'RISK_ADJ_POS_FLOOR_PCT': '0.2',
            'RISK_ADJ_CAPITAL_FLOOR_PCT': '0.5',
        }
      
        db_params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
      
        for key, default_value in required_params.items():
            value = db_params.get(key, Decimal(str(default_value)))
            if key in ['ORIGINAL_MAX_POSITIONS', 'MIN_POSITIONS_COUNT', 'lookback_atr']:
                params[key] = int(value)
            else:
                params[key] = Decimal(str(value))
        return params

    # --- æš´éœ²ç»™å¤–éƒ¨è°ƒåº¦çš„æ ¸å¿ƒå‡½æ•° ---

    def adjust_trading_plan_daily(self):
        """
        å‡½æ•°ä¸€ï¼šæ‰§è¡Œæ¯æ—¥äº¤æ˜“é¢„æ¡ˆå†è°ƒæ•´ (é€»è¾‘ä¸å˜)ã€‚
        """
        logger.debug(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„äº¤æ˜“é¢„æ¡ˆäºŒæ¬¡ç­›é€‰...")
        relevant_plan_date = self._find_relevant_plan_date()
        if not relevant_plan_date:
            msg = f"åœ¨ {self.execution_date} åŠä¹‹å‰ {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.debug(msg)
            self._log_to_db('WARNING', msg)
            return
        plans_today = DailyTradingPlan.objects.filter(
            plan_date=relevant_plan_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')

        if not plans_today.exists():
            msg = f"åœ¨ {self.execution_date} æ²¡æœ‰æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.debug(msg)
            self._log_to_db('WARNING', msg)
            return

        plans_to_cancel = []
        for plan in plans_today:
            try:
                open_price = self.handler.get_opening_price(plan.stock_code_id)
                if open_price <= 0:
                    logger.warning(f"è‚¡ç¥¨ {plan.stock_code_id} å¼€ç›˜ä»·ä¸º0æˆ–æ— æ•ˆï¼Œè§†ä¸ºä¸ç¬¦åˆæ¡ä»¶ã€‚")
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)
                    continue

                if not (plan.miop <= open_price <= plan.maop):
                    msg = (f"é¢„æ¡ˆ {plan.stock_code_id} (Rank:{plan.rank}) å¼€ç›˜ä»· {open_price} "
                           f"ä¸åœ¨åŒºé—´ [{plan.miop}, {plan.maop}] å†…ï¼Œå·²ä½œåºŸã€‚")
                    logger.debug(msg)
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)

            except Exception as e:
                msg = f"è·å– {plan.stock_code_id} å¼€ç›˜ä»·æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œè¯¥é¢„æ¡ˆä½œåºŸã€‚"
                logger.error(msg)
                self._log_to_db('ERROR', msg)
                plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                plans_to_cancel.append(plan)

        if plans_to_cancel:
            with transaction.atomic():
                DailyTradingPlan.objects.bulk_update(plans_to_cancel, ['status'])
            logger.debug(f"æˆåŠŸä½œåºŸ {len(plans_to_cancel)} æ¡ä¸ç¬¦åˆå¼€ç›˜æ¡ä»¶çš„äº¤æ˜“é¢„æ¡ˆã€‚")
        else:
            logger.debug("æ‰€æœ‰å¾…æ‰§è¡Œé¢„æ¡ˆå‡ç¬¦åˆå¼€ç›˜ä»·æ¡ä»¶ã€‚")

    def execute_orders(self):
        """
        å‡½æ•°äºŒï¼šè¿›è¡Œä¸‹å• (é€»è¾‘ä¸å˜)ã€‚
        """
        logger.debug(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„ä¸‹å•æµç¨‹...")

        open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
        # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„å½“æ—¥æœ€å¤§æŒä»“æ•°
        remaining_slots = self.current_max_positions - open_positions_count

        if remaining_slots <= 0:
            msg = f"å½“å‰æŒä»“æ•° {open_positions_count} å·²è¾¾æˆ–è¶…è¿‡å½“æ—¥åŠ¨æ€ä¸Šé™ {self.current_max_positions}ï¼Œä¸è¿›è¡Œä¹°å…¥ã€‚"
            logger.debug(msg)
            self._log_to_db('WARNING', msg)
            return

        relevant_plan_date = self._find_relevant_plan_date()
        if not relevant_plan_date:
            msg = f"åœ¨ {self.execution_date} åŠä¹‹å‰ {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆå¯ä¾›ä¸‹å•ã€‚"
            logger.debug(msg)
            self._log_to_db('INFO', msg)
            return

        candidates = DailyTradingPlan.objects.filter(
            plan_date=relevant_plan_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')
 
        if not candidates.exists():
            msg = f"åœ¨ {self.execution_date} æ— ç¬¦åˆæ¡ä»¶çš„ä¹°å…¥æ ‡çš„ã€‚"
            logger.debug(msg)
            self._log_to_db('INFO', msg)
            return

        for candidate in candidates:
            try:
                stock_code = candidate.stock_code_id
                open_price = self.handler.get_opening_price(stock_code)
              
                k_slip = self.params['k_slip']
                limit_price = (open_price * (Decimal('1.0') + k_slip)).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
 
                # è·å–ä¸‹å•æ—¶æœ€ç»ˆçš„åä¹‰æœ¬é‡‘
                available_balance = self.handler.get_available_balance()
                
                # self.final_nominal_principal æ˜¯å·²æŒ‰M(t)è°ƒæ•´è¿‡çš„å€¼
                # å†ç»“åˆç¡¬æ€§é£æ§å’ŒæµåŠ¨æ€§çº¦æŸ
                nominal_principal = min(
                    self.final_nominal_principal, 
                    self.params['MAX_CAPITAL_PER_POSITION'], 
                    available_balance
                )
                nominal_principal=nominal_principal*min(Decimal('1.0'),Decimal(2.0)*max(Decimal('0.0'),candidate.final_score))
                logger.debug(f"æ ‡çš„ {stock_code}: åŠ¨æ€è°ƒæ•´åæœ¬é‡‘={self.final_nominal_principal:.2f}, "
                             f"å•ä»“ä¸Šé™={self.params['MAX_CAPITAL_PER_POSITION']:.2f}, "
                             f"å¯ç”¨ç°é‡‘={available_balance:.2f}. "
                             f"é€‰è‚¡è¯„åˆ†={available_balance:.2f}. "
                             f"æœ€ç»ˆåä¹‰æœ¬é‡‘={nominal_principal:.2f}")
 
                if limit_price <= 0:
                    logger.debug(f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„ä¸‹å•é™ä»·æ— æ•ˆï¼ˆ{limit_price}ï¼‰ï¼Œè·³è¿‡ã€‚")
                    continue
 
                shares_to_buy = int(nominal_principal / limit_price)
                quantity = (shares_to_buy // 100) * 100
 
                if quantity < 100:
                    msg = (f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„åä¹‰æœ¬é‡‘ {nominal_principal:.2f} ä¸è¶³ä»¥è´­ä¹°ä¸€æ‰‹ï¼ˆ100è‚¡ï¼‰ã€‚")
                    logger.warning(msg)
                    self._log_to_db('WARNING', msg)
                    continue
 
                msg = (f"ç¡®å®šå”¯ä¸€ä¹°å…¥æ ‡çš„: {candidate.stock_code.stock_name}({stock_code}) (Rank:{candidate.rank})ã€‚ "
                       f"è®¡åˆ’ä»¥é™ä»· {limit_price} ä¹°å…¥ {quantity} è‚¡ã€‚")
                logger.info(msg)
                self._log_to_db('INFO', msg)
              
                self.handler.place_buy_order(stock_code, limit_price, quantity)
              
                candidate.status = DailyTradingPlan.StatusChoices.EXECUTED
                candidate.save()
 
                return
 
            except Exception as e:
                msg = f"å¤„ç†å€™é€‰è‚¡ {candidate.stock_code_id} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
                logger.error(msg, exc_info=True)
                self._log_to_db('CRITICAL', msg)
                continue
 
        logger.debug(f"å·²å°è¯•æ‰€æœ‰ {len(candidates)} ä¸ªå€™é€‰æ ‡çš„ï¼Œå‡æœªæˆåŠŸä¹°å…¥ã€‚")

    def calculate_stop_profit_loss(self, trade_id: int):
        """
        å‡½æ•°ä¸‰ï¼šæ­¢ç›ˆæ­¢æŸåŒºé—´è®¡ç®— (V2.0 é‡æ„ç‰ˆ)ã€‚
        åœ¨è®¢å•æˆäº¤åï¼Œä¸ºæ–°æŒä»“è®¡ç®—å¹¶æ›´æ–°ç”±M(t)é©±åŠ¨çš„åŠ¨æ€æ­¢ç›ˆæ­¢æŸä»·ã€‚
 
        :param trade_id: å·²æˆäº¤çš„ä¹°å…¥äº¤æ˜“åœ¨ tb_trade_log ä¸­çš„å”¯ä¸€IDã€‚
        """
        logger.debug(f"å¼€å§‹ä¸º trade_id={trade_id} è®¡ç®—åŠ¨æ€æ­¢ç›ˆæ­¢æŸåŒºé—´...")
        try:
            with transaction.atomic():
                # 1. è·å–äº¤æ˜“å’ŒæŒä»“ä¿¡æ¯
                trade_log = TradeLog.objects.select_for_update().get(
                    trade_id=trade_id,
                    trade_type=TradeLog.TradeTypeChoices.BUY,
                    status=TradeLog.StatusChoices.FILLED
                )
                position = Position.objects.select_for_update().get(pk=trade_log.position_id)
 
                if position.current_stop_loss > 0 and position.current_take_profit > 0:
                    logger.warning(f"Position ID {position.position_id} ä¼¼ä¹å·²è®¡ç®—è¿‡æ­¢ç›ˆæ­¢æŸï¼Œå°†è·³è¿‡ã€‚")
                    return
 
                stock_code = trade_log.stock_code_id
                aep = trade_log.price
                buy_date = trade_log.trade_datetime.date()
                t_minus_1_date = DailyQuotes.objects.filter(trade_date__lt=buy_date).latest('trade_date').trade_date
              
                # 2. è·å–è®¡ç®—æ‰€éœ€çš„æ ¸å¿ƒæ•°æ®ï¼šM(t) å’Œ ATR
                # 2.1 è·å– T-1 æ—¥çš„å¸‚åœºçŠ¶æ€ M(t)
                try:
                    m_value_record = DailyFactorValues.objects.get(
                        stock_code_id=MARKET_INDICATOR_CODE,
                        trade_date=t_minus_1_date,
                        factor_code_id='dynamic_M_VALUE'
                    )
                    market_regime_M = m_value_record.raw_value
                except DailyFactorValues.DoesNotExist:
                    logger.error(f"æ— æ³•æ‰¾åˆ° {t_minus_1_date} çš„å¸‚åœºçŠ¶æ€M(t)å€¼ï¼å°†ä½¿ç”¨ä¸­æ€§å€¼0.0è¿›è¡Œè®¡ç®—ã€‚")
                    market_regime_M = Decimal('0.0')

                # 2.2 è·å–è®¡ç®— ATR æ‰€éœ€çš„å†å²è¡Œæƒ…
                lookback_days = self.params['lookback_atr'] + 50 # å¢åŠ buffer
                start_date_for_calc = t_minus_1_date - timedelta(days=lookback_days * 2)
 
                quotes_qs = DailyQuotes.objects.filter(
                    stock_code_id=stock_code,
                    trade_date__gte=start_date_for_calc,
                    trade_date__lte=t_minus_1_date
                ).order_by('trade_date')
 
                if len(quotes_qs) < self.params['lookback_atr']:
                    raise ValueError(f"è‚¡ç¥¨ {stock_code} åœ¨ {t_minus_1_date} å‰çš„å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ATRã€‚")
 
                df = pd.DataFrame.from_records(quotes_qs.values('high', 'low', 'close'))
                df = df.astype(float)
 
                atr_series = ta.atr(df['high'], df['low'], df['close'], length=self.params['lookback_atr'])
                atr_14_buy = Decimal(str(atr_series.iloc[-1])) if not atr_series.empty else Decimal('0.0')

                # 3. è®¡ç®—åŠ¨æ€æ­¢ç›ˆä»· g_new(y)
                tp_min = self.params['risk_adj_tp_pct_min']
                tp_max = self.params['risk_adj_tp_pct_max']
                tp_pct = tp_min + (tp_max - tp_min) * (market_regime_M + 1) / 2
                take_profit_price = aep * (1 + tp_pct)

                # 4. è®¡ç®—è‡ªé€‚åº”æ­¢æŸä»· h_new(z)
                # 4.1 è®¡ç®—åŠ¨æ€ATRä¹˜æ•° k_h(M(t))
                kh_min = self.params['risk_adj_sl_atr_min']
                kh_max = self.params['risk_adj_sl_atr_max']
                k_h_dynamic = kh_min + (kh_max - kh_min) * (market_regime_M + 1) / 2
                
                # 4.2 è®¡ç®—åŠ¨æ€æ³¢åŠ¨æ­¢æŸçº¿
                z1_dynamic_atr = aep - k_h_dynamic * atr_14_buy

                # 4.3 è®¡ç®—ç»å¯¹æœ€å¤§äºæŸåº•çº¿
                z2_max_loss = aep * (1 - self.params['risk_adj_max_loss_pct'])
              
                # 4.4 å–æœ€ä¸¥æ ¼çš„æ­¢æŸä½ï¼ˆä»·æ ¼æœ€é«˜è€…ï¼‰ï¼Œä½†æ˜¯æ­¢æŸç‡ä¸èƒ½ä½äº0.5%
                stop_loss_price =min(aep *Decimal('0.995'),max(z1_dynamic_atr, z2_max_loss))
              
                logger.debug(f"[{stock_code}] æ­¢æŸçº¿æ¯”è¾ƒ (åŸºäºM(t)={market_regime_M:.4f}): "
                            f"åŠ¨æ€ATRæ­¢æŸ(ä¹˜æ•°{k_h_dynamic:.2f})={z1_dynamic_atr:.2f}, "
                            f"ç»å¯¹æœ€å¤§äºæŸ={z2_max_loss:.2f}")
 
                # 5. æ›´æ–°æŒä»“ä¿¡æ¯è¡¨
                position.current_take_profit = take_profit_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                position.current_stop_loss = stop_loss_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                
                # æœ€ç»ˆæ ¡éªŒï¼Œé˜²æ­¢å‡ºç°æç«¯æƒ…å†µ
                if position.current_stop_loss >= position.current_take_profit:
                    logger.critical(f"ä¸¥é‡é€»è¾‘é”™è¯¯ï¼è®¡ç®—åæ­¢æŸä»·({position.current_stop_loss})ä»é«˜äºæˆ–ç­‰äºæ­¢ç›ˆä»·({position.current_take_profit})ã€‚å°†ä½¿ç”¨æœ€å¤§äºæŸåº•çº¿ä½œä¸ºæ­¢æŸã€‚")
                    position.current_stop_loss = z2_max_loss.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)

                position.save(update_fields=['current_take_profit', 'current_stop_loss'])
                loss_pct = (aep - position.current_stop_loss) / aep if aep > 0 else Decimal('0.0')
                msg = (f"æˆåŠŸè®¡ç®—å¹¶æ›´æ–° Position ID {position.position_id} ({stock_code}) çš„åŠ¨æ€é£æ§ä»·æ ¼: "
                       f"è´­å…¥ä»·={aep:.2f}, æ­¢ç›ˆä»·={position.current_take_profit:.2f} (ç›®æ ‡æ”¶ç›Šç‡ {tp_pct:.2%}), "
                       f"æ­¢æŸä»·={position.current_stop_loss:.2f} (æœ€å¤§å®¹å¿äºæŸ {loss_pct:.2%})")
                logger.info(msg)
                self._log_to_db('INFO', msg)
 
        except TradeLog.DoesNotExist:
            logger.error(f"Trade ID {trade_id} ä¸å­˜åœ¨æˆ–ä¸æ»¡è¶³è®¡ç®—æ¡ä»¶ï¼ˆéä¹°å…¥/æœªæˆäº¤ï¼‰ã€‚")
        except Position.DoesNotExist:
            logger.error(f"ä¸ Trade ID {trade_id} å…³è”çš„ Position ä¸å­˜åœ¨ã€‚")
        except Exception as e:
            msg = f"ä¸º Trade ID {trade_id} è®¡ç®—åŠ¨æ€æ­¢ç›ˆæ­¢æŸæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
            logger.critical(msg, exc_info=True)
            self._log_to_db('CRITICAL', msg)
            raise

    # --- å·¥å…·å‡½æ•° ---

    @staticmethod
    def initialize_strategy_parameters():
        """
        å·¥å…·å‡½æ•°ï¼šåˆå§‹åŒ–æœ¬æ¨¡å—æ‰€éœ€çš„ç­–ç•¥å‚æ•°åˆ°æ•°æ®åº“ã€‚
        è¿™æ˜¯ä¸€ä¸ªå¹‚ç­‰æ“ä½œï¼Œå¯ä»¥å®‰å…¨åœ°é‡å¤è¿è¡Œã€‚
        """
        logger.info("å¼€å§‹åˆå§‹åŒ–[å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—-åŠ¨æ€é£é™©ç‰ˆ]çš„ç­–ç•¥å‚æ•°...")

        params_to_define = {
            # é€šç”¨å‚æ•°
            #'MAX_POSITIONS': {'value': '3', 'group': 'POSITION_MGMT', 'desc': 'æœ€å¤§å¯å…·å¤‡çš„æ€»ä»“ä½æ•°'},
            'MAX_CAPITAL_PER_POSITION': {'value': '20000.00', 'group': 'POSITION_MGMT', 'desc': 'æ¯ä»“æœ€å¤§æŠ•å…¥èµ„é‡‘æ•°(å…ƒ)'},
            'k_slip': {'value': '0.002', 'group': 'ORDER_EXEC', 'desc': 'ä¸‹å•æ»‘ç‚¹ç³»æ•°, ç”¨äºè®¡ç®—é™ä»·å•ä»·æ ¼'},
            'lookback_atr': {'value': '14', 'group': 'INDICATORS', 'desc': 'ATRè®¡ç®—å‘¨æœŸ'},
            
            # æ–°ç‰ˆ M(t) é©±åŠ¨çš„åŠ¨æ€é£é™©å‚æ•°
            'risk_adj_tp_pct_min': {'value': '0.15', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å°æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯” (ç†Šå¸‚)'},
            'risk_adj_tp_pct_max': {'value': '0.15', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å¤§æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯” (ç‰›å¸‚)'},
            'risk_adj_sl_atr_min': {'value': '2', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å°ATRæ­¢æŸä¹˜æ•° (ç†Šå¸‚)'},
            'risk_adj_sl_atr_max': {'value': '2', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å¤§ATRæ­¢æŸä¹˜æ•° (ç‰›å¸‚)'},
            'risk_adj_max_loss_pct': {'value': '0.1', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-ç»å¯¹æœ€å¤§äºæŸç™¾åˆ†æ¯”'},
            # --- å…¨æ–°åŠ¨æ€ä»“ä½ç®¡ç†å‚æ•° ---
            'ORIGINAL_MAX_POSITIONS': {'value': '5', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘ç­–ç•¥åŸºå‡†æœ€å¤§æŒä»“æ•°'},
            'MIN_POSITIONS_COUNT': {'value': '1', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘æœ€å°æŒä»“æ•°ç¡¬ä¸‹é™'},
            'RISK_ADJ_POS_FLOOR_PCT': {'value': '0.1', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘æ€»ä»“ä½æ•°ç¼©æ”¾å› å­çš„ä¸‹é™ S_min_pos (ä¾‹å¦‚0.4ä»£è¡¨æœ€å·®æƒ…å†µæŒæœ‰åŸºå‡†çš„40%)'},
            'RISK_ADJ_CAPITAL_FLOOR_PCT': {'value': '0.6', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘å•ä½åä¹‰æœ¬é‡‘ç¼©æ”¾å› å­çš„ä¸‹é™ S_min_cap (ä¾‹å¦‚0.6ä»£è¡¨æœ€å·®æƒ…å†µæŠ•å…¥åŸºå‡†çš„60%)'},
        
            # --- è¿½è¸ªæ­¢ç›ˆå‚æ•° ---
            'trailing_tp_increment_pct': {'value': '0.02', 'group': 'TRAILING_STOP', 'desc': 'è¿½è¸ªæ­¢ç›ˆçš„æ­¥è¿›ç™¾åˆ†æ¯”'},
            'trailing_sl_buffer_pct': {'value': '0.015', 'group': 'TRAILING_STOP', 'desc': 'è¿½è¸ªæ­¢ç›ˆçš„å›æ’¤ç¼“å†²ç™¾åˆ†æ¯”'},
        
        }

        with transaction.atomic():
            for name, data in params_to_define.items():
                StrategyParameters.objects.update_or_create(
                    param_name=name,
                    defaults={
                        'param_value': Decimal(data['value']),
                        'group_name': data['group'],
                        'description': data['desc']
                    }
                )
      
        logger.info(f"æˆåŠŸåˆå§‹åŒ–/æ›´æ–° {len(params_to_define)} ä¸ªåŠ¨æ€é£é™©ç­–ç•¥å‚æ•°ã€‚")

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\decision_order_service_old.py####
# trade_manager/service/decision_order_service.py

import logging
from datetime import date, timedelta
from decimal import Decimal, ROUND_HALF_UP
import pandas as pd
import pandas_ta as ta

from django.db import transaction
from django.utils import timezone

from common.models import (
    DailyTradingPlan,
    Position,
    TradeLog,
    StrategyParameters,
    DailyQuotes,
    SystemLog
)
from .trade_handler import ITradeHandler

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class DecisionOrderService:
    """
    å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—ã€‚

    è¯¥æœåŠ¡è´Ÿè´£åœ¨Tæ—¥å¼€ç›˜åçš„é»„é‡‘æ—¶é—´å†…ï¼Œæ ¹æ®é¢„æ¡ˆã€å®é™…å¼€ç›˜ä»·å’Œè´¦æˆ·çŠ¶æ€ï¼Œ
    åšå‡ºæœ€ç»ˆçš„ä¹°å…¥å†³ç­–ï¼Œå¹¶æ‰§è¡Œä¸‹å•ã€‚åŒæ—¶ï¼Œå®ƒä¹Ÿæä¾›äº†åœ¨è®¢å•æˆäº¤åè®¡ç®—
    æ­¢ç›ˆæ­¢æŸåŒºé—´çš„åŠŸèƒ½ã€‚
    """
    MODULE_NAME = 'å¼€ç›˜å†³ç­–ä¸ä¸‹å•'

    def __init__(self, handler: ITradeHandler, execution_date: date = None):
        """
        åˆå§‹åŒ–æœåŠ¡ã€‚

        :param handler: ä¸€ä¸ªå®ç°äº† ITradeHandler æ¥å£çš„å®ä¾‹ï¼Œç”¨äºä¸äº¤æ˜“ç¯å¢ƒäº¤äº’ã€‚
        :param execution_date: Tæ—¥ï¼Œå³æ‰§è¡Œå†³ç­–çš„æ—¥æœŸã€‚å¦‚æœä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºå½“å¤©ã€‚
                               æ­¤å‚æ•°ä¸ºå›æµ‹æ¨¡å—æä¾›äº†è®¾ç½®æ¨¡æ‹Ÿæ—¥æœŸçš„å…¥å£ã€‚
        """
        if not isinstance(handler, ITradeHandler):
            raise TypeError("ä¼ å…¥çš„ handler å¿…é¡»æ˜¯ ITradeHandler çš„ä¸€ä¸ªå®ä¾‹ã€‚")
        
        self.handler = handler
        self.execution_date = execution_date if execution_date else date.today()
        self.params = self._load_strategy_parameters()
        
        logger.debug(f"[{self.MODULE_NAME}] æœåŠ¡åˆå§‹åŒ–ã€‚æ‰§è¡ŒTæ—¥: {self.execution_date}")
        logger.debug(f"ç­–ç•¥å‚æ•°åŠ è½½æˆåŠŸ: {self.params}")

    def _log_to_db(self, level: str, message: str):
        """è¾…åŠ©æ–¹æ³•ï¼šå°†æ—¥å¿—å†™å…¥æ•°æ®åº“"""
        SystemLog.objects.create(
            log_level=level,
            module_name=self.MODULE_NAME,
            message=message
        )

    def _load_strategy_parameters(self) -> dict:
        """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç­–ç•¥å‚æ•°åˆ°å†…å­˜"""
        params = {}
        # å®šä¹‰éœ€è¦åŠ è½½çš„å‚æ•°åŠå…¶é»˜è®¤å€¼ï¼Œä»¥é˜²æ•°æ®åº“ä¸­æ²¡æœ‰
        required_params = {
            'MAX_POSITIONS': 2,
            'MAX_CAPITAL_PER_POSITION': 25000.00,
            'k_slip': 0.002,
            'Base_Target': 0.07,
            'k_g1': 1.5,
            'Max_Target': 0.20,
            'k_h1': 2.0,
            'k_h2': 3.0,
            'Max_Loss_Percent': 0.08,
            'lookback_atr': 14,
            'lookback_adx': 14,
            'lookback_ma20': 20,
            'param_adx_threshold': 25
        }
        
        db_params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
        
        for key, default_value in required_params.items():
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„å€¼ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
            value = db_params.get(key, Decimal(str(default_value)))
            # å°†éœ€è¦æ•´æ•°çš„å‚æ•°è½¬æ¢ä¸ºint
            if key in ['MAX_POSITIONS', 'lookback_atr', 'lookback_adx', 'lookback_ma20', 'param_adx_threshold']:
                params[key] = int(value)
            else:
                params[key] = Decimal(str(value))
        return params

    # --- æš´éœ²ç»™å¤–éƒ¨è°ƒåº¦çš„æ ¸å¿ƒå‡½æ•° ---

    def adjust_trading_plan_daily(self):
        """
        å‡½æ•°ä¸€ï¼šæ‰§è¡Œæ¯æ—¥äº¤æ˜“é¢„æ¡ˆå†è°ƒæ•´ã€‚
        æ ¹æ®å®é™…å¼€ç›˜ä»·ä¸å‰©ä½™ä»“ä½è¿›è¡ŒäºŒæ¬¡ç­›é€‰ï¼Œå…³é—­ä¸ä¼šè¢«é€‰æ‹©çš„äº¤æ˜“é¢„æ¡ˆã€‚
        """
        logger.debug(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„äº¤æ˜“é¢„æ¡ˆäºŒæ¬¡ç­›é€‰...")
        
        plans_today = DailyTradingPlan.objects.filter(
            plan_date=self.execution_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')

        if not plans_today.exists():
            msg = f"åœ¨ {self.execution_date} æ²¡æœ‰æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.warning(msg)
            self._log_to_db('WARNING', msg)
            return

        plans_to_cancel = []
        for plan in plans_today:
            try:
                open_price = self.handler.get_opening_price(plan.stock_code)
                if open_price <= 0:
                    logger.warning(f"è‚¡ç¥¨ {plan.stock_code} å¼€ç›˜ä»·ä¸º0æˆ–æ— æ•ˆï¼Œè§†ä¸ºä¸ç¬¦åˆæ¡ä»¶ã€‚")
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)
                    continue

                if not (plan.miop <= open_price <= plan.maop):
                    msg = (f"é¢„æ¡ˆ {plan.stock_code} (Rank:{plan.rank}) å¼€ç›˜ä»· {open_price} "
                           f"ä¸åœ¨åŒºé—´ [{plan.miop}, {plan.maop}] å†…ï¼Œå·²ä½œåºŸã€‚")
                    logger.debug(msg)
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)

            except Exception as e:
                msg = f"è·å– {plan.stock_code} å¼€ç›˜ä»·æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œè¯¥é¢„æ¡ˆä½œåºŸã€‚"
                logger.error(msg)
                self._log_to_db('ERROR', msg)
                plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                plans_to_cancel.append(plan)

        if plans_to_cancel:
            with transaction.atomic():
                DailyTradingPlan.objects.bulk_update(plans_to_cancel, ['status'])
            logger.info(f"æˆåŠŸä½œåºŸ {len(plans_to_cancel)} æ¡ä¸ç¬¦åˆå¼€ç›˜æ¡ä»¶çš„äº¤æ˜“é¢„æ¡ˆã€‚")
        else:
            logger.info("æ‰€æœ‰å¾…æ‰§è¡Œé¢„æ¡ˆå‡ç¬¦åˆå¼€ç›˜ä»·æ¡ä»¶ã€‚")

    def execute_orders(self):
        """
        å‡½æ•°äºŒï¼šè¿›è¡Œä¸‹å•ã€‚
        è¯»å–é¢„æ¡ˆè¡¨ï¼Œé€‰æ‹©æœ€ä¼˜æ ‡çš„ï¼Œè®¡ç®—ä»“ä½å’Œä»·æ ¼ï¼Œå¹¶è°ƒç”¨å¤„ç†å™¨æ‰§è¡Œä¸‹å•ã€‚
        """
        logger.info(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„ä¸‹å•æµç¨‹...")

        # 1. æ£€æŸ¥å‰©ä½™ä»“ä½
        open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
        remaining_slots = self.params['MAX_POSITIONS'] - open_positions_count

        if remaining_slots <= 0:
            msg = f"å½“å‰æŒä»“æ•° {open_positions_count} å·²è¾¾ä¸Šé™ {self.params['MAX_POSITIONS']}ï¼Œä»Šæ—¥ä¸è¿›è¡Œä¹°å…¥æ“ä½œã€‚"
            logger.warning(msg)
            self._log_to_db('WARNING', msg)
            return

        #2. è·å–æ‰€æœ‰å¾…å¤„ç†çš„å€™é€‰æ ‡çš„
        candidates = DailyTradingPlan.objects.filter(
            plan_date=self.execution_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')
 
        if not candidates.exists():
            msg = f"åœ¨ {self.execution_date} æ— ç¬¦åˆæ¡ä»¶çš„ä¹°å…¥æ ‡çš„ã€‚"
            logger.info(msg)
            self._log_to_db('INFO', msg)
            return

        # 3. éå†æ‰€æœ‰å€™é€‰æ ‡çš„ï¼Œç›´åˆ°æˆåŠŸä¹°å…¥ä¸€ä¸ª
        for candidate in candidates:
            try:
                stock_code = candidate.stock_code
                open_price = self.handler.get_opening_price(stock_code)
                
                # è®¡ç®—ä¸‹å•é™ä»·
                k_slip = self.params['k_slip']
                limit_price = (open_price * (Decimal('1.0') + k_slip)).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
 
                # è®¡ç®—æœ¬æ¬¡äº¤æ˜“å¯ç”¨èµ„é‡‘
                available_balance = self.handler.get_available_balance()
                capital_per_slot = available_balance / Decimal(remaining_slots)
                nominal_principal = min(capital_per_slot, self.params['MAX_CAPITAL_PER_POSITION'])
 
                # è®¡ç®—è´­å…¥è‚¡æ•°
                if limit_price <= 0:
                    logger.warning(f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„ä¸‹å•é™ä»·æ— æ•ˆï¼ˆ{limit_price}ï¼‰ï¼Œè·³è¿‡ã€‚")
                    continue # å°è¯•ä¸‹ä¸€ä¸ªå€™é€‰
 
                shares_to_buy = int(nominal_principal / limit_price)
                quantity = (shares_to_buy // 100) * 100 # å‘ä¸‹å–æ•´åˆ°100çš„å€æ•°
 
                if quantity < 100:
                    msg = (f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„åä¹‰æœ¬é‡‘ {nominal_principal:.2f} ä¸è¶³ä»¥è´­ä¹°ä¸€æ‰‹ï¼ˆ100è‚¡ï¼‰ï¼Œ"
                           f"æ‰€éœ€é‡‘é¢çº¦ä¸º {limit_price * 100:.2f}ã€‚æ”¾å¼ƒæœ¬æ¬¡äº¤æ˜“ã€‚")
                    logger.warning(msg)
                    self._log_to_db('WARNING', msg)
                    continue # èµ„é‡‘ä¸è¶³ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå€™é€‰
 
                # 4. æ‰§è¡Œä¸‹å•
                msg = (f"ç¡®å®šå”¯ä¸€ä¹°å…¥æ ‡çš„: {stock_code} (Rank:{candidate.rank})ã€‚ "
                       f"è®¡åˆ’ä»¥é™ä»· {limit_price} ä¹°å…¥ {quantity} è‚¡ã€‚")
                logger.info(msg)
                self._log_to_db('INFO', msg)
                
                self.handler.place_buy_order(stock_code, limit_price, quantity)
                
                # æ ‡è®°é¢„æ¡ˆä¸ºå·²æ‰§è¡Œ
                candidate.status = DailyTradingPlan.StatusChoices.EXECUTED
                candidate.save()
 
                # æˆåŠŸä¹°å…¥åï¼Œç«‹å³é€€å‡ºå‡½æ•°ï¼Œå¤–å±‚å¾ªç¯ä¼šå†³å®šæ˜¯å¦ç»§ç»­ä¹°å…¥ä¸‹ä¸€ä¸ªä»“ä½
                return
 
            except Exception as e:
                msg = f"å¤„ç†å€™é€‰è‚¡ {candidate.stock_code} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
                logger.error(msg, exc_info=True)
                self._log_to_db('CRITICAL', msg)
                continue # å‘ç”Ÿå¼‚å¸¸ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªå€™é€‰
 
        # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸï¼Œè¯´æ˜æ‰€æœ‰å€™é€‰è‚¡éƒ½æ— æ³•ä¹°å…¥
        logger.info(f"å·²å°è¯•æ‰€æœ‰ {len(candidates)} ä¸ªå€™é€‰æ ‡çš„ï¼Œå‡æœªæˆåŠŸä¹°å…¥ã€‚")

    def calculate_stop_profit_loss(self, trade_id: int):
        """
        å‡½æ•°ä¸‰ï¼šæ­¢ç›ˆæ­¢æŸåŒºé—´è®¡ç®— (ä¿®æ­£ç‰ˆ)ã€‚
        åœ¨è®¢å•æˆäº¤åï¼Œä¸ºæ–°æŒä»“è®¡ç®—å¹¶æ›´æ–°åˆå§‹çš„æ­¢ç›ˆæ­¢æŸä»·ã€‚
 
        :param trade_id: å·²æˆäº¤çš„ä¹°å…¥äº¤æ˜“åœ¨ tb_trade_log ä¸­çš„å”¯ä¸€IDã€‚
        """
        logger.info(f"å¼€å§‹ä¸º trade_id={trade_id} è®¡ç®—æ­¢ç›ˆæ­¢æŸåŒºé—´...")
        try:
            with transaction.atomic():
                # 1. è·å–äº¤æ˜“å’ŒæŒä»“ä¿¡æ¯
                trade_log = TradeLog.objects.select_for_update().get(
                    trade_id=trade_id,
                    trade_type=TradeLog.TradeTypeChoices.BUY,
                    status=TradeLog.StatusChoices.FILLED
                )
                position = Position.objects.select_for_update().get(pk=trade_log.position_id)
 
                if position.current_stop_loss > 0:
                    logger.warning(f"Position ID {position.position_id} ä¼¼ä¹å·²è®¡ç®—è¿‡æ­¢ç›ˆæ­¢æŸï¼Œå°†è·³è¿‡ã€‚")
                    return
 
                stock_code = trade_log.stock_code_id
                aep = trade_log.price
                buy_date = trade_log.trade_datetime.date()
                
                # 2. è·å–è®¡ç®—æ‰€éœ€è¡Œæƒ…æ•°æ® (é¿å…æœªæ¥å‡½æ•°)
                lookback_days = self.params['lookback_adx'] + 50
                start_date_for_calc = buy_date - timedelta(days=lookback_days * 2)
                end_date_for_calc = buy_date - timedelta(days=1)
 
                quotes_qs = DailyQuotes.objects.filter(
                    stock_code_id=stock_code,
                    trade_date__gte=start_date_for_calc,
                    trade_date__lte=end_date_for_calc
                ).order_by('trade_date')
 
                if len(quotes_qs) < max(self.params['lookback_atr'], self.params['lookback_adx'], self.params['lookback_ma20']):
                    raise ValueError(f"è‚¡ç¥¨ {stock_code} åœ¨ {end_date_for_calc} å‰çš„å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡ã€‚")
 
                df = pd.DataFrame.from_records(quotes_qs.values('high', 'low', 'close'))
                df = df.astype(float)
 
                # 3. è®¡ç®—æ‰€æœ‰å¿…éœ€æŒ‡æ ‡
                atr_series = ta.atr(df['high'], df['low'], df['close'], length=self.params['lookback_atr'])
                atr_14_buy = Decimal(str(atr_series.iloc[-1]))
 
                ma20_series = ta.sma(df['close'], length=self.params['lookback_ma20'])
                ma20_buy = Decimal(str(ma20_series.iloc[-1]))
 
                adx_df = ta.adx(df['high'], df['low'], df['close'], length=self.params['lookback_adx'])
                adx_14_buy = Decimal(str(adx_df[f'ADX_{self.params["lookback_adx"]}'].iloc[-1]))
 
                # 4. è®¡ç®—æ­¢ç›ˆä»· g(y) - é€»è¾‘ä¸å˜
                profit_margin = min(
                    self.params['Base_Target'] + self.params['k_g1'] * (atr_14_buy / aep),
                    self.params['Max_Target']
                )
                take_profit_price = aep * (Decimal('1.0') + profit_margin)
 
                # 5. è®¡ç®—æ­¢æŸä»· h(z) - ä¸¥æ ¼æŒ‰ç…§éœ€æ±‚æ–‡æ¡£é€»è¾‘
                # 5.1 æ ¹æ®ADXåˆ¤æ–­å¸‚åœºçŠ¶æ€ï¼Œé€‰æ‹©z_final
                adx_threshold = self.params['param_adx_threshold']
                if adx_14_buy > adx_threshold:
                    # è¶‹åŠ¿çŠ¶æ€ï¼Œä½¿ç”¨è¾ƒçª„çš„ATRä¹˜æ•°
                    z_final = aep - self.params['k_h1'] * atr_14_buy
                else:
                    # éœ‡è¡çŠ¶æ€ï¼Œä½¿ç”¨è¾ƒå®½çš„ATRä¹˜æ•°
                    z_final = aep - self.params['k_h2'] * atr_14_buy
 
                # 5.2 è®¡ç®—å…¶ä»–æ­¢æŸçº¿
                z2_technical = ma20_buy
                z3_max_loss = aep * (Decimal('1.0') - self.params['Max_Loss_Percent'])
                
                # 5.3 å–æœ€ä¸¥æ ¼çš„æ­¢æŸä½ï¼ˆä»·æ ¼æœ€é«˜è€…ï¼‰
                stop_loss_price = max(z_final, z2_technical, z3_max_loss)
                
                logger.info(f"[{stock_code}] æ­¢æŸçº¿æ¯”è¾ƒ: è¶‹åŠ¿ä½={z_final:.2f}, æŠ€æœ¯ä½={z2_technical:.2f}, åº•çº¿={z3_max_loss:.2f}")
 
                # 6. æ›´æ–°æŒä»“ä¿¡æ¯è¡¨
                position.current_take_profit = take_profit_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                position.current_stop_loss = stop_loss_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                position.save(update_fields=['current_take_profit', 'current_stop_loss'])
 
                msg = (f"æˆåŠŸè®¡ç®—å¹¶æ›´æ–° Position ID {position.position_id} ({stock_code}) çš„é£æ§ä»·æ ¼: "
                       f"è´­å…¥ä»·={aep}, æ­¢ç›ˆä»·={position.current_take_profit}, æ­¢ç›ˆç‡={((Decimal('1.0') + profit_margin)*100):.2f}%, æ­¢æŸä»·={position.current_stop_loss}, æ­¢æŸç‡={((position.current_stop_loss/aep)*100):.2f}%")
                logger.info(msg)
                self._log_to_db('INFO', msg)
 
        except TradeLog.DoesNotExist:
            logger.error(f"Trade ID {trade_id} ä¸å­˜åœ¨æˆ–ä¸æ»¡è¶³è®¡ç®—æ¡ä»¶ï¼ˆéä¹°å…¥/æœªæˆäº¤ï¼‰ã€‚")
        except Position.DoesNotExist:
            logger.error(f"ä¸ Trade ID {trade_id} å…³è”çš„ Position ä¸å­˜åœ¨ã€‚")
        except Exception as e:
            msg = f"ä¸º Trade ID {trade_id} è®¡ç®—æ­¢ç›ˆæ­¢æŸæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"

    # --- å·¥å…·å‡½æ•° ---

    @staticmethod
    def initialize_strategy_parameters():
        """
        å·¥å…·å‡½æ•°ï¼šåˆå§‹åŒ–æœ¬æ¨¡å—æ‰€éœ€çš„ç­–ç•¥å‚æ•°åˆ°æ•°æ®åº“ã€‚
        è¿™æ˜¯ä¸€ä¸ªå¹‚ç­‰æ“ä½œï¼Œå¯ä»¥å®‰å…¨åœ°é‡å¤è¿è¡Œã€‚
        """
        logger.info("å¼€å§‹åˆå§‹åŒ–[å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—]çš„ç­–ç•¥å‚æ•°...")

        params_to_define = {
            # ä»“ä½ç®¡ç†
            'MAX_POSITIONS': {'value': '2', 'group': 'POSITION_MGMT', 'desc': 'æœ€å¤§å¯å…·å¤‡çš„æ€»ä»“ä½æ•°'},
            'MAX_CAPITAL_PER_POSITION': {'value': '25000.00', 'group': 'POSITION_MGMT', 'desc': 'æ¯ä»“æœ€å¤§æŠ•å…¥èµ„é‡‘æ•°(å…ƒ)'},
            # ä¸‹å•å‚æ•°
            'k_slip': {'value': '0.002', 'group': 'ORDER_EXEC', 'desc': 'ä¸‹å•æ»‘ç‚¹ç³»æ•°, ç”¨äºè®¡ç®—é™ä»·å•ä»·æ ¼'},
            # æ­¢ç›ˆå‚æ•° g(y)
            'Base_Target': {'value': '0.07', 'group': 'TAKE_PROFIT', 'desc': 'åŸºç¡€æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯”'},
            'k_g1': {'value': '1.5', 'group': 'TAKE_PROFIT', 'desc': 'ATRæº¢ä»·ä¹˜æ•°, ç”¨äºåŠ¨æ€è°ƒæ•´æ­¢ç›ˆç›®æ ‡'},
            'Max_Target': {'value': '0.20', 'group': 'TAKE_PROFIT', 'desc': 'æœ€å¤§æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯”ä¸Šé™'},
            # æ­¢æŸå‚æ•° h(z)
            'k_h1': {'value': '2.0', 'group': 'STOP_LOSS', 'desc': 'è¶‹åŠ¿å¸‚ATRæ­¢æŸä¹˜æ•° (ç›˜ä¸­åŠ¨æ€ä½¿ç”¨)'},
            'k_h2': {'value': '3.0', 'group': 'STOP_LOSS', 'desc': 'éœ‡è¡å¸‚ATRæ­¢æŸä¹˜æ•° (ç”¨äºè®¡ç®—åˆå§‹æ­¢æŸ)'},
            'Max_Loss_Percent': {'value': '0.08', 'group': 'STOP_LOSS', 'desc': 'æœ€å¤§å›æ’¤å®¹å¿åº¦(ç»å¯¹äºæŸç™¾åˆ†æ¯”ä¸Šé™)'},
            # æŒ‡æ ‡å‘¨æœŸ
            'lookback_atr': {'value': '14', 'group': 'INDICATORS', 'desc': 'ATRè®¡ç®—å‘¨æœŸ'},
            'lookback_adx': {'value': '14', 'group': 'INDICATORS', 'desc': 'ADXè®¡ç®—å‘¨æœŸ'},
            'lookback_ma20': {'value': '20', 'group': 'INDICATORS', 'desc': 'MA20è®¡ç®—å‘¨æœŸ'},
        }

        with transaction.atomic():
            for name, data in params_to_define.items():
                StrategyParameters.objects.update_or_create(
                    param_name=name,
                    defaults={
                        'param_value': Decimal(data['value']),
                        'group_name': data['group'],
                        'description': data['desc']
                    }
                )
        
        logger.info(f"æˆåŠŸåˆå§‹åŒ–/æ›´æ–° {len(params_to_define)} ä¸ªç­–ç•¥å‚æ•°ã€‚")


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\m_distribution_backtest_service.py####
# trade_manager/service/m_distribution_backtest_service.py (æ›¿æ¢å…¨éƒ¨å†…å®¹)

import logging
from datetime import date, timedelta, datetime
from decimal import Decimal

import pandas as pd
from django.db import connections, transaction
from django.core.management import call_command
from django.utils import timezone

from common.models import (
    DailyQuotes, StockInfo, CorporateAction, FactorDefinitions, StrategyParameters,
    DailyFactorValues, IndexQuotesCsi300, Position, TradeLog, DailyTradingPlan
)
from common.models.backtest_logs import MDistributionBacktestLog
from selection_manager.service.selection_service import SelectionService
from trade_manager.service.decision_order_service import DecisionOrderService
from .db_utils import use_backtest_schema
from .m_distribution_reporter import MDistributionReporter
from trade_manager.service.simulate_trade import SimulateTradeService
from trade_manager.service.simulate_trade_handler import SimulateTradeHandler
from .position_monitor_logic import PositionMonitorLogic
from common.models import Position
logger = logging.getLogger(__name__)
STRATEGIES = ['MT', 'BO', 'QD', 'MR','OLD']
class MDistributionBacktestService:
    """
    Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æœåŠ¡ (V2 - ä¿®æ­£ç‰ˆ)ã€‚
    
    æ ¸å¿ƒæµç¨‹:
    1. åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“schemaè¿›è¡Œå›æµ‹ï¼Œä¸ä¸»ç¯å¢ƒéš”ç¦»ã€‚
    2. æŒ‰å¤©å¾ªç¯ï¼Œæ¯å¤©è¿è¡ŒSelectionServiceç”Ÿæˆå¹¶ä¿å­˜äº¤æ˜“é¢„æ¡ˆï¼ˆåŒ…å«ç­–ç•¥DNAï¼‰ã€‚
    3. ä»æ•°æ®åº“è¯»å–é¢„æ¡ˆï¼Œå¯¹æ¯ä¸ªé¢„æ¡ˆè¿›è¡Œâ€œå‰å‘è¿½æº¯â€ã€‚
    4. å°†æ¯æ¬¡æ¨¡æ‹Ÿäº¤æ˜“çš„ç»“æœè®°å½•åˆ°ä¸“ç”¨çš„æ—¥å¿—è¡¨ä¸­ã€‚
    5. å›æµ‹ç»“æŸåï¼Œè°ƒç”¨æŠ¥å‘Šæ¨¡å—ç”Ÿæˆåˆ†ææŠ¥å‘Šã€‚
    """
    
    def __init__(self, start_date: str, end_date: str, single_strategy_mode: bool = False):
        self.start_date = date.fromisoformat(start_date)
        self.end_date = date.fromisoformat(end_date)
        self.backtest_run_id = f"m_dist_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.max_holding_days = 90
        self.single_strategy_mode = single_strategy_mode
        self.params = {}
    def _get_next_trading_day(self, from_date: date) -> date | None: return (DailyQuotes.objects .filter(trade_date__gte=from_date) .order_by('trade_date') .values_list('trade_date', flat=True) .first())

    def _simulate_intraday_monitoring(self, position_dict: dict, daily_quote: dict) -> tuple[str, Decimal, Decimal, Decimal]:
        """
        [é‡å†™] å¯¹å•ä¸ªæŒä»“åœ¨ä¸€å¤©å†…è¿›è¡Œé«˜ä¿çœŸç›‘æ§æ¨¡æ‹Ÿã€‚
        æ­¤å‡½æ•°ç°åœ¨å®Œå…¨å¤ç”¨ PositionMonitorLogic çš„é€»è¾‘ã€‚
        """
        open_p, high_p, low_p = daily_quote['open'], daily_quote['high'], daily_quote['low']
        
        # åˆå§‹åŒ–ä¸´æ—¶çš„ã€å†…å­˜ä¸­çš„æŒä»“çŠ¶æ€
        temp_sl = position_dict['current_stop_loss']
        temp_tp = position_dict['current_take_profit']
        
        # 1. å¼€ç›˜ä»·æ£€æŸ¥ (é»‘å¤©é¹…äº‹ä»¶)
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ã€ä¸è½è¡¨çš„Positionå¯¹è±¡ä»¥é€‚é…æ¥å£
        temp_position_obj = Position(
            entry_price=position_dict['entry_price'],
            current_stop_loss=temp_sl,
            current_take_profit=temp_tp
        )
        decision_open = PositionMonitorLogic.check_and_decide(temp_position_obj, open_p, self.params)
        
        if decision_open['action'] == 'SELL':
            # å¼€ç›˜ä»·ç›´æ¥è§¦å‘å–å‡ºï¼Œä»¥å¼€ç›˜ä»·æˆäº¤
            exit_price = min(open_p, decision_open['exit_price']) # å–æ›´ä¸åˆ©çš„ä»·æ ¼
            logger.debug(f"    -> ç›‘æ§: å¼€ç›˜ä»· {open_p:.2f} è§¦å‘å–å‡ºï¼Œæˆäº¤ä»· {exit_price:.2f}")
            return 'SOLD', exit_price, temp_sl, temp_tp
        elif decision_open['action'] == 'UPDATE':
            # å¼€ç›˜ä»·è§¦å‘äº†é£æ§çº¿æ›´æ–°
            temp_sl = decision_open['updates'].get('current_stop_loss', temp_sl)
            temp_tp = decision_open['updates'].get('current_take_profit', temp_tp)
            logger.debug(f"    -> ç›‘æ§: å¼€ç›˜ä»·æ›´æ–°é£æ§çº¿. SL: {temp_sl:.2f}, TP: {temp_tp:.2f}")
        # 2. æ—¥å†…å¾ªç¯è¯•æ¢ (æœ€ä½ä»· -> æœ€é«˜ä»·)
        while True:
            action_taken_in_loop = False
            
            # 2.1 è¯•æ¢æœ€ä½ä»·æ˜¯å¦è§¦å‘å–å‡º
            temp_position_obj.current_stop_loss = temp_sl
            temp_position_obj.current_take_profit = temp_tp
            decision_low = PositionMonitorLogic.check_and_decide(temp_position_obj, low_p, self.params)
            
            if decision_low['action'] == 'SELL':
                # æœ€ä½ä»·è§¦å‘å–å‡ºï¼Œä»¥æ­¢æŸä»·æˆäº¤
                logger.debug(f"    -> ç›‘æ§: æœ€ä½ä»· {low_p:.2f} è§¦å‘å–å‡ºï¼Œæˆäº¤ä»· {decision_low['exit_price']:.2f}")
                return 'SOLD', decision_low['exit_price'], temp_sl, temp_tp
            # 2.2 è¯•æ¢æœ€é«˜ä»·æ˜¯å¦è§¦å‘æ›´æ–°
            decision_high = PositionMonitorLogic.check_and_decide(temp_position_obj, high_p, self.params)
            
            if decision_high['action'] == 'UPDATE':
                new_sl = decision_high['updates'].get('current_stop_loss', temp_sl)
                new_tp = decision_high['updates'].get('current_take_profit', temp_tp)
                
                # åªæœ‰å½“é£æ§çº¿å®é™…å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ‰è®¤ä¸ºæœ‰åŠ¨ä½œå‘ç”Ÿ
                if new_sl != temp_sl or new_tp != temp_tp:
                    logger.debug(f"    -> ç›‘æ§: æœ€é«˜ä»· {high_p:.2f} è§¦å‘é£æ§çº¿æ›´æ–°. SL: {new_sl:.2f}, TP: {new_tp:.2f}")
                    temp_sl, temp_tp = new_sl, new_tp
                    action_taken_in_loop = True
            # å¦‚æœæœ¬è½®å¾ªç¯æ²¡æœ‰æ›´æ–°ä»»ä½•é£æ§çº¿ï¼Œåˆ™è¯´æ˜ä»·æ ¼æ³¢åŠ¨å·²ç¨³å®šåœ¨å½“å‰é£æ§åŒºé—´å†…ï¼Œå¯ä»¥è·³å‡ºå¾ªç¯
            if not action_taken_in_loop:
                break
        
        # 3. å¦‚æœæœªè§¦å‘å–å‡ºï¼Œåˆ™è¿”å›æŒæœ‰çŠ¶æ€å’Œæœ€ç»ˆæ›´æ–°çš„é£æ§çº¿
        return 'HOLD', Decimal('0.0'), temp_sl, temp_tp
    
    def _setup_backtest_schema(self):
        """
        ã€æœ€ç»ˆä¿®æ­£ç‰ˆã€‘åœ¨ Schema ä¸­å‡†å¤‡å›æµ‹ç¯å¢ƒï¼Œå¹¶é›†æˆç´¢å¼•/çº¦æŸä¼˜åŒ–é€»è¾‘ã€‚
        """
        logger.info(f"--- 1. åœ¨ Schema '{self.backtest_run_id}' ä¸­å‡†å¤‡å›æµ‹ç¯å¢ƒ (é›†æˆç´¢å¼•ä¼˜åŒ–) ---")
        
        with connections['default'].cursor() as cursor:
            cursor.execute(f'CREATE SCHEMA IF NOT EXISTS "{self.backtest_run_id}";')
            cursor.execute(f'SET search_path TO "{self.backtest_run_id}";')
            call_command('migrate')
        logger.info("è¡¨ç»“æ„åˆ›å»ºå®Œæˆã€‚")
        tables_to_copy = [
            StockInfo, DailyQuotes, CorporateAction, FactorDefinitions,
            StrategyParameters, DailyFactorValues, IndexQuotesCsi300
        ]
        
        logger.info(f"å‡†å¤‡ä» 'public' schema å¤åˆ¶åŸºç¡€æ•°æ®åˆ° '{self.backtest_run_id}'...")
        with transaction.atomic(), connections['default'].cursor() as cursor:
            # ç¡®ä¿åç»­æ“ä½œéƒ½åœ¨æ–°schemaä¸‹
            cursor.execute(f'SET search_path TO "{self.backtest_run_id}";')
            
            for model in tables_to_copy:
                table_name = model._meta.db_table
                logger.info(f"  - æ­£åœ¨å¤„ç†è¡¨: {table_name}")
                
                # =========================================================================
                # 1. è·å–å¹¶æš‚å­˜ç´¢å¼•å’Œçº¦æŸçš„å®šä¹‰
                # =========================================================================
                # 1a. è·å–æ™®é€šç´¢å¼• (ä¸åŒ…æ‹¬ç”±UNIQUEæˆ–PRIMARY KEYçº¦æŸåˆ›å»ºçš„ç´¢å¼•)
                cursor.execute("""
                    SELECT indexdef
                    FROM pg_indexes
                    WHERE schemaname = %s AND tablename = %s
                    AND indexname NOT IN (
                        SELECT conname FROM pg_constraint WHERE conrelid = %s::regclass
                    );
                """, [self.backtest_run_id, table_name, f'"{self.backtest_run_id}"."{table_name}"'])
                plain_indexes_to_recreate = [row[0] for row in cursor.fetchall()]
                # 1b. è·å–çº¦æŸ (å¤–é”®ã€å”¯ä¸€ã€ä¸»é”®ç­‰)
                cursor.execute("""
                    SELECT 'ALTER TABLE ' || quote_ident(conrelid::regclass::text) || ' ADD CONSTRAINT ' || quote_ident(conname) || ' ' || pg_get_constraintdef(oid)
                    FROM pg_constraint
                    WHERE conrelid = %s::regclass;
                """, [f'"{self.backtest_run_id}"."{table_name}"'])
                constraints_to_recreate = [row[0] for row in cursor.fetchall()]
                
                # =========================================================================
                # 2. åˆ é™¤æ‰€æœ‰çº¦æŸå’Œç´¢å¼•ä»¥æå¤§åœ°åŠ é€Ÿæ•°æ®æ’å…¥
                # =========================================================================
                for const_def in constraints_to_recreate:
                    const_name = const_def.split('ADD CONSTRAINT ')[1].split(' ')[0]
                    logger.debug(f"      - åˆ é™¤çº¦æŸ: {const_name}")
                    cursor.execute(f'ALTER TABLE "{table_name}" DROP CONSTRAINT IF EXISTS {const_name} CASCADE;')
                for index_def in plain_indexes_to_recreate:
                    try:
                        index_name = index_def.split(' ')[2]
                        logger.debug(f"      - åˆ é™¤ç´¢å¼•: {index_name}")
                        cursor.execute(f'DROP INDEX IF EXISTS "{index_name}";')
                    except IndexError:
                        logger.warning(f"æ— æ³•ä» '{index_def}' è§£æç´¢å¼•åç§°ï¼Œè·³è¿‡åˆ é™¤ã€‚")
                # =========================================================================
                # 3. é«˜æ•ˆå¤åˆ¶æ•°æ®
                # =========================================================================
                logger.info(f"    - æ­£åœ¨ä» public.{table_name} å¤åˆ¶æ•°æ®...")
                sql = f'INSERT INTO "{table_name}" SELECT * FROM public."{table_name}";'
                cursor.execute(sql)
                logger.info(f"    - æ•°æ®å¤åˆ¶å®Œæˆã€‚")
                # =========================================================================
                # 4. é‡å»ºç´¢å¼•å’Œçº¦æŸ
                # =========================================================================
                logger.info(f"    - æ­£åœ¨é‡å»º '{table_name}' çš„ç´¢å¼•å’Œçº¦æŸ...")
                # 4a. é‡å»ºæ™®é€šç´¢å¼•
                for index_def in plain_indexes_to_recreate:
                    logger.debug(f"      - é‡å»ºç´¢å¼•: {index_def}")
                    cursor.execute(index_def)
                
                # 4b. é‡å»ºçº¦æŸ (è¿™ä¼šè‡ªåŠ¨é‡å»ºå®ƒä»¬çš„åº•å±‚ç´¢å¼•)
                #     æ³¨æ„ï¼šä¸»é”®çº¦æŸå¿…é¡»æœ€å…ˆé‡å»º
                constraints_to_recreate.sort(key=lambda x: 'PRIMARY KEY' not in x)
                for const_def in constraints_to_recreate:
                    logger.debug(f"      - é‡å»ºçº¦æŸ: {const_def}")
                    cursor.execute(const_def)
                # =========================================================================
                # 5. é‡ç½®è‡ªå¢ä¸»é”®åºåˆ— (å¦‚æœå­˜åœ¨)
                # =========================================================================
                find_serial_sql = """
                    SELECT a.attname, pg_get_serial_sequence(quote_ident(n.nspname) || '.' || quote_ident(c.relname), a.attname)
                    FROM pg_class c
                    JOIN pg_attribute a ON a.attrelid = c.oid
                    JOIN pg_namespace n ON c.relnamespace = n.oid
                    WHERE n.nspname = %s AND c.relname = %s AND a.attnum > 0 AND NOT a.attisdropped
                    AND pg_get_serial_sequence(quote_ident(n.nspname) || '.' || quote_ident(c.relname), a.attname) IS NOT NULL;
                """
                cursor.execute(find_serial_sql, [self.backtest_run_id, table_name])
                serial_columns = cursor.fetchall()
                for column_name, sequence_name in serial_columns:
                    if sequence_name:
                        logger.info(f"    - å‘ç°è‡ªå¢åˆ— '{column_name}'ï¼Œæ­£åœ¨é‡ç½®å…¶åºåˆ— '{sequence_name}'...")
                        update_sequence_sql = f"""
                            SELECT setval('{sequence_name}', COALESCE((SELECT MAX("{column_name}") FROM "{table_name}"), 0) + 1, false);
                        """
                        cursor.execute(update_sequence_sql)
        
        logger.info("åŸºç¡€æ•°æ®å¤åˆ¶å®Œæˆï¼Œå¹¶å·²å®Œæˆç´¢å¼•ä¼˜åŒ–ã€‚")
    def _load_parameters(self):
        """
        [æ–°å¢] åœ¨å›æµ‹å¼€å§‹å‰åŠ è½½æ‰€æœ‰éœ€è¦çš„ç­–ç•¥å‚æ•°ã€‚
        å‚è€ƒ simulate_trade.py çš„å®ç°ã€‚
        """
        logger.info("åŠ è½½å›æµ‹æ‰€éœ€ç­–ç•¥å‚æ•°...")
        # ä» StrategyParameters è¡¨ä¸­ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å‚æ•°
        all_params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
        
        # å®šä¹‰ PositionMonitorLogic ä¸­å¯èƒ½ç”¨åˆ°çš„å‚æ•°åŠå…¶é»˜è®¤å€¼
        required_params = {
            'trailing_tp_increment_pct': '0.02',
            'trailing_sl_buffer_pct': '0.015',
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–æœªæ¥å¯èƒ½ç”¨åˆ°çš„å‚æ•°
        }
        for key, default_value in required_params.items():
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“çš„å€¼ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
            self.params[key] = all_params.get(key, Decimal(default_value))
        
        logger.info(f"ç­–ç•¥å‚æ•°åŠ è½½å®Œæˆ: {self.params}")
    def run(self):
        try:
            with use_backtest_schema(self.backtest_run_id):
                self._setup_backtest_schema()
                self._load_parameters()
                trading_days = list(DailyQuotes.objects.filter(
                    trade_date__gte=self.start_date,
                    trade_date__lte=self.end_date
                ).values_list('trade_date', flat=True).distinct().order_by('trade_date'))
                # --- [ä¿®æ­£ç‰ˆ] ä½å†…å­˜æ»šåŠ¨çª—å£æ•°æ®åŠ è½½é€»è¾‘ ---
                logger.info("--- [æ»šåŠ¨çª—å£] å¼€å§‹å‡†å¤‡æ•°æ® ---")
                lookback_window_size = 250
                extra_buffer_days = 20
                
                preload_start_date = trading_days[0] - timedelta(days=lookback_window_size + extra_buffer_days)
                
                logger.info(f"ä¸€æ¬¡æ€§æŸ¥è¯¢æ•°æ®åº“ï¼Œæ—¶é—´çª—å£: {preload_start_date} to {self.end_date}")
                
                quotes_iterator = DailyQuotes.objects.filter(
                    trade_date__gte=preload_start_date,
                    trade_date__lte=self.end_date
                ).order_by('trade_date', 'stock_code_id').values(
                    'trade_date', 'stock_code_id', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close'
                ).iterator(chunk_size=20000)
                quotes_by_date = {}
                for row in quotes_iterator:
                    trade_date = row['trade_date']
                    if trade_date not in quotes_by_date:
                        quotes_by_date[trade_date] = []
                    quotes_by_date[trade_date].append(row)
                
                logger.info("åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ»šåŠ¨çª—å£é¢æ¿...")
                all_loaded_dates = sorted(quotes_by_date.keys())
                first_backtest_day = trading_days[0]
                initial_window_dates = [d for d in all_loaded_dates if d <= first_backtest_day]
                initial_rows = [row for d in initial_window_dates for row in quotes_by_date.get(d, [])]
                
                if not initial_rows:
                    raise ValueError("åˆå§‹åŒ–æ»šåŠ¨çª—å£å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®ã€‚")
                df_window = pd.DataFrame(initial_rows)
                df_window['trade_date'] = pd.to_datetime(df_window['trade_date'])
                
                rolling_panels = {}
                for col in ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']:
                    panel = df_window.pivot(index='trade_date', columns='stock_code_id', values=col).astype(float)
                    rolling_panels[col] = panel
                
                logger.info(f"æ»šåŠ¨çª—å£åˆå§‹åŒ–å®Œæˆã€‚")
                logger.info(f"--- 2. å¼€å§‹æ—¥åº¦å›æµ‹å¾ªç¯ ({len(trading_days)}å¤©) ---")
                last_sent_month = None
                for i, t_minus_1 in enumerate(trading_days):
                    logger.info(f"\n{'='*20} æ¨¡æ‹Ÿé¢„æ¡ˆæ—¥: {t_minus_1} ({i+1}/{len(trading_days)}) {'='*20}")
                    if i > 0:
                        new_day_data = quotes_by_date.get(t_minus_1)
                        if new_day_data:
                            logger.debug(f"æ»šåŠ¨çª—å£: ç§»é™¤ {rolling_panels['close'].index[0].date()}, æ·»åŠ  {t_minus_1}")
                            for key in rolling_panels:
                                rolling_panels[key] = rolling_panels[key].iloc[1:]
                            
                            df_new_day = pd.DataFrame(new_day_data)
                            df_new_day['trade_date'] = pd.to_datetime(df_new_day['trade_date'])
                            for col in ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']:
                                new_row = df_new_day.pivot(index='trade_date', columns='stock_code_id', values=col).astype(float)
                                rolling_panels[col] = pd.concat([rolling_panels[col], new_row])
                        else:
                            logger.warning(f"æ—¥æœŸ {t_minus_1} åœ¨é¢„åŠ è½½æ•°æ®ä¸­ä¸å­˜åœ¨ï¼Œçª—å£æœªæ»šåŠ¨ã€‚")
                    # 1. è¿è¡Œæ ‡å‡†çš„MåŠ¨æ€ç­–ç•¥
                    logger.info(f"  Running M-Dynamic Strategy for {t_minus_1}...")
                    selection_service_dynamic = SelectionService(trade_date=t_minus_1, mode='backtest', one_strategy=None,preloaded_panels=rolling_panels)
                    selection_service_dynamic.run_selection()
                    plan_date_for_t = t_minus_1 + timedelta(days=1)
                    plans_dynamic = DailyTradingPlan.objects.filter(plan_date=plan_date_for_t)
                    if not plans_dynamic.exists():
                        logger.info(f"    åœ¨MåŠ¨æ€ç­–ç•¥ä¸‹æœªç”Ÿæˆä»»ä½•äº¤æ˜“é¢„æ¡ˆã€‚")
                    else:
                        for plan in plans_dynamic:
                            self._trace_forward_and_log(t_minus_1, plan, selection_service_dynamic.market_regime_M, one_stratage_mode=None)
                    # 2. å¦‚æœå¼€å¯äº†å•ç­–ç•¥æ¨¡å¼ï¼Œåˆ™å¾ªç¯è¿è¡Œ
                    if self.single_strategy_mode:
                        for strategy_name in STRATEGIES:
                            logger.info(f"  Running Single Strategy '{strategy_name}' for {t_minus_1}...")
                            selection_service_single = SelectionService(trade_date=t_minus_1, mode='backtest', one_strategy=strategy_name,preloaded_panels=rolling_panels)
                            selection_service_single.run_selection()
                            
                            # æ³¨æ„ï¼šrun_selectionä¼šè¦†ç›–æ—§é¢„æ¡ˆï¼Œæ‰€ä»¥éœ€è¦é‡æ–°æŸ¥è¯¢
                            plans_single = DailyTradingPlan.objects.filter(plan_date=plan_date_for_t)
                            if not plans_single.exists():
                                logger.info(f"    åœ¨å•ç­–ç•¥ {strategy_name} ä¸‹æœªç”Ÿæˆä»»ä½•äº¤æ˜“é¢„æ¡ˆã€‚")
                                continue
                            
                            for plan in plans_single:
                                self._trace_forward_and_log(t_minus_1, plan, selection_service_single.market_regime_M, one_stratage_mode=strategy_name)
                    # --- é‚®ä»¶å‘é€é€»è¾‘ ---
                    is_last_day = (i == len(trading_days) - 1)
                    current_month = t_minus_1.month
                    send_mail_flag = False

                    if is_last_day:
                        send_mail_flag = True
                        logger.info("å›æµ‹ç»“æŸï¼Œè§¦å‘æœ€ç»ˆé‚®ä»¶æŠ¥å‘Šã€‚")
                    elif last_sent_month is not None and current_month != last_sent_month:
                        send_mail_flag = True
                        logger.info(f"æœˆä»½ä» {last_sent_month} å˜ä¸º {current_month}ï¼Œè§¦å‘æœˆåº¦é‚®ä»¶æŠ¥å‘Šã€‚")
                    
                    if send_mail_flag:
                        reporter = MDistributionReporter(self.backtest_run_id,f"{self.start_date}è‡³{t_minus_1}")
                        reporter.generate_and_send_report()
                    
                    last_sent_month = current_month
                    # --- é‚®ä»¶å‘é€é€»è¾‘ç»“æŸ ---


        except Exception as e:
            logger.critical(f"Må€¼åˆ†å¸ƒå›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        finally:
            # æ¸…ç†schemaï¼ˆå¯ä»¥æš‚æ—¶æ³¨é‡Šæ‰ä»¥ä¾¿è°ƒè¯•ï¼‰
            # with connections['default'].cursor() as cursor:
            #     cursor.execute(f'DROP SCHEMA IF EXISTS "{self.backtest_run_id}" CASCADE;')
            # logger.info(f"å·²æ¸…ç†å›æµ‹ç¯å¢ƒ Schema: {self.backtest_run_id}")
            pass

    def _trace_forward_and_log(self, t_minus_1: date, plan_obj: DailyTradingPlan, m_value: float, one_stratage_mode: str = None):
        """å¯¹å•ä¸ªé¢„æ¡ˆ (æ•°æ®åº“å¯¹è±¡) è¿›è¡Œå‰å‘è¿½æº¯å¹¶è®°å½•ç»“æœ"""
        stock_code = plan_obj.stock_code_id
        logger.debug(f"  -> å¼€å§‹è¿½æº¯è‚¡ç¥¨: {stock_code}")
        actual_entry_date = self._get_next_trading_day(plan_obj.plan_date)
        if not actual_entry_date:
            logger.warning(f"    ä» {plan_obj.plan_date} èµ·æœªæ‰¾åˆ°åç»­äº¤æ˜“æ—¥ï¼Œè·³è¿‡ {stock_code}ã€‚")
            return
        try:
            entry_day_quote = DailyQuotes.objects.get(stock_code_id=stock_code, trade_date=actual_entry_date)
            entry_date = actual_entry_date
            entry_price = entry_day_quote.open
        except DailyQuotes.DoesNotExist:
            logger.warning(f"    æ— æ³•åœ¨ {actual_entry_date} æ‰¾åˆ° {stock_code} çš„è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡ã€‚")
            return
        try:
            if entry_price<plan_obj.miop or entry_price>plan_obj.maop:
                logger.debug(f"{stock_code}è¯¥è‚¡ç¥¨ä¸åœ¨å¼€ç›˜åŒºé—´è·³è¿‡æ­¤è‚¡ç¥¨ã€‚")
                return
            tp_price, sl_price, tp_rate, sl_rate = self._get_simulated_stop_profit_loss(stock_code, entry_date, entry_price)
        except ValueError as e:
            logger.warning(f"    æ— æ³•ä¸º {stock_code} è®¡ç®—æ­¢ç›ˆæ­¢æŸ: {e}ï¼Œè·³è¿‡æ­¤è‚¡ç¥¨ã€‚")
            return
        # åˆå§‹åŒ–å†…å­˜ä¸­çš„æŒä»“çŠ¶æ€
        position_state = {
            'entry_price': entry_price,
            'current_stop_loss': sl_price,
            'current_take_profit': tp_price,
        }
        future_quotes_qs = DailyQuotes.objects.filter(
            stock_code_id=stock_code,
            trade_date__gt=entry_date
        ).order_by('trade_date').values('trade_date', 'open', 'high', 'low', 'close')[:self.max_holding_days]
        
        future_quotes = list(future_quotes_qs)
        if not future_quotes:
            logger.warning(f"    {stock_code} åœ¨å…¥åœºåæ— åç»­è¡Œæƒ…æ•°æ®ï¼Œæ— æ³•è¿½æº¯ã€‚")
            return

        exit_info = None
        for i, quote_dict in enumerate(future_quotes):
            status, exit_price, new_sl, new_tp = self._simulate_intraday_monitoring(position_state, quote_dict)
        
            if status == 'SOLD':
                final_reason = 'TAKE_PROFIT' if exit_price >= entry_price else 'STOP_LOSS'
                exit_info = {'date': quote_dict['trade_date'], 'price': exit_price, 'reason': final_reason, 'period': i + 1}
                break
            else: # HOLD
                position_state['current_stop_loss'] = new_sl
                position_state['current_take_profit'] = new_tp
            
        
        if not exit_info:
            last_quote = future_quotes[-1]
            exit_info = {'date': last_quote['trade_date'], 'price': last_quote['close'], 'reason': 'END_OF_PERIOD', 'period': len(future_quotes)}
        
        actual_return = (exit_info['price'] / entry_price) - 1 if entry_price > 0 else 0

        MDistributionBacktestLog.objects.create(
            backtest_run_id=self.backtest_run_id,
            plan_date=t_minus_1,
            stock_code=stock_code,
            stock_name=plan_obj.stock_code.stock_name,
            m_value_at_plan=Decimal(str(m_value)),
            strategy_dna=plan_obj.strategy_dna,
            entry_date=entry_date,
            entry_price=entry_price,
            exit_date=exit_info['date'],
            exit_price=exit_info['price'],
            exit_reason=exit_info['reason'],
            holding_period=exit_info['period'],
            preset_take_profit_rate=tp_rate,
            preset_stop_loss_rate=sl_rate,
            actual_return_rate=actual_return,
            one_stratage_mode=one_stratage_mode
        )
        logger.info(f"    [è®°å½•æˆåŠŸ] {stock_code}: å…¥åœº {entry_date}@{entry_price:.2f}, å‡ºåœº {exit_info['date']}@{exit_info['price']:.2f}, åŸå› : {exit_info['reason']}")

    def _get_simulated_stop_profit_loss(self, stock_code: str, entry_date: date, entry_price: Decimal):
        """å¤ç”¨DecisionOrderServiceé€»è¾‘è®¡ç®—æ­¢ç›ˆæ­¢æŸï¼Œä½†ä¸å®é™…ä¿®æ”¹æ•°æ®åº“"""
        tp_price, sl_price, tp_rate, sl_rate = (Decimal(0), Decimal(0), Decimal(0), Decimal(0))
        simulated_trade_time = timezone.make_aware(datetime.combine(entry_date, datetime.min.time()))
        with transaction.atomic():
            temp_position = Position.objects.create(
                stock_code_id=stock_code, entry_price=entry_price, quantity=100,
                entry_datetime=simulated_trade_time, status=Position.StatusChoices.OPEN,
                current_stop_loss=Decimal('0.00'),
                current_take_profit=Decimal('0.00')
            )
            temp_trade_log = TradeLog.objects.create(
                position=temp_position, stock_code_id=stock_code, trade_datetime=simulated_trade_time,
                trade_type=TradeLog.TradeTypeChoices.BUY, status=TradeLog.StatusChoices.FILLED,
                price=entry_price, quantity=100,
                commission=0,
                stamp_duty=0
            )
            dummy_sim_service = SimulateTradeService()
            dummy_handler = SimulateTradeHandler(dummy_sim_service)
            decision_service = DecisionOrderService(handler=dummy_handler, execution_date=entry_date)
            decision_service.calculate_stop_profit_loss(trade_id=temp_trade_log.trade_id)

            temp_position.refresh_from_db()
            tp_price = temp_position.current_take_profit
            sl_price = temp_position.current_stop_loss
            
            if entry_price > 0:
                tp_rate = (tp_price / entry_price) - 1
                sl_rate = 1 - (sl_price / entry_price)

            transaction.set_rollback(True)
            
        if tp_price == 0 or sl_price == 0:
            raise ValueError("è®¡ç®—å‡ºçš„æ­¢ç›ˆæ­¢æŸä»·æ— æ•ˆ")
            
        return tp_price, sl_price, tp_rate, sl_rate


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\m_distribution_reporter.py####
# trade_manager/service/m_distribution_reporter.py (æ›¿æ¢æ•´ä¸ªæ–‡ä»¶)

import logging
import base64
import io
from decimal import Decimal
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from datetime import date, timedelta,datetime
from django.db.models import Q

from common.models.backtest_logs import MDistributionBacktestLog
from data_manager.service.email_handler import EmailHandler

logger = logging.getLogger(__name__)

class MDistributionReporter:
    """
    Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹çš„æŠ¥å‘Šç”Ÿæˆä¸å‘é€å™¨ (V2 - å¤šç­–ç•¥å¯¹æ¯”ç‰ˆ)ã€‚
    """
    def __init__(self, backtest_run_id: str, date_range_text: str):
        self.backtest_run_id = backtest_run_id
        self.date_range_text = date_range_text
        self.email_handler = EmailHandler()
        self.recipients = ['876858298@qq.com']

    def _fetch_data_for_strategy(self, query_filter: Q) -> pd.DataFrame:
        """ä»æ•°æ®åº“è·å–æŒ‡å®šç­–ç•¥çš„å›æµ‹ç»“æœ"""
        base_query = MDistributionBacktestLog.objects.filter(
            backtest_run_id=self.backtest_run_id
        ).exclude(
            exit_reason=MDistributionBacktestLog.ExitReason.END_OF_PERIOD
        )
        
        logs = base_query.filter(query_filter)
        
        if not logs.exists():
            return pd.DataFrame()
        
        return pd.DataFrame.from_records(logs.values())

    def _analyze_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¯¹å•ä¸ªç­–ç•¥çš„æ•°æ®è¿›è¡Œåˆ†ç®±å’Œç»Ÿè®¡åˆ†æ"""
        if df.empty:
            return pd.DataFrame()

        bins = np.arange(-1.0, 1.1, 0.1)
        labels = [f"{i:.1f} to {i+0.1:.1f}" for i in bins[:-1]]
        
        df['m_interval'] = pd.cut(df['m_value_at_plan'].astype(float), bins=bins, labels=labels, right=False)

        def agg_func(group):
            total_trades = len(group)
            if total_trades == 0:
                return pd.Series({
                    'total_trades': 0, 'win_rate': 0, 'expected_return': 0
                })
            
            win_trades = (group['exit_reason'] == 'TAKE_PROFIT').sum()
            win_rate = win_trades / total_trades
            
            avg_tp_rate = np.nan_to_num(group[group['exit_reason'] == 'TAKE_PROFIT']['preset_take_profit_rate'].astype(float).mean())
            avg_sl_rate = np.nan_to_num(group[group['exit_reason'] == 'STOP_LOSS']['preset_stop_loss_rate'].astype(float).mean())
            
            expected_return = (win_rate * avg_tp_rate - (1 - win_rate) * avg_sl_rate)
            
            return pd.Series({
                'total_trades': total_trades,
                'win_rate': win_rate,
                'expected_return': expected_return
            })

        analysis_df = df.groupby('m_interval', observed=True).apply(agg_func, include_groups=False).reset_index()
        return analysis_df

    def _generate_combined_plots_base64(self, all_analysis_results: dict) -> tuple[str, str]:
        """ç”ŸæˆåŒ…å«å¤šæ¡æ›²çº¿çš„ç»„åˆå›¾è¡¨"""
        if not all_analysis_results:
            return "", ""

        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False
        except Exception:
            pass

        # èƒœç‡ç»„åˆå›¾
        fig_win, ax_win = plt.subplots(figsize=(14, 7))
        for name, df in all_analysis_results.items():
            if not df.empty:
                ax_win.plot(df['m_interval'], df['win_rate'], marker='o', linestyle='-', label=name)
        
        ax_win.set_title('å„ç­–ç•¥èƒœç‡ vs Må€¼', fontsize=16)
        ax_win.set_xlabel('Må€¼åŒºé—´', fontsize=12)
        ax_win.set_ylabel('èƒœç‡', fontsize=12)
        ax_win.yaxis.set_major_formatter(plt.FuncFormatter('{:.0%}'.format))
        ax_win.grid(True, linestyle='--', alpha=0.6)
        ax_win.legend()
        plt.setp(ax_win.get_xticklabels(), rotation=45, ha="right")
        plt.tight_layout()
        buf_win = io.BytesIO()
        fig_win.savefig(buf_win, format='png', dpi=120)
        win_rate_b64 = base64.b64encode(buf_win.getvalue()).decode('utf-8')
        plt.close(fig_win)

        # æœŸæœ›æ”¶ç›Šç»„åˆå›¾
        fig_exp, ax_exp = plt.subplots(figsize=(14, 7))
        for name, df in all_analysis_results.items():
            if not df.empty:
                ax_exp.plot(df['m_interval'], df['expected_return'], marker='s', linestyle='--', label=name)

        ax_exp.set_title('å„ç­–ç•¥æœŸæœ›æ”¶ç›Šç‡ vs Må€¼', fontsize=16)
        ax_exp.set_xlabel('Må€¼åŒºé—´', fontsize=12)
        ax_exp.set_ylabel('æœŸæœ›æ”¶ç›Šç‡', fontsize=12)
        ax_exp.yaxis.set_major_formatter(plt.FuncFormatter('{:.2%}'.format))
        ax_exp.axhline(0, color='grey', linestyle=':', linewidth=1)
        ax_exp.grid(True, linestyle='--', alpha=0.6)
        ax_exp.legend()
        plt.setp(ax_exp.get_xticklabels(), rotation=45, ha="right")
        plt.tight_layout()
        buf_exp = io.BytesIO()
        fig_exp.savefig(buf_exp, format='png', dpi=120)
        exp_return_b64 = base64.b64encode(buf_exp.getvalue()).decode('utf-8')
        plt.close(fig_exp)

        return win_rate_b64, exp_return_b64

    def _format_html_content(self, all_analysis_results: dict, plot1_b64: str, plot2_b64: str) -> str:
        """å°†æ‰€æœ‰å†…å®¹æ•´åˆæˆHTMLé‚®ä»¶"""
        
        # --- ç”Ÿæˆæ‰€æœ‰è¡¨æ ¼ ---
        tables_html = ""
        for name, df in all_analysis_results.items():
            tables_html += f"<h2>{name} - è¯¦ç»†æ•°æ®ç»Ÿè®¡</h2>"
            if df.empty:
                tables_html += "<p>è¯¥ç­–ç•¥æ— æœ‰æ•ˆäº¤æ˜“æ•°æ®ã€‚</p>"
                continue

            df_display = df.copy()
            df_display['win_rate'] = df_display['win_rate'].apply(lambda x: f"{x:.2%}")
            df_display['expected_return'] = df_display['expected_return'].apply(lambda x: f"{x:.2%}")
            df_display.rename(columns={
                'm_interval': 'Må€¼åŒºé—´',
                'total_trades': 'æ€»äº¤æ˜“æ•°',
                'win_rate': 'èƒœç‡',
                'expected_return': 'æœŸæœ›æ”¶ç›Šç‡',
            }, inplace=True)
            
            tables_html += df_display.to_html(index=False, classes='styled-table', border=0)

        # --- æœ€ç»ˆHTMLæ¨¡æ¿ ---
        html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <title>Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æŠ¥å‘Š</title>
            <style>
                body {{ font-family: 'Segoe UI', 'Microsoft YaHei', sans-serif; margin: 20px; background-color: #f8f9fa; }}
                h1, h2 {{ color: #0056b3; border-bottom: 2px solid #e9ecef; padding-bottom: 8px; }}
                .styled-table {{ border-collapse: collapse; margin: 25px 0; font-size: 0.9em; min-width: 600px; box-shadow: 0 0 20px rgba(0, 0, 0, 0.1); }}
                .styled-table thead tr {{ background-color: #007bff; color: #ffffff; text-align: left; }}
                .styled-table th, .styled-table td {{ padding: 12px 15px; }}
                .styled-table tbody tr {{ border-bottom: 1px solid #dddddd; }}
                .styled-table tbody tr:nth-of-type(even) {{ background-color: #f3f3f3; }}
                .plot-container {{ text-align: center; margin-top: 20px; padding: 20px; background-color: #fff; border-radius: 8px; box-shadow: 0 0 20px rgba(0, 0, 0, 0.1); }}
                img {{ max-width: 100%; height: auto; }}
            </style>
        </head>
        <body>
            <h1>Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æŠ¥å‘Š</h1>
            <h2>æ—¥æœŸåŒºé—´: {self.date_range_text}</h2>
            
            <h2>ç»„åˆå›¾è¡¨åˆ†æ</h2>
            <div class="plot-container">
                <h3>å„ç­–ç•¥èƒœç‡ vs Må€¼</h3>
                <img src="data:image/png;base64,{plot1_b64}" alt="Win Rate Plot">
            </div>
            <div class.plot-container">
                <h3>å„ç­–ç•¥æœŸæœ›æ”¶ç›Šç‡ vs Må€¼</h3>
                <img src="data:image/png;base64,{plot2_b64}" alt="Expected Return Plot">
            </div>
            
            {tables_html}
        </body>
        </html>
        """
        return html

    def generate_and_send_report(self):
        """ç”Ÿæˆå¹¶å‘é€æŠ¥å‘Šé‚®ä»¶çš„ä¸»æ–¹æ³•"""
        logger.info(f"[{self.backtest_run_id}] å¼€å§‹ç”ŸæˆMå€¼åˆ†å¸ƒå›æµ‹æŠ¥å‘Š (å¤šç­–ç•¥ç‰ˆ)...")
        try:
            # 1. è·å–ç­–ç•¥åˆ†ç»„
            strategy_groups_raw = MDistributionBacktestLog.objects.filter(
                backtest_run_id=self.backtest_run_id
            ).values_list('one_stratage_mode', flat=True).distinct()

            if not strategy_groups_raw:
                logger.warning(f"[{self.backtest_run_id}] æ•°æ®åº“ä¸­æ— ä»»ä½•æ—¥å¿—ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚")
                return

            # 2. æ•´ç†å’Œæ’åºåˆ†ç»„
            groups_to_process = sorted(
                [g if g is not None else 'M_DYNAMIC' for g in strategy_groups_raw],
                key=lambda x: (x != 'M_DYNAMIC', x)
            )

            # 3. å¾ªç¯è·å–æ•°æ®å¹¶åˆ†æ
            all_analysis_results = {}
            for strategy_key in groups_to_process:
                display_name = "MåŠ¨æ€ç­–ç•¥" if strategy_key == 'M_DYNAMIC' else f"å•ç­–ç•¥ - {strategy_key}"
                query_filter = Q(one_stratage_mode__isnull=True) if strategy_key == 'M_DYNAMIC' else Q(one_stratage_mode=strategy_key)
                
                strategy_df = self._fetch_data_for_strategy(query_filter)
                analysis_df = self._analyze_data(strategy_df)
                all_analysis_results[display_name] = analysis_df

            # 4. ç”Ÿæˆå›¾è¡¨å’ŒHTML
            plot1_b64, plot2_b64 = self._generate_combined_plots_base64(all_analysis_results)
            html_content = self._format_html_content(all_analysis_results, plot1_b64, plot2_b64)
            
            subject = f"Må€¼èƒœç‡åˆ†å¸ƒå›æµ‹æŠ¥å‘Š (å¤šç­–ç•¥ç‰ˆ) - {datetime.now().strftime('%Y-%m-%d')}"
            
            self.email_handler.send_email(
                recipients=self.recipients,
                subject=subject,
                html_content=html_content
            )
            logger.info(f"[{self.backtest_run_id}] å¤šç­–ç•¥å›æµ‹æŠ¥å‘Šé‚®ä»¶å·²æˆåŠŸå‘é€ã€‚")
        except Exception as e:
            logger.error(f"[{self.backtest_run_id}] ç”Ÿæˆæˆ–å‘é€å¤šç­–ç•¥æŠ¥å‘Šæ—¶å¤±è´¥: {e}", exc_info=True)

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\monitor_exit_service.py####
# trade_manager/service/monitor_exit_service.py

import logging
from datetime import date
from django.utils import timezone
from decimal import Decimal

# å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å‹å’Œæ¥å£
from common.models import Position, TradeLog
from .trade_handler import ITradeHandler
from .position_monitor_logic import PositionMonitorLogic
persistent_logger = logging.getLogger(__name__)


class MonitorExitService:
    """
    3.5 - ç›˜ä¸­æŒä»“ç›‘æ§ä¸é€€å‡ºæ¨¡å—

    è¯¥æœåŠ¡è´Ÿè´£åœ¨äº¤æ˜“æ—¶æ®µå†…ï¼Œä»¥å›ºå®šé¢‘ç‡è½®è¯¢ï¼Œç›‘æ§æ‰€æœ‰éå½“æ—¥å»ºä»“çš„æŒä»“ã€‚
    å½“æŒä»“è‚¡ç¥¨çš„å®æ—¶ä»·æ ¼è§¦åŠé¢„è®¾çš„æ­¢ç›ˆæˆ–æ­¢æŸçº¿æ—¶ï¼Œè°ƒç”¨äº¤æ˜“å¤„ç†å™¨æ‰§è¡Œå–å‡ºæ“ä½œã€‚
    """
    MODULE_NAME = 'ç›˜ä¸­æŒä»“ç›‘æ§ä¸é€€å‡º'

    def __init__(self, handler: ITradeHandler,execution_date: date = None):
        """
        åˆå§‹åŒ–ç›‘æ§æœåŠ¡ã€‚

        :param handler: ä¸€ä¸ªå®ç°äº† ITradeHandler æ¥å£çš„å®ä¾‹ï¼Œç”¨äºä¸äº¤æ˜“ç¯å¢ƒäº¤äº’ã€‚
        """
        if not isinstance(handler, ITradeHandler):
            raise TypeError("ä¼ å…¥çš„ handler å¿…é¡»æ˜¯ ITradeHandler çš„ä¸€ä¸ªå®ä¾‹ã€‚")
        
        self.handler = handler
        self.execution_date = execution_date if execution_date else timezone.now().date()
        # ä½¿ç”¨ç‰¹å®šçš„loggerè¿›è¡Œé«˜é¢‘ã€éæŒä¹…åŒ–çš„æ—¥å¿—è®°å½•
        self.logger = persistent_logger

    def monitor_and_exit_positions(self):
        """
        æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æŒä»“ç›‘æ§ä¸é€€å‡ºæ£€æŸ¥ã€‚
        æ­¤å‡½æ•°åº”ç”±ä¸€ä¸ªå®šæ—¶è°ƒåº¦å™¨åœ¨äº¤æ˜“æ—¶æ®µå†…ï¼ˆ09:30:01 - 14:57:00ï¼‰
        ä»¥è®¾å®šçš„é¢‘ç‡åå¤è°ƒç”¨ã€‚
        """
        self.logger.debug(f"[{self.MODULE_NAME}] ä»»åŠ¡å¼€å§‹...")

        # 1. ä»æŒä»“ä¿¡æ¯è¡¨è¯»å–å‡ºentry_datetimeå»ºä»“æˆäº¤æ—¶é—´ä¸ä¸ºä»Šå¤©çš„æŒä»“ä¿¡æ¯
        today = timezone.now().date()
        positions_to_monitor = Position.objects.filter(
            status=Position.StatusChoices.OPEN
        ).exclude(
            entry_datetime__date=self.execution_date
        )

        if not positions_to_monitor.exists():
            self.logger.debug("å½“å‰æ— éœ€è¦ç›‘æ§çš„éš”å¤œæŒä»“ã€‚")
            return

        # 2. å¾ªç¯è°ƒç”¨å¤„ç†å™¨åˆ¤æ–­æ˜¯å¦è¾¾åˆ°äº†æ­¢ç›ˆæ­¢æŸçŠ¶æ€
        for position in positions_to_monitor:
            try:
                # è·å–å®æ—¶ä»·æ ¼
                current_price = self.handler.get_realtime_price(position.stock_code)

                if current_price is None or current_price <= 0:
                    self.logger.debug(f"æ— æ³•è·å– {position.stock_code} çš„æœ‰æ•ˆå®æ—¶ä»·æ ¼ï¼Œè·³è¿‡æœ¬æ¬¡æ£€æŸ¥ã€‚")
                    continue
                
                self.logger.debug(
                    f"ç›‘æ§: {position.stock_code}, "
                    f"å½“å‰ä»·: {current_price}, "
                    f"æ­¢æŸä»·: {position.current_stop_loss}, "
                    f"æ­¢ç›ˆä»·: {position.current_take_profit}"
                )

                # è°ƒç”¨ä¸­å¤®å†³ç­–é€»è¾‘
                decision = PositionMonitorLogic.check_and_decide(position, current_price, self.params)
                if decision['action'] == 'SELL':
                    msg = f"è§¦å‘å–å‡º! è‚¡ç¥¨: {position.stock_code_id}, ä»·æ ¼: {current_price:.2f}, æœºåˆ¶åŸå› : {decision['reason']}"
                    persistent_logger.info(msg)
                    # æ³¨æ„ï¼šå®ç›˜å–å‡ºæ—¶ï¼Œæˆäº¤ä»·æœªçŸ¥ï¼Œæ‰€ä»¥reasonæ˜¯åŸºäºè§¦å‘æœºåˆ¶çš„
                    self.handler.sell_stock_by_market_price(position, decision['reason'])
                
                elif decision['action'] == 'UPDATE':
                    updates = decision['updates']
                    for field, value in updates.items():
                        setattr(position, field, value)
                    position.save(update_fields=list(updates.keys()))
                    persistent_logger.info(f"é£æ§ä»·æ ¼æ›´æ–°! è‚¡ç¥¨: {position.stock_code_id}, æ›´æ–°å†…å®¹: {updates}")

            except Exception as e:
                # æ ¹æ®è¦æ±‚ï¼Œå–å‡ºå¤±è´¥ç­‰å¼‚å¸¸åªåœ¨æ§åˆ¶å°æ‰“å°é”™è¯¯æ—¥å¿—ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å¾ªç¯
                self.logger.error(
                    f"å¤„ç†æŒä»“ {position.position_id} ({position.stock_code}) æ—¶å‘ç”Ÿé”™è¯¯: {e}",
                    exc_info=False # åœ¨é«˜é¢‘åœºæ™¯ä¸‹ï¼Œå¯ä»¥å…³é—­tracebackä»¥ä¿æŒæ—¥å¿—ç®€æ´
                )
                continue
        
        self.logger.debug(f"[{self.MODULE_NAME}] ä»»åŠ¡ç»“æŸã€‚")


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\position_monitor_logic.py####
# trade_manager/service/position_monitor_logic.py (æ–°å¢æˆ–åœ¨monitor_exit_service.pyä¸­å®šä¹‰)
from decimal import Decimal
from common.models import Position, TradeLog

class PositionMonitorLogic:
    """
    æŒä»“ç›‘æ§çš„æ ¸å¿ƒå†³ç­–é€»è¾‘ã€‚
    è¿™æ˜¯ä¸€ä¸ªæ— çŠ¶æ€çš„ç±»ï¼Œæ‰€æœ‰æ–¹æ³•éƒ½æ˜¯é™æ€çš„ï¼Œä¾¿äºåœ¨ä»»ä½•åœ°æ–¹è°ƒç”¨ã€‚
    """
    @staticmethod
    def check_and_decide(position: Position, current_price: Decimal, params: dict) -> dict:
        """
        æ ¹æ®å½“å‰ä»·æ ¼ï¼Œå¯¹ä¸€ä¸ªæŒä»“åšå‡ºå†³ç­–ã€‚
        è¿™æ˜¯æ‰€æœ‰ç›‘æ§é€»è¾‘çš„å”¯ä¸€å…¥å£ã€‚

        :param position: æŒä»“å¯¹è±¡
        :param current_price: å½“å‰æ£€æŸ¥çš„ä»·æ ¼
        :param params: åŒ…å«æ‰€éœ€ç­–ç•¥å‚æ•°çš„å­—å…¸
        :return: ä¸€ä¸ªåŒ…å«å†³ç­–çš„å­—å…¸, e.g.,
                 {'action': 'SELL', 'reason': 'stop_loss', 'exit_price': Decimal('10.00')}
                 {'action': 'UPDATE', 'updates': {'current_stop_loss': ..., 'current_take_profit': ...}}
                 {'action': 'NONE'}
        """
        # é˜¶æ®µä¸€ï¼šæ­¢æŸé€€å‡ºæ£€æŸ¥ (æœ€é«˜ä¼˜å…ˆçº§)
        if current_price <= position.current_stop_loss:
            final_reason = TradeLog.ReasonChoices.TAKE_PROFIT if position.current_stop_loss >= position.entry_price else TradeLog.ReasonChoices.STOP_LOSS
            return {
                'action': 'SELL',
                'reason': final_reason,
                'exit_price': position.current_stop_loss
            }

        # é˜¶æ®µäºŒï¼šè¿½è¸ªæ­¢ç›ˆ
        if current_price >= position.current_take_profit:
            if 1+1>0:
                return {
                    'action': 'SELL',
                    'reason': TradeLog.ReasonChoices.TAKE_PROFIT,
                    'exit_price': position.current_take_profit
                }
                
            change=(position.current_take_profit-max(position.current_stop_loss,position.entry_price))/Decimal(2)
            if position.current_stop_loss>position.entry_price*Decimal(1.3):
                new_sl=current_price-Decimal(0.01)
            else:
                new_sl=position.current_take_profit-change
            #new_tp = position.current_take_profit * (1 + params['trailing_tp_increment_pct'])
            new_tp=max(position.current_take_profit+change,current_price)
            #new_sl = position.current_take_profit * (1 - params['trailing_sl_buffer_pct'])

            if current_price>=new_tp:
                return {
                    'action': 'SELL',
                    'reason': TradeLog.ReasonChoices.TAKE_PROFIT,
                    'exit_price': current_price
                }
            else:
                return {
                    'action': 'UPDATE',
                    'updates': {
                        'current_take_profit': new_tp.quantize(Decimal('0.01')),
                        'current_stop_loss': new_sl.quantize(Decimal('0.01'))
                    }
                }

        # é˜¶æ®µä¸‰ï¼šæˆæœ¬é”å®š
        middle=(position.current_take_profit+position.entry_price)/Decimal(2)
        if current_price>middle and position.current_stop_loss<position.entry_price and False:
            new_sl=position.entry_price*Decimal(1.01)
            return {
                        'action': 'UPDATE',
                        'updates': {'current_stop_loss': new_sl.quantize(Decimal('0.01'))}
                    }
        # if position.current_stop_loss < position.entry_price:
        #     base_price = max(position.entry_price, position.current_stop_loss)
        #     cost_lock_price = min(
        #         (base_price + position.current_take_profit) / 2,
        #         base_price * Decimal('1.012')
        #     )
        #     if current_price > cost_lock_price:
        #         new_sl = ((base_price + cost_lock_price) / 2)
        #         # ç¡®ä¿æ–°çš„æ­¢æŸä»·ä¸ä¼šé«˜äºå½“å‰ä»·ï¼Œé¿å…ç«‹å³è§¦å‘
        #         if new_sl < current_price:
        #             return {
        #                 'action': 'UPDATE',
        #                 'updates': {'current_stop_loss': new_sl.quantize(Decimal('0.01'))}
        #             }

        return {'action': 'NONE'}

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\real_trade_handler.py####
# trade_manager/service/real_trade_handler.py

import logging
import json
from decimal import Decimal, ROUND_HALF_UP
from datetime import date, time, datetime, timedelta

import easytrader
import akshare as ak
from django.db import transaction
from django.utils import timezone

from .trade_handler import ITradeHandler
from common.models import Position, TradeLog, DailyQuotes
from trade_manager.service.decision_order_service import DecisionOrderService
from common.config_loader import config_loader # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®åŠ è½½å™¨

logger = logging.getLogger(__name__)

class ConnectionManager:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(ConnectionManager, cls).__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.user = None
            self.last_connected_date = None
            self.last_refreshed_time = None # æ–°å¢ï¼šä¸Šæ¬¡åˆ·æ–°æ—¶é—´
            self.refresh_interval = timedelta(seconds=5) # æ–°å¢ï¼šåˆ·æ–°é—´éš”
            self.initialized = True
            logger.info("ConnectionManager å·²åˆå§‹åŒ–ã€‚")

    def get_user(self):
        """è·å–æˆ–åˆ›å»ºå½“å¤©çš„ easytrader è¿æ¥ï¼Œå¹¶æŒ‰éœ€åˆ·æ–°"""
        config = config_loader.get('easytrader')
        today = date.today()
        
        if not self.user or self.last_connected_date != today:
            logger.info("å½“å¤©é¦–æ¬¡è¿æ¥æˆ–è¿æ¥å·²å¤±æ•ˆï¼Œæ­£åœ¨é‡æ–°å»ºç«‹ easytrader è¿æ¥...")
            try:
                self._connect(config)
                self.last_connected_date = today
                self.last_refreshed_time = datetime.now()
                logger.info("easytrader è¿æ¥æˆåŠŸã€‚")
            except Exception as e:
                logger.error(f"è¿æ¥ easytrader å¤±è´¥: {e}", exc_info=True)
                self.user = None
                self.last_connected_date = None
                raise
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if datetime.now() - self.last_refreshed_time > self.refresh_interval:
            logger.info("ä¼šè¯è¶…è¿‡5åˆ†é’Ÿæœªåˆ·æ–°ï¼Œæ‰§è¡Œ user.refresh()...")
            try:
                self.user.refresh()
                self.last_refreshed_time = datetime.now()
                logger.info("user.refresh() æ‰§è¡ŒæˆåŠŸã€‚")
            except Exception as e:
                logger.error(f"æ‰§è¡Œ user.refresh() å¤±è´¥: {e}ï¼Œå°†å°è¯•æ–­å¼€é‡è¿ã€‚")
                self.disconnect() # åˆ·æ–°å¤±è´¥ï¼Œå¯èƒ½è¿æ¥å·²æ–­ï¼Œå¼ºåˆ¶æ–­å¼€
                # ä¸‹æ¬¡è°ƒç”¨ get_user æ—¶ä¼šè‡ªåŠ¨é‡è¿
                raise # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å½“å‰æ“ä½œå¤±è´¥
        
        return self.user

    def _connect(self, config: dict):
        client_type = config.get('client_type', 'ht_client')
        user_config_path = config.get('user_config_path')
        
        if client_type == 'ht_client':
            self.user = easytrader.use('ht_client')
            self.user.prepare(user_config_path)
        else:
            raise NotImplementedError(f"ä¸æ”¯æŒçš„å®¢æˆ·ç«¯ç±»å‹: {client_type}")

    def disconnect(self):
        if self.user:
            try:
                self.user.exit()
                logger.info("easytrader è¿æ¥å·²æˆåŠŸæ–­å¼€ã€‚")
            except Exception as e:
                logger.error(f"æ–­å¼€ easytrader è¿æ¥æ—¶å‡ºé”™: {e}", exc_info=True)
            finally:
                self.user = None
                self.last_connected_date = None
                self.last_refreshed_time = None

connection_manager = ConnectionManager()

class RealTradeHandler(ITradeHandler):
    COMMISSION_RATE = Decimal('0.00025')
    MIN_COMMISSION = Decimal('5')
    STAMP_DUTY_RATE = Decimal('0.001')

    def __init__(self):
        config = config_loader.get_config()
        self.is_simulation = (config.get('trading_mode') == 'real_simulation_observation')
        logger.info(f"RealTradeHandler åˆå§‹åŒ–ã€‚æ¨¡å¼: {'å®ç›˜æ¨¡æ‹Ÿè§‚æµ‹' if self.is_simulation else 'å®ç›˜äº¤æ˜“'}")

    def _get_user(self):
        return connection_manager.get_user()

    def _api_buy(self, stock_code: str, price: Decimal, quantity: int):
        user = self._get_user()
        ak_code = stock_code.split('.')[-1]
        return user.buy(ak_code, price=float(price), amount=quantity)

    def _api_sell(self, stock_code: str, quantity: int):
        user = self._get_user()
        ak_code = stock_code.split('.')[-1]
        return user.sell(ak_code, amount=quantity)

    def _api_get_orders(self):
        user = self._get_user()
        return user.entrust

    def _api_get_balance(self):
        user = self._get_user()
        return user.balance

    def _api_get_realtime_quote(self, stock_code: str) -> dict:
        ak_code = stock_code.split('.')[-1]
        try:
            df = ak.stock_zh_a_spot_em(symbol=ak_code)
            if not df.empty:
                quote = df.iloc[0]
                return {
                    'open': Decimal(str(quote['ä»Šå¼€'])),
                    'price': Decimal(str(quote['æœ€æ–°ä»·'])),
                }
        except Exception as e:
            logger.warning(f"é€šè¿‡ akshare è·å– {stock_code} å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
        return {}

    def get_opening_price(self, stock_code: str) -> Decimal:
        quote = self._api_get_realtime_quote(stock_code)
        return quote.get('open', Decimal('0.00'))

    def get_realtime_price(self, stock_code: str) -> Decimal | None:
        quote = self._api_get_realtime_quote(stock_code)
        return quote.get('price')

    def get_available_balance(self) -> Decimal:
        if self.is_simulation:
            return Decimal('1000000.00')
        
        balance_info = self._api_get_balance()
        return Decimal(str(balance_info.get('å¯ç”¨é‡‘é¢', '0.00')))

    @transaction.atomic
    def place_buy_order(self, stock_code: str, price: Decimal, quantity: int):
        logger.info(f"å‡†å¤‡ä¸‹å•ä¹°å…¥: {stock_code}, ä»·æ ¼: {price}, æ•°é‡: {quantity}")
        
        entry_datetime = timezone.now()
        position = Position.objects.create(
            stock_code_id=stock_code, entry_datetime=entry_datetime,
            entry_price=price, quantity=quantity,
            current_stop_loss=Decimal('0.00'), current_take_profit=Decimal('0.00'),
            status=Position.StatusChoices.OPEN
        )
        trade_log = TradeLog.objects.create(
            position=position, stock_code_id=stock_code,
            trade_datetime=entry_datetime, trade_type=TradeLog.TradeTypeChoices.BUY,
            order_type=TradeLog.OrderTypeChoices.LIMIT, price=price,
            quantity=quantity, commission=Decimal('0.00'), stamp_duty=Decimal('0.00'),
            reason=TradeLog.ReasonChoices.ENTRY, status=TradeLog.StatusChoices.PENDING
        )

        if self.is_simulation:
            logger.info("[æ¨¡æ‹Ÿæ¨¡å¼] è·³è¿‡çœŸå®APIè°ƒç”¨ï¼Œç›´æ¥æ¨¡æ‹Ÿæˆäº¤ã€‚")
            amount = price * quantity
            commission = max(amount * self.COMMISSION_RATE, self.MIN_COMMISSION)
            trade_log.status = TradeLog.StatusChoices.FILLED
            trade_log.commission = commission.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            trade_log.save()
            
            decision_service = DecisionOrderService(self, execution_date=date.today())
            decision_service.calculate_stop_profit_loss(trade_log.trade_id)
        else:
            try:
                order_result = self._api_buy(stock_code, price, quantity)
                logger.info(f"çœŸå®ä¹°å…¥å§”æ‰˜å·²æäº¤: {order_result}")
                # å…³é”®ï¼šä¿å­˜å§”æ‰˜ç¼–å·
                if order_result and 'entrust_no' in order_result:
                    trade_log.external_order_id = str(order_result['entrust_no'])
                    trade_log.save()
            except Exception as e:
                logger.error(f"æäº¤ä¹°å…¥å§”æ‰˜å¤±è´¥: {e}", exc_info=True)
                trade_log.status = TradeLog.StatusChoices.FAILED
                trade_log.save()
                position.status = Position.StatusChoices.CLOSED
                position.save()

    @transaction.atomic
    def sell_stock_by_market_price(self, position: Position, reason: str):
        logger.info(f"å‡†å¤‡å¸‚ä»·å–å‡º: {position.stock_code_id}, æ•°é‡: {position.quantity}, åŸå› : {reason}")

        trade_log = TradeLog.objects.create(
            position=position, stock_code_id=position.stock_code_id,
            trade_datetime=timezone.now(), trade_type=TradeLog.TradeTypeChoices.SELL,
            order_type=TradeLog.OrderTypeChoices.MARKET, price=Decimal('0.00'),
            quantity=position.quantity, commission=Decimal('0.00'), stamp_duty=Decimal('0.00'),
            reason=reason, status=TradeLog.StatusChoices.PENDING
        )

        if self.is_simulation:
            logger.info("[æ¨¡æ‹Ÿæ¨¡å¼] è·³è¿‡çœŸå®APIè°ƒç”¨ï¼Œç›´æ¥æ¨¡æ‹Ÿæˆäº¤ã€‚")
            try:
                last_quote = DailyQuotes.objects.filter(stock_code_id=position.stock_code_id).latest('trade_date')
                sell_price = last_quote.close
            except DailyQuotes.DoesNotExist:
                sell_price = position.entry_price

            amount = sell_price * position.quantity
            commission = max(amount * self.COMMISSION_RATE, self.MIN_COMMISSION)
            stamp_duty = amount * self.STAMP_DUTY_RATE

            trade_log.status = TradeLog.StatusChoices.FILLED
            trade_log.price = sell_price
            trade_log.commission = commission.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            trade_log.stamp_duty = stamp_duty.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            trade_log.save()

            position.status = Position.StatusChoices.CLOSED
            position.save()
        else:
            try:
                order_result = self._api_sell(position.stock_code_id, position.quantity)
                logger.info(f"çœŸå®å–å‡ºå§”æ‰˜å·²æäº¤: {order_result}")
                if order_result and 'entrust_no' in order_result:
                    trade_log.external_order_id = str(order_result['entrust_no'])
                    trade_log.save()
            except Exception as e:
                logger.error(f"æäº¤å–å‡ºå§”æ‰˜å¤±è´¥: {e}", exc_info=True)
                trade_log.status = TradeLog.StatusChoices.FAILED
                trade_log.save()

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\scheduler_service.py####
# trade_manager/service/scheduler_service.py

import logging
import pandas as pd # ä¿®æ­£ï¼šå¯¼å…¥pandas
from datetime import date, timedelta, datetime

import akshare as ak
from apscheduler.schedulers.background import BackgroundScheduler # ä½¿ç”¨BackgroundScheduler
from django.conf import settings
from django.db import transaction
from decimal import Decimal

from selection_manager.service.selection_service import SelectionService
from data_manager.service.corporate_action_service import CorporateActionService
from data_manager.service.stock_service import StockService
from data_manager.service.email_service import EmailNotificationService
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.monitor_exit_service import MonitorExitService
from trade_manager.service.real_trade_handler import RealTradeHandler, connection_manager
from common.models import TradeLog, Position
from common.config_loader import config_loader

logger = logging.getLogger(__name__)

class TradingCalendar:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(TradingCalendar, cls).__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.trade_dates = set()
            self.last_updated = None
            self.initialized = True
            self._update_calendar()

    def _update_calendar(self):
        logger.info("æ­£åœ¨æ›´æ–°äº¤æ˜“æ—¥å†...")
        try:
            df = ak.tool_trade_date_hist_sina()
            self.trade_dates = set(pd.to_datetime(df['trade_date']).dt.date)
            self.last_updated = date.today()
            logger.info(f"äº¤æ˜“æ—¥å†æ›´æ–°æˆåŠŸï¼Œå…±è·å– {len(self.trade_dates)} ä¸ªäº¤æ˜“æ—¥ã€‚")
        except Exception as e:
            logger.error(f"æ›´æ–°äº¤æ˜“æ—¥å†å¤±è´¥: {e}", exc_info=True)

    def is_trading_day(self, check_date: date) -> bool:
        if date.today() != self.last_updated:
            self._update_calendar()
        return check_date in self.trade_dates

trading_calendar = TradingCalendar()

# --- Job Functions ---

def run_job_wrapper(job_func, job_name, *args, **kwargs):
    scheduler_status = config_loader.get('scheduler', {}).get('status')
    if scheduler_status == 'off': return

    logger.info(f"--- [{job_name}] ä»»åŠ¡è§¦å‘ ---")
    if scheduler_status == 'dry_run':
        logger.info(f"[{job_name}] ç©ºè½¬æ¨¡å¼ï¼Œä»»åŠ¡ä»…æ‰“å°æ—¥å¿—ï¼Œä¸æ‰§è¡Œã€‚")
        return
    
    try:
        job_func(*args, **kwargs)
        logger.info(f"--- [{job_name}] ä»»åŠ¡æˆåŠŸæ‰§è¡Œ ---")
    except Exception as e:
        logger.error(f"--- [{job_name}] ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e} ---", exc_info=True)

def daily_check():
    today = date.today()
    if not trading_calendar.is_trading_day(today):
        logger.debug(f"{today} ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä»Šæ—¥ä¸»è¦äº¤æ˜“æµç¨‹ä»»åŠ¡å°†è·³è¿‡ã€‚")
        return False
    return True

def selection_job():
    

    t_minus_1 = date.today() - timedelta(days=1)
    if not trading_calendar.is_trading_day(date.today()):
        logger.info(f"ä»Šæ—¥({date.today()})ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸æ‰§è¡Œé€‰è‚¡ä»»åŠ¡ã€‚")
        return
    service = StockService()
    service.update_local_a_shares(start_date=date.today().strftime('%Y-%m-%d'),end_date=date.today().strftime('%Y-%m-%d'))
    service.update_csi300_index_data(start_date=date.today().strftime('%Y-%m-%d'), end_date=date.today().strftime('%Y-%m-%d'))
    service = SelectionService(trade_date=date.today(), mode='realtime')
    service.run_selection()

def premarket_fix_job():
    if not daily_check(): return
    service = BeforeFixService(execution_date=date.today())
    service.run()

def opening_decision_job():
    if not daily_check(): return
    handler = RealTradeHandler()
    service = DecisionOrderService(handler, execution_date=date.today())
    
    logger.info("æ‰§è¡Œäº¤æ˜“é¢„æ¡ˆäºŒæ¬¡ç­›é€‰...")
    service.adjust_trading_plan_daily()
    
    logger.info("å¾ªç¯æ‰§è¡Œä¸‹å•ï¼Œå°è¯•å¡«æ»¡ä»“ä½...")
    max_positions = service.current_max_positions
    logger.info(f"æ ¹æ®M(t)è®¡ç®—ï¼Œå½“æ—¥åŠ¨æ€æœ€å¤§æŒä»“æ•°ä¸º: {max_positions}")

    
    open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
    slots_to_fill = max_positions - open_positions_count
 
    # 3. å¾ªç¯è°ƒç”¨åŒä¸€ä¸ªå®ä¾‹çš„æ–¹æ³•
    for i in range(slots_to_fill):
        logger.info(f"å°è¯•å¡«å……ç¬¬ {i+1}/{slots_to_fill} ä¸ªä»“ä½...")
        service.execute_orders()

def monitoring_job():
    if not daily_check(): return
    handler = RealTradeHandler()
    service = MonitorExitService(handler, execution_date=date.today())
    service.monitor_and_exit_positions()

def update_order_status_job():
    if not daily_check(): return
    handler = RealTradeHandler()
    if handler.is_simulation: return

    pending_trades = TradeLog.objects.filter(status=TradeLog.StatusChoices.PENDING, external_order_id__isnull=False)
    if not pending_trades.exists(): return
    
    try:
        real_orders = handler._api_get_orders()
        if not real_orders: return
        real_orders_map = {str(o['entrust_no']): o for o in real_orders}

        for trade in pending_trades:
            real_order = real_orders_map.get(trade.external_order_id)
            if not real_order: continue
            
            if real_order['order_status'] in ['å·²æˆ', 'å…¨éƒ¨æˆäº¤']:
                with transaction.atomic():
                    trade.status = TradeLog.StatusChoices.FILLED
                    trade.price = Decimal(str(real_order['filled_price']))
                    # æ³¨æ„ï¼šeasytraderè¿”å›çš„ä½£é‡‘å¯èƒ½ä¸å‡†ç¡®ï¼Œè¿™é‡Œä»…ä¸ºç¤ºä¾‹
                    trade.commission = Decimal(str(real_order.get('business_balance', '0.0'))) - Decimal(str(real_order.get('clear_balance', '0.0')))
                    

                    if trade.trade_type == 'buy':
                        decision_service = DecisionOrderService(handler, execution_date=date.today())
                        decision_service.calculate_stop_profit_loss(trade.trade_id)
                    else: # sell
                        if trade.price >= position.entry_price:
                            trade.reason = TradeLog.ReasonChoices.TAKE_PROFIT
                        else:
                            trade.reason = TradeLog.ReasonChoices.STOP_LOSS
                        position = trade.position
                        position.status = Position.StatusChoices.CLOSED
                        position.save()
                    trade.save()
                logger.info(f"è®¢å• {trade.trade_id} (å§”æ‰˜å·: {trade.external_order_id}) çŠ¶æ€æ›´æ–°ä¸ºå·²æˆäº¤ã€‚")

            elif real_order['order_status'] in ['å·²æ’¤', 'åºŸå•', 'éƒ¨æˆå·²æ’¤']:
                with transaction.atomic():
                    trade.status = TradeLog.StatusChoices.CANCELLED if 'æ’¤' in real_order['order_status'] else TradeLog.StatusChoices.FAILED
                    trade.save()
                    if trade.trade_type == 'buy':
                        position = trade.position
                        position.status = Position.StatusChoices.CLOSED
                        position.save()
                logger.info(f"è®¢å• {trade.trade_id} (å§”æ‰˜å·: {trade.external_order_id}) çŠ¶æ€æ›´æ–°ä¸º {trade.status}ã€‚")

    except Exception as e:
        logger.error(f"æ›´æ–°è®¢å•çŠ¶æ€æ—¶å‡ºé”™: {e}", exc_info=True)

def update_corporate_actions_job():
    today = date.today()
    start_date = today - timedelta(days=30)
    end_date = today + timedelta(days=30)
    service = CorporateActionService()
    service.sync_corporate_actions(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'))

def disconnect_job():
    logger.info("æ‰§è¡Œæ¯æ—¥æ–­å¼€è¿æ¥ä»»åŠ¡...")
    connection_manager.disconnect()

scheduler = BackgroundScheduler(timezone='Asia/Shanghai')


def schedule_intraday_jobs():
    """åœ¨æ¯ä¸ªäº¤æ˜“æ—¥å¼€ç›˜å‰ï¼Œæ·»åŠ å½“å¤©çš„ç›˜ä¸­ç›‘æ§ä»»åŠ¡ã€‚"""
    job_id_monitor = 'intraday_monitoring_job'
    job_id_order_status = 'intraday_order_status_job'
    
    # ä¸ºé˜²æ­¢é‡å¤æ·»åŠ ï¼Œå…ˆå°è¯•ç§»é™¤æ—§çš„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    try:
        scheduler.remove_job(job_id_monitor)
        logger.info(f"æˆåŠŸç§»é™¤æ—§çš„ç›˜ä¸­ç›‘æ§ä»»åŠ¡ (ID: {job_id_monitor})ã€‚")
    except Exception:
        pass # JobNotFoundError, a normal case
    
    try:
        scheduler.remove_job(job_id_order_status)
        logger.info(f"æˆåŠŸç§»é™¤æ—§çš„è®¢å•çŠ¶æ€æ›´æ–°ä»»åŠ¡ (ID: {job_id_order_status})ã€‚")
    except Exception:
        pass
 
    if not daily_check(): return
 
    today_str = date.today().isoformat()
    logger.info(f"æ­£åœ¨ä¸º {today_str} æ·»åŠ ç›˜ä¸­ä»»åŠ¡...")
 
    scheduler.add_job(
        run_job_wrapper, 
        'interval', 
        seconds=5, 
        start_date=f'{today_str} 09:30:01', 
        end_date=f'{today_str} 14:57:00', 
        args=[monitoring_job, 'ç›˜ä¸­ç›‘æ§'],
        id=job_id_monitor, # **ç»™ä»»åŠ¡ä¸€ä¸ªå”¯ä¸€çš„ID**
        replace_existing=True # å¦‚æœIDå·²å­˜åœ¨ï¼Œåˆ™æ›¿æ¢
    )
 
    scheduler.add_job(
        run_job_wrapper, 
        'interval', 
        seconds=10, 
        start_date=f'{today_str} 09:30:00', 
        end_date=f'{today_str} 15:00:00', 
        args=[update_order_status_job, 'æ›´æ–°è®¢å•çŠ¶æ€'],
        id=job_id_order_status, # **ç»™ä»»åŠ¡ä¸€ä¸ªå”¯ä¸€çš„ID**
        replace_existing=True
    )
    logger.info("å½“æ—¥ç›˜ä¸­ä»»åŠ¡å·²æˆåŠŸè°ƒåº¦ã€‚")
 
 
# æ¸…ç†ä»»åŠ¡çš„å‡½æ•°ï¼Œè™½ç„¶ replace_existing=Trueä¹Ÿèƒ½å·¥ä½œï¼Œä½†æ˜¾å¼æ¸…ç†æ›´å¹²å‡€
def cleanup_intraday_jobs():
    """æ”¶ç›˜åæ¸…ç†ï¼Œä»¥é˜²ä¸‡ä¸€ã€‚"""
    try:
        scheduler.remove_job('intraday_monitoring_job')
        scheduler.remove_job('intraday_order_status_job')
        logger.info("å·²æ¸…ç†å½“æ—¥ç›˜ä¸­ä»»åŠ¡ã€‚")
    except Exception:
        pass

# é‚®ä»¶å‘é€ä»»åŠ¡
def email_jobs():
    """æ¯å¤©å‘é€è®¡åˆ’é‚®ä»¶"""
    today = date.today()
    service = EmailNotificationService(today)
    service.runEmailSend()


def start():
    """å¯åŠ¨è°ƒåº¦å™¨çš„ä¸»å‡½æ•°"""
    if config_loader.get('scheduler', {}).get('status') == 'off':
        logger.info("è°ƒåº¦å™¨çŠ¶æ€ä¸º 'off'ï¼Œä¸å¯åŠ¨ã€‚")
        return

    if scheduler.running:
        logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­ã€‚")
        return

    # æ·»åŠ ä»»åŠ¡
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=19, minute=0, args=[selection_job, 'æ—¥ç»ˆé€‰è‚¡'])
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=6, minute=10, args=[premarket_fix_job, 'ç›˜å‰æ ¡å‡†'])
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=6, minute=30, args=[email_jobs, 'é¢„æ¡ˆæ¨é€'])
    #scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=9, minute=25, second=5, args=[opening_decision_job, 'å¼€ç›˜å†³ç­–'])
    
    # --- æ¯æ—¥åŠ¨æ€ä»»åŠ¡çš„è°ƒåº¦å™¨ ---
    # åœ¨æ¯ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜å‰ï¼ˆä¾‹å¦‚9:00ï¼‰å®‰æ’å¥½å½“å¤©çš„ç›˜ä¸­ä»»åŠ¡
    #scheduler.add_job(schedule_intraday_jobs, 'cron', day='*', hour=9, minute=0)
    #åœ¨æ”¶ç›˜åæ¸…ç†
    #scheduler.add_job(cleanup_intraday_jobs, 'cron', day='*', hour=15, minute=5)
    
    # æ•°æ®å’Œè¿æ¥ç®¡ç†ä»»åŠ¡
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=6, minute=0, args=[update_corporate_actions_job, 'æ›´æ–°é™¤æƒé™¤æ¯'])
    #scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=15, minute=30, args=[disconnect_job, 'æ–­å¼€è¿æ¥'])
    # today_str = date.today().isoformat()
    # scheduler.add_job(
    #     run_job_wrapper, 
    #     'interval', 
    #     seconds=10, 
    #     start_date=f'{today_str} 07:30:00', 
    #     end_date=f'{today_str} 19:30:00',
    #     args=[update_order_status_job, 'æ›´æ–°è®¢å•çŠ¶æ€'],
    #     id='job_id_order_status', # **ç»™ä»»åŠ¡ä¸€ä¸ªå”¯ä¸€çš„ID**
    #     replace_existing=True
    # )
    logger.info("APScheduler å·²é…ç½®å®Œæˆï¼Œå‡†å¤‡åœ¨åå°å¯åŠ¨...")
    scheduler.start()

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\simulate_trade.py####
# ==============================================================================
# æ–‡ä»¶ 4/5: trade_manager/service/simulate_trade.py (ä¿®æ”¹)
# æè¿°: æ ¸å¿ƒå›æµ‹æœåŠ¡ï¼Œé›†æˆæ—¥å¿—è®°å½•å’Œé‚®ä»¶å‘é€ã€‚
# ==============================================================================
# trade_manager/service/simulate_trade.py

import logging
from datetime import date, timedelta, datetime
from decimal import Decimal
import numpy as np
import pandas as pd
from django.db import connections, transaction
from django.core.management import call_command

# å†…éƒ¨æ¨¡å—å¯¼å…¥
from common.models import (
    DailyFactorValues, DailyTradingPlan, Position, TradeLog, SystemLog,
    StrategyParameters, DailyQuotes, CorporateAction
)
# æ–°å¢å¯¼å…¥
from common.models.backtest_logs import BacktestDailyLog, BacktestOperationLog 
from selection_manager.service.selection_service import SelectionService, MARKET_INDICATOR_CODE
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.monitor_exit_service import MonitorExitService
from .simulate_trade_handler import SimulateTradeHandler
from .db_utils import use_backtest_schema
from .backtest_reporter import BacktestReporter 
from .position_monitor_logic import PositionMonitorLogic

logger = logging.getLogger(__name__)

class SimulateTradeService:
    """
    å›æµ‹å®æ–½æœåŠ¡ (V3 - é›†æˆæ—¥å¿—ä¸æŠ¥å‘Š)ã€‚
    """
    COMMISSION_RATE = Decimal('0.0002854')
    MIN_COMMISSION = Decimal('5')
    STAMP_DUTY_RATE = Decimal('0.001')
    SELL_SLIPPAGE_RATE = Decimal('0.002')

    def __init__(self):
        self.start_date: date = None
        self.end_date: date = None
        self.current_date: date = None
        self.initial_capital = Decimal('0.0')
        self.cash_balance = Decimal('0.0')
        self.portfolio_history = []
        self.last_buy_trade_id = None
        self.backtest_run_id: str = None # æ–°å¢ï¼šå›æµ‹å”¯ä¸€ID
        self.params: dict = {}
    def _persist_risk_prices_if_changed(self, position, new_sl, new_tp, label='ç›˜ä¸­'):
        if new_sl != position.current_stop_loss or new_tp != position.current_take_profit:
            position.current_stop_loss = new_sl
            position.current_take_profit = new_tp
            position.save(update_fields=['current_stop_loss', 'current_take_profit'])
            logger.info(f"[å›æµ‹] {position.stock_code_id} {label}æ›´æ–°é£æ§ä»·æ ¼ã€‚SL: {position.current_stop_loss:.2f}, TP: {position.current_take_profit:.2f}")
    def _load_parameters(self):
        """åœ¨å›æµ‹å¼€å§‹å‰åŠ è½½æ‰€æœ‰éœ€è¦çš„ç­–ç•¥å‚æ•°ã€‚"""
        logger.info("åŠ è½½å›æµ‹æ‰€éœ€ç­–ç•¥å‚æ•°...")
        # ä» StrategyParameters è¡¨ä¸­ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å‚æ•°
        all_params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
        
        # å®šä¹‰å›æµ‹é€»è¾‘ä¸­éœ€è¦ç”¨åˆ°çš„å‚æ•°åŠå…¶é»˜è®¤å€¼
        required_params = {
            'trailing_tp_increment_pct': '0.02',
            'trailing_sl_buffer_pct': '0.01',
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–æœªæ¥å¯èƒ½ç”¨åˆ°çš„å‚æ•°
        }
        for key, default_value in required_params.items():
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“çš„å€¼ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
            self.params[key] = all_params.get(key, Decimal(default_value))
        
        logger.info(f"ç­–ç•¥å‚æ•°åŠ è½½å®Œæˆ: {self.params}")
    def _setup_backtest_schema(self, schema_name: str, initial_capital: Decimal):
        logger.info(f"--- 1. åœ¨ Schema '{schema_name}' ä¸­å‡†å¤‡å›æµ‹ç¯å¢ƒ ---")
        
        logger.info("æ­£åœ¨æ–° Schema ä¸­åˆ›å»ºè¡¨ç»“æ„ (æ‰§è¡Œ migrate)...")
        with connections['default'].cursor() as cursor:
            logger.info(f"ä¸´æ—¶éš”ç¦» search_path åˆ° '{schema_name}' ä»¥ä¾¿è¿è¡Œ migrate å‘½ä»¤ã€‚")
            cursor.execute(f'SET search_path TO "{schema_name}";')
            
            logger.info("æ­£åœ¨æ–° Schema ä¸­åˆ›å»ºè¡¨ç»“æ„ (æ‰§è¡Œ migrate)...")
            # åœ¨è¿™ä¸ªéš”ç¦»çš„ç¯å¢ƒä¸‹ï¼Œmigrate çœ‹ä¸åˆ° public.django_migrationsï¼Œå› æ­¤ä¼šåˆ›å»ºæ‰€æœ‰è¡¨ã€‚
            call_command('migrate')
            logger.info("è¡¨ç»“æ„åˆ›å»ºå®Œæˆã€‚")

        tables_to_copy = [
            'tb_stock_info', 'tb_daily_quotes', 'tb_corporate_actions',
            'tb_factor_definitions', 'tb_strategy_parameters', 
            'tb_daily_factor_values','tb_daily_trading_plan','tb_index_quotes_csi300'
        ]
        
        logger.info(f"å‡†å¤‡ä» 'public' schema å¤åˆ¶åŸºç¡€æ•°æ®åˆ° '{schema_name}'...")
        with transaction.atomic(), connections['default'].cursor() as cursor:
            cursor.execute(f'SET search_path TO "{schema_name}";')
            for table_name in tables_to_copy:
                logger.info(f"  - æ­£åœ¨å¤„ç†è¡¨: {table_name}")
                # 1. åŒºåˆ†å¹¶è·å– "æ™®é€šç´¢å¼•" å’Œ "çº¦æŸ"
                # =========================================================================
                # 1a. è·å–æ™®é€šç´¢å¼• (ä¸åŒ…æ‹¬ç”± UNIQUE æˆ– PRIMARY KEY çº¦æŸåˆ›å»ºçš„ç´¢å¼•)
                logger.info(f"    - æ­£åœ¨è·å– '{table_name}' çš„æ™®é€šç´¢å¼•...")
                cursor.execute("""
                    SELECT indexdef
                    FROM pg_indexes
                    WHERE schemaname = %s AND tablename = %s
                    AND indexname NOT IN (
                        SELECT conname FROM pg_constraint WHERE conrelid = %s::regclass
                    );
                """, [schema_name, table_name, f'"{schema_name}"."{table_name}"'])
                plain_indexes_to_recreate = [row[0] for row in cursor.fetchall()]
                # 1b. è·å–çº¦æŸ (å¤–é”®å’Œå”¯ä¸€çº¦æŸ)
                logger.info(f"    - æ­£åœ¨è·å– '{table_name}' çš„å¤–é”®å’Œå”¯ä¸€çº¦æŸ...")
                cursor.execute("""
                    SELECT 'ALTER TABLE ' || quote_ident(conrelid::regclass::text) || ' ADD CONSTRAINT ' || quote_ident(conname) || ' ' || pg_get_constraintdef(oid)
                    FROM pg_constraint
                    WHERE contype IN ('f', 'u') AND conrelid = %s::regclass;
                """, [f'"{schema_name}"."{table_name}"'])
                constraints_to_recreate = [row[0] for row in cursor.fetchall()]
                # 2. åˆ é™¤ç´¢å¼•å’Œçº¦æŸ (åˆ é™¤çº¦æŸä¼šè‡ªåŠ¨åˆ é™¤å…¶åº•å±‚ç´¢å¼•)
                # =========================================================================
                # 2a. åˆ é™¤çº¦æŸ
                for const_def in constraints_to_recreate:
                    const_name = const_def.split('ADD CONSTRAINT ')[1].split(' ')[0]
                    logger.info(f"      - åˆ é™¤çº¦æŸ: {const_name}")
                    cursor.execute(f'ALTER TABLE "{table_name}" DROP CONSTRAINT IF EXISTS {const_name};')
                
                # 2b. åˆ é™¤æ™®é€šç´¢å¼•
                for index_def in plain_indexes_to_recreate:
                    # ä» "CREATE INDEX index_name ON ..." ä¸­æå– index_name
                    try:
                        index_name = index_def.split(' ')[2]
                        logger.info(f"      - åˆ é™¤ç´¢å¼•: {index_name}")
                        cursor.execute(f'DROP INDEX IF EXISTS "{index_name}";')
                    except IndexError:
                        logger.warning(f"æ— æ³•ä» '{index_def}' è§£æç´¢å¼•åç§°ï¼Œè·³è¿‡åˆ é™¤ã€‚")
                # 3. é«˜æ•ˆå¤åˆ¶æ•°æ® (ç°åœ¨éå¸¸å¿«)
                # =========================================================================
                logger.info(f"    - æ­£åœ¨ä» public.{table_name} å¤åˆ¶æ•°æ®...")
                sql = f'INSERT INTO "{table_name}" SELECT * FROM public."{table_name}";'
                cursor.execute(sql)
                logger.info(f"    - æ•°æ®å¤åˆ¶å®Œæˆã€‚")
                # 4. é‡å»ºç´¢å¼•å’Œçº¦æŸ
                # =========================================================================
                logger.info(f"    - æ­£åœ¨é‡å»º '{table_name}' çš„ç´¢å¼•å’Œçº¦æŸ...")
                # 4a. é‡å»ºæ™®é€šç´¢å¼•
                for index_def in plain_indexes_to_recreate:
                    logger.info(f"      - é‡å»ºç´¢å¼•: {index_def}")
                    cursor.execute(index_def)
                
                # 4b. é‡å»ºçº¦æŸ (è¿™ä¼šè‡ªåŠ¨é‡å»ºå®ƒä»¬çš„åº•å±‚ç´¢å¼•)
                for const_def in constraints_to_recreate:
                    logger.info(f"      - é‡å»ºçº¦æŸ: {const_def}")
                    cursor.execute(const_def)

                # =========================================================================
                # 5. é‡ç½®è‡ªå¢ä¸»é”®åºåˆ— (è§£å†³ä¸»é”®å†²çªçš„å…³é”®)
                # =========================================================================
                # è‡ªåŠ¨æŸ¥æ‰¾å¹¶æ›´æ–°å½“å‰è¡¨çš„è‡ªå¢åºåˆ—
                find_serial_sql = """
                    SELECT 
                        a.attname, 
                        pg_get_serial_sequence(
                            quote_ident(n.nspname) || '.' || quote_ident(c.relname), 
                            a.attname
                        )
                    FROM 
                        pg_class c
                    JOIN 
                        pg_attribute a ON a.attrelid = c.oid
                    JOIN 
                        pg_namespace n ON c.relnamespace = n.oid -- é€šè¿‡namespace OIDå…³è”
                    WHERE 
                        n.nspname = %s      -- å‚æ•°1: schemaçš„åç§°
                        AND c.relname = %s  -- å‚æ•°2: è¡¨çš„åç§°
                        AND a.attnum > 0 
                        AND NOT a.attisdropped
                        AND pg_get_serial_sequence(quote_ident(n.nspname) || '.' || quote_ident(c.relname), a.attname) IS NOT NULL;
                """
                cursor.execute(find_serial_sql, [schema_name, table_name])
                serial_columns = cursor.fetchall()

                for column_name, sequence_name in serial_columns:
                    logger.info(f"    - å‘ç°è‡ªå¢åˆ— '{column_name}'ï¼Œæ­£åœ¨é‡ç½®å…¶åºåˆ— '{sequence_name}'...")
                    
                    # å°†åºåˆ—çš„ä¸‹ä¸€ä¸ªå€¼è®¾ç½®ä¸º (è¡¨ä¸­è¯¥åˆ—çš„æœ€å¤§å€¼ + 1)ï¼Œå¦‚æœè¡¨ä¸ºç©ºåˆ™è®¾ç½®ä¸º1
                    update_sequence_sql = f"""
                        SELECT setval(
                            '{sequence_name}', 
                            COALESCE((SELECT MAX("{column_name}") FROM "{table_name}"), 0) + 1, 
                            true
                        )
                    """
                    cursor.execute(update_sequence_sql)
                    logger.info(f"    - åºåˆ— '{sequence_name}' å·²æ›´æ–°ã€‚")

                
        logger.info("åŸºç¡€æ•°æ®å¤åˆ¶å®Œæˆã€‚")
        # with connections['default'].cursor() as cursor:
        #     for table_name in tables_to_copy:
        #         logger.info(f"  - æ­£åœ¨å¤åˆ¶è¡¨: {table_name}")
        #         sql = f'INSERT INTO "{schema_name}"."{table_name}" SELECT * FROM public."{table_name}";'
        #         cursor.execute(sql)
        # logger.info("åŸºç¡€æ•°æ®å¤åˆ¶å®Œæˆã€‚")

        self.initial_capital = initial_capital
        self.cash_balance = self.initial_capital
        logger.info(f"åˆå§‹èµ„é‡‘å·²è®¾å®šä¸º: {self.initial_capital:.2f}")

    def _simulate_intraday_monitoring(self, position: Position, daily_quote: DailyQuotes):
        open_p, high_p, low_p = daily_quote.open, daily_quote.high, daily_quote.low
        
        # ä¸´æ—¶å˜é‡ï¼Œæ¨¡æ‹Ÿç›˜ä¸­çŠ¶æ€
        temp_position_state = {
            'current_stop_loss': position.current_stop_loss,
            'current_take_profit': position.current_take_profit
        }
        
        # 1. å¼€ç›˜ä»·æ£€æŸ¥
        decision = PositionMonitorLogic.check_and_decide(position, open_p, self.params)
        if decision['action'] == 'SELL':
            price=min(open_p,decision['exit_price'])
            logger.info(f"[å›æµ‹] {position.stock_code_id} å¼€ç›˜ä»· {open_p:.2f} è§¦å‘å–å‡ºï¼Œæˆäº¤ä»· {decision['exit_price']:.2f}")
            self._persist_risk_prices_if_changed(
                position,
                temp_position_state['current_stop_loss'],
                temp_position_state['current_take_profit'],
                label='ç›˜ä¸­'
            )
            logger.info(f"[å›æµ‹] {position.stock_code_id} å¼€ç›˜ä»· {open_p:.2f} è§¦å‘å–å‡ºï¼Œæˆäº¤ä»· {price:.2f}")
            self.handler.sell_stock_by_market_price(position, decision['reason'], simulated_exit_price=price)
            return
        elif decision['action'] == 'UPDATE':
            temp_position_state.update(decision['updates'])
        # 2. æ—¥å†…å¾ªç¯ç›‘æ§
        while True:
            action_taken_in_loop = False
            
            # æ£€æŸ¥ç‚¹1: æœ€ä½ä»·æ˜¯å¦è§¦å‘å–å‡º
            decision_low = PositionMonitorLogic.check_and_decide(
                Position( # ä¼ å…¥ä¸€ä¸ªä¸´æ—¶çš„ã€åŒ…å«æœ€æ–°çŠ¶æ€çš„Positionå¯¹è±¡
                    entry_price=position.entry_price,
                    current_stop_loss=temp_position_state['current_stop_loss'],
                    current_take_profit=temp_position_state['current_take_profit']
                ), 
                low_p, 
                self.params
            )
            if decision_low['action'] == 'SELL':
                self._persist_risk_prices_if_changed(
                    position,
                    temp_position_state['current_stop_loss'],
                    temp_position_state['current_take_profit'],
                    label='ç›˜ä¸­'
                )
                logger.info(f"[å›æµ‹] {position.stock_code_id} æœ€ä½ä»· {low_p:.2f} è§¦å‘å–å‡ºï¼Œæˆäº¤ä»· {decision_low['exit_price']:.2f}")
                self.handler.sell_stock_by_market_price(position, decision_low['reason'], simulated_exit_price=decision_low['exit_price'])
                return
            # æ£€æŸ¥ç‚¹2: æœ€é«˜ä»·æ˜¯å¦è§¦å‘ä»·æ ¼æ›´æ–°
            decision_high = PositionMonitorLogic.check_and_decide(
                Position(
                    entry_price=position.entry_price,
                    current_stop_loss=temp_position_state['current_stop_loss'],
                    current_take_profit=temp_position_state['current_take_profit']
                ), 
                high_p, 
                self.params
            )
            if decision_high['action'] == 'UPDATE':
                # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„æ›´æ–°
                if temp_position_state != decision_high['updates']:
                    temp_position_state.update(decision_high['updates'])
                    action_taken_in_loop = True
            if not action_taken_in_loop:
                break
                
        # 3. æ—¥ç»ˆç»“ç®—
        if temp_position_state['current_stop_loss'] != position.current_stop_loss or \
        temp_position_state['current_take_profit'] != position.current_take_profit:
            position.current_stop_loss = temp_position_state['current_stop_loss']
            position.current_take_profit = temp_position_state['current_take_profit']
            position.save(update_fields=['current_stop_loss', 'current_take_profit'])
            logger.info(f"[å›æµ‹] {position.stock_code_id} æ—¥ç»ˆæ›´æ–°é£æ§ä»·æ ¼ã€‚SL: {position.current_stop_loss:.2f}, TP: {position.current_take_profit:.2f}")

    def run_backtest(self, start_date: str, end_date: str, initial_capital: Decimal) -> dict:
        self.start_date = date.fromisoformat(start_date)
        self.end_date = date.fromisoformat(end_date)
        self.backtest_run_id = f"backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"ä¸ºæœ¬æ¬¡å›æµ‹åˆ›å»ºä¸´æ—¶ Schema: {self.backtest_run_id}")

        try:
            with connections['default'].cursor() as cursor:
                cursor.execute(f'CREATE SCHEMA IF NOT EXISTS "{self.backtest_run_id}";')

            with use_backtest_schema(self.backtest_run_id):
                self._setup_backtest_schema(self.backtest_run_id, initial_capital)
                self._load_parameters()
                handler = SimulateTradeHandler(self)
                self.handler=handler
                trading_days = self._get_trading_days()
                if not trading_days:
                    logger.error("åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•äº¤æ˜“æ—¥ï¼Œå›æµ‹ç»ˆæ­¢ã€‚")
                    return {}
                #master_panels = self._preload_data_for_backtest(trading_days)
                logger.info("--- [æ»šåŠ¨çª—å£] å¼€å§‹å‡†å¤‡æ•°æ® ---")
                lookback_window_size = 250  # å› å­è®¡ç®—æ‰€éœ€çš„æœ€å¤§å›æº¯æœŸ
                # ä¸ºäº†ä¿è¯æœ‰è¶³å¤Ÿçš„äº¤æ˜“æ—¥ï¼Œæˆ‘ä»¬å›æº¯æ›´å¤šçš„è‡ªç„¶æ—¥
                extra_buffer_days = 20 
                
                # 1. ç›´æ¥è®¡ç®—é¢„åŠ è½½çš„èµ·å§‹æ—¥æœŸï¼Œä¸å†æ‰«æå…¨è¡¨
                preload_start_date = trading_days[0] - timedelta(days=lookback_window_size + extra_buffer_days)
                
                logger.info(f"ä¸€æ¬¡æ€§æŸ¥è¯¢æ•°æ®åº“ï¼Œæ—¶é—´çª—å£: {preload_start_date} to {self.end_date}")
                
                quotes_iterator = DailyQuotes.objects.filter(
                    trade_date__gte=preload_start_date,
                    trade_date__lte=self.end_date
                ).order_by('trade_date', 'stock_code_id').values(
                    'trade_date', 'stock_code_id', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close'
                ).iterator(chunk_size=20000)
                logger.info("å°†è¿­ä»£å™¨æ•°æ®æŒ‰æ—¥æœŸåˆ†ç»„åˆ°å­—å…¸ä¸­...")
                quotes_by_date = {}
                for row in quotes_iterator:
                    trade_date = row['trade_date']
                    if trade_date not in quotes_by_date:
                        quotes_by_date[trade_date] = []
                    quotes_by_date[trade_date].append(row)
                
                # 2. åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ»šåŠ¨çª—å£
                logger.info("åˆå§‹åŒ–ç¬¬ä¸€ä¸ªæ»šåŠ¨çª—å£é¢æ¿...")
                # è·å–æ‰€æœ‰å·²åŠ è½½çš„æ—¥æœŸï¼Œå¹¶æ’åº
                all_loaded_dates = sorted(quotes_by_date.keys())
                
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå›æµ‹æ—¥
                first_backtest_day = trading_days[0]
                
                # ä»å·²åŠ è½½çš„æ—¥æœŸä¸­ï¼Œç­›é€‰å‡ºç”¨äºåˆå§‹åŒ–çš„éƒ¨åˆ†
                initial_window_dates = [d for d in all_loaded_dates if d <= first_backtest_day]
                initial_rows = []
                for d in initial_window_dates:
                    initial_rows.extend(quotes_by_date.get(d, []))
                
                if not initial_rows:
                    raise ValueError("åˆå§‹åŒ–æ»šåŠ¨çª—å£å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®ã€‚")
                df_window = pd.DataFrame(initial_rows)
                df_window['trade_date'] = pd.to_datetime(df_window['trade_date'])
                
                rolling_panels = {}
                for col in ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']:
                    panel = df_window.pivot(index='trade_date', columns='stock_code_id', values=col).astype(float)
                    rolling_panels[col] = panel
                
                logger.info(f"æ»šåŠ¨çª—å£åˆå§‹åŒ–å®Œæˆï¼ŒåŒ…å« {len(initial_window_dates)} å¤©æ•°æ®ã€‚")
                logger.info(f"--- 2. å¼€å§‹æ—¥åº¦å›æµ‹å¾ªç¯ ({len(trading_days)}å¤©) ---")
                
                last_sent_month = None # ç”¨äºé‚®ä»¶è§¦å‘

                for i, current_day in enumerate(trading_days):
                    self.current_date = current_day
                    logger.info(f"\n{'='*20} æ¨¡æ‹Ÿæ—¥: {self.current_date} ({i+1}/{len(trading_days)}) {'='*20}")
                    if i > 0:
                        # æ£€æŸ¥æ–°çš„ä¸€å¤©æ˜¯å¦æœ‰æ•°æ®ï¼Œæœ‰æ‰æ»šåŠ¨
                        new_day_data = quotes_by_date.get(current_day)
                        if new_day_data:
                            logger.debug(f"æ»šåŠ¨çª—å£: ç§»é™¤ {rolling_panels['close'].index[0].date()}, æ·»åŠ  {current_day}")
                            # ç§»é™¤æœ€è€çš„ä¸€å¤©
                            for key in rolling_panels:
                                rolling_panels[key] = rolling_panels[key].iloc[1:]
                            
                            # æ·»åŠ æ–°çš„ä¸€å¤©
                            df_new_day = pd.DataFrame(new_day_data)
                            df_new_day['trade_date'] = pd.to_datetime(df_new_day['trade_date'])
                            
                            for col in ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']:
                                new_row = df_new_day.pivot(index='trade_date', columns='stock_code_id', values=col).astype(float)
                                # ä½¿ç”¨ pd.concat åˆå¹¶ï¼Œæ¯” append æ›´æ¨è
                                rolling_panels[col] = pd.concat([rolling_panels[col], new_row])
                        else:
                            logger.warning(f"æ—¥æœŸ {current_day} åœ¨é¢„åŠ è½½æ•°æ®ä¸­ä¸å­˜åœ¨ï¼Œçª—å£æœªæ»šåŠ¨ã€‚")

                    logger.info("-> [Tæ—¥ ç›˜å‰æ ¡å‡†] ...")
                    before_fix_service = BeforeFixService(execution_date=self.current_date)
                    before_fix_service.run()
                    
                    self._handle_dividends()

                    logger.info("-> [Tæ—¥ å¼€ç›˜å†³ç­–ä¸ä¹°å…¥] ...")
                    decision_order_service = DecisionOrderService(handler=handler, execution_date=self.current_date)
                    decision_order_service.adjust_trading_plan_daily()
                    
                    while True:
                        open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
                        max_pos = decision_order_service.current_max_positions
                        if open_positions_count >= max_pos: break
                        
                        self.last_buy_trade_id = None
                        decision_order_service.execute_orders()
                        
                        if self.last_buy_trade_id:
                            decision_order_service.calculate_stop_profit_loss(self.last_buy_trade_id)
                            # åœ¨æ­¢ç›ˆæ­¢æŸè®¡ç®—å®Œæ¯•åï¼Œè·å–æ›´æ–°åçš„æŒä»“å¯¹è±¡
                            trade_log = TradeLog.objects.get(pk=self.last_buy_trade_id)
                            position = trade_log.position
                            # ç°åœ¨æ‰è°ƒç”¨æ—¥å¿—è®°å½•å‡½æ•°ï¼Œæ­¤æ—¶ position å¯¹è±¡å·²åŒ…å«æ­£ç¡®çš„æ­¢ç›ˆæ­¢æŸä»·
                            handler._record_buy_operation(position)
                        else:
                            break

                    positions_to_monitor = Position.objects.filter(status=Position.StatusChoices.OPEN).exclude(
                        entry_datetime__date=self.current_date
                    )
                
                    for pos in positions_to_monitor:
                        # å¦‚æœæŒä»“å·²åœ¨å¾ªç¯ä¸­è¢«å–å‡ºï¼Œåˆ™è·³è¿‡
                        if pos.status != Position.StatusChoices.OPEN:
                            continue
                        
                        try:
                            daily_quote = DailyQuotes.objects.get(stock_code_id=pos.stock_code_id, trade_date=self.current_date)
                            self._simulate_intraday_monitoring(pos, daily_quote)
                        except DailyQuotes.DoesNotExist:
                            logger.warning(f"[å›æµ‹] æ— æ³•æ‰¾åˆ° {pos.stock_code_id} åœ¨ {self.current_date} çš„è¡Œæƒ…ï¼Œå½“æ—¥æ— æ³•ç›‘æ§ã€‚")
                            continue

                    


                    logger.info(f"-> [Tæ—¥ ç›˜åé€‰è‚¡] åŸºäº {self.current_date} çš„æ•°æ®ä¸ºä¸‹ä¸€äº¤æ˜“æ—¥åšå‡†å¤‡...")
                    current_day_dt = pd.to_datetime(current_day)
                    selection_service = SelectionService(trade_date=self.current_date, mode='backtest',preloaded_panels=rolling_panels)
                    selection_service.run_selection()
                    
                    self._record_daily_log()

                    # --- é‚®ä»¶å‘é€é€»è¾‘ ---
                    is_last_day = (i == len(trading_days) - 1)
                    current_month = current_day.month
                    send_mail_flag = False

                    if is_last_day:
                        send_mail_flag = True
                        logger.info("å›æµ‹ç»“æŸï¼Œè§¦å‘æœ€ç»ˆé‚®ä»¶æŠ¥å‘Šã€‚")
                    elif last_sent_month is not None and current_month != last_sent_month:
                        send_mail_flag = True
                        logger.info(f"æœˆä»½ä» {last_sent_month} å˜ä¸º {current_month}ï¼Œè§¦å‘æœˆåº¦é‚®ä»¶æŠ¥å‘Šã€‚")
                    
                    if send_mail_flag:
                        reporter = BacktestReporter(
                            schema_name=self.backtest_run_id,
                            start_date=self.start_date,
                            current_date=self.current_date,
                            initial_capital=self.initial_capital
                        )
                        reporter.send_report()
                    
                    last_sent_month = current_month
                    # --- é‚®ä»¶å‘é€é€»è¾‘ç»“æŸ ---

                logger.info("--- 3. å›æµ‹å¾ªç¯ç»“æŸ ---")
                return self._calculate_performance_metrics()

        except Exception as e:
            logger.critical(f"å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            return {"error": str(e)}

    def _get_trading_days(self) -> list[date]:
        dates = DailyQuotes.objects.filter(
            trade_date__gte=self.start_date,
            trade_date__lte=self.end_date
        ).values_list('trade_date', flat=True).distinct().order_by('trade_date')
        return list(dates)

    def _handle_dividends(self):
        dividend_events = CorporateAction.objects.filter(
            ex_dividend_date=self.current_date, event_type=CorporateAction.EventType.DIVIDEND
        )
        if not dividend_events.exists(): return

        events_by_stock = {}
        for event in dividend_events:
            events_by_stock.setdefault(event.stock_code, []).append(event)
        
        open_positions = Position.objects.filter(
            stock_code_id__in=events_by_stock.keys(), status=Position.StatusChoices.OPEN
        )
        for pos in open_positions:
            for event in events_by_stock.get(pos.stock_code_id, []):
                dividend_amount = event.dividend_per_share * pos.quantity
                self.cash_balance += dividend_amount
                logger.info(f"é™¤æ¯äº‹ä»¶: æŒä»“ID {pos.position_id} ({pos.stock_code_id}) è·å¾—åˆ†çº¢ {dividend_amount:.2f}")

    def _record_daily_log(self):
        open_positions = Position.objects.filter(status=Position.StatusChoices.OPEN)
        market_value = Decimal('0.0')
        for pos in open_positions:
            try:
                quote = DailyQuotes.objects.get(stock_code_id=pos.stock_code_id, trade_date=self.current_date)
                market_value += quote.close * pos.quantity
            except DailyQuotes.DoesNotExist:
                market_value += pos.entry_price * pos.quantity
        
        total_assets = self.cash_balance + market_value

        try:
            m_value_obj = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                factor_code_id='dynamic_M_VALUE',
                trade_date=self.current_date
            )
            m_value = m_value_obj.raw_value
        except DailyFactorValues.DoesNotExist:
            m_value = None

        BacktestDailyLog.objects.create(
            backtest_run_id=self.backtest_run_id,
            trade_date=self.current_date,
            total_assets=total_assets,
            cash=self.cash_balance,
            holdings_value=market_value,
            market_m_value=m_value
        )
        logger.info(f"--- æ—¥ç»ˆç»“ç®— ({self.current_date}) ---")
        logger.info(f"ç°é‡‘: {self.cash_balance:.2f}, æŒä»“å¸‚å€¼: {market_value:.2f}, æ€»èµ„äº§: {total_assets:.2f}, Må€¼: {m_value}")

    def _calculate_performance_metrics(self) -> dict:
        logger.info("--- 4. è®¡ç®—å›æµ‹æ€§èƒ½æŒ‡æ ‡ ---")
        daily_logs = BacktestDailyLog.objects.filter(backtest_run_id=self.backtest_run_id).order_by('trade_date')
        if not daily_logs.exists():
            return {}

        df = pd.DataFrame(list(daily_logs.values('total_assets')))
        df['total_assets'] = df['total_assets'].astype(float)
        
        final_value = df['total_assets'].iloc[-1]
        total_return_rate = (final_value / float(self.initial_capital)) - 1
        
        total_days = (self.end_date - self.start_date).days
        if total_days > 0:
            annualized_return = ((final_value / float(self.initial_capital)) ** (365.0 / total_days)) - 1
        else:
            annualized_return = 0.0

        df['peak'] = df['total_assets'].cummax()
        df['drawdown'] = (df['total_assets'] - df['peak']) / df['peak']
        max_drawdown = df['drawdown'].min()

        result = {
            'total_return_rate': f"{total_return_rate:.2%}",
            'annualized_return': f"{annualized_return:.2%}",
            'max_drawdown': f"{max_drawdown:.2%}"
        }
        logger.info(f"æœ€ç»ˆå›æµ‹ç»“æœ: {result}")
        return result


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\simulate_trade_handler.py####
# ==============================================================================
# æ–‡ä»¶ 5/5: trade_manager/service/simulate_trade_handler.py (ä¿®æ”¹)
# æè¿°: æ¨¡æ‹Ÿäº¤æ˜“å¤„ç†å™¨ï¼Œé›†æˆæ“ä½œæ—¥å¿—è®°å½•ã€‚
# ==============================================================================
# trade_manager/service/simulate_trade_handler.py

import logging
from datetime import time, timedelta
from decimal import Decimal, ROUND_HALF_UP
from datetime import date, timedelta, datetime
from django.db import transaction
from django.utils import timezone

from .trade_handler import ITradeHandler
from common.models import Position, TradeLog, DailyQuotes, StockInfo, DailyFactorValues
from common.models.backtest_logs import BacktestOperationLog # æ–°å¢å¯¼å…¥
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE # æ–°å¢å¯¼å…¥

from typing import TYPE_CHECKING, Literal
if TYPE_CHECKING:
    from .simulate_trade import SimulateTradeService

logger = logging.getLogger(__name__)

class SimulateTradeHandler(ITradeHandler):
    """
    æ¨¡æ‹Ÿäº¤æ˜“å¤„ç†å™¨ (SimulateTradeHandler) - é›†æˆæ“ä½œæ—¥å¿—ã€‚
    """

    def __init__(self, service: 'SimulateTradeService'):
        self.service = service
        self.current_price_node: Literal['OPEN', 'LOW', 'HIGH', 'CLOSE'] = 'CLOSE'

    def get_opening_price(self, stock_code: str) -> Decimal:
        try:
            quote = DailyQuotes.objects.get(
                stock_code_id=stock_code,
                trade_date=self.service.current_date
            )
            return quote.open
        except DailyQuotes.DoesNotExist:
            logger.warning(f"[å›æµ‹] æ— æ³•åœ¨ {self.service.current_date} æ‰¾åˆ° {stock_code} çš„è¡Œæƒ…æ•°æ®ï¼Œè¿”å›0ã€‚")
            return Decimal('0.00')

    def get_realtime_price(self, stock_code: str) -> Decimal | None:
        try:
            quote = DailyQuotes.objects.get(
                stock_code_id=stock_code,
                trade_date=self.service.current_date
            )
            if self.current_price_node == 'LOW':
                return quote.low
            elif self.current_price_node == 'HIGH':
                return quote.high
            else:
                return quote.close
        except DailyQuotes.DoesNotExist:
            return None

    def get_available_balance(self) -> Decimal:
        return self.service.cash_balance

    @transaction.atomic
    def place_buy_order(self, stock_code: str, price: Decimal, quantity: int) -> None:
        amount = price * quantity
        commission = max(amount * self.service.COMMISSION_RATE, self.service.MIN_COMMISSION)
        total_cost = amount + commission

        if self.service.cash_balance < total_cost:
            raise ValueError(f"èµ„é‡‘ä¸è¶³ï¼")

        self.service.cash_balance -= total_cost
        logger.info(f"[å›æµ‹] ä¹°å…¥ {stock_code} {quantity}è‚¡ @{price:.2f}, èŠ±è´¹: {amount:.2f}, ç°é‡‘ä½™é¢: {self.service.cash_balance:.2f}")

        entry_time = time(9, 30, 1)
        entry_datetime = timezone.make_aware(timezone.datetime.combine(self.service.current_date, entry_time))

        new_position = Position.objects.create(
            stock_code_id=stock_code, entry_datetime=entry_datetime, entry_price=price,
            quantity=quantity, status=Position.StatusChoices.OPEN,
            current_stop_loss=Decimal('0.00'), current_take_profit=Decimal('0.00')
        )

        trade_log = TradeLog.objects.create(
            position=new_position, stock_code_id=stock_code, trade_datetime=entry_datetime,
            trade_type=TradeLog.TradeTypeChoices.BUY, order_type=TradeLog.OrderTypeChoices.LIMIT,
            price=price, quantity=quantity, commission=commission,
            reason=TradeLog.ReasonChoices.ENTRY, status=TradeLog.StatusChoices.FILLED
        )
        
        self.service.last_buy_trade_id = trade_log.trade_id

        

    @transaction.atomic
    def sell_stock_by_market_price(self, position: Position, reason: str, simulated_exit_price: Decimal = None) -> None:
        
        if simulated_exit_price is None:
            raise ValueError("å›æµ‹æ¨¡å¼ä¸‹è°ƒç”¨ sell_stock_by_market_price å¿…é¡»æä¾› simulated_exit_price")

        sell_price = (simulated_exit_price * (Decimal('1.0') - self.service.SELL_SLIPPAGE_RATE))
        sell_price = sell_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)

        amount = sell_price * position.quantity
        commission = max(amount * self.service.COMMISSION_RATE, self.service.MIN_COMMISSION)
        stamp_duty = amount * self.service.STAMP_DUTY_RATE
        net_income = amount - commission - stamp_duty

        self.service.cash_balance += net_income
        logger.info(f"[å›æµ‹] å–å‡º {position.stock_code_id} {position.quantity}è‚¡ @{sell_price:.2f}, åŸå› : {reason}, ç°é‡‘ä½™é¢: {self.service.cash_balance:.2f}")

        position.status = Position.StatusChoices.CLOSED
        position.save()

        sell_time = time(14, 57, 0)
        sell_datetime = timezone.make_aware(timezone.datetime.combine(self.service.current_date, sell_time))

        TradeLog.objects.create(
            position=position, stock_code_id=position.stock_code_id, trade_datetime=sell_datetime,
            trade_type=TradeLog.TradeTypeChoices.SELL, order_type=TradeLog.OrderTypeChoices.MARKET,
            price=sell_price, quantity=position.quantity, commission=commission,
            stamp_duty=stamp_duty, reason=reason, status=TradeLog.StatusChoices.FILLED
        )
        
        # --- æ–°å¢: è®°å½•å–å‡ºæ“ä½œæ—¥å¿— ---
        self._record_sell_operation(position, sell_price, reason)
        
    def _get_t_minus_1_date(self) -> date:
        """å®‰å…¨åœ°è·å–T-1äº¤æ˜“æ—¥"""
        try:
            return DailyQuotes.objects.filter(trade_date__lt=self.service.current_date).latest('trade_date').trade_date
        except DailyQuotes.DoesNotExist:
            logger.warning(f"æ— æ³•æ‰¾åˆ° {self.service.current_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ã€‚")
            return self.service.current_date - timedelta(days=1)

    def _record_buy_operation(self, position: Position):
        t_minus_1 = self._get_t_minus_1_date()
        
        # è·å–Må€¼
        try:
            m_value_obj = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                factor_code_id='dynamic_M_VALUE',
                trade_date=t_minus_1
            )
            m_value = m_value_obj.raw_value
        except DailyFactorValues.DoesNotExist:
            m_value = None
        
        # è·å–å› å­å¾—åˆ†
        # æ­¥éª¤1: å…ˆè·å–è¯¥è‚¡ç¥¨å½“å¤©çš„æ‰€æœ‰å› å­å€¼
        all_factor_scores_qs = DailyFactorValues.objects.filter(
            stock_code_id=position.stock_code_id,
            trade_date=t_minus_1
        )
        
        # æ­¥éª¤2: åœ¨ Python å±‚é¢è¿›è¡Œè¿‡æ»¤å’Œæ ¼å¼åŒ–
        scores_list = []
        for f in all_factor_scores_qs:
            scores_list.append(f"{f.factor_code_id}:{f.norm_score:.2f}")
        scores_str = "|".join(scores_list)
        
        # è·å–æ­¢ç›ˆæ­¢æŸç‡ (åœ¨è°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼ŒPositionåº”å·²è¢«æ›´æ–°)
        profit_rate = (position.current_take_profit / position.entry_price) - 1 if position.entry_price > 0 else 0
        loss_rate = 1 - (position.current_stop_loss / position.entry_price) if position.entry_price > 0 else 0

        BacktestOperationLog.objects.create(
            backtest_run_id=self.service.backtest_run_id,
            position_id_ref=position.position_id,
            stock_code=position.stock_code_id,
            stock_name=position.stock_code.stock_name,
            trade_date=self.service.current_date,
            direction=BacktestOperationLog.Direction.BUY,
            exit_reason=None,
            profit_rate=profit_rate,
            loss_rate=loss_rate,
            buy_date_m_value=m_value,
            factor_scores=scores_str,
            price=position.entry_price,
            quantity=position.quantity,
            amount=position.entry_price * position.quantity
        )
        logger.debug(f"å·²è®°å½•ä¹°å…¥æ“ä½œæ—¥å¿— for Position ID: {position.position_id}")
        
    def _record_sell_operation(self, position: Position, sell_price: Decimal, reason: str):
        # åæŸ¥ä¹°å…¥è®°å½•
        try:
            buy_op = BacktestOperationLog.objects.get(
                backtest_run_id=self.service.backtest_run_id,
                position_id_ref=position.position_id,
                direction=BacktestOperationLog.Direction.BUY
            )
            m_value = buy_op.buy_date_m_value
            scores_str = buy_op.factor_scores
            profit_rate = buy_op.profit_rate
            loss_rate = buy_op.loss_rate
        except BacktestOperationLog.DoesNotExist:
            logger.error(f"ä¸¥é‡é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ° Position ID {position.position_id} å¯¹åº”çš„ä¹°å…¥æ“ä½œæ—¥å¿—ï¼")
            m_value, scores_str, profit_rate, loss_rate = None, "", None, None

        exit_reason_for_log = None
        if reason == TradeLog.ReasonChoices.TAKE_PROFIT:
            exit_reason_for_log = BacktestOperationLog.ExitReason.TAKE_PROFIT
        elif reason == TradeLog.ReasonChoices.STOP_LOSS:
            exit_reason_for_log = BacktestOperationLog.ExitReason.STOP_LOSS
        final_profit_rate = (position.current_take_profit / position.entry_price - 1) if position.entry_price > 0 else None
        final_loss_rate = (1 - (position.current_stop_loss / position.entry_price)) if position.entry_price > 0 else None
        BacktestOperationLog.objects.create(
            backtest_run_id=self.service.backtest_run_id,
            position_id_ref=position.position_id,
            stock_code=position.stock_code_id,
            stock_name=position.stock_code.stock_name,
            trade_date=self.service.current_date,
            direction=BacktestOperationLog.Direction.SELL,
            exit_reason=exit_reason_for_log,
            profit_rate=final_profit_rate,
            loss_rate=final_loss_rate,
            buy_date_m_value=m_value,
            factor_scores=scores_str,
            price=sell_price,
            quantity=position.quantity,
            amount=sell_price * position.quantity
        )
        logger.debug(f"å·²è®°å½•å–å‡ºæ“ä½œæ—¥å¿— for Position ID: {position.position_id}")

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\simulate_trade_old.py####
# trade_manager/service/simulate_trade.py

import logging
import shutil
import os
from datetime import date, timedelta
from decimal import Decimal, ROUND_HALF_UP
import numpy as np
import pandas as pd
import time
from django.conf import settings
from django.db import connections, transaction
import sqlite3
from common.models import (
    DailyFactorValues, DailyTradingPlan, Position, TradeLog, SystemLog,
    StrategyParameters, DailyQuotes, CorporateAction
)
from selection_manager.service.selection_service import SelectionService
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.monitor_exit_service import MonitorExitService
from .simulate_trade_handler import SimulateTradeHandler

logger = logging.getLogger(__name__)

class SimulateTradeService:
    """
    å›æµ‹å®æ–½æœåŠ¡ã€‚
    """
    COMMISSION_RATE = Decimal('0.0002854')
    MIN_COMMISSION = Decimal('5')
    STAMP_DUTY_RATE = Decimal('0.001')
    SELL_SLIPPAGE_RATE = Decimal('0.002')
    ANNUAL_RISK_FREE_RATE = Decimal('0.015')
    TRADING_DAYS_PER_YEAR = 252

    def __init__(self):
        self.start_date: date = None
        self.end_date: date = None
        self.current_date: date = None
        self.initial_capital = Decimal('0.0')
        self.cash_balance = Decimal('0.0')
        self.portfolio_history = []
        self.last_buy_trade_id = None
        self.original_db_config = None
    def _load_db_to_memory(self, source_db_path: str):
        """
        ã€ä¼˜åŒ–ç‰ˆã€‘ä½¿ç”¨ SQLite Backup API é«˜æ•ˆåœ°å°†ç£ç›˜æ•°æ®åº“åŠ è½½åˆ°å†…å­˜ã€‚
        """
        logger.info(f"å¼€å§‹å°†æ•°æ®ä» {source_db_path} åŠ è½½åˆ°å†…å­˜ (ä½¿ç”¨ Backup API)...")
        start_time = time.time()
        
        # 1. åˆ›å»ºä¸€ä¸ªåˆ°æºæ–‡ä»¶æ•°æ®åº“çš„ç›´æ¥è¿æ¥ (åªè¯»)
        try:
            source_conn = sqlite3.connect(f'file:{source_db_path}?mode=ro', uri=True)
        except sqlite3.OperationalError as e:
            logger.error(f"æ— æ³•ä»¥åªè¯»æ¨¡å¼æ‰“å¼€æºæ•°æ®åº“ {source_db_path}: {e}")
            raise
 
        # 2. è·å–åˆ°Djangoç®¡ç†çš„å†…å­˜æ•°æ®åº“çš„åº•å±‚è¿æ¥
        mem_conn = connections['default'].connection
 
        try:
            # 3. ã€æ ¸å¿ƒä¼˜åŒ–ã€‘ä½¿ç”¨ backup æ–¹æ³•
            #    å®ƒä¼šä»¥æœ€æœ‰æ•ˆçš„æ–¹å¼ï¼ˆé€šå¸¸æ˜¯æŒ‰æ•°æ®é¡µï¼‰å°†æºæ•°æ®åº“å†…å®¹å¤åˆ¶åˆ°ç›®æ ‡æ•°æ®åº“
            source_conn.backup(mem_conn)
            
            duration = time.time() - start_time
            logger.info(f"æ•°æ®æˆåŠŸåŠ è½½åˆ°å†…å­˜æ•°æ®åº“ï¼Œè€—æ—¶: {duration:.2f} ç§’ã€‚")
 
        except Exception as e:
            logger.error(f"ä½¿ç”¨ Backup API åŠ è½½æ•°æ®åˆ°å†…å­˜æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise
        finally:
            # 4. å…³é—­è¿æ¥
            source_conn.close()
            # mem_conn ä¸éœ€è¦æˆ‘ä»¬æ‰‹åŠ¨å…³é—­ï¼ŒDjangoä¼šç®¡ç†å®ƒ
 
    def _setup_environment(self):
        """
        ä¿®æ­£ç‰ˆï¼šè°ƒæ•´äº†æ“ä½œé¡ºåºï¼Œå…ˆåŠ è½½æ•°æ®ï¼Œå†æ‰§è¡ŒORMæ“ä½œã€‚
        """
        logger.info("--- 1. å‡†å¤‡å›æµ‹ç¯å¢ƒ (å†…å­˜æ¨¡å¼) ---")
        
        base_dir = settings.BASE_DIR
        source_db = os.path.join(base_dir, 'mainDB.sqlite3')
        
        # 1. å…³é—­æ‰€æœ‰ç°æœ‰è¿æ¥
        connections.close_all()
        
        # 2. ä¿å­˜åŸå§‹é…ç½®ï¼Œå¹¶å°† 'default' æ•°æ®åº“é‡å®šå‘åˆ°å†…å­˜
        self.original_db_config = settings.DATABASES['default'].copy()
        settings.DATABASES['default']['NAME'] = ':memory:'
        logger.info("å·²å°† 'default' æ•°æ®åº“è¿æ¥é‡å®šå‘åˆ° :memory:")
 
        # 3. ç¡®ä¿Djangoå»ºç«‹åˆ°æ–°å†…å­˜æ•°æ®åº“çš„è¿æ¥
        #    è¿™ä¸€æ­¥è‡³å…³é‡è¦ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªç©ºçš„å†…å­˜æ•°æ®åº“å®ä¾‹
        connections['default'].ensure_connection()
        
        # 4. ã€æ ¸å¿ƒä¿®æ­£ã€‘ç«‹å³å°†ç£ç›˜æ•°æ®åŠ è½½åˆ°å†…å­˜æ•°æ®åº“ä¸­
        #    æ­¤æ—¶ï¼Œå†…å­˜æ•°æ®åº“ä»ç©ºå˜æˆäº† mainDB.sqlite3 çš„ä¸€ä¸ªå®Œæ•´å…‹éš†
        self._load_db_to_memory(source_db)
 
        # 5. ã€é¡ºåºè°ƒæ•´ã€‘ç°åœ¨å†…å­˜æ•°æ®åº“æ˜¯å®Œæ•´çš„äº†ï¼Œå¯ä»¥å®‰å…¨åœ°æ‰§è¡Œä»»ä½•Django ORMæ“ä½œ
        

        #DailyFactorValues, DailyTradingPlan,
        # æ¸…ç©ºå›æµ‹è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿæ•°æ®çš„è¡¨
        tables_to_clear = [
             Position,
            TradeLog, SystemLog
        ]
        # ä½¿ç”¨ transaction.atomic() æ¥ä¿è¯æ“ä½œçš„åŸå­æ€§
        with transaction.atomic():
            for model in tables_to_clear:
                # ç°åœ¨ model.objects.all() å¯ä»¥æ­£å¸¸å·¥ä½œäº†
                model.objects.all().delete()
                logger.info(f"å·²æ¸…ç©ºè¡¨: {model._meta.db_table}")
 
        # è¯»å–ç­–ç•¥å‚æ•°
        # ç°åœ¨ StrategyParameters.objects.all() ä¹Ÿå¯ä»¥æ­£å¸¸å·¥ä½œäº†
        params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
        max_positions = int(params.get('MAX_POSITIONS', Decimal('5')))
        max_capital_per_pos = params.get('MAX_CAPITAL_PER_POSITION', Decimal('10000'))
        self.initial_capital = Decimal(max_positions) * max_capital_per_pos
        self.initial_capital=150000
        self.cash_balance = self.initial_capital
        logger.info(f"åˆå§‹èµ„é‡‘å·²è®¾å®šä¸º: {self.initial_capital:.2f}")
 
    def _cleanup_environment(self):
        """åœ¨å›æµ‹ç»“æŸåæ¢å¤åŸå§‹æ•°æ®åº“é…ç½®"""
        if self.original_db_config:
            connections.close_all()
            settings.DATABASES['default'] = self.original_db_config
            # å†…å­˜æ•°æ®åº“çš„è¿æ¥å…³é—­åï¼Œå…¶å†…å®¹ä¼šè‡ªåŠ¨é”€æ¯ï¼Œæ— éœ€æ‰‹åŠ¨åˆ é™¤æ–‡ä»¶
            logger.info("å·²æ¢å¤ 'default' æ•°æ®åº“è¿æ¥åˆ°åŸå§‹é…ç½®ï¼Œå†…å­˜æ•°æ®åº“å·²é‡Šæ”¾ã€‚")
    def _get_trading_days(self) -> list[date]:
        dates = DailyQuotes.objects.filter(
            trade_date__gte=self.start_date,
            trade_date__lte=self.end_date
        ).values_list('trade_date', flat=True).distinct().order_by('trade_date')
        return list(dates)

    def _calculate_daily_portfolio_value(self):
        open_positions = Position.objects.filter(status=Position.StatusChoices.OPEN)
        market_value = Decimal('0.0')
        for pos in open_positions:
            try:
                quote = DailyQuotes.objects.get(
                    stock_code_id=pos.stock_code_id,
                    trade_date=self.current_date
                )
                market_value += quote.close * pos.quantity
            except DailyQuotes.DoesNotExist:
                market_value += pos.entry_price * pos.quantity
        
        total_value = self.cash_balance + market_value
        self.portfolio_history.append({
            'date': self.current_date,
            'total_value': total_value
        })
        logger.info(f"--- æ—¥ç»ˆç»“ç®— ({self.current_date}) ---")
        logger.info(f"ç°é‡‘: {self.cash_balance:.2f}, æŒä»“å¸‚å€¼: {market_value:.2f}, æ€»èµ„äº§: {total_value:.2f}")

    def _calculate_performance_metrics(self) -> dict:
        logger.info("--- 4. è®¡ç®—å›æµ‹æ€§èƒ½æŒ‡æ ‡ ---")
        if not self.portfolio_history:
            return {}

        df = pd.DataFrame(self.portfolio_history)
        df['total_value'] = df['total_value'].astype(float)
        df['daily_return'] = df['total_value'].pct_change().fillna(0)
        
        final_value = float(df['total_value'].iloc[-1])
        total_return_amount = final_value - float(self.initial_capital)
        total_return_rate = (final_value / float(self.initial_capital)) - 1

        mean_daily_return = df['daily_return'].mean()
        std_daily_return = df['daily_return'].std()
        
        if std_daily_return == 0 or np.isnan(std_daily_return):
            sharpe_ratio = 0.0
        else:
            daily_risk_free_rate = (1 + self.ANNUAL_RISK_FREE_RATE) ** Decimal(1/self.TRADING_DAYS_PER_YEAR) - 1
            sharpe_ratio = (mean_daily_return - float(daily_risk_free_rate)) / std_daily_return
            sharpe_ratio *= np.sqrt(self.TRADING_DAYS_PER_YEAR)

        result = {
            'total_return_amount': round(total_return_amount, 2),
            'total_return_rate': round(total_return_rate, 4),
            'sharpe_ratio': round(float(sharpe_ratio), 4)
        }
        logger.info(f"å›æµ‹ç»“æœ: {result}")
        return result

    def run_backtest(self, start_date: str, end_date: str) -> dict:
        try:
            self.start_date = date.fromisoformat(start_date)
            self.end_date = date.fromisoformat(end_date)

            self._setup_environment()

            handler = SimulateTradeHandler(self)
            
            trading_days = self._get_trading_days()
            if not trading_days:
                logger.error("åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•äº¤æ˜“æ—¥ï¼Œå›æµ‹ç»ˆæ­¢ã€‚")
                return {}

            baseline_date = trading_days[0] - timedelta(days=1)
            self.portfolio_history.append({'date': baseline_date, 'total_value': self.initial_capital})

            logger.info(f"--- 2. å¼€å§‹æ—¥åº¦å›æµ‹å¾ªç¯ ({len(trading_days)}å¤©) ---")
            for i, current_day in enumerate(trading_days):
                self.current_date = current_day
                logger.info(f"\n{'='*20} æ¨¡æ‹Ÿæ—¥: {self.current_date} ({i+1}/{len(trading_days)}) {'='*20}")

                prev_trading_day = trading_days[i-1] if i > 0 else None
                if prev_trading_day:
                    logger.info(f"-> [T-1 é€‰è‚¡] åŸºäº {prev_trading_day} çš„æ•°æ®...")
                    selection_service = SelectionService(trade_date=prev_trading_day, mode='backtest')
                    selection_service.run_selection()

                logger.info("-> [Tæ—¥ ç›˜å‰æ ¡å‡†] ...")
                before_fix_service = BeforeFixService(execution_date=self.current_date)
                before_fix_service.run()
                
                dividend_events = CorporateAction.objects.filter(
                    ex_dividend_date=self.current_date, event_type=CorporateAction.EventType.DIVIDEND
                )
                # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼Œæé«˜æ•ˆç‡
                events_by_stock = {}
                for event in dividend_events:
                    events_by_stock.setdefault(event.stock_code, []).append(event)

                if events_by_stock:
                    # è·å–æ‰€æœ‰å¯èƒ½å—å½±å“çš„æŒä»“
                    open_positions_for_dividend = Position.objects.filter(
                        stock_code_id__in=events_by_stock.keys(),
                        status=Position.StatusChoices.OPEN
                    )
                    
                    for pos in open_positions_for_dividend:
                        # æ‰¾åˆ°è¯¥è‚¡ç¥¨å¯¹åº”çš„æ‰€æœ‰åˆ†çº¢äº‹ä»¶ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
                        stock_events = events_by_stock.get(pos.stock_code_id, [])
                        for event in stock_events:
                            dividend_amount = event.dividend_per_share * pos.quantity
                            self.cash_balance += dividend_amount
                            logger.info(f"é™¤æ¯äº‹ä»¶: æŒä»“ID {pos.position_id} ({pos.stock_code_id}) è·å¾—åˆ†çº¢ {dividend_amount:.2f}ï¼Œç°é‡‘ä½™é¢æ›´æ–°ä¸º {self.cash_balance:.2f}")



                logger.info("-> [Tæ—¥ å¼€ç›˜å†³ç­–ä¸ä¹°å…¥] ...")
                decision_order_service = DecisionOrderService(handler=handler, execution_date=self.current_date)
                decision_order_service.adjust_trading_plan_daily()
                
                while True:
                    open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
                    max_pos = decision_order_service.current_max_positions
                    if open_positions_count >= max_pos:
                        break
                    
                    self.last_buy_trade_id = None
                    decision_order_service.execute_orders()
                    
                    if self.last_buy_trade_id:
                        decision_order_service.calculate_stop_profit_loss(self.last_buy_trade_id)
                    else:
                        break

                # å…³é”®ä¿®å¤ï¼šåœ¨å¾ªç¯å†…å®ä¾‹åŒ– MonitorExitService å¹¶ä¼ å…¥æ—¥æœŸ
                monitor_exit_service = MonitorExitService(handler=handler, execution_date=self.current_date)

                logger.info("-> [Tæ—¥ ç›˜ä¸­ç›‘æ§] æ¨¡æ‹Ÿä»·æ ¼è·Œè‡³æœ€ä½ç‚¹...")
                handler.current_price_node = 'LOW'
                monitor_exit_service.monitor_and_exit_positions()

                logger.info("-> [Tæ—¥ ç›˜ä¸­ç›‘æ§] æ¨¡æ‹Ÿä»·æ ¼æ¶¨è‡³æœ€é«˜ç‚¹...")
                handler.current_price_node = 'HIGH'
                monitor_exit_service.monitor_and_exit_positions()

                self._calculate_daily_portfolio_value()

            logger.info("--- 3. å›æµ‹å¾ªç¯ç»“æŸ ---")
            return self._calculate_performance_metrics()
        
        finally:
            # ç¡®ä¿æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½æ¸…ç†ç¯å¢ƒ
            self._cleanup_environment()

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\trade_handler.py####
# trade_manager/service/trade_handler.py

from abc import ABC, abstractmethod
from decimal import Decimal
from django.db import transaction
from django.utils import timezone
# ä¸ºäº†ç±»å‹æç¤ºï¼Œæˆ‘ä»¬å¯ä»¥ä» common.models å¯¼å…¥ Position å’Œ TradeLog
# æ³¨æ„ï¼šä¸ºäº†é¿å…å¾ªç¯å¯¼å…¥ï¼Œé€šå¸¸åœ¨å®ç°ç±»ä¸­è¿›è¡Œå®é™…å¯¼å…¥ï¼Œè¿™é‡Œä»…ä¸ºç±»å‹æç¤º
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from common.models import Position, TradeLog



class ITradeHandler(ABC):
    """
    äº¤æ˜“å¤„ç†å™¨æŠ½è±¡åŸºç±» (Abstract Base Class)ã€‚

    è¯¥æ¥å£å®šä¹‰äº†å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—æ‰€éœ€çš„æ‰€æœ‰å¤–éƒ¨äº¤äº’è¡Œä¸ºã€‚
    é€šè¿‡ä¾èµ–æ­¤æŠ½è±¡æ¥å£è€Œéå…·ä½“å®ç°ï¼Œ`DecisionOrderService` å¯ä»¥ä¸ä¸åŒçš„
    äº¤æ˜“ç¯å¢ƒï¼ˆå¦‚çœŸå®äº¤æ˜“æ¥å£ã€å›æµ‹å¼•æ“ï¼‰è§£è€¦ã€‚

    - å¯¹äºçœŸå®äº¤æ˜“ï¼Œå®ç°ç±»å°†é€šè¿‡APIä¸åˆ¸å•†æœåŠ¡å™¨äº¤äº’ã€‚
    - å¯¹äºå›æµ‹ï¼Œå®ç°ç±»å°†æ¨¡æ‹Ÿè¿™äº›äº¤äº’ï¼Œä¾‹å¦‚ä»å†å²æ•°æ®ä¸­è¯»å–å¼€ç›˜ä»·ã€
      æ¨¡æ‹Ÿè®¢å•æˆäº¤ã€å¹¶ç®¡ç†ä¸€ä¸ªè™šæ‹Ÿè´¦æˆ·çš„ä½™é¢ã€‚
    """

    @abstractmethod
    def get_opening_price(self, stock_code: str) -> Decimal:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æ‰§è¡Œæ—¥çš„å®é™…å¼€ç›˜ä»·ã€‚

        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼ä¸ tb_stock_info è¡¨ä¸€è‡´ (å¦‚ 'sh.600000')ã€‚
        :return: å½“æ—¥çš„å¼€ç›˜ä»·ã€‚å¦‚æœæ— æ³•è·å–ï¼ˆä¾‹å¦‚åœç‰Œï¼‰ï¼Œåº”å¼•å‘å¼‚å¸¸æˆ–è¿”å›ä¸€ä¸ªå¯è¯†åˆ«çš„é”™è¯¯å€¼ï¼ˆå¦‚Decimal('0.00')ï¼‰ã€‚
        """
        pass

    @abstractmethod
    def place_buy_order(self, stock_code: str, price: Decimal, quantity: int) -> None:
        """
        æäº¤ä¸€ä¸ªä¹°å…¥è®¢å•ã€‚

        æ­¤æ–¹æ³•çš„å®ç°è€…è´Ÿè´£å¤„ç†ä¸äº¤æ˜“ç³»ç»Ÿçš„æ‰€æœ‰äº¤äº’ã€‚æ ¹æ®éœ€æ±‚ï¼Œæ­¤æ–¹æ³•
        åœ¨æ‰§è¡Œæ—¶ï¼Œéœ€è¦å®Œæˆä»¥ä¸‹æ•°æ®åº“æ“ä½œï¼š
        1. åœ¨ `tb_positions` è¡¨ä¸­æ’å…¥ä¸€æ¡æ–°çš„æŒä»“è®°å½•ï¼Œå…¶ä¸­æ‰€æœ‰éç©ºå­—æ®µ
           ï¼ˆå¦‚ current_stop_loss, current_take_profitï¼‰å¯ä½¿ç”¨å“¨å…µå€¼ï¼ˆå¦‚-1ï¼‰å¡«å……ï¼Œ
           ç­‰å¾…åç»­çš„æ­¢ç›ˆæ­¢æŸè®¡ç®—ä»»åŠ¡æ¥æ›´æ–°ã€‚
        2. åœ¨ `tb_trade_log` è¡¨ä¸­æ’å…¥ä¸€æ¡å¯¹åº”çš„äº¤æ˜“è®°å½•ï¼Œåˆå§‹çŠ¶æ€åº”ä¸º
           'pending'ã€‚

        :param stock_code: è‚¡ç¥¨ä»£ç ã€‚
        :param price: é¢„æœŸçš„ä¹°å…¥é™ä»·ã€‚
        :param quantity: è®¡åˆ’ä¹°å…¥çš„è‚¡æ•°ï¼ˆå¿…é¡»æ˜¯100çš„æ•´æ•°å€ï¼‰ã€‚
        :return: æ— è¿”å›å€¼ã€‚
        """
        pass

    @abstractmethod
    def get_available_balance(self) -> Decimal:
        """
        æŸ¥è¯¢å½“å‰è´¦æˆ·çš„å¯ç”¨èµ„é‡‘ä½™é¢ã€‚

        :return: å¯ç”¨äºäº¤æ˜“çš„ç°é‡‘ä½™é¢ã€‚
        """
        pass

    
    @abstractmethod
    def get_realtime_price(self, stock_code: str) -> Decimal | None:
        """
        è·å–ä¸€åªè‚¡ç¥¨çš„å®æ—¶ä»·æ ¼ã€‚
 
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼å¦‚ 'sh.600000'ã€‚
        :return: è¯¥è‚¡ç¥¨æ­¤æ—¶æ­¤åˆ»çš„å¸‚åœºä»· (Decimalç±»å‹)ã€‚å¦‚æœè·å–å¤±è´¥ï¼ˆå¦‚ç½‘ç»œé—®é¢˜ã€è‚¡ç¥¨åœç‰Œï¼‰ï¼Œ
                 åº”è¿”å› Noneï¼Œä»¥ä¾¿è°ƒç”¨æ–¹è¿›è¡Œé”™è¯¯å¤„ç†ã€‚
        """
        pass
 
    @abstractmethod
    def sell_stock_by_market_price(self, position: 'Position', reason: str) -> None:
        """
        ä»¥å¸‚ä»·å•å…¨é‡å–å‡ºæŒ‡å®šçš„æŒä»“ã€‚
 
        æ­¤æ–¹æ³•çš„å…·ä½“å®ç°éœ€è¦å®Œæˆä¸€ä¸ªåŸå­æ€§çš„æ“ä½œæµç¨‹ï¼š
        1. è°ƒç”¨äº¤æ˜“APIï¼Œä»¥å¸‚ä»·å•å–å‡º `position.quantity` æ•°é‡çš„ `position.stock_code`ã€‚
        2. **åœ¨APIè°ƒç”¨æˆåŠŸè¿”å›æˆäº¤å›æŠ¥å**ï¼Œæ‰§è¡Œä»¥ä¸‹æ•°æ®åº“æ“ä½œï¼š
           a. **æ›´æ–°æŒä»“è¡¨ (tb_positions)**: å°†ä¼ å…¥çš„ `position` å¯¹è±¡çš„çŠ¶æ€æ›´æ–°ä¸º 'closed'ã€‚
              `position.status = Position.StatusChoices.CLOSED`
              `position.save()`
           b. **æ’å…¥äº¤æ˜“è®°å½• (tb_trade_log)**: åˆ›å»ºä¸€æ¡æ–°çš„å–å‡ºè®°å½•ã€‚
              - `position`: å…³è”åˆ°æ­¤æŒä»“ã€‚
              - `stock_code`: è‚¡ç¥¨ä»£ç ã€‚
              - `trade_datetime`: äº¤æ˜“çš„å®é™…æˆäº¤æ—¶é—´ã€‚
              - `trade_type`: 'sell'ã€‚
              - `order_type`: 'market'ã€‚
              - `quantity`: å®é™…æˆäº¤æ•°é‡ã€‚
              - `price`: å®é™…çš„æˆäº¤å‡ä»·ã€‚ä»æˆäº¤å›æŠ¥ä¸­è·å–ã€‚å¦‚æœæ— æ³•ç«‹å³è·å–ï¼Œ
                                            åˆ™ä½¿ç”¨ -1 ä½œä¸ºå ä½ç¬¦ï¼Œç­‰å¾…åç»­ä»»åŠ¡å›è¡¥ã€‚
              - `commission`, `stamp_duty`: ä»æˆäº¤å›æŠ¥ä¸­è·å–ã€‚å¦‚æœæ— æ³•ç«‹å³è·å–ï¼Œ
                                            åˆ™ä½¿ç”¨ -1 ä½œä¸ºå ä½ç¬¦ï¼Œç­‰å¾…åç»­ä»»åŠ¡å›è¡¥ã€‚
              - `reason`: ä½¿ç”¨ä¼ å…¥çš„ `reason` å‚æ•° ('take_profit' æˆ– 'stop_loss')ã€‚
              - `status`: 'filled' (å·²æˆäº¤)ã€‚
        3. æ•´ä¸ªæ•°æ®åº“æ›´æ–°è¿‡ç¨‹åº”è¯¥è¢«åŒ…è£¹åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­ (`transaction.atomic`)ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚
 
        :param position: è¦å–å‡ºçš„æŒä»“å¯¹è±¡ (common.models.positions.Position)ã€‚
                         è¯¥å¯¹è±¡åŒ…å«äº†æŒä»“IDã€è‚¡ç¥¨ä»£ç ã€æŒä»“æ•°é‡ç­‰æ‰€æœ‰å¿…è¦ä¿¡æ¯ã€‚
        :param reason: å–å‡ºåŸå› çš„å­—ç¬¦ä¸²ï¼Œå¦‚ 'take_profit' æˆ– 'stop_loss'ã€‚
                       è¿™ä¸ªå€¼å°†ç”¨äºå¡«å……äº¤æ˜“è®°å½•è¡¨çš„ `reason` å­—æ®µã€‚
        :return: æ— è¿”å›å€¼ã€‚å¦‚æœæ‰§è¡Œå¤±è´¥ï¼ˆå¦‚APIè°ƒç”¨å¤±è´¥ã€è‚¡ç¥¨è·Œåœæ— æ³•å–å‡ºï¼‰ï¼Œ
                 åº”åœ¨æ–¹æ³•å†…éƒ¨å¤„ç†å¼‚å¸¸ï¼ˆå¦‚è®°å½•æ—¥å¿—ï¼‰ï¼Œå¹¶å‘ä¸Šå±‚è°ƒç”¨è€…ï¼ˆMonitorExitServiceï¼‰
                 æŠ›å‡ºå¼‚å¸¸æˆ–é€šè¿‡å…¶ä»–æ–¹å¼é€šçŸ¥å¤±è´¥ï¼Œä»¥ä¾¿ä¸Šå±‚å†³å®šæ˜¯å¦é‡è¯•ã€‚
        """
        pass
####æ–‡ä»¶ç»“æŸ####
