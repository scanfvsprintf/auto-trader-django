======= é¡¹ç›®æ–‡ä»¶æ ‘ =======

ğŸ“‚ ./
    ğŸ“„ .env
    ğŸ“„ .env.example
    ğŸ“„ config.json
    ğŸ“„ manage.py
    ğŸ“„ requirements.txt
    ğŸ“„ restart.sh
    ğŸ“„ trade_report.html
    ğŸ“„ user.json
    ğŸ“„ uwsgi.ini
    ğŸ“„ äº¤æ˜“å˜åŒ–.html
    ğŸ“„ å›æµ‹ç®€å•æ—¥å¿—.txt
    ğŸ“„ å›æµ‹ç®€å•æ—¥å¿—_v2.1.txt
    ğŸ“„ å›æµ‹ç®€å•æ—¥å¿—_v2.2.txt
    ğŸ“„ æå–æ—¥å¿—.py
    ğŸ“„ æ—¥å¿—åˆ†ææç¤ºè¯.txt
    ğŸ“„ æµ‹è¯•akshare.py
    ğŸ“„ æµ‹è¯•easytrader.py
    ğŸ“„ èµ„é‡‘å˜åŒ–å›¾.png
    ğŸ“‚ autoTrade/
        ğŸ“„ __init__.py
        ğŸ“„ asgi.py
        ğŸ“„ settings.py
        ğŸ“„ urls.py
        ğŸ“„ wsgi.py
    ğŸ“‚ common/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ config_loader.py
        ğŸ“„ tests.py
        ğŸ“„ views.py
        ğŸ“‚ models/
            ğŸ“„ __init__.py
            ğŸ“„ backtest_logs.py
            ğŸ“„ corporate_action.py
            ğŸ“„ daily_factor_values.py
            ğŸ“„ daily_quotes.py
            ğŸ“„ daily_trading_plan.py
            ğŸ“„ factor_definitions.py
            ğŸ“„ positions.py
            ğŸ“„ stock_info.py
            ğŸ“„ strategy_parameters.py
            ğŸ“„ system_log.py
            ğŸ“„ trade_log.py
    ğŸ“‚ data_manager/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ models.py
        ğŸ“„ tests.py
        ğŸ“„ urls.py
        ğŸ“„ views.py
        ğŸ“‚ management/
            ğŸ“‚ commands/
                ğŸ“„ full_update_stocks.py
                ğŸ“„ migrate_to_pg.py
                ğŸ“„ reset_sequences.py
        ğŸ“‚ service/
            ğŸ“„ corporate_action_service.py
            ğŸ“„ db_service.py
            ğŸ“„ email_handler.py
            ğŸ“„ email_service.py
            ğŸ“„ stock_service.py
    ğŸ“‚ logs/
        ğŸ“„ .__django.lock
        ğŸ“„ django.log
    ğŸ“‚ selection_manager/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ models.py
        ğŸ“„ tests.py
        ğŸ“„ urls.py
        ğŸ“„ views.py
        ğŸ“‚ management/
            ğŸ“‚ commands/
                ğŸ“„ prime_market_regime_cache.py
        ğŸ“‚ service/
            ğŸ“„ selection_service.py
            ğŸ“„ selection_service.py.old_v1
    ğŸ“‚ trade_manager/
        ğŸ“„ __init__.py
        ğŸ“„ admin.py
        ğŸ“„ apps.py
        ğŸ“„ models.py
        ğŸ“„ tests.py
        ğŸ“„ urls.py
        ğŸ“„ views.py
        ğŸ“‚ management/
            ğŸ“‚ commands/
                ğŸ“„ run_backtest.py
                ğŸ“„ run_scheduler.py
        ğŸ“‚ service/
            ğŸ“„ backtest_reporter.py
            ğŸ“„ before_fix_service.py
            ğŸ“„ db_utils.py
            ğŸ“„ decision_order_service.py
            ğŸ“„ decision_order_service_old.py
            ğŸ“„ monitor_exit_service.py
            ğŸ“„ real_trade_handler.py
            ğŸ“„ scheduler_service.py
            ğŸ“„ simulate_trade.py
            ğŸ“„ simulate_trade_handler.py
            ğŸ“„ simulate_trade_old.py
            ğŸ“„ trade_handler.py

========================

======= Pythonæ–‡ä»¶å†…å®¹ =======

####manage.py####
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys
import dotenv

def main():
    """Run administrative tasks."""
    dotenv.load_dotenv()
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'autoTrade.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()

####æ–‡ä»¶ç»“æŸ####

####æå–æ—¥å¿—.py####
import re
import html
import matplotlib.pyplot as plt
from collections import defaultdict
import os

# ==============================================================================
# é…ç½®åŒºåŸŸ
# ==============================================================================
LOG_FILE_PATH = 'å›æµ‹ç®€å•æ—¥å¿—.txt'
PLOT_OUTPUT_PATH = 'èµ„é‡‘å˜åŒ–å›¾.png'
HTML_REPORT_PATH = 'äº¤æ˜“å˜åŒ–.html'


# ==============================================================================
# 1. æ—¥å¿—è§£æ
# ==============================================================================
def parse_log_file(file_path):
    """
    è§£ææ—¥å¿—æ–‡ä»¶ï¼Œæå–ç»˜å›¾å’ŒæŠ¥å‘Šæ‰€éœ€çš„æ•°æ®ã€‚
    """
    # ç”¨äºå­˜å‚¨æ¯æ—¥èµ„äº§
    asset_dates = []
    asset_values = []
    
    # ç”¨äºå­˜å‚¨æ¯æ—¥çš„æ—¥å¿—å—
    daily_logs = []
    
    # ç”¨äºè®¡ç®—æ¯æ”¯è‚¡ç¥¨çš„ç›ˆäº
    # ç»“æ„: {'sz.002364': {'spent': 1000, 'received': 1100, 'dividends': 10, 'name': 'ä¸­æ’ç”µæ°”'}}
    stock_profits = defaultdict(lambda: {'spent': 0, 'received': 0, 'dividends': 0, 'name': ''})

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            current_day_block = None
            for line in f:
                line = line.strip()
                if not line:
                    continue

                # åŒ¹é…æ–°çš„ä¸€å¤©
                day_match = re.search(r"æ¨¡æ‹Ÿæ—¥: ([\d-]+)", line)
                if day_match:
                    if current_day_block:
                        daily_logs.append(current_day_block)
                    date_str = day_match.group(1)
                    current_day_block = {'date': date_str, 'logs': [line]}
                    continue
                
                if not current_day_block:
                    continue

                current_day_block['logs'].append(line)

                # åŒ¹é…æ€»èµ„äº§
                asset_match = re.search(r"æ€»èµ„äº§: ([\d.]+)", line)
                if asset_match:
                    asset_dates.append(current_day_block['date'])
                    asset_values.append(float(asset_match.group(1)))

                # åŒ¹é…ä¹°å…¥æ“ä½œ
                buy_match = re.search(r"ä¹°å…¥ (.+?)\((.+?)\).*?èŠ±è´¹: ([\d.]+)", line)
                if buy_match:
                    name, code, cost = buy_match.groups()
                    stock_profits[code]['spent'] += float(cost)
                    if not stock_profits[code]['name']: # é¦–æ¬¡è®°å½•è‚¡ç¥¨åç§°
                        stock_profits[code]['name'] = name

                # åŒ¹é…å–å‡ºæ“ä½œ
                sell_match = re.search(r"å–å‡º (.+?) .*?æ”¶å…¥: ([\d.]+)", line)
                if sell_match:
                    code, income = sell_match.groups()
                    stock_profits[code]['received'] += float(income)

                # åŒ¹é…åˆ†çº¢äº‹ä»¶
                dividend_match = re.search(r"æŒä»“ID \d+ \((.+?)\) è·å¾—åˆ†çº¢ ([\d.]+)", line)
                if dividend_match:
                    code, dividend = dividend_match.groups()
                    stock_profits[code]['dividends'] += float(dividend)


            if current_day_block: # æ·»åŠ æœ€åä¸€å¤©çš„æ•°æ®
                daily_logs.append(current_day_block)

    except FileNotFoundError:
        print(f"é”™è¯¯: æ—¥å¿—æ–‡ä»¶ '{file_path}' æœªæ‰¾åˆ°ã€‚")
        return None, None, None, None
    
    return asset_dates, asset_values, daily_logs, stock_profits

# ==============================================================================
# 2. ç”Ÿæˆèµ„é‡‘æ›²çº¿å›¾
# ==============================================================================
def generate_asset_plot(dates, assets, output_path):
    """
    ä½¿ç”¨matplotlibç”Ÿæˆèµ„é‡‘æ›²çº¿å›¾å¹¶ä¿å­˜ã€‚
    """
    if not dates or not assets:
        print("æ²¡æœ‰è¶³å¤Ÿçš„èµ„äº§æ•°æ®æ¥ç”Ÿæˆå›¾è¡¨ã€‚")
        return

    print("æ­£åœ¨ç”Ÿæˆèµ„é‡‘å˜åŒ–å›¾...")
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œä»¥é˜²ä¹±ç 
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
    plt.rcParams['axes.unicode_minus'] = False

    # åˆ›å»ºä¸€ä¸ªè¾ƒå¤§å°ºå¯¸çš„å›¾å½¢
    fig, ax = plt.subplots(figsize=(18, 9))

    ax.plot(dates, assets, marker='.', linestyle='-', color='b')

    # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
    ax.set_title('ç­–ç•¥å›æµ‹èµ„é‡‘æ›²çº¿', fontsize=20)
    ax.set_xlabel('æ¨¡æ‹Ÿæ—¥æœŸ', fontsize=14)
    ax.set_ylabel('æ€»èµ„äº§ (å…ƒ)', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.6)

    # è‡ªåŠ¨è°ƒæ•´xè½´æ ‡ç­¾ä»¥é¿å…é‡å 
    fig.autofmt_xdate(rotation=45)
    
    # æ ¼å¼åŒ–yè½´ä¸ºè´§å¸æ ¼å¼
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))

    # ç¡®ä¿å¸ƒå±€ç´§å‡‘ï¼Œæ‰€æœ‰å…ƒç´ éƒ½å¯è§
    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"èµ„é‡‘å˜åŒ–å›¾å·²æˆåŠŸä¿å­˜åˆ°: {output_path}")

# ==============================================================================
# 3. ç”ŸæˆHTMLæŠ¥å‘Š
# ==============================================================================
def generate_html_report(daily_logs, stock_profits, output_path):
    """
    ç”ŸæˆåŒ…å«é«˜äº®æ—¥å¿—å’Œç›ˆäºæ±‡æ€»çš„HTMLæŠ¥å‘Šã€‚
    """
    if not daily_logs or not stock_profits:
        print("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”ŸæˆHTMLæŠ¥å‘Šã€‚")
        return
        
    print("æ­£åœ¨ç”ŸæˆHTMLæŠ¥å‘Š...")

    # --- è®¡ç®—å¹¶æ’åºè‚¡ç¥¨ç›ˆäº ---
    profit_summary = []
    for code, data in stock_profits.items():
        total_profit = data['received'] + data['dividends'] - data['spent']
        profit_summary.append({
            'code': code,
            'name': data['name'] or 'æœªçŸ¥åç§°',
            'profit': total_profit
        })
    
    # ä»å¤§åˆ°å°æ’åº
    sorted_profits = sorted(profit_summary, key=lambda x: x['profit'], reverse=True)

    # --- æ„å»ºHTMLå†…å®¹ ---
    html_content = """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <title>å›æµ‹äº¤æ˜“æ—¥å¿—æŠ¥å‘Š</title>
        <style>
            body { font-family: 'Segoe UI', 'Microsoft YaHei', sans-serif; line-height: 1.6; margin: 20px; background-color: #f4f4f4; color: #333; }
            h1, h2 { color: #0056b3; border-bottom: 2px solid #0056b3; padding-bottom: 10px; }
            .container { max-width: 1200px; margin: auto; background: #fff; padding: 20px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
            .summary-table { width: 100%; border-collapse: collapse; margin-bottom: 30px; }
            .summary-table th, .summary-table td { border: 1px solid #ddd; padding: 12px; text-align: left; }
            .summary-table th { background-color: #007bff; color: white; }
            .summary-table tr:nth-child(even) { background-color: #f2f2f2; }
            .profit { color: #d9534f; } /* çº¢è‰² */
            .loss { color: #5cb85c; } /* ç»¿è‰² */
            .day-block { border: 1px solid #ccc; border-radius: 5px; margin-bottom: 20px; padding: 15px; background-color: #fafafa; }
            .day-block h3 { margin-top: 0; color: #555; }
            .log-entry { font-family: 'Courier New', Courier, monospace; white-space: pre-wrap; word-wrap: break-word; }
            .log-profit-sell { color: #d9534f; font-weight: bold; } /* æ­¢ç›ˆå–å‡º - çº¢è‰² */
            .log-stop-loss { color: #5cb85c; font-weight: bold; } /* æ­¢æŸå–å‡º - ç»¿è‰² */
        </style>
    </head>
    <body>
        <div class="container">
            <h1>å›æµ‹äº¤æ˜“æ—¥å¿—æŠ¥å‘Š</h1>
            
            <h2>å„è‚¡ç›ˆäºæ±‡æ€» (ä»é«˜åˆ°ä½)</h2>
            <table class="summary-table">
                <thead>
                    <tr>
                        <th>æ’å</th>
                        <th>è‚¡ç¥¨åç§°</th>
                        <th>è‚¡ç¥¨ä»£ç </th>
                        <th>æ€»ç›ˆäº (å…ƒ)</th>
                    </tr>
                </thead>
                <tbody>
    """

    # å¡«å……ç›ˆäºæ±‡æ€»è¡¨æ ¼
    for i, item in enumerate(sorted_profits):
        profit_class = 'profit' if item['profit'] >= 0 else 'loss'
        html_content += f"""
                    <tr>
                        <td>{i + 1}</td>
                        <td>{html.escape(item['name'])}</td>
                        <td>{html.escape(item['code'])}</td>
                        <td class="{profit_class}">{item['profit']:.2f}</td>
                    </tr>
        """
    
    html_content += """
                </tbody>
            </table>

            <h2>è¯¦ç»†æ—¥å¿—è®°å½•</h2>
    """

    # å¡«å……è¯¦ç»†æ—¥å¿—
    for day in daily_logs:
        html_content += f"""
            <div class="day-block">
                <h3>{html.escape(day['date'])}</h3>
                <div class="log-entry">
        """
        for log_line in day['logs']:
            escaped_line = html.escape(log_line)
            if 'è§¦å‘æ­¢ç›ˆ' in log_line or 'æ­¢ç›ˆå–å‡º' in log_line:
                html_content += f'<span class="log-profit-sell">{escaped_line}</span>\n'
            elif 'è§¦å‘æ­¢æŸ' in log_line or 'æ­¢æŸå–å‡º' in log_line:
                html_content += f'<span class="log-stop-loss">{escaped_line}</span>\n'
            else:
                html_content += f'{escaped_line}\n'
        html_content += """
                </div>
            </div>
        """

    html_content += """
        </div>
    </body>
    </html>
    """

    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    print(f"HTMLæŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°: {output_path}")

# ==============================================================================
# ä¸»æ‰§è¡Œå‡½æ•°
# ==============================================================================
def main():
    """ä¸»å‡½æ•°ï¼Œåè°ƒæ‰€æœ‰æ“ä½œã€‚"""
    print("å¼€å§‹å¤„ç†å›æµ‹æ—¥å¿—...")
    symbol=['==================== æ¨¡æ‹Ÿæ—¥','è§¦å‘','[å›æµ‹] å–å‡º',' [å›æµ‹] ä¹°å…¥','æ€»èµ„äº§: ','è·å¾—åˆ†çº¢','é£æ§ä»·æ ¼','M(t)','ç¡®å®šå”¯ä¸€ä¹°å…¥æ ‡çš„']
    log_prefix_pattern = re.compile(r"^[A-Z]+\s+[\d\-\s:,]+\s+\w+\s+\d+\s+\d+\s+(.*)")
 
    clean_log_content = []
    
    # ä½¿ç”¨ 'with' è¯­å¥èƒ½æ›´å¥½åœ°å¤„ç†æ–‡ä»¶ï¼Œå¹¶ä¸”æ›´å®‰å…¨
    # æ³¨æ„ï¼šå¦‚æœä½ çš„åŸå§‹æ—¥å¿—æ–‡ä»¶ä¸æ˜¯gbkç¼–ç ï¼Œè¯·ä¿®æ”¹è¿™é‡Œçš„ encoding
    try:
        with open('logs/django.log', "r", encoding="gbk") as f:
            for line in f:
                # æ£€æŸ¥è¯¥è¡Œæ˜¯å¦åŒ…å«æˆ‘ä»¬å…³å¿ƒçš„å…³é”®å­—
                should_keep = False
                for keyword in symbol:
                    if keyword in line:
                        should_keep = True
                        break
                
                if should_keep:
                    # å»æ‰è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
                    stripped_line = line.strip()
                    
                    # å°è¯•ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¹¶å»é™¤å‰ç¼€
                    match = log_prefix_pattern.match(stripped_line)
                    if match:
                        # å¦‚æœåŒ¹é…æˆåŠŸï¼Œåªå–æ‹¬å·é‡Œæ•è·çš„å†…å®¹ (æ ¸å¿ƒæ—¥å¿—)
                        clean_line = match.group(1)
                    else:
                        # å¦‚æœä¸åŒ¹é… (æ¯”å¦‚ "==== æ¨¡æ‹Ÿæ—¥..." è¿™ç§è¡Œ)ï¼Œå°±ä¿ç•™åŸæ ·
                        clean_line = stripped_line
                    
                    clean_log_content.append(clean_line)
    except FileNotFoundError:
        print("é”™è¯¯: åŸå§‹æ—¥å¿—æ–‡ä»¶ 'logs/django.log' æœªæ‰¾åˆ°ã€‚")
        return
    except Exception as e:
        print(f"è¯»å–åŸå§‹æ—¥å¿—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return
 
    # å°†å¤„ç†è¿‡çš„ã€å¹²å‡€çš„æ—¥å¿—å†…å®¹å†™å…¥åˆ°ç®€å•æ—¥å¿—æ–‡ä»¶ä¸­
    with open(LOG_FILE_PATH, 'w', encoding='utf-8') as f:
        f.write('\n'.join(clean_log_content))

    # 1. è§£ææ—¥å¿—
    asset_dates, asset_values, daily_logs, stock_profits = parse_log_file(LOG_FILE_PATH)

    if asset_dates is None: # å¦‚æœè§£æå¤±è´¥
        print("æ—¥å¿—å¤„ç†ç»ˆæ­¢ã€‚")
        return

    # 2. ç”Ÿæˆå›¾è¡¨
    generate_asset_plot(asset_dates, asset_values, PLOT_OUTPUT_PATH)

    # 3. ç”ŸæˆHTMLæŠ¥å‘Š
    generate_html_report(daily_logs, stock_profits, HTML_REPORT_PATH)
    
    print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print(f" - å›¾è¡¨æ–‡ä»¶: {os.path.abspath(PLOT_OUTPUT_PATH)}")
    print(f" - æŠ¥å‘Šæ–‡ä»¶: {os.path.abspath(HTML_REPORT_PATH)}")


if __name__ == '__main__':
    main()
main()
####æ–‡ä»¶ç»“æŸ####

####æµ‹è¯•akshare.py####
import akshare as ak
index_zh_a_hist_df = ak.index_zh_a_hist(symbol="000300", period="daily", start_date="20180101", end_date="20250815")
print(index_zh_a_hist_df)
####æ–‡ä»¶ç»“æŸ####

####æµ‹è¯•easytrader.py####
import easytrader
import json
f=open('config.json','r',encoding='utf-8')
t=""
for line in f:
    line = line.strip()
    t=t+line
    if not line:
        continue
f.close()
config=json.loads(t)
print(config)
user = easytrader.use('ht_client')
user.connect(config['easytrader']['client_path'])
user.prepare(config['easytrader']['user'])
user.refresh()
print(user.balance)
user.exit()
####æ–‡ä»¶ç»“æŸ####

####éå†æ–‡ä»¶.py####
import os

# --- é…ç½® ---
# è¦æ‰«æçš„æ ¹ç›®å½•ï¼Œ'.' è¡¨ç¤ºå½“å‰ç›®å½•
ROOT_DIR = '.'
# è¾“å‡ºæ–‡ä»¶å
OUTPUT_FILE = 'result.txt'
# è¦å¿½ç•¥çš„ç›®å½•ï¼ˆä½¿ç”¨é›†åˆä»¥æé«˜æŸ¥æ‰¾æ•ˆç‡ï¼‰
IGNORE_DIRS = {'.git', '__pycache__', 'venv', '.vscode', 'node_modules','migrations'}
# è¦å¿½ç•¥çš„æ–‡ä»¶
IGNORE_FILES = {'.DS_Store', OUTPUT_FILE,'éå†æ–‡ä»¶.py'} # ç¡®ä¿ä¸æŠŠè¾“å‡ºæ–‡ä»¶æœ¬èº«åŒ…å«è¿›å»

def generate_file_tree(root_dir, ignore_dirs, ignore_files):
    """ç”Ÿæˆé¡¹ç›®æ–‡ä»¶æ ‘ç»“æ„"""
    tree_lines = []
    for root, dirs, files in os.walk(root_dir, topdown=True):
        # åœ¨éå†å‰ï¼Œä»dirsåˆ—è¡¨ä¸­ç§»é™¤è¦å¿½ç•¥çš„ç›®å½•
        dirs[:] = [d for d in dirs if d not in ignore_dirs]
        
        # è®¡ç®—å½“å‰æ·±åº¦ï¼Œç”¨äºç”Ÿæˆå‰ç¼€
        level = root.replace(root_dir, '').count(os.sep)
        indent = ' ' * 4 * level
        
        # æ·»åŠ ç›®å½•ååˆ°æ ‘
        # os.path.basename(root) ç”¨äºè·å–å½“å‰ç›®å½•å
        tree_lines.append(f"{indent}ğŸ“‚ {os.path.basename(root)}/")

        # æ·»åŠ æ–‡ä»¶åˆ°æ ‘
        sub_indent = ' ' * 4 * (level + 1)
        for f in sorted(files): # å¯¹æ–‡ä»¶è¿›è¡Œæ’åº
            if f not in ignore_files:
                tree_lines.append(f"{sub_indent}ğŸ“„ {f}")
                
    return "\n".join(tree_lines)

def get_python_file_contents(root_dir, ignore_dirs):
    """è·å–æ‰€æœ‰.pyæ–‡ä»¶çš„å†…å®¹å¹¶æ ¼å¼åŒ–"""
    py_contents = []
    for root, dirs, files in os.walk(root_dir, topdown=True):
        # åŒæ ·ï¼Œå¿½ç•¥æŒ‡å®šç›®å½•
        dirs[:] = [d for d in dirs if d not in ignore_dirs]
        
        for file in sorted(files):
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè®©è¾“å‡ºæ›´æ¸…æ™°
                relative_path = os.path.relpath(file_path, root_dir)
                
                header = f"####{relative_path}####"
                footer = "####æ–‡ä»¶ç»“æŸ####"
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    py_contents.append(f"{header}\n{content}\n{footer}\n")
                except Exception as e:
                    py_contents.append(f"{header}\næ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {e}\n{footer}\n")
                    
    return "\n".join(py_contents)

def main():
    """ä¸»å‡½æ•°ï¼Œæ‰§è¡Œæ‰€æœ‰æ“ä½œ"""
    print("å¼€å§‹ç”Ÿæˆé¡¹ç›®æ–‡ä»¶æ ‘...")
    file_tree = generate_file_tree(ROOT_DIR, IGNORE_DIRS, IGNORE_FILES)
    
    print("å¼€å§‹è¯»å–æ‰€æœ‰.pyæ–‡ä»¶å†…å®¹...")
    python_contents = get_python_file_contents(ROOT_DIR, IGNORE_DIRS)
    
    print(f"æ­£åœ¨å°†ç»“æœå†™å…¥ {OUTPUT_FILE}...")
    
    # å°†æ‰€æœ‰å†…å®¹åˆå¹¶å†™å…¥æ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write("======= é¡¹ç›®æ–‡ä»¶æ ‘ =======\n\n")
        f.write(file_tree)
        f.write("\n\n========================\n\n")
        f.write("======= Pythonæ–‡ä»¶å†…å®¹ =======\n\n")
        f.write(python_contents)
        
    print(f"âœ… æˆåŠŸï¼é¡¹ç›®ç»“æ„å’Œä»£ç å·²ä¿å­˜åˆ° {OUTPUT_FILE}")

if __name__ == '__main__':
    main()

####æ–‡ä»¶ç»“æŸ####

####autoTrade\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####autoTrade\asgi.py####
"""
ASGI config for autoTrade project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'autoTrade.settings')

application = get_asgi_application()

####æ–‡ä»¶ç»“æŸ####

####autoTrade\settings.py####
"""
Django settings for autoTrade project.

Generated by 'django-admin startproject' using Django 5.2.4.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""

from pathlib import Path
import os
import dotenv
# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent
dotenv.load_dotenv(os.path.join(BASE_DIR, '.env'))


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!

# SECURITY WARNING: don't run with debug turned on in production!

SECRET_KEY = os.getenv('SECRET_KEY', 'default-secret-key-for-dev')
ENVIRONMENT = os.getenv('ENVIRONMENT', 'development')
DEBUG = (ENVIRONMENT == 'development')
if ENVIRONMENT == 'production':
    # è¯·å°† 'your_domain.com' å’ŒæœåŠ¡å™¨çš„å…¬ç½‘/å†…ç½‘IPå¡«å…¥
    ALLOWED_HOSTS = ['your_domain.com', '1.15.100.196', '10.0.4.15','10.0.12.10','127.0.0.1','0.0.0.0']
else:
    ALLOWED_HOSTS = ['*']


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'data_manager',
    'selection_manager',
    'trade_manager',
    'common'
]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    #'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'autoTrade.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'autoTrade.wsgi.application'


# Database
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME', 'maindb'),
        'USER': os.getenv('DB_USER', 'xyx'),
        'PASSWORD': os.getenv('DB_PASSWORD', 'xyx123'),
        'HOST': os.getenv('DB_HOST', 'localhost'), # é»˜è®¤ä½¿ç”¨ localhost
        'PORT': os.getenv('DB_PORT', '5432'),
        'OPTIONS': {
            'keepalives': 1,
            'keepalives_idle': 60,
            'keepalives_interval': 10,
            'keepalives_count': 6,
        }
    }
}


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'Asia/Shanghai'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'


LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,  # ä¸è¦ç¦ç”¨å·²å­˜åœ¨çš„æ—¥å¿—å™¨ï¼Œå¦åˆ™ Django è‡ªå¸¦çš„æ—¥å¿—ä¼šå¤±æ•ˆ
    
    # 1. å®šä¹‰æ—¥å¿—æ ¼å¼
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
        'simple': {
            'format': '{levelname} {message}',
            'style': '{',
        },
    },
    
    # 2. å®šä¹‰å¤„ç†å™¨ (æ—¥å¿—å»å“ªé‡Œ)
    'handlers': {
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        'console': {
            'level': 'DEBUG',  # å¤„ç† DEBUG åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
            'class': 'logging.StreamHandler',
            'formatter': 'verbose', # ä½¿ç”¨ verbose æ ¼å¼
        },
        # è¾“å‡ºåˆ°æ–‡ä»¶
        'file': {
            'level': 'DEBUG',  # å¤„ç† INFO åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
            'class': 'concurrent_log_handler.ConcurrentRotatingFileHandler',
            'filename': os.path.join(BASE_DIR, 'logs/django.log'), # æ—¥å¿—æ–‡ä»¶è·¯å¾„
            'maxBytes': 1024 * 1024 * 10,  # 5 MB
            'backupCount': 5, # æœ€å¤šä¿ç•™ 5 ä¸ªå¤‡ä»½æ–‡ä»¶
            'formatter': 'verbose', # ä½¿ç”¨ verbose æ ¼å¼
        },
    },
    
    # 3. å®šä¹‰è®°å½•å™¨ (å“ªäº›æ—¥å¿—éœ€è¦å¤„ç†)
    'loggers': {
        # Django æ¡†æ¶è‡ªèº«çš„æ—¥å¿—
        'django': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': True,
        },
        # ä½ è‡ªå·±åº”ç”¨çš„æ—¥å¿—
        'data_manager': { # è¿™é‡Œä½¿ç”¨ä½ çš„ app åç§°
            'handlers': ['console','file'],
            'level': 'DEBUG', # åœ¨å¼€å‘æ—¶è®¾ä¸º DEBUGï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯
            'propagate': False, # ä¸å‘ä¸Šä¼ é€’ç»™ root logger
        },
        'selection_manager': { # è¿™é‡Œä½¿ç”¨ä½ çš„ app åç§°
            'handlers': ['console','file'],
            'level': 'DEBUG', # åœ¨å¼€å‘æ—¶è®¾ä¸º DEBUGï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯
            'propagate': False, # ä¸å‘ä¸Šä¼ é€’ç»™ root logger
        },
        'trade_manager': { # è¿™é‡Œä½¿ç”¨ä½ çš„ app åç§°
            'handlers': ['console','file'],
            'level': 'DEBUG', # åœ¨å¼€å‘æ—¶è®¾ä¸º DEBUGï¼Œå¯ä»¥çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯
            'propagate': False, # ä¸å‘ä¸Šä¼ é€’ç»™ root logger
        },
        # ä½ å¯ä»¥ä¸ºä»»ä½•æ¨¡å—å®šä¹‰ logger
        'common': {
            'handlers': ['console', 'file'],
            'level': 'DEBUG',
            'propagate': False,
        },
        # --- æ–°å¢æ—¥å¿—æ¸…ç†é…ç½® ---
        'sqlalchemy.engine': {
            'handlers': ['console', 'file'],
            'level': 'WARNING',  # <-- åªæ˜¾ç¤º WARNING åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—ï¼Œè¿‡æ»¤æ‰SQLè¯­å¥
            'propagate': False,
        },
        'psycopg2': {
            'handlers': ['console', 'file'],
            'level': 'WARNING',  # <-- è¿‡æ»¤æ‰ psycopg2 çš„ä½çº§åˆ«æ—¥å¿—
            'propagate': False,
        },
        'apscheduler': {
            'handlers': ['console', 'file'],
            'level': 'WARNING', # <-- è¿‡æ»¤æ‰ apscheduler çš„ INFO æ—¥å¿—
            'propagate': False,
        }

    }
}
 
# ç¡®ä¿ logs ç›®å½•å­˜åœ¨
LOGS_DIR = os.path.join(BASE_DIR, 'logs')
if not os.path.exists(LOGS_DIR):
    os.makedirs(LOGS_DIR)
####æ–‡ä»¶ç»“æŸ####

####autoTrade\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include

urlpatterns = [
    path('admin/', admin.site.urls),
    path('dataManager/', include('data_manager.urls')),
    path('selectionManager/', include('selection_manager.urls')),
    path('tradeManager/', include('trade_manager.urls'))
]

####æ–‡ä»¶ç»“æŸ####

####autoTrade\wsgi.py####
"""
WSGI config for autoTrade project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'autoTrade.settings')

application = get_wsgi_application()

####æ–‡ä»¶ç»“æŸ####

####common\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####common\admin.py####
# common/admin.py

from django.contrib import admin
from .models import (
    StockInfo, DailyQuotes, FactorDefinitions, DailyFactorValues,
    StrategyParameters, DailyTradingPlan, Position, TradeLog,
    SystemLog, CorporateAction
)

# -----------------------------------------------------------------------------
# 1. åŸºç¡€æ•°æ®ç®¡ç† (è‚¡ç¥¨ä¿¡æ¯ã€è¡Œæƒ…ã€è‚¡æƒäº‹ä»¶)
# -----------------------------------------------------------------------------

@admin.register(StockInfo)
class StockInfoAdmin(admin.ModelAdmin):
    """è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ç®¡ç†"""
    list_display = ('stock_code', 'stock_name', 'listing_date', 'status', 'updated_at')
    search_fields = ('stock_code', 'stock_name')
    list_filter = ('status', 'listing_date')
    ordering = ('stock_code',)
    readonly_fields = ('created_at', 'updated_at')

@admin.register(DailyQuotes)
class DailyQuotesAdmin(admin.ModelAdmin):
    """æ—¥çº¿è¡Œæƒ…ç®¡ç†"""
    list_display = ('trade_date', 'stock_code', 'open', 'close', 'volume', 'turnover', 'hfq_close')
    search_fields = ('stock_code__stock_code', 'stock_code__stock_name')
    list_filter = ('trade_date',)
    ordering = ('-trade_date', 'stock_code')
    # å…³é”®æ€§èƒ½ä¼˜åŒ–ï¼šå¯¹äºæœ‰æˆåƒä¸Šä¸‡æ¡è®°å½•çš„å¤–é”®ï¼Œä½¿ç”¨ raw_id_fields æ›¿ä»£ä¸‹æ‹‰æ¡†
    raw_id_fields = ('stock_code',)
    readonly_fields = ('hfq_close',)
    list_per_page = 25 # è®¾ç½®æ¯é¡µæ˜¾ç¤ºæ¡æ•°

class CorporateActionAdmin(admin.ModelAdmin):
    """è‚¡æƒäº‹ä»¶ç®¡ç†"""
    list_display = ('ex_dividend_date', 'stock_code', 'event_type', 'dividend_per_share', 'shares_before', 'shares_after', 'rights_issue_price')
    # ä¿®æ­£ï¼šç›´æ¥æœç´¢æœ¬è¡¨çš„ stock_code å­—æ®µå³å¯
    search_fields = ('stock_code',) 
    list_filter = ('event_type', 'ex_dividend_date')
    ordering = ('-ex_dividend_date', 'stock_code')
    # raw_id_fields = ('stock_code',)

# -----------------------------------------------------------------------------
# 2. ç­–ç•¥ä¸å› å­å®šä¹‰ç®¡ç†
# -----------------------------------------------------------------------------

@admin.register(FactorDefinitions)
class FactorDefinitionsAdmin(admin.ModelAdmin):
    """å› å­å®šä¹‰ç®¡ç†"""
    list_display = ('factor_code', 'factor_name', 'direction', 'is_active', 'description')
    search_fields = ('factor_code', 'factor_name')
    list_filter = ('direction', 'is_active')
    ordering = ('factor_code',)

@admin.register(StrategyParameters)
class StrategyParametersAdmin(admin.ModelAdmin):
    """ç­–ç•¥å‚æ•°ç®¡ç†"""
    list_display = ('param_name', 'param_value', 'group_name', 'description')
    search_fields = ('param_name', 'group_name')
    list_filter = ('group_name',)
    ordering = ('group_name', 'param_name')
    # æ ¸å¿ƒåŠŸèƒ½ï¼šå…è®¸åœ¨åˆ—è¡¨é¡µç›´æ¥ç¼–è¾‘å‚æ•°å€¼ï¼Œéå¸¸æ–¹ä¾¿è°ƒå‚
    list_editable = ('param_value',)

@admin.register(DailyFactorValues)
class DailyFactorValuesAdmin(admin.ModelAdmin):
    """æ¯æ—¥å› å­å€¼ç®¡ç†"""
    list_display = ('trade_date', 'stock_code', 'factor_code', 'raw_value', 'norm_score')
    search_fields = ('stock_code__stock_code', 'factor_code__factor_code')
    list_filter = ('trade_date', 'factor_code')
    ordering = ('-trade_date', 'stock_code')
    # å…³é”®æ€§èƒ½ä¼˜åŒ–
    raw_id_fields = ('stock_code', 'factor_code')
    list_per_page = 25

# -----------------------------------------------------------------------------
# 3. äº¤æ˜“æµç¨‹ç®¡ç† (é¢„æ¡ˆã€æŒä»“ã€è®°å½•)
# -----------------------------------------------------------------------------

@admin.register(DailyTradingPlan)
class DailyTradingPlanAdmin(admin.ModelAdmin):
    """æ¯æ—¥äº¤æ˜“é¢„æ¡ˆç®¡ç†"""
    list_display = ('plan_date', 'stock_code', 'rank', 'final_score', 'miop', 'maop', 'status')
    search_fields = ('stock_code__stock_code',)
    list_filter = ('plan_date', 'status')
    ordering = ('-plan_date', 'rank')
    raw_id_fields = ('stock_code',)
    list_per_page = 20

@admin.register(Position)
class PositionAdmin(admin.ModelAdmin):
    """æŒä»“ä¿¡æ¯ç®¡ç†"""
    list_display = ('position_id', 'stock_code', 'entry_datetime', 'entry_price', 'quantity', 'current_stop_loss', 'current_take_profit', 'status')
    search_fields = ('stock_code__stock_code',)
    list_filter = ('status', 'entry_datetime')
    ordering = ('-entry_datetime',)
    raw_id_fields = ('stock_code',)

@admin.register(TradeLog)
class TradeLogAdmin(admin.ModelAdmin):
    """äº¤æ˜“è®°å½•ç®¡ç†"""
    list_display = ('trade_id', 'position', 'stock_code', 'trade_datetime', 'trade_type', 'price', 'quantity', 'reason', 'status')
    search_fields = ('stock_code__stock_code', 'position__position_id')
    list_filter = ('trade_type', 'status', 'reason', 'trade_datetime')
    ordering = ('-trade_datetime',)
    raw_id_fields = ('position', 'stock_code')
    list_per_page = 25

# -----------------------------------------------------------------------------
# 4. ç³»ç»Ÿä¸æ—¥å¿—ç®¡ç†
# -----------------------------------------------------------------------------

@admin.register(SystemLog)
class SystemLogAdmin(admin.ModelAdmin):
    """ç³»ç»Ÿæ—¥å¿—ç®¡ç†"""
    list_display = ('log_time', 'log_level', 'module_name', 'message_summary')
    list_filter = ('log_level', 'module_name', 'log_time')
    search_fields = ('message', 'module_name')
    ordering = ('-log_time',)
    # æ—¥å¿—åº”è¯¥æ˜¯ä¸å¯å˜çš„ï¼Œæ‰€ä»¥è®¾ä¸ºåªè¯»
    readonly_fields = ('log_time', 'log_level', 'module_name', 'message')
    list_per_page = 30

    def message_summary(self, obj):
        """åœ¨åˆ—è¡¨é¡µæ˜¾ç¤ºæˆªæ–­çš„æ—¥å¿—ä¿¡æ¯"""
        return (obj.message[:80] + '...') if len(obj.message) > 80 else obj.message
    message_summary.short_description = 'æ—¥å¿—æ‘˜è¦'

    def has_add_permission(self, request):
        # ç¦æ­¢åœ¨Adminåå°æ‰‹åŠ¨æ·»åŠ æ—¥å¿—
        return False

    def has_change_permission(self, request, obj=None):
        # ç¦æ­¢åœ¨Adminåå°ä¿®æ”¹æ—¥å¿—
        return False

####æ–‡ä»¶ç»“æŸ####

####common\apps.py####
from django.apps import AppConfig


class CommonConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'common'

####æ–‡ä»¶ç»“æŸ####

####common\config_loader.py####
# common/config_loader.py

import json
import os
import logging
from django.conf import settings

logger = logging.getLogger(__name__)

class ConfigLoader:
    _instance = None
    _config = None

    def __new__(cls):
        if not cls._instance:
            cls._instance = super(ConfigLoader, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if self._config is None:
            self._load_config()

    def _load_config(self):
        config_path = os.path.join(settings.BASE_DIR, 'config.json')
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self._config = json.load(f)
            logger.info("ConfigLoader: config.json åŠ è½½æˆåŠŸã€‚")
        except (FileNotFoundError, json.JSONDecodeError) as e:
            logger.critical(f"ConfigLoader: æ— æ³•åŠ è½½æˆ–è§£æ config.json: {e}ã€‚ç³»ç»Ÿå°†æ— æ³•æ­£å¸¸è¿è¡Œã€‚")
            self._config = {} # è¿”å›ä¸€ä¸ªç©ºå­—å…¸ä»¥é¿å…åç»­è°ƒç”¨å‡ºé”™

    def get_config(self):
        """è·å–å®Œæ•´çš„é…ç½®å­—å…¸"""
        return self._config

    def get(self, key, default=None):
        """è·å–æŒ‡å®šé”®çš„é…ç½®å€¼"""
        return self._config.get(key, default)

# åˆ›å»ºä¸€ä¸ªå…¨å±€å®ä¾‹ï¼Œä¾›é¡¹ç›®å„å¤„è°ƒç”¨
config_loader = ConfigLoader()

####æ–‡ä»¶ç»“æŸ####

####common\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####common\views.py####
from django.shortcuts import render

# Create your views here.

####æ–‡ä»¶ç»“æŸ####

####common\models\__init__.py####
# my_strategy_app/__init__.py

from .stock_info import StockInfo
from .daily_quotes import DailyQuotes
from .factor_definitions import FactorDefinitions
from .daily_factor_values import DailyFactorValues
from .strategy_parameters import StrategyParameters
from .daily_trading_plan import DailyTradingPlan
from .positions import Position
from .trade_log import TradeLog
from .system_log import SystemLog
from .corporate_action import CorporateAction

__all__ = [
    'StockInfo',
    'DailyQuotes',
    'FactorDefinitions',
    'DailyFactorValues',
    'StrategyParameters',
    'DailyTradingPlan',
    'Position',
    'TradeLog',
    'SystemLog',
    'CorporateAction'
]

####æ–‡ä»¶ç»“æŸ####

####common\models\backtest_logs.py####
# ==============================================================================
# æè¿°: å®šä¹‰å›æµ‹æ—¥å¿—ç›¸å…³çš„æ–°æ¨¡å‹ã€‚
# ==============================================================================
from django.db import models

class BacktestDailyLog(models.Model):
    """
    å›æµ‹æ¯æ—¥æ—¥å¿—è¡¨
    
    è¯´æ˜: è®°å½•æ¯ä¸€æ¬¡å›æµ‹è¿è¡Œä¸­ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥ç»“æŸåçš„èµ„é‡‘ã€æŒä»“å’Œå¸‚åœºçŠ¶æ€ã€‚
    è¿™å¼ è¡¨ç”¨äºç”Ÿæˆèµ„é‡‘æ›²çº¿å›¾å’Œå…³é”®çš„å›æ’¤æŒ‡æ ‡ã€‚
    """
    backtest_run_id = models.CharField(
        max_length=50,
        db_index=True,
        help_text="å›æµ‹è¿è¡Œçš„å”¯ä¸€æ ‡è¯†ç¬¦, å¦‚ 'backtest_20231027_153000'"
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    total_assets = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="å½“æ—¥æ—¥ç»ˆæ€»èµ„äº§ (ç°é‡‘ + æŒä»“å¸‚å€¼)"
    )
    cash = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="å½“æ—¥æ—¥ç»ˆç°é‡‘ä½™é¢"
    )
    holdings_value = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="å½“æ—¥æ—¥ç»ˆæŒä»“å¸‚å€¼"
    )
    market_m_value = models.DecimalField(
        max_digits=18,
        decimal_places=10,
        null=True,
        blank=True,
        help_text="å½“æ—¥çš„å¸‚åœºçŠ¶æ€M(t)å€¼"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )

    class Meta:
        db_table = 'tb_trade_manager_backtest_daily_log'
        verbose_name = 'å›æµ‹æ¯æ—¥æ—¥å¿—'
        verbose_name_plural = verbose_name
        ordering = ['backtest_run_id', 'trade_date']
        # ä¸ºå¸¸ç”¨æŸ¥è¯¢æ·»åŠ ç´¢å¼•
        indexes = [
            models.Index(fields=['backtest_run_id', 'trade_date']),
        ]

class BacktestOperationLog(models.Model):
    """
    å›æµ‹æ“ä½œè®°å½•è¡¨
    
    è¯´æ˜: å¢é‡è®°å½•å›æµ‹è¿‡ç¨‹ä¸­çš„æ¯ä¸€æ¬¡ä¹°å…¥å’Œå–å‡ºæ“ä½œã€‚
    è¿™å¼ è¡¨ç”¨äºè®¡ç®—èƒœç‡ã€æ”¶ç›Šè´¡çŒ®ç­‰äº¤æ˜“å±‚é¢çš„æŒ‡æ ‡ã€‚
    """
    class Direction(models.TextChoices):
        BUY = 'BUY', 'ä¹°å…¥'
        SELL = 'SELL', 'å–å‡º'

    class ExitReason(models.TextChoices):
        TAKE_PROFIT = 'TAKE_PROFIT', 'æ­¢ç›ˆ'
        STOP_LOSS = 'STOP_LOSS', 'æ­¢æŸ'

    backtest_run_id = models.CharField(
        max_length=50,
        db_index=True,
        help_text="å›æµ‹è¿è¡Œçš„å”¯ä¸€æ ‡è¯†ç¬¦"
    )
    position_id_ref = models.BigIntegerField(
        db_index=True,
        help_text="å…³è”çš„æŒä»“ID (tb_positions.position_id)ï¼Œç”¨äºåæŸ¥"
    )
    stock_code = models.CharField(
        max_length=50,
        help_text="è‚¡ç¥¨ä»£ç , å¦‚ 'sh.600000'"
    )
    stock_name = models.CharField(
        max_length=50,
        help_text="è‚¡ç¥¨åç§°"
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“å‘ç”Ÿçš„æ—¥æœŸ"
    )
    direction = models.CharField(
        max_length=10,
        choices=Direction.choices,
        help_text="ä¹°å–æ–¹å‘"
    )
    exit_reason = models.CharField(
        max_length=20,
        choices=ExitReason.choices,
        null=True,
        blank=True,
        help_text="æ­¢ç›ˆ/æ­¢æŸæ–¹å‘ (ä»…å–å‡ºæ—¶æœ‰æ•ˆ)"
    )
    profit_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="è¯¥ç¬”äº¤æ˜“è®¾ç½®çš„æ­¢ç›ˆç‡"
    )
    loss_rate = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="è¯¥ç¬”äº¤æ˜“è®¾ç½®çš„æ­¢æŸç‡"
    )
    buy_date_m_value = models.DecimalField(
        max_digits=18,
        decimal_places=10,
        null=True,
        blank=True,
        help_text="ä¹°å…¥å†³ç­–æ‰€ä¾æ®çš„T-1æ—¥å¸‚åœºM(t)å€¼"
    )
    factor_scores = models.TextField(
        help_text="ä¹°å…¥æ—¶å„å› å­å¾—åˆ†, æ ¼å¼: factor1:score1|factor2:score2"
    )
    price = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        help_text="æˆäº¤ä»·æ ¼"
    )
    quantity = models.BigIntegerField(
        help_text="æˆäº¤æ•°é‡"
    )
    amount = models.DecimalField(
        max_digits=20,
        decimal_places=4,
        help_text="æˆäº¤æ€»é‡‘é¢"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )

    class Meta:
        db_table = 'tb_trade_manager_backtest_operation_log'
        verbose_name = 'å›æµ‹æ“ä½œè®°å½•'
        verbose_name_plural = verbose_name
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['backtest_run_id', 'stock_code']),
            models.Index(fields=['backtest_run_id', 'position_id_ref']),
        ]


####æ–‡ä»¶ç»“æŸ####

####common\models\corporate_action.py####
from django.db import models

class CorporateAction(models.Model):
    """
    è‚¡æƒäº‹ä»¶è¡¨ (tb_corporate_actions)
    
    è¯´æ˜: å­˜å‚¨æ‰€æœ‰å½±å“è‚¡ä»·éäº¤æ˜“æ€§å˜åŠ¨çš„è‚¡æƒäº‹ä»¶ï¼Œæ˜¯ç›˜å‰æ ¡å‡†æ¨¡å—å’Œå›æµ‹å¼•æ“çš„æ ¸å¿ƒæ•°æ®æºã€‚
    
    ä¾‹å­:
    10é€5ï¼ševent_type='bonus', shares_before=10, shares_after=15
    10è½¬3ï¼ševent_type='transfer', shares_before=10, shares_after=13
    10é…3ï¼Œé…è‚¡ä»·8å…ƒï¼ševent_type='rights', shares_before=10, shares_after=13, rights_issue_price=8
    1æ‹†2ï¼ševent_type='split', shares_before=1, shares_after=2 (ç†è§£ä¸ºåœ¨1è‚¡åŸºç¡€ä¸Šå¢åŠ 1è‚¡)
    10å¹¶1ï¼ševent_type='split', shares_before=10, shares_after=1 (ç†è§£ä¸ºåœ¨10è‚¡åŸºç¡€ä¸Šå‡å°‘9è‚¡)
    æ´¾1å…ƒï¼ševent_type='dividend', dividend_per_share=0.1
    """

    # ä½¿ç”¨ Django æ¨èçš„ TextChoices æ¥å®šä¹‰äº‹ä»¶ç±»å‹çš„æšä¸¾
    class EventType(models.TextChoices):
        DIVIDEND = 'dividend', 'åˆ†çº¢'
        BONUS = 'bonus', 'é€è‚¡'
        TRANSFER = 'transfer', 'è½¬è‚¡'
        RIGHTS = 'rights', 'é…è‚¡'
        SPLIT = 'split', 'æ‹†è‚¡/å¹¶è‚¡'

    # å­—æ®µå®šä¹‰
    event_id = models.BigAutoField(
        primary_key=True,
        help_text="äº‹ä»¶å”¯ä¸€ID"
    )
    stock_code = models.CharField(
        max_length=50,
        null=False,
        blank=False,
        help_text="è‚¡ç¥¨ä»£ç , æ ¼å¼å¦‚ 'sh.600000'"
    )
    ex_dividend_date = models.DateField(
        null=False,
        db_index=True,
        help_text="é™¤æƒé™¤æ¯æ—¥ (ç­–ç•¥åˆ¤æ–­çš„åŸºå‡†æ—¥æœŸ)ï¼Œå¯¹äºé…è‚¡æ¥è¯´ï¼Œå®é™…ä¸ºè‚¡æƒç™»è®°æ—¥è€Œéé™¤æƒæ—¥"
    )
    record_date = models.DateField(
        null=True,
        blank=True,
        help_text="è‚¡æƒç™»è®°æ—¥"
    )
    notice_date = models.DateField(
        null=True,
        blank=True,
        help_text="å…¬å‘Šæ—¥æœŸ"
    )
    event_type = models.CharField(
        max_length=20,
        choices=EventType.choices,
        null=False,
        blank=False,
        help_text="äº‹ä»¶ç±»å‹ã€‚æšä¸¾: dividend(åˆ†çº¢), bonus(é€è‚¡), transfer(è½¬è‚¡),rights(é…è‚¡), split(æ‹†è‚¡/å¹¶è‚¡)"
    )
    dividend_per_share = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="æ¯è‚¡æ´¾æ¯(ç¨å‰, å…ƒï¼Œåˆ†çº¢ä¸“ç”¨)"
    )
    shares_before = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="åŸºå‡†è‚¡æ•° (å¦‚â€œ10é€5â€ï¼Œæ­¤å€¼ä¸º10ï¼Œé€è‚¡/è½¬è‚¡/æ‹†è‚¡/å¹¶è‚¡ä¸“ç”¨)"
    )
    shares_after = models.DecimalField(
        max_digits=10,
        decimal_places=4,
        null=True,
        blank=True,
        help_text="å˜åŠ¨è‚¡æ•° (å¦‚â€œ10é€5â€ï¼Œæ­¤å€¼ä¸º15ï¼Œé€è‚¡/è½¬è‚¡/æ‹†è‚¡/å¹¶è‚¡ä¸“ç”¨)"
    )
    rights_issue_price = models.DecimalField(
        max_digits=10,
        decimal_places=2,
        null=True,
        blank=True,
        help_text="é…è‚¡ä»·æ ¼ï¼Œé…è‚¡ä¸“ç”¨"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        null=False,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )

    class Meta:
        # æ˜¾å¼æŒ‡å®šæ•°æ®åº“ä¸­çš„è¡¨å
        db_table = 'tb_corporate_actions'
        # åœ¨ Django Admin ä¸­æ˜¾ç¤ºçš„åç§°
        verbose_name = 'è‚¡æƒäº‹ä»¶'
        verbose_name_plural = 'è‚¡æƒäº‹ä»¶'
        # é»˜è®¤æ’åºè§„åˆ™
        ordering = ['-ex_dividend_date', 'stock_code']

    def __str__(self):
        # æä¾›ä¸€ä¸ªæ˜“äºé˜…è¯»çš„å¯¹è±¡è¡¨ç¤ºå½¢å¼
        return f"{self.stock_code} on {self.ex_dividend_date}: {self.get_event_type_display()}"


####æ–‡ä»¶ç»“æŸ####

####common\models\daily_factor_values.py####
from django.db import models
from .stock_info import StockInfo
from .factor_definitions import FactorDefinitions

class DailyFactorValues(models.Model):
    """
    2.2. æ¯æ—¥å› å­å€¼è¡¨ (tb_daily_factor_values)
    è¯´æ˜: (æ ¸å¿ƒè®¾è®¡) å­˜å‚¨æ¯åªè‚¡ç¥¨åœ¨æ¯ä¸ªäº¤æ˜“æ—¥è®¡ç®—å‡ºçš„æ‰€æœ‰å› å­åŸå§‹å€¼å’Œæ ‡å‡†åŒ–åˆ†å€¼ã€‚
    """
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.CASCADE, 
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    factor_code = models.ForeignKey(
        FactorDefinitions, 
        on_delete=models.CASCADE, 
        db_column='factor_code',
        help_text="å› å­ä»£ç "
    )
    raw_value = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        help_text="å› å­è®¡ç®—å‡ºçš„åŸå§‹å€¼"
    )
    norm_score = models.DecimalField(
        max_digits=10, 
        decimal_places=4, 
        null=True, 
        blank=True,
        help_text="ç»è¿‡norm()å‡½æ•°æ ‡å‡†åŒ–åçš„åˆ†å€¼ (-100åˆ°100)"
    )

    def __str__(self):
        return f"{self.stock_code} - {self.factor_code} on {self.trade_date}"

    class Meta:
        db_table = 'tb_daily_factor_values'
        # ä½¿ç”¨ unique_together å®ç°å¤åˆä¸»é”®çš„å”¯ä¸€æ€§çº¦æŸ
        unique_together = (('stock_code', 'trade_date', 'factor_code'),)
        verbose_name = 'æ¯æ—¥å› å­å€¼'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\daily_quotes.py####
from django.db import models
from .stock_info import StockInfo

class DailyQuotes(models.Model):
    """
    1.2. æ—¥çº¿è¡Œæƒ…è¡¨ (tb_daily_quotes)
    è¯´æ˜: å­˜å‚¨ä»æ•°æ®æºè·å–çš„æœ€åŸå§‹çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œæ˜¯æ‰€æœ‰è®¡ç®—çš„åŸºçŸ³ã€‚
    """
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.CASCADE, 
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    trade_date = models.DateField(
        help_text="äº¤æ˜“æ—¥æœŸ"
    )
    open = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒå¼€ç›˜ä»·"
    )
    high = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒæœ€é«˜ä»·"
    )
    low = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒæœ€ä½ä»·"
    )
    close = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä¸å¤æƒæ”¶ç›˜ä»·"
    )
    volume = models.BigIntegerField(
        help_text="æˆäº¤é‡ (è‚¡)"
    )
    turnover = models.DecimalField(
        max_digits=20, 
        decimal_places=2, 
        help_text="æˆäº¤é¢ (å…ƒ)"
    )
    adjust_factor = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        help_text="æˆªè‡³å½“æ—¥çš„åå¤æƒå› å­"
    )
    # (è¦æ±‚1) è®¡ç®—åˆ— hfq_close
    hfq_close = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        editable=False,
        help_text="åå¤æƒæ”¶ç›˜ä»·ï¼Œå…¬å¼: close * adjust_factor"
    )

    def save(self, *args, **kwargs):
        # åœ¨ä¿å­˜æ¨¡å‹å‰è®¡ç®— hfq_close çš„å€¼
        self.hfq_close = self.close * self.adjust_factor
        super().save(*args, **kwargs)

    def __str__(self):
        return f"{self.stock_code} on {self.trade_date}"

    class Meta:
        db_table = 'tb_daily_quotes'
        # ä½¿ç”¨ unique_together å®ç°å¤åˆä¸»é”®çš„å”¯ä¸€æ€§çº¦æŸ
        unique_together = (('stock_code', 'trade_date'),)
        verbose_name = 'æ—¥çº¿è¡Œæƒ…'
        verbose_name_plural = verbose_name
        indexes = [
            models.Index(fields=['trade_date'], name='dailyquotes_tradedate_idx'), # <--- åœ¨è¿™é‡Œæ·»åŠ 
        ]

####æ–‡ä»¶ç»“æŸ####

####common\models\daily_trading_plan.py####
from django.db import models
from .stock_info import StockInfo

class DailyTradingPlan(models.Model):
    """
    3.1. æ¯æ—¥äº¤æ˜“é¢„æ¡ˆè¡¨ (tb_daily_trading_plan)
    è¯´æ˜: å­˜å‚¨ T-1 æ—¥ç»ˆé€‰è‚¡æ¨¡å—ç”Ÿæˆçš„â€œæ¬¡æ—¥è§‚å¯Ÿæ± â€åŠç›¸å…³äº¤æ˜“é¢„æ¡ˆã€‚
    """
    class StatusChoices(models.TextChoices):
        PENDING = 'pending', 'å¾…æ‰§è¡Œ'
        EXECUTED = 'executed', 'å·²æ‰§è¡Œä¹°å…¥'
        CANCELLED = 'cancelled', 'å½“æ—¥æœªæ»¡è¶³æ¡ä»¶ä½œåºŸ'

    plan_date = models.DateField(
        help_text="é¢„æ¡ˆæ‰§è¡Œæ—¥æœŸ (Tæ—¥)"
    )
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.CASCADE, 
        db_column='stock_code',
        help_text="å€™é€‰è‚¡ç¥¨ä»£ç "
    )
    rank = models.IntegerField(
        help_text="ç»¼åˆå¾—åˆ†æ’å (1-10)"
    )
    final_score = models.DecimalField(
        max_digits=10, 
        decimal_places=4, 
        help_text="f(x)é€‰è‚¡ç»¼åˆå¾—åˆ†"
    )
    miop = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="æœ€ä½å¯æ¥å—å¼€ç›˜ä»· (Minimum Acceptable Open Price)"
    )
    maop = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="æœ€é«˜å¯æ¥å—å¼€ç›˜ä»· (Maximum Acceptable Open Price)"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices, 
        default=StatusChoices.PENDING,
        help_text="é¢„æ¡ˆçŠ¶æ€ã€‚æšä¸¾: pending(å¾…æ‰§è¡Œ), executed(å·²æ‰§è¡Œä¹°å…¥), cancelled(å½“æ—¥æœªæ»¡è¶³æ¡ä»¶ä½œåºŸ)"
    )

    def __str__(self):
        return f"Plan for {self.stock_code} on {self.plan_date} (Rank: {self.rank})"

    class Meta:
        db_table = 'tb_daily_trading_plan'
        # ä½¿ç”¨ unique_together å®ç°å¤åˆä¸»é”®çš„å”¯ä¸€æ€§çº¦æŸ
        unique_together = (('plan_date', 'stock_code'),)
        verbose_name = 'æ¯æ—¥äº¤æ˜“é¢„æ¡ˆ'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\factor_definitions.py####
from django.db import models

class FactorDefinitions(models.Model):
    """
    2.1. å› å­å®šä¹‰è¡¨ (tb_factor_definitions)
    è¯´æ˜: (æ ¸å¿ƒè®¾è®¡) ç”¨äºå®šä¹‰æ‰€æœ‰ç­–ç•¥ä¸­ä½¿ç”¨çš„å› å­ï¼Œå®ç°å› å­çš„å¯æ’æ‹”ã€‚æ–°å¢å› å­åªéœ€åœ¨æ­¤è¡¨å¢åŠ ä¸€æ¡è®°å½•ã€‚
    """
    class DirectionChoices(models.TextChoices):
        POSITIVE = 'positive', 'æ­£å‘, å€¼è¶Šå¤§è¶Šå¥½'
        NEGATIVE = 'negative', 'è´Ÿå‘, å€¼è¶Šå°è¶Šå¥½'

    factor_code = models.CharField(
        max_length=50, 
        primary_key=True, 
        help_text="å› å­å”¯ä¸€è‹±æ–‡ä»£ç , å¦‚ 'MA20_SLOPE'"
    )
    factor_name = models.CharField(
        max_length=100, 
        help_text="å› å­ä¸­æ–‡åç§°, å¦‚ '20æ—¥å‡çº¿æ–œç‡'"
    )
    description = models.TextField(
        blank=True, 
        null=True, 
        help_text="è¯¦ç»†æè¿°å› å­çš„è®¡ç®—é€»è¾‘å’Œä¸šåŠ¡å«ä¹‰"
    )
    direction = models.CharField(
        max_length=10, 
        choices=DirectionChoices.choices,
        help_text="å› å­æ–¹å‘æ€§ã€‚æšä¸¾: positive(æ­£å‘, å€¼è¶Šå¤§è¶Šå¥½), negative(è´Ÿå‘, å€¼è¶Šå°è¶Šå¥½)"
    )
    is_active = models.BooleanField(
        default=True, 
        help_text="æ˜¯å¦å¯ç”¨è¯¥å› å­"
    )

    def __str__(self):
        return f"{self.factor_name} ({self.factor_code})"

    class Meta:
        db_table = 'tb_factor_definitions'
        verbose_name = 'å› å­å®šä¹‰'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\positions.py####
from django.db import models
from .stock_info import StockInfo

class Position(models.Model):
    """
    3.2. æŒä»“ä¿¡æ¯è¡¨ (tb_positions)
    è¯´æ˜: å­˜å‚¨å½“å‰æ‰€æœ‰æŒä»“çš„è¯¦ç»†ä¿¡æ¯ï¼Œæ˜¯ç›˜ä¸­ç›‘æ§æ¨¡å—çš„æ ¸å¿ƒæ•°æ®ä¾æ®ã€‚
    """
    class StatusChoices(models.TextChoices):
        OPEN = 'open', 'æŒä»“ä¸­'
        CLOSED = 'closed', 'å·²å¹³ä»“'

    position_id = models.BigAutoField(
        primary_key=True, 
        help_text="æŒä»“å”¯ä¸€ID"
    )
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.PROTECT, # ä¿æŠ¤ï¼Œé˜²æ­¢æ„å¤–åˆ é™¤å…³è”è‚¡ç¥¨ä¿¡æ¯
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    entry_datetime = models.DateTimeField(
        help_text="å»ºä»“æˆäº¤æ—¶é—´"
    )
    entry_price = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="å®é™…æˆäº¤å‡ä»· (AEP)"
    )
    quantity = models.BigIntegerField(
        help_text="æŒä»“æ•°é‡ (è‚¡)"
    )
    current_stop_loss = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="å½“å‰æ­¢æŸä»·"
    )
    current_take_profit = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="å½“å‰æ­¢ç›ˆä»·"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices, 
        default=StatusChoices.OPEN,
        help_text="æŒä»“çŠ¶æ€ã€‚æšä¸¾: open(æŒä»“ä¸­), closed(å·²å¹³ä»“)"
    )

    def __str__(self):
        return f"Position {self.position_id}: {self.quantity} of {self.stock_code}"

    class Meta:
        db_table = 'tb_positions'
        verbose_name = 'æŒä»“ä¿¡æ¯'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\stock_info.py####
from django.db import models
from django.utils import timezone

class StockInfo(models.Model):
    """
    1.1. è‚¡ç¥¨åŸºç¡€ä¿¡æ¯è¡¨ (tb_stock_info)
    è¯´æ˜: å­˜å‚¨æ‰€æœ‰Aè‚¡è‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯ï¼Œå¦‚ä»£ç ã€åç§°ã€ä¸Šå¸‚æ—¥æœŸç­‰ï¼Œä½œä¸ºå…¶ä»–æ•°æ®è¡¨çš„å…³è”åŸºç¡€ã€‚
    """
    class StatusChoices(models.TextChoices):
        LISTING = 'listing', 'ä¸Šå¸‚'
        DELISTED = 'delisted', 'é€€å¸‚'
        SUSPENDED = 'suspended', 'åœç‰Œ'

    stock_code = models.CharField(
        max_length=50, 
        primary_key=True, 
        help_text="è‚¡ç¥¨ä»£ç , æ ¼å¼å¦‚ 'sh.600000'"
    )
    stock_name = models.CharField(
        max_length=50, 
        help_text="è‚¡ç¥¨åç§°"
    )
    listing_date = models.DateField(
        help_text="ä¸Šå¸‚æ—¥æœŸ, ç”¨äºå‰”é™¤æ¬¡æ–°è‚¡"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices,
        help_text="è‚¡ç¥¨çŠ¶æ€ã€‚æšä¸¾: listing(ä¸Šå¸‚), delisted(é€€å¸‚), suspended(åœç‰Œ)"
    )
    created_at = models.DateTimeField(
        default=timezone.now, 
        editable=False,
        help_text="è®°å½•åˆ›å»ºæ—¶é—´"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        help_text="è®°å½•æ›´æ–°æ—¶é—´"
    )

    def __str__(self):
        return f"{self.stock_name}({self.stock_code})"

    class Meta:
        db_table = 'tb_stock_info'
        verbose_name = 'è‚¡ç¥¨åŸºç¡€ä¿¡æ¯'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\strategy_parameters.py####
from django.db import models

class StrategyParameters(models.Model):
    """
    2.3. ç­–ç•¥å‚æ•°è¡¨ (tb_strategy_parameters)
    è¯´æ˜: å­˜å‚¨æ‰€æœ‰ç­–ç•¥ä¸­å¯ä¼˜åŒ–çš„å‚æ•°ï¼Œå¦‚æƒé‡ã€ç³»æ•°ç­‰ï¼Œæ–¹ä¾¿å›æµ‹ä¸ä¼˜åŒ–æ¨¡å—è¿›è¡Œè¯»å–å’Œä¿®æ”¹ã€‚
    """
    param_name = models.CharField(
        max_length=50, 
        primary_key=True, 
        help_text="å‚æ•°å”¯ä¸€è‹±æ–‡å, å¦‚ 'w_trend', 'k_h1'"
    )
    param_value = models.DecimalField(
        max_digits=20, 
        decimal_places=10, 
        help_text="å‚æ•°çš„æ•°å€¼"
    )
    group_name = models.CharField(
        max_length=50, 
        blank=True, 
        null=True, 
        help_text="å‚æ•°æ‰€å±åˆ†ç»„, å¦‚ 'WEIGHTS', 'STOP_LOSS'"
    )
    description = models.TextField(
        blank=True, 
        null=True, 
        help_text="å‚æ•°çš„è¯¦ç»†è¯´æ˜"
    )

    def __str__(self):
        return f"{self.param_name} = {self.param_value}"

    class Meta:
        db_table = 'tb_strategy_parameters'
        verbose_name = 'ç­–ç•¥å‚æ•°'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\system_log.py####
from django.db import models
from django.utils import timezone

class SystemLog(models.Model):
    """
    4.1. ç³»ç»Ÿæ—¥å¿—è¡¨ (tb_system_log)
    è¯´æ˜: è®°å½•ç³»ç»Ÿè¿è¡Œè¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯ã€è­¦å‘Šå’Œé”™è¯¯ï¼Œä¾¿äºç›‘æ§å’Œè°ƒè¯•ã€‚
    """
    class LogLevelChoices(models.TextChoices):
        INFO = 'INFO', 'INFO'
        WARNING = 'WARNING', 'WARNING'
        ERROR = 'ERROR', 'ERROR'
        CRITICAL = 'CRITICAL', 'CRITICAL'

    log_id = models.BigAutoField(
        primary_key=True, 
        help_text="æ—¥å¿—å”¯ä¸€ID"
    )
    log_time = models.DateTimeField(
        default=timezone.now, 
        editable=False,
        help_text="æ—¥å¿—è®°å½•æ—¶é—´"
    )
    log_level = models.CharField(
        max_length=10, 
        choices=LogLevelChoices.choices,
        help_text="æ—¥å¿—çº§åˆ«ã€‚æšä¸¾: INFO, WARNING, ERROR, CRITICAL"
    )
    module_name = models.CharField(
        max_length=50, 
        blank=True, 
        null=True,
        help_text="äº§ç”Ÿæ—¥å¿—çš„æ¨¡å—å, å¦‚ 'æ—¥ç»ˆé€‰è‚¡', 'å¼€ç›˜å†³ç­–'"
    )
    message = models.TextField(
        help_text="æ—¥å¿—å†…å®¹, å¦‚ 'æ— åˆé€‚ä¹°ç‚¹', 'ä¸‹å•APIè¯·æ±‚å¤±è´¥'"
    )

    def __str__(self):
        return f"[{self.log_time.strftime('%Y-%m-%d %H:%M:%S')}] [{self.log_level}] {self.message[:80]}"

    class Meta:
        db_table = 'tb_system_log'
        verbose_name = 'ç³»ç»Ÿæ—¥å¿—'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####common\models\trade_log.py####
from django.db import models
from .stock_info import StockInfo

class TradeLog(models.Model):
    """
    3.3. äº¤æ˜“è®°å½•è¡¨ (tb_trade_log)
    è¯´æ˜: è®°å½•æ¯ä¸€æ¬¡ä¹°å…¥å’Œå–å‡ºçš„è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºæˆæœ¬æ ¸ç®—ã€ä¸šç»©åˆ†æå’Œé—®é¢˜æ’æŸ¥ã€‚
    """
    class TradeTypeChoices(models.TextChoices):
        BUY = 'buy', 'ä¹°å…¥'
        SELL = 'sell', 'å–å‡º'

    class OrderTypeChoices(models.TextChoices):
        LIMIT = 'limit', 'é™ä»·'
        MARKET = 'market', 'å¸‚ä»·'

    class ReasonChoices(models.TextChoices):
        ENTRY = 'entry', 'ç­–ç•¥å…¥åœº'
        TAKE_PROFIT = 'take_profit', 'æ­¢ç›ˆ'
        STOP_LOSS = 'stop_loss', 'æ­¢æŸ'
        MANUAL = 'manual', 'äººå·¥å¹²é¢„'

    class StatusChoices(models.TextChoices):
        FILLED = 'filled', 'å·²æˆäº¤'
        FAILED = 'failed', 'å¤±è´¥'
        CANCELLED = 'cancelled', 'å·²æ’¤é”€'
        PENDING = 'pending','å¾…æ‰§è¡Œ'

    trade_id = models.BigAutoField(
        primary_key=True, 
        help_text="äº¤æ˜“å”¯ä¸€ID"
    )
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨å­—ç¬¦ä¸² 'positions.Position' æ¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
    # related_name='trade_logs' å…è®¸ä» Position å¯¹è±¡åå‘è®¿é—®å…¶æ‰€æœ‰äº¤æ˜“è®°å½•
    position = models.ForeignKey(
        'Position', 
        on_delete=models.CASCADE, # å¦‚æœæŒä»“è¢«åˆ é™¤ï¼Œå…³è”çš„äº¤æ˜“è®°å½•ä¹Ÿåº”åˆ é™¤
        related_name='trade_logs',
        help_text="å…³è”çš„æŒä»“ID (ä¹°å…¥æ—¶ç”Ÿæˆ, å–å‡ºæ—¶å¼•ç”¨)"
    )
    stock_code = models.ForeignKey(
        StockInfo, 
        on_delete=models.PROTECT,
        db_column='stock_code',
        help_text="è‚¡ç¥¨ä»£ç "
    )
    trade_datetime = models.DateTimeField(
        help_text="äº¤æ˜“æˆäº¤æ—¶é—´"
    )
    trade_type = models.CharField(
        max_length=10, 
        choices=TradeTypeChoices.choices,
        help_text="äº¤æ˜“ç±»å‹ã€‚æšä¸¾: buy(ä¹°å…¥), sell(å–å‡º)"
    )
    order_type = models.CharField(
        max_length=10, 
        choices=OrderTypeChoices.choices,
        help_text="è®¢å•ç±»å‹ã€‚æšä¸¾: limit(é™ä»·), market(å¸‚ä»·)"
    )
    price = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="æˆäº¤å‡ä»·"
    )
    quantity = models.BigIntegerField(
        help_text="æˆäº¤æ•°é‡"
    )
    commission = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        help_text="ä½£é‡‘"
    )
    stamp_duty = models.DecimalField(
        max_digits=10, 
        decimal_places=2, 
        default=0,
        help_text="å°èŠ±ç¨ (ä»…å–å‡ºæ—¶æœ‰)"
    )
    reason = models.CharField(
        max_length=50, 
        choices=ReasonChoices.choices, 
        blank=True, 
        null=True,
        help_text="äº¤æ˜“åŸå› ã€‚æšä¸¾: entry(ç­–ç•¥å…¥åœº), take_profit(æ­¢ç›ˆ), stop_loss(æ­¢æŸ), manual(äººå·¥å¹²é¢„)"
    )
    status = models.CharField(
        max_length=20, 
        choices=StatusChoices.choices,
        help_text="è®¢å•çŠ¶æ€ã€‚æšä¸¾: filled(å·²æˆäº¤), failed(å¤±è´¥), cancelled(å·²æ’¤é”€),pending(å¾…æ‰§è¡Œ)"
    )

    external_order_id = models.CharField(
        max_length=50, 
        null=True, 
        blank=True, 
        db_index=True,
        help_text="å¤–éƒ¨äº¤æ˜“ç³»ç»Ÿçš„è®¢å•IDï¼Œå¦‚åˆ¸å•†çš„å§”æ‰˜ç¼–å·"
    )

    def __str__(self):
        return f"Trade {self.trade_id}: {self.trade_type.upper()} {self.quantity} of {self.stock_code}"

    class Meta:
        db_table = 'tb_trade_log'
        verbose_name = 'äº¤æ˜“è®°å½•'
        verbose_name_plural = verbose_name

####æ–‡ä»¶ç»“æŸ####

####data_manager\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####data_manager\admin.py####
from django.contrib import admin

# Register your models here.

####æ–‡ä»¶ç»“æŸ####

####data_manager\apps.py####
from django.apps import AppConfig


class DataManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'data_manager'

####æ–‡ä»¶ç»“æŸ####

####data_manager\models.py####
from django.db import models

# Create your models here.

####æ–‡ä»¶ç»“æŸ####

####data_manager\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####data_manager\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include
from . import views
urlpatterns = [
    path('test', views.test_get),
    path('updateLocalStock', views.update_local_a_shares),
    path('syncCorporateActions', views.sync_corporate_actions),
    path('sendEmail', views.email_send)
]

####æ–‡ä»¶ç»“æŸ####

####data_manager\views.py####
from django.http.response import JsonResponse
from django.shortcuts import render
from common.models import StockInfo
from data_manager.service.stock_service import StockService
from data_manager.service.corporate_action_service import CorporateActionService
from data_manager.service.email_service import EmailNotificationService
from django.views.decorators.http import require_http_methods
import json
from datetime import date,datetime
# Create your views here.
def test_get(request):
    result={}
    if request.method=='GET':
        result=  {'method':'get'}
    if request.method=='POST':
        result= {'methods':'post'}
    # service=StockService()
    # service.clear_all_data()
    # service.update_local_a_shares(start_date="2025-01-01",end_date="2025-08-04")
    # service.update_local_a_shares(start_date="2024-01-01",end_date="2024-12-31")
    # service.update_local_a_shares(start_date="2023-01-01",end_date="2023-12-31")
    # service.update_local_a_shares(start_date="2022-01-01",end_date="2022-12-31")
    # service.update_local_a_shares(start_date="2021-01-01",end_date="2021-12-31")
    return JsonResponse(result)

@require_http_methods(["POST"])
def update_local_a_shares(request):
    body= json.loads(request.body)
    service=StockService()
    service.update_local_a_shares(stock_codes=body['stockCodes'],start_date=body['startDate'],end_date=body['endDate'])
    return JsonResponse({"result":"success"})

@require_http_methods(["POST"])
def sync_corporate_actions(request):
    body= json.loads(request.body)
    service=CorporateActionService()
    service.sync_corporate_actions(start_date=body['startDate'],end_date=body['endDate'])
    return JsonResponse({"result":"success"})

@require_http_methods(["POST"])
def email_send(request):
    body= json.loads(request.body)
    service=EmailNotificationService(t_day=datetime.strptime(body['date'], "%Y-%m-%d").date())
    service.runEmailSend()
    return JsonResponse({"result":"success"})
####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\full_update_stocks.py####
# data_manager/management/commands/full_update_stocks.py

from django.core.management.base import BaseCommand
from data_manager.service.stock_service import StockService
from selection_manager.service.selection_service import SelectionService
import time
from datetime import date,datetime
class Command(BaseCommand):
    help = 'æ¸…ç©ºå¹¶é‡æ–°è·å–è¿‡å»äº”å¹´çš„å…¨éƒ¨Aè‚¡æ•°æ®'

    def handle(self, *args, **options):
        total_start_time = time.time()
        self.stdout.write(self.style.SUCCESS('===== å¼€å§‹æ‰§è¡Œå…¨é‡æ•°æ®æ›´æ–°ä»»åŠ¡ ====='))
        
        service = StockService()
        
        # 1. æ¸…ç©ºæ‰€æœ‰æ—§æ•°æ®
        self.stdout.write('æ­£åœ¨æ¸…ç©ºæ‰€æœ‰å†å²æ•°æ®...')
        #service.clear_all_data()
        self.stdout.write(self.style.SUCCESS('å†å²æ•°æ®å·²æ¸…ç©ºã€‚'))
        
        # 2. æŒ‰å¹´ä»½é¡ºåºè·å–æ•°æ®
        #service.clear_all_data()
        service.update_local_a_shares(start_date="2025-08-06",end_date="2025-08-08")
        service.update_local_a_shares(start_date="2018-01-01",end_date="2019-12-31")
        # service.update_local_a_shares(start_date="2023-01-01",end_date="2023-12-31")
        # service.update_local_a_shares(start_date="2022-01-01",end_date="2022-12-31")
        # service.update_local_a_shares(start_date="2021-01-01",end_date="2021-12-31")
        total_end_time = time.time()
        self.stdout.write(self.style.SUCCESS(f'\n===== æ‰€æœ‰å¹´ä»½æ•°æ®æ›´æ–°å®Œæ¯•ï¼æ€»è€—æ—¶: {(total_end_time - total_start_time) / 3600:.2f} å°æ—¶ ====='))
        self.stdout.write('å¼€å§‹é¢„çƒ­Må€¼...')
        service=SelectionService(datetime.strptime('2025-08-08', "%Y-%m-%d").date())
        service.run_selection()
        total_end_time_2 = time.time()

####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\migrate_to_pg.py####
# data_manager/management/commands/migrate_to_pg.py

from django.core.management.base import BaseCommand
from data_manager.service.db_service import DbMigrationService

class Command(BaseCommand):
    help = 'å°†æ•´ä¸ªSQLiteæ•°æ®åº“çš„ç»“æ„å’Œæ•°æ®è¿ç§»åˆ°PostgreSQL'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('å¼€å§‹æ‰§è¡Œæ•°æ®åº“è¿ç§»ä»»åŠ¡...'))
        
        try:
            service = DbMigrationService()
            service.migrate()
            self.stdout.write(self.style.SUCCESS('æ•°æ®åº“è¿ç§»ä»»åŠ¡å·²æˆåŠŸå®Œæˆã€‚'))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'æ•°æ®åº“è¿ç§»å¤±è´¥: {e}'))


####æ–‡ä»¶ç»“æŸ####

####data_manager\management\commands\reset_sequences.py####
# data_manager/management/commands/reset_sequences.py (V2 - ä¿®æ­£ç‰ˆ)
import logging
from django.core.management.base import BaseCommand
from django.db import connection, models
from django.apps import apps

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'Resets PostgreSQL sequences for integer AutoFields to the max value of their primary key columns.'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('===== å¼€å§‹æ™ºèƒ½é‡ç½®æ•°æ®åº“åºåˆ— (ä»…å¤„ç†è‡ªå¢æ•´æ•°ä¸»é”®) ====='))
        
        all_models = apps.get_models()
        
        with connection.cursor() as cursor:
            for model in all_models:
                table_name = model._meta.db_table
                pk_field = model._meta.pk
                
                # --- æ ¸å¿ƒä¿®æ­£ï¼šå¢åŠ ç±»å‹æ£€æŸ¥ ---
                # 1. æ£€æŸ¥ä¸»é”®æ˜¯å¦å­˜åœ¨ä¸”æ˜¯å¦ä¸ºè‡ªå¢å­—æ®µ
                if not pk_field or not isinstance(pk_field, models.AutoField):
                    self.stdout.write(f'æ­£åœ¨å¤„ç†è¡¨: {table_name} ... ' + self.style.WARNING('è·³è¿‡ (ä¸»é”®éè‡ªå¢æ•´æ•°)'))
                    continue

                # 2. å¦‚æœæ˜¯è‡ªå¢å­—æ®µï¼Œå…¶å†…éƒ¨ç±»å‹ä¸€å®šæ˜¯æ•´æ•°ï¼Œå¯ä»¥å®‰å…¨å¤„ç†
                pk_name = pk_field.name
                sequence_name = f"{table_name}_{pk_name}_seq"
                
                self.stdout.write(f'æ­£åœ¨å¤„ç†è¡¨: {table_name} (åºåˆ—: {sequence_name}) ... ', ending='')
                
                try:
                    # SQL to get the max PK value.
                    # COALESCE is still useful for empty tables.
                    # The third argument 'false' in setval means the next value will be max_id + 1
                    # No change needed here as we've already filtered for integer PKs.
                    sql = f"""
                    SELECT setval('"{sequence_name}"', (SELECT COALESCE(MAX("{pk_name}"), 1) FROM "{table_name}"), false);
                    """
                    cursor.execute(sql)
                    self.stdout.write(self.style.SUCCESS('OK'))
                except Exception as e:
                    # æ•è·å…¶ä»–å¯èƒ½çš„é”™è¯¯ï¼Œä¾‹å¦‚åºåˆ—çœŸçš„ä¸å­˜åœ¨
                    if "does not exist" in str(e):
                        self.stdout.write(self.style.WARNING(f'è·³è¿‡ (åºåˆ—ä¸å­˜åœ¨)'))
                    else:
                        self.stdout.write(self.style.ERROR(f'å¤±è´¥: {e}'))
                        logger.error(f"é‡ç½®åºåˆ— {sequence_name} å¤±è´¥: {e}", exc_info=True)

        self.stdout.write(self.style.SUCCESS('\n===== æ•°æ®åº“åºåˆ—æ™ºèƒ½é‡ç½®å®Œæ¯• ====='))

####æ–‡ä»¶ç»“æŸ####

####data_manager\service\corporate_action_service.py####
import logging
import time
from datetime import datetime

import akshare
import pandas as pd
from django.db import transaction

# å¯¼å…¥æ‚¨çš„ Django models
# è¯·æ ¹æ®æ‚¨çš„é¡¹ç›®ç»“æ„è°ƒæ•´ä»¥ä¸‹å¯¼å…¥è·¯å¾„
from common.models.corporate_action import CorporateAction
from common.models.stock_info import StockInfo

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)
class CorporateActionService:
    def _fetch_and_save_split_events(self,stock_codes_filter: list, start_date: str, end_date: str):
        """
        é¢„ç•™çš„æ‹†è‚¡/å¹¶è‚¡äº‹ä»¶å¤„ç†å‡½æ•°ã€‚
        """
        # logger.info(f"æ­£åœ¨æ£€æŸ¥æ‹†è‚¡/å¹¶è‚¡äº‹ä»¶ (å½“å‰ç‰ˆæœ¬æš‚æœªå®ç°)...")
        pass

    def sync_corporate_actions(self,start_date: str, end_date: str, stock_codes: list = None):
        """
        ä» Akshare é«˜æ•ˆåŒæ­¥æŒ‡å®šæ—¥æœŸèŒƒå›´å’Œè‚¡ç¥¨èŒƒå›´çš„è‚¡æƒäº‹ä»¶æ•°æ®ï¼Œå¹¶å­˜å…¥æ•°æ®åº“ã€‚
        """
        logger.info(f"å¼€å§‹åŒæ­¥è‚¡æƒäº‹ä»¶ï¼Œæ—¥æœŸèŒƒå›´: {start_date} to {end_date}ã€‚")
        if stock_codes:
            logger.info(f"ç›®æ ‡è‚¡ç¥¨: {len(stock_codes)} åªã€‚")
        else:
            logger.info("ç›®æ ‡è‚¡ç¥¨: å…¨éƒ¨Aè‚¡ã€‚")

        # 1. ä»»åŠ¡å¼€å§‹å‰ï¼Œä¸€æ¬¡æ€§æ¸…ç†æ•°æ®
        try:
            with transaction.atomic():
                qs = CorporateAction.objects.filter(
                    ex_dividend_date__gte=start_date,
                    ex_dividend_date__lte=end_date
                )
                if stock_codes:
                    qs = qs.filter(stock_code__in=stock_codes)
                
                deleted_count, _ = qs.delete()
                logger.info(f"æ•°æ®æ¸…ç†å®Œæˆã€‚åœ¨ {start_date} åˆ° {end_date} èŒƒå›´å†…å…±åˆ é™¤ {deleted_count} æ¡æ—§è®°å½•ã€‚")
        except Exception as e:
            logger.error(f"æ¸…ç†å†å²æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä»»åŠ¡ç»ˆæ­¢: {e}", exc_info=True)
            return

        all_stocks_map = {s.split('.')[-1]: s for s in StockInfo.objects.values_list('stock_code', flat=True)}
        ak_codes_filter = [c.split('.')[-1] for c in stock_codes] if stock_codes else None

        # 2. å¤„ç†åˆ†çº¢ã€é€è‚¡ã€è½¬è‚¡ (stock_fhps_em)
        try:
            logger.info("å¼€å§‹å¤„ç†åˆ†çº¢ã€é€è‚¡ã€è½¬è‚¡äº‹ä»¶...")
            fhps_dfs = []
            start_year = datetime.strptime(start_date, '%Y-%m-%d').year
            end_year = datetime.strptime(end_date, '%Y-%m-%d').year
            
            # â˜…â˜…â˜…â˜…â˜… ä¼˜åŒ–ç‚¹ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„å¹´ä»½èŒƒå›´ï¼Œè¦†ç›–è·¨å¹´é¢„æ¡ˆ â˜…â˜…â˜…â˜…â˜…
            report_suffixes = ["0331", "0630", "0930", "1231"]
            for year in range(start_year - 1, end_year + 1):
                for suffix in report_suffixes:
                    report_date = f"{year}{suffix}"
                    logger.info(f"æ­£åœ¨æ‹‰å–æŠ¥å‘ŠæœŸ {report_date} çš„åˆ†çº¢é€é…é¢„æ¡ˆ...")
                    try:
                        time.sleep(1)
                        fhps_df = akshare.stock_fhps_em(date=report_date)
                        if not fhps_df.empty:
                            fhps_dfs.append(fhps_df)
                    except Exception as e:
                        logger.warning(f"æ‹‰å–æŠ¥å‘ŠæœŸ {report_date} æ•°æ®å¤±è´¥æˆ–æ— æ•°æ®: {e}")
            
            if fhps_dfs:
                # ä½¿ç”¨ 'ä»£ç ' å’Œ 'é™¤æƒé™¤æ¯æ—¥' ä½œä¸ºè”åˆä¸»é”®å»é‡ï¼Œé˜²æ­¢åŒä¸€äº‹ä»¶å› åœ¨ä¸åŒæŠ¥å‘ŠæœŸæŠ«éœ²è€Œé‡å¤
                all_fhps_df = pd.concat(fhps_dfs, ignore_index=True).drop_duplicates(subset=['ä»£ç ', 'é™¤æƒé™¤æ¯æ—¥'])
                
                all_fhps_df['é™¤æƒé™¤æ¯æ—¥'] = pd.to_datetime(all_fhps_df['é™¤æƒé™¤æ¯æ—¥'], errors='coerce')
                all_fhps_df.dropna(subset=['é™¤æƒé™¤æ¯æ—¥'], inplace=True)
                
                mask = (all_fhps_df['é™¤æƒé™¤æ¯æ—¥'] >= pd.to_datetime(start_date)) & (all_fhps_df['é™¤æƒé™¤æ¯æ—¥'] <= pd.to_datetime(end_date))
                filtered_fhps_df = all_fhps_df[mask].copy()

                if ak_codes_filter:
                    filtered_fhps_df = filtered_fhps_df[filtered_fhps_df['ä»£ç '].isin(ak_codes_filter)]

                logger.info(f"å…±è·å–åˆ° {len(filtered_fhps_df)} æ¡ç¬¦åˆæ¡ä»¶çš„åˆ†çº¢é€è½¬è®°å½•ï¼Œå‡†å¤‡å…¥åº“...")

                with transaction.atomic():
                    for _, row in filtered_fhps_df.iterrows():
                        ak_code = row['ä»£ç ']
                        stock_code_prefixed = all_stocks_map.get(ak_code)
                        if not stock_code_prefixed:
                            continue

                        # åˆ†çº¢
                        if pd.notna(row['ç°é‡‘åˆ†çº¢-ç°é‡‘åˆ†çº¢æ¯”ä¾‹']) and row['ç°é‡‘åˆ†çº¢-ç°é‡‘åˆ†çº¢æ¯”ä¾‹'] > 0:
                            CorporateAction.objects.create(
                                stock_code=stock_code_prefixed,
                                ex_dividend_date=row['é™¤æƒé™¤æ¯æ—¥'].date(),
                                record_date=pd.to_datetime(row['è‚¡æƒç™»è®°æ—¥'], errors='coerce').date() if pd.notna(row['è‚¡æƒç™»è®°æ—¥']) else None,
                                notice_date=pd.to_datetime(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ'], errors='coerce').date() if pd.notna(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ']) else None,
                                event_type=CorporateAction.EventType.DIVIDEND,
                                dividend_per_share=row['ç°é‡‘åˆ†çº¢-ç°é‡‘åˆ†çº¢æ¯”ä¾‹'] / 10
                            )

                        # é€è‚¡
                        if pd.notna(row['é€è½¬è‚¡ä»½-é€è½¬æ¯”ä¾‹']) and row['é€è½¬è‚¡ä»½-é€è½¬æ¯”ä¾‹'] > 0:
                            CorporateAction.objects.create(
                                stock_code=stock_code_prefixed,
                                ex_dividend_date=row['é™¤æƒé™¤æ¯æ—¥'].date(),
                                record_date=pd.to_datetime(row['è‚¡æƒç™»è®°æ—¥'], errors='coerce').date() if pd.notna(row['è‚¡æƒç™»è®°æ—¥']) else None,
                                notice_date=pd.to_datetime(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ'], errors='coerce').date() if pd.notna(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ']) else None,
                                event_type=CorporateAction.EventType.BONUS,
                                shares_before=10,
                                shares_after=10 + row['é€è½¬è‚¡ä»½-é€è½¬æ¯”ä¾‹']
                            )

                        # è½¬è‚¡
                        if pd.notna(row['é€è½¬è‚¡ä»½-è½¬è‚¡æ¯”ä¾‹']) and row['é€è½¬è‚¡ä»½-è½¬è‚¡æ¯”ä¾‹'] > 0:
                            CorporateAction.objects.create(
                                stock_code=stock_code_prefixed,
                                ex_dividend_date=row['é™¤æƒé™¤æ¯æ—¥'].date(),
                                record_date=pd.to_datetime(row['è‚¡æƒç™»è®°æ—¥'], errors='coerce').date() if pd.notna(row['è‚¡æƒç™»è®°æ—¥']) else None,
                                notice_date=pd.to_datetime(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ'], errors='coerce').date() if pd.notna(row['æœ€æ–°å…¬å‘Šæ—¥æœŸ']) else None,
                                event_type=CorporateAction.EventType.TRANSFER,
                                shares_before=10,
                                shares_after=10 + row['é€è½¬è‚¡ä»½-è½¬è‚¡æ¯”ä¾‹']
                            )
            logger.info("åˆ†çº¢ã€é€è‚¡ã€è½¬è‚¡äº‹ä»¶å¤„ç†å®Œæˆã€‚")
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†çº¢é€è½¬æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)

        # 3. å¤„ç†é…è‚¡ (stock_pg_em)
        try:
            logger.info("å¼€å§‹å¤„ç†é…è‚¡äº‹ä»¶...")
            time.sleep(1)
            all_pg_df = akshare.stock_pg_em()
            
            # Akshare è¿”å›çš„ 'è‚¡æƒç™»è®°æ—¥' å¯èƒ½åŒ…å«æ— æ•ˆæ—¥æœŸï¼Œéœ€è¦å¤„ç†
            all_pg_df['è‚¡æƒç™»è®°æ—¥'] = pd.to_datetime(all_pg_df['è‚¡æƒç™»è®°æ—¥'], errors='coerce')
            all_pg_df.dropna(subset=['è‚¡æƒç™»è®°æ—¥'], inplace=True)
 
            mask = (all_pg_df['è‚¡æƒç™»è®°æ—¥'] >= pd.to_datetime(start_date)) & (all_pg_df['è‚¡æƒç™»è®°æ—¥'] <= pd.to_datetime(end_date))
            filtered_pg_df = all_pg_df[mask].copy()
 
            if ak_codes_filter:
                filtered_pg_df = filtered_pg_df[filtered_pg_df['è‚¡ç¥¨ä»£ç '].isin(ak_codes_filter)]
            
            logger.info(f"å…±è·å–åˆ° {len(filtered_pg_df)} æ¡ç¬¦åˆæ¡ä»¶çš„é…è‚¡è®°å½•ï¼Œå‡†å¤‡å…¥åº“...")
 
            with transaction.atomic():
                for _, row in filtered_pg_df.iterrows():
                    ak_code = row['è‚¡ç¥¨ä»£ç ']
                    stock_code_prefixed = all_stocks_map.get(ak_code)
                    if not stock_code_prefixed:
                        continue
 
                    # --- ä¿®æ”¹å¼€å§‹ ---
                    # ä» '10é…3.0' è¿™æ ·çš„å­—ç¬¦ä¸²ä¸­è§£æå‡ºé…è‚¡æ¯”ä¾‹æ•°å€¼
                    rights_ratio_val = 0
                    rights_ratio_str = row['é…è‚¡æ¯”ä¾‹']
                    
                    # ç¡®ä¿ 'é…è‚¡æ¯”ä¾‹' æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ã€å¯è§£æçš„å­—ç¬¦ä¸²
                    if pd.notna(rights_ratio_str) and isinstance(rights_ratio_str, str) and 'é…' in rights_ratio_str:
                        try:
                            # æŒ‰ 'é…' åˆ†å‰²ï¼Œå–åé¢çš„éƒ¨åˆ†ï¼Œå¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                            ratio_str_part = rights_ratio_str.split('é…')[1]
                            rights_ratio_val = float(ratio_str_part)
                        except (IndexError, ValueError) as e:
                            logger.warning(f"æ— æ³•è§£æè‚¡ç¥¨ {ak_code} çš„é…è‚¡æ¯”ä¾‹ '{rights_ratio_str}'ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯: {e}")
                            continue # è·³è¿‡æ­¤æ¡è®°å½•
 
                    if rights_ratio_val > 0:
                        CorporateAction.objects.create(
                            stock_code=stock_code_prefixed,
                            # æ³¨æ„ï¼šé…è‚¡é€šå¸¸ä½¿ç”¨ 'è‚¡æƒç™»è®°æ—¥' ä½œä¸ºå…³é”®æ—¥æœŸï¼Œ'é™¤æƒæ—¥' åœ¨æ­¤æ¥å£ä¸­å¯èƒ½ä¸æä¾›
                            ex_dividend_date=row['è‚¡æƒç™»è®°æ—¥'].date(), 
                            record_date=row['è‚¡æƒç™»è®°æ—¥'].date(),
                            notice_date=None, # akshare.stock_pg_em() æœªæä¾›å…¬å‘Šæ—¥æœŸ
                            event_type=CorporateAction.EventType.RIGHTS,
                            shares_before=10, # é…è‚¡åŸºå‡†é€šå¸¸æ˜¯10è‚¡
                            shares_after=10 + rights_ratio_val, # ä½¿ç”¨è§£æåçš„æ•°å€¼
                            rights_issue_price=row['é…è‚¡ä»·']
                        )
                    # --- ä¿®æ”¹ç»“æŸ ---
 
            logger.info("é…è‚¡äº‹ä»¶å¤„ç†å®Œæˆã€‚")
        except KeyError as e:
            # æ•è· 'é…è‚¡æ¯”ä¾‹' ç­‰å­—æ®µä¸å­˜åœ¨çš„é”™è¯¯
            logger.error(f"å¤„ç†é…è‚¡æ•°æ®æ—¶å‘ç”Ÿå­—æ®µç¼ºå¤±é”™è¯¯: {e}ã€‚è¯·æ£€æŸ¥ Akshare è¿”å›çš„æ•°æ®åˆ—åæ˜¯å¦å·²å˜æ›´ã€‚", exc_info=True)
        except Exception as e:
            logger.error(f"å¤„ç†é…è‚¡æ•°æ®æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)

        # 4. è°ƒç”¨é¢„ç•™çš„æ‹†è‚¡/å¹¶è‚¡å¤„ç†å‡½æ•°
        self._fetch_and_save_split_events(stock_codes, start_date, end_date)

        logger.info("æ‰€æœ‰è‚¡æƒäº‹ä»¶åŒæ­¥ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆã€‚")

####æ–‡ä»¶ç»“æŸ####

####data_manager\service\db_service.py####
# data_manager/service/db_service.py

import logging
import time
import pandas as pd
from sqlalchemy import create_engine, text
from django.apps import apps
from django.db import connections
from django.conf import settings
from collections import deque

logger = logging.getLogger(__name__)

class DbMigrationService:
    """
    ä¸€ä¸ªå¥å£®çš„æœåŠ¡ï¼Œç”¨äºå°†æ•°æ®ä»æºæ•°æ®åº“ï¼ˆSQLiteï¼‰è¿ç§»åˆ°ç›®æ ‡æ•°æ®åº“ï¼ˆPostgreSQLï¼‰ã€‚
    å®ƒèƒ½è‡ªåŠ¨å¤„ç†è¡¨ä¾èµ–å…³ç³»ï¼Œå¹¶ä½¿ç”¨åˆ†å—è¯»å†™æ¥å¤„ç†å¤§æ•°æ®è¡¨ã€‚
    """
    def __init__(self):
        # ä» Django settings è·å–ç›®æ ‡æ•°æ®åº“é…ç½®
        pg_config = settings.DATABASES['default']
        self.pg_uri = f"postgresql+psycopg2://{pg_config['USER']}:{pg_config['PASSWORD']}@{pg_config['HOST']}:{pg_config['PORT']}/{pg_config['NAME']}"
        
        # æºæ•°æ®åº“è·¯å¾„
        sqlite_path = settings.BASE_DIR / 'mainDB.sqlite3'
        self.sqlite_uri = f"sqlite:///{sqlite_path}"
        
        self.chunk_size = 50000  # æ¯æ¬¡å¤„ç†5ä¸‡è¡Œï¼Œé˜²æ­¢å†…å­˜æº¢å‡º

    def _get_migration_order(self) -> list:
        """
        é€šè¿‡æ‹“æ‰‘æ’åºåˆ†æ Django æ¨¡å‹ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç”Ÿæˆæ­£ç¡®çš„è¿ç§»é¡ºåºã€‚
        çˆ¶è¡¨ï¼ˆè¢«å¤–é”®å¼•ç”¨çš„è¡¨ï¼‰ä¼šæ’åœ¨å­è¡¨ï¼ˆæœ‰å¤–é”®çš„è¡¨ï¼‰å‰é¢ã€‚
        """
        all_models = apps.get_models()
        model_map = {model: model._meta.db_table for model in all_models}
        
        # æ„å»ºä¾èµ–å›¾å’Œå…¥åº¦è®¡æ•°
        dependencies = {model: set() for model in all_models}
        in_degree = {model: 0 for model in all_models}

        for model in all_models:
            for field in model._meta.get_fields():
                if field.is_relation and field.many_to_one and field.related_model in model_map:
                    # å¦‚æœ model ä¾èµ–äº related_model
                    related_model = field.related_model
                    if model in dependencies[related_model]:
                        continue
                    dependencies[related_model].add(model)
                    in_degree[model] += 1
        
        # æ‹“æ‰‘æ’åº
        queue = deque([model for model in all_models if in_degree[model] == 0])
        sorted_models = []
        
        while queue:
            model = queue.popleft()
            sorted_models.append(model)
            
            for dependent_model in dependencies[model]:
                in_degree[dependent_model] -= 1
                if in_degree[dependent_model] == 0:
                    queue.append(dependent_model)

        if len(sorted_models) != len(all_models):
            raise Exception("æ•°æ®åº“æ¨¡å‹å­˜åœ¨å¾ªç¯ä¾èµ–ï¼Œæ— æ³•è¿›è¡Œæ‹“æ‰‘æ’åºï¼")
            
        logger.info(f"è®¡ç®—å‡ºæ¨¡å‹è¿ç§»é¡ºåº: {[model._meta.db_table for model in sorted_models]}")
        return sorted_models

    def migrate(self):
        """
        æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“è¿ç§»æµç¨‹ã€‚
        """
        logger.info("===== å¼€å§‹æ•°æ®åº“è¿ç§»ï¼šSQLite -> PostgreSQL =====")
        start_total_time = time.time()

        try:
            migration_order = self._get_migration_order()
            
            source_engine = create_engine(self.sqlite_uri)
            target_engine = create_engine(self.pg_uri)

            with target_engine.connect() as pg_conn:
                for model in migration_order:
                    if not(model._meta.db_table =='tb_daily_factor_values' or model._meta.db_table =='tb_daily_trading_plan' or model._meta.db_table =='tb_trade_log'):
                        logger.info(f"è·³è¿‡è¡¨ {model}")
                        continue
                    else:
                        logger.info(f"æ‰§è¡Œè¡¨ {model}")
                    table_name = model._meta.db_table
                    logger.info(f"--- æ­£åœ¨è¿ç§»è¡¨: {table_name} ---")
                    start_table_time = time.time()

                    try:
                        # 1. æ¸…ç©ºç›®æ ‡è¡¨å¹¶é‡ç½®è‡ªå¢IDï¼Œä¿è¯å¹‚ç­‰æ€§
                        logger.info(f"æ¸…ç©ºç›®æ ‡è¡¨ {table_name}...")
                        # ä½¿ç”¨ text() æ¥ç¡®ä¿SQLè¯­å¥è¢«æ­£ç¡®å¤„ç†
                        truncate_sql = text(f'TRUNCATE TABLE public."{table_name}" RESTART IDENTITY CASCADE;')
                        pg_conn.execute(truncate_sql)
                        pg_conn.commit() # TRUNCATE éœ€è¦æ˜¾å¼æäº¤

                        # 2. åˆ†å—è¯»å–æºæ•°æ®å¹¶å†™å…¥ç›®æ ‡åº“
                        query = f'SELECT * FROM "{table_name}";'
                        total_rows = 0
                        for chunk_df in pd.read_sql_query(query, source_engine, chunksize=self.chunk_size):
                            
                            # ä¿®æ­£æ•°æ®ç±»å‹é—®é¢˜ï¼šPandasæœ‰æ—¶ä¼šå°†boolè½¬ä¸ºintï¼Œéœ€è¦è½¬å›æ¥
                            for col in chunk_df.columns:
                                model_field = model._meta.get_field(col)
                                if model_field.get_internal_type() == 'BooleanField':
                                    chunk_df[col] = chunk_df[col].astype(bool)

                            chunk_df.to_sql(
                                name=table_name,
                                con=target_engine,
                                if_exists='append',
                                index=False,
                                method='multi',
                                schema='public' # æ˜¾å¼æŒ‡å®š schema
                            )
                            total_rows += len(chunk_df)
                            logger.info(f"å·²è¿ç§» {total_rows} è¡Œ...")
                        
                        table_duration = time.time() - start_table_time
                        logger.info(f"è¡¨ {table_name} è¿ç§»å®Œæˆï¼Œå…± {total_rows} è¡Œï¼Œè€—æ—¶ {table_duration:.2f} ç§’ã€‚")

                    except Exception as e:
                        logger.error(f"è¿ç§»è¡¨ {table_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                        pg_conn.rollback() # å¦‚æœå‡ºé”™åˆ™å›æ»š
                        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä¸­æ–­æ•´ä¸ªè¿ç§»è¿‡ç¨‹

        except Exception as e:
            logger.critical(f"æ•°æ®åº“è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä»»åŠ¡ç»ˆæ­¢: {e}", exc_info=True)
            return

        total_duration = time.time() - start_total_time
        logger.info(f"===== æ•°æ®åº“è¿ç§»æˆåŠŸå®Œæˆï¼æ€»è€—æ—¶: {total_duration:.2f} ç§’ =====")


####æ–‡ä»¶ç»“æŸ####

####data_manager\service\email_handler.py####
# data_manager/service/email_handler.py

import smtplib
import logging
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.header import Header

logger = logging.getLogger(__name__)

class EmailHandler:
    """
    ä¸€ä¸ªé€šç”¨çš„é‚®ä»¶å‘é€å¤„ç†å™¨ã€‚
    å®ƒå°è£…äº†SMTPåè®®çš„ç»†èŠ‚ï¼Œåªå‘ä¸Šå±‚æä¾›ä¸€ä¸ªç®€å•çš„send_emailæ¥å£ã€‚
    æ‰€æœ‰é…ç½®é¡¹éƒ½åœ¨ç±»çš„èµ·å§‹åŒºåŸŸå®šä¹‰ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†ã€‚
    """

    # ==========================================================================
    # SMTP é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„é‚®ç®±æœåŠ¡å•†å¡«å……ä»¥ä¸‹ä¿¡æ¯
    # å¼ºçƒˆå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å®‰å…¨çš„é…ç½®ç®¡ç†æ–¹å¼ï¼Œè€Œéç¡¬ç¼–ç 
    # å¯¹äºå¤šæ•°é‚®ç®±ï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨â€œåº”ç”¨ä¸“ç”¨å¯†ç â€è€Œéæ‚¨çš„ç™»å½•å¯†ç 
    # ==========================================================================
    SMTP_SERVER = 'smtp.qq.com'  # ä¾‹å¦‚: 'smtp.qq.com' æˆ– 'smtp.gmail.com'
    SMTP_PORT = 465                   # SSLåŠ å¯†ç«¯å£é€šå¸¸ä¸º 465
    SMTP_USER = '876858298@qq.com' # æ‚¨çš„é‚®ç®±ç™»å½•è´¦å·
    SMTP_PASSWORD = 'eoyktuuifrmxbdba'  # æ‚¨çš„é‚®ç®±æˆæƒç æˆ–å¯†ç 
    SENDER_EMAIL = '876858298@qq.com' # å‘ä»¶äººé‚®ç®±åœ°å€
    SENDER_NAME = 'é‡åŒ–äº¤æ˜“é¢„æ¡ˆæ¨é€'          # å‘ä»¶äººæ˜¾ç¤ºåç§°
    # ==========================================================================

    def send_email(self, recipients: list[str], subject: str, html_content: str) -> bool:
        """
        å‘é€ä¸€å°HTMLæ ¼å¼çš„é‚®ä»¶ç»™ä¸€ä¸ªæˆ–å¤šä¸ªæ”¶ä»¶äººã€‚

        :param recipients: ç›®æ ‡é‚®ç®±åœ°å€çš„åˆ—è¡¨, e.g., ['user1@example.com', 'user2@example.com']
        :param subject: é‚®ä»¶ä¸»é¢˜
        :param html_content: é‚®ä»¶æ­£æ–‡ (HTMLæ ¼å¼)
        :return: True å¦‚æœå‘é€æˆåŠŸ, False å¦‚æœå¤±è´¥
        """
        if not all([self.SMTP_SERVER, self.SMTP_PORT, self.SMTP_USER, self.SMTP_PASSWORD, self.SENDER_EMAIL]):
            logger.critical("SMTPé…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•å‘é€é‚®ä»¶ã€‚è¯·æ£€æŸ¥ EmailHandler ä¸­çš„é…ç½®é¡¹ã€‚")
            return False

        if not recipients:
            logger.warning("æ”¶ä»¶äººåˆ—è¡¨ä¸ºç©ºï¼Œé‚®ä»¶æœªå‘é€ã€‚")
            return False

        # åˆ›å»ºä¸€ä¸ªå¸¦é™„ä»¶çš„å®ä¾‹
        message = MIMEMultipart('alternative')
        message['From'] = f'"{Header(self.SENDER_NAME, "utf-8").encode()}" <{self.SENDER_EMAIL}>'
        message['To'] = ", ".join(recipients)
        message['Subject'] = Header(subject, 'utf-8')

        # é‚®ä»¶æ­£æ–‡å†…å®¹
        html_part = MIMEText(html_content, 'html', 'utf-8')
        message.attach(html_part)
        server = None  # åˆå§‹åŒ–serverå˜é‡
        try:
            logger.info(f"å‡†å¤‡é€šè¿‡ {self.SMTP_SERVER}:{self.SMTP_PORT} å‘é€é‚®ä»¶è‡³ {recipients}...")
            
            # 1. æ‰‹åŠ¨å»ºç«‹è¿æ¥
            server = smtplib.SMTP_SSL(self.SMTP_SERVER, self.SMTP_PORT)
            server.login(self.SMTP_USER, self.SMTP_PASSWORD)
            server.sendmail(self.SENDER_EMAIL, recipients, message.as_string())
            
            logger.info(f"é‚®ä»¶å‘é€æˆåŠŸï¼ä¸»é¢˜: '{subject}'")
            return True
            
        except smtplib.SMTPException as e:
            logger.error(f"å‘é€é‚®ä»¶æ—¶å‘ç”ŸSMTPé”™è¯¯: {e}", exc_info=True)
            return False
        except Exception as e:
            logger.error(f"å‘é€é‚®ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            return False
        finally:
            # 2. åœ¨finallyå—ä¸­ç¡®ä¿å…³é—­è¿æ¥
            if server:
                try:
                    # 3. å¯¹quit()å‘½ä»¤è¿›è¡Œç‹¬ç«‹çš„å¼‚å¸¸å¤„ç†
                    server.quit()
                except smtplib.SMTPResponseException as e:
                    # ä¼˜é›…åœ°å¤„ç†æœåŠ¡å™¨æå‰å…³é—­è¿æ¥çš„æƒ…å†µ
                    logger.warning(f"å…³é—­SMTPè¿æ¥æ—¶å‘ç”Ÿå“åº”å¼‚å¸¸ (é€šå¸¸æ— å®³): {e}")
                except Exception as e:
                    logger.error(f"å…³é—­SMTPè¿æ¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)


####æ–‡ä»¶ç»“æŸ####

####data_manager\service\email_service.py####
# data_manager/service/email_service.py

import logging
from datetime import date, timedelta
from decimal import Decimal

from django.utils import timezone
from django.db import transaction

# å†…éƒ¨æ¨¡å—å¯¼å…¥
from .email_handler import EmailHandler

# Djangoæ¨¡å‹å¯¼å…¥
from common.models import (
    DailyFactorValues, DailyTradingPlan, DailyQuotes, StockInfo,
    Position, TradeLog
)
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.simulate_trade_handler import SimulateTradeHandler
from trade_manager.service.simulate_trade import SimulateTradeService


logger = logging.getLogger(__name__)

class EmailNotificationService:
    """
    å°è£…äº†åœ¨Tæ—¥ç›˜å‰ï¼ˆå¦‚9:10ï¼‰å‘æŒ‡å®šé‚®ç®±æ¨é€T-1æ—¥é¢„æ¡ˆçš„ä¸šåŠ¡é€»è¾‘ã€‚
    """

    def __init__(self, t_day: date):
        """
        åˆå§‹åŒ–é‚®ä»¶é€šçŸ¥æœåŠ¡ã€‚
        :param t_day: Tæ—¥ï¼Œå³é¢„æ¡ˆæ‰§è¡Œæ—¥ã€‚
        """
        self.t_day = t_day
        try:
            # è·å–Tæ—¥ä¹‹å‰çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºT-1æ—¥
            self.t_minus_1_day = DailyQuotes.objects.filter(
                trade_date__lt=self.t_day
            ).latest('trade_date').trade_date
        except DailyQuotes.DoesNotExist:
            raise ValueError(f"æ— æ³•æ‰¾åˆ° {self.t_day} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥(T-1)ï¼ŒæœåŠ¡æ— æ³•åˆå§‹åŒ–ã€‚")

        self.email_handler = EmailHandler()
        # ä»EmailHandlerçš„é…ç½®ä¸­ç›´æ¥è¯»å–æ”¶ä»¶äººåˆ—è¡¨
        self.recipients = self.email_handler.recipients if hasattr(self.email_handler, 'recipients') else ['876858298@qq.com','850696281@qq.com','285173686@qq.com']


    def runEmailSend(self):
        """
        ä¸€é”®æ‰§è¡Œé‚®ä»¶å‘é€çš„ä¸»æ–¹æ³•ã€‚
        """
        logger.info(f"å¼€å§‹ä¸ºTæ—¥({self.t_day})ç”Ÿæˆé¢„æ¡ˆæ¨é€é‚®ä»¶...")
        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘å…ˆæ‰¾åˆ°çœŸæ­£éœ€è¦å¤„ç†çš„é¢„æ¡ˆæ—¥æœŸ
        plan_date_to_process = self._find_latest_pending_plan_date()
        if not plan_date_to_process:
            logger.warning(f"ä»Tæ—¥({self.t_day})å›æº¯ï¼Œæœªæ‰¾åˆ°ä»»ä½•å¾…å¤„ç†çš„äº¤æ˜“é¢„æ¡ˆï¼Œé‚®ä»¶å‘é€ä»»åŠ¡ç»ˆæ­¢ã€‚")
            return
        # 1. è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®
        market_data = self._get_market_regime_data()
        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘å°†æ‰¾åˆ°çš„æ—¥æœŸä¼ é€’ç»™ä¸‹ä¸€æ­¥
        plan_details = self._get_trading_plan_details(plan_date_to_process)
        if not plan_details:
            logger.warning(f"é¢„æ¡ˆæ—¥({plan_date_to_process})çš„é¢„æ¡ˆè¯¦æƒ…ä¸ºç©ºï¼Œé‚®ä»¶å‘é€ä»»åŠ¡ç»ˆæ­¢ã€‚")
            return
        # 2. ç”ŸæˆHTMLå†…å®¹
        html_content = self._format_html_content(market_data, plan_details)
        # 3. å‘é€é‚®ä»¶
        subject = f"ã€äº¤æ˜“é¢„æ¡ˆã€‘{self.t_day.strftime('%Y-%m-%d')} ç›˜å‰ç¡®è®¤ (æ•°æ®æº: {plan_date_to_process.strftime('%Y-%m-%d')})"
        self.email_handler.send_email(self.recipients, subject, html_content)

    def _get_market_regime_data(self) -> dict:
        """è·å–æ˜¨æ—¥Må€¼åŠè¿‘10æ—¥Må€¼å†å²"""
        try:
            # è·å–T-1æ—¥åŠä¹‹å‰çš„10ä¸ªäº¤æ˜“æ—¥
            trade_dates = list(DailyQuotes.objects.filter(trade_date__lte=self.t_minus_1_day)
                               .values_list('trade_date', flat=True)
                               .distinct().order_by('-trade_date')[:10])
            trade_dates.reverse()

            m_values_qs = DailyFactorValues.objects.filter(
                stock_code_id=MARKET_INDICATOR_CODE,
                factor_code_id='dynamic_M_VALUE',
                trade_date__in=trade_dates
            ).order_by('-trade_date')

            m_values_map = {fv.trade_date: fv.raw_value for fv in m_values_qs}

            yesterday_m = m_values_map.get(self.t_minus_1_day, Decimal('NaN'))
            history_m = [{'date': d, 'value': m_values_map.get(d, Decimal('NaN'))} for d in trade_dates]

            return {'yesterday_m': yesterday_m, 'history_m': history_m}

        except Exception as e:
            logger.error(f"è·å–Må€¼æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            return {'yesterday_m': Decimal('NaN'), 'history_m': []}

    def _get_trading_plan_details(self, plan_date: date) -> list[dict]:
        """è·å–Tæ—¥äº¤æ˜“é¢„æ¡ˆåŠç›¸å…³çš„æ‰€æœ‰è¯¦ç»†ä¿¡æ¯"""
        plans = DailyTradingPlan.objects.filter(plan_date=plan_date, status=DailyTradingPlan.StatusChoices.PENDING).order_by('rank')
        if not plans.exists():
            return []

        detailed_plans = []
        for plan in plans:
            stock_code = plan.stock_code_id
            logger.debug(f"æ­£åœ¨å¤„ç†é¢„æ¡ˆè‚¡ç¥¨: {stock_code}")
            try:
                # è·å–æ­¢ç›ˆæ­¢æŸç‡
                rates = self._calculate_profit_loss_rates(stock_code)
                # è·å–å†å²è¡Œæƒ…
                history = self._get_stock_historical_data(stock_code)

                detailed_plans.append({
                    'plan': plan,
                    'stock_info': plan.stock_code, # StockInfo object
                    'rates': rates,
                    'history': history
                })
            except Exception as e:
                logger.error(f"å¤„ç†è‚¡ç¥¨ {stock_code} çš„é¢„æ¡ˆè¯¦æƒ…æ—¶å¤±è´¥: {e}", exc_info=True)
                continue # è·³è¿‡è¿™ä¸ªå‡ºé”™çš„è‚¡ç¥¨

        return detailed_plans

    def _calculate_profit_loss_rates(self, stock_code: str) -> dict:
        """
        é€šè¿‡åˆ›å»ºä¸´æ—¶æ•°æ®åº“è®°å½•æ¥å¤ç”¨ç°æœ‰æ­¢ç›ˆæ­¢æŸè®¡ç®—é€»è¾‘ã€‚
        æ•´ä¸ªè¿‡ç¨‹åœ¨å•ä¸ªæ•°æ®åº“äº‹åŠ¡ä¸­å®Œæˆï¼Œç¡®ä¿å®‰å…¨ã€‚
        """
        tp_rate, sl_rate = Decimal('NaN'), Decimal('NaN')
        try:
            # ã€æ–°å¢æ­¥éª¤1ã€‘: è·å–T-1æ—¥æ”¶ç›˜ä»·ä½œä¸ºåŸºå‡†
            try:
                t_minus_1_quote = DailyQuotes.objects.get(stock_code_id=stock_code, trade_date=self.t_minus_1_day)
                base_price = t_minus_1_quote.close
                if base_price <= 0:
                    raise ValueError("T-1æ—¥æ”¶ç›˜ä»·æ— æ•ˆ")
            except DailyQuotes.DoesNotExist:
                logger.error(f"æ— æ³•æ‰¾åˆ° {stock_code} åœ¨ {self.t_minus_1_day} çš„è¡Œæƒ…æ•°æ®ï¼Œæ— æ³•è®¡ç®—æ­¢ç›ˆæ­¢æŸç‡ã€‚")
                return {'tp_rate': tp_rate, 'sl_rate': sl_rate}
            except ValueError as e:
                logger.error(f"è‚¡ç¥¨ {stock_code} åœ¨ {self.t_minus_1_day} çš„æ”¶ç›˜ä»·ä¸åˆæ³•: {e}")
                return {'tp_rate': tp_rate, 'sl_rate': sl_rate}
            with transaction.atomic():
                # ã€ä¿®æ”¹æ­¥éª¤2ã€‘: ä½¿ç”¨è·å–åˆ°çš„base_priceåˆ›å»ºä¸´æ—¶è®°å½•
                temp_position = Position.objects.create(
                    stock_code_id=stock_code,
                    entry_price=base_price, # ä½¿ç”¨T-1æ”¶ç›˜ä»·
                    quantity=100,
                    entry_datetime=timezone.now(),
                    status=Position.StatusChoices.OPEN,
                    current_stop_loss=Decimal('0.00'),
                    current_take_profit=Decimal('0.00')
                )
                temp_trade_log = TradeLog.objects.create(
                    position=temp_position,
                    stock_code_id=stock_code,
                    trade_datetime=timezone.now(),
                    trade_type=TradeLog.TradeTypeChoices.BUY,
                    status=TradeLog.StatusChoices.FILLED,
                    price=base_price, # ä½¿ç”¨T-1æ”¶ç›˜ä»·
                    quantity=100,
                    commission=0,
                    stamp_duty=0
                )
                # è°ƒç”¨æœåŠ¡è¿›è¡Œè®¡ç®— (è¿™éƒ¨åˆ†ä¸å˜)
                dummy_sim_service = SimulateTradeService()
                dummy_handler = SimulateTradeHandler(dummy_sim_service)
                decision_service = DecisionOrderService(handler=dummy_handler, execution_date=self.t_day)
                decision_service.calculate_stop_profit_loss(trade_id=temp_trade_log.trade_id)
                temp_position.refresh_from_db()
                # ã€ä¿®æ”¹æ­¥éª¤3ã€‘: ä½¿ç”¨base_priceä½œä¸ºåˆ†æ¯è®¡ç®—æ¯”ç‡
                take_profit_price = temp_position.current_take_profit
                stop_loss_price = temp_position.current_stop_loss
                if take_profit_price > 0:
                    tp_rate = (take_profit_price / base_price) - 1
                if stop_loss_price > 0:
                    sl_rate = 1 - (stop_loss_price / base_price)
                # å›æ»šäº‹åŠ¡ï¼Œæ¸…é™¤ä¸´æ—¶æ•°æ® (è¿™éƒ¨åˆ†ä¸å˜)
                transaction.set_rollback(True)
        except Exception as e:
            logger.error(f"ä¸º {stock_code} è®¡ç®—æ­¢ç›ˆæ­¢æŸç‡æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            transaction.set_rollback(True)
        logger.debug(f"{stock_code} (åŸºå‡†ä»·: {base_price:.2f}) -> TP Rate: {tp_rate:.4%}, SL Rate: {sl_rate:.4%}")
        return {'tp_rate': tp_rate, 'sl_rate': sl_rate}


    def _get_stock_historical_data(self, stock_code: str) -> list[dict]:
        """è·å–æŒ‡å®šè‚¡ç¥¨è¿‘10ä¸ªäº¤æ˜“æ—¥çš„å†å²è¡Œæƒ…"""
        trade_dates = list(DailyQuotes.objects.filter(trade_date__lte=self.t_minus_1_day)
                           .values_list('trade_date', flat=True)
                           .distinct().order_by('-trade_date')[:10])
        trade_dates.reverse()

        quotes = DailyQuotes.objects.filter(
            stock_code_id=stock_code,
            trade_date__in=trade_dates
        ).order_by('trade_date')

        history = []
        prev_close = None
        for quote in quotes:
            change_pct = Decimal('0.0')
            if prev_close and prev_close > 0:
                change_pct = (quote.close / prev_close) - 1
            
            history.append({
                'date': quote.trade_date,
                'open': quote.open,
                'high': quote.high,
                'low': quote.low,
                'close': quote.close,
                'hfq_close': quote.hfq_close,
                'change_pct': change_pct
            })
            prev_close = quote.close
        return history

    def _format_html_content(self, market_data: dict, plan_details: list[dict]) -> str:
        """å°†æ‰€æœ‰æ•°æ®æ ¼å¼åŒ–ä¸ºç¾è§‚çš„HTMLå­—ç¬¦ä¸²"""
        
        # --- CSSæ ·å¼ ---
        style = """
        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; line-height: 1.6; color: #333; background-color: #f8f9fa; margin: 0; padding: 20px; }
            .container { max-width: 800px; margin: auto; background: #fff; padding: 25px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
            h2 { color: #0056b3; border-bottom: 2px solid #0056b3; padding-bottom: 10px; margin-top: 30px; }
            h3 { color: #17a2b8; margin-top: 25px; }
            table { width: 100%; border-collapse: collapse; margin-top: 15px; font-size: 14px; }
            th, td { border: 1px solid #dee2e6; padding: 10px; text-align: left; }
            th { background-color: #e9ecef; font-weight: 600; }
            tr:nth-child(even) { background-color: #f8f9fa; }
            .summary { font-size: 16px; font-weight: bold; margin-bottom: 20px; }
            .red { color: #dc3545; }
            .green { color: #28a745; }
            .footer { margin-top: 30px; font-size: 12px; color: #6c757d; text-align: center; }
        </style>
        """

        # --- HTMLå¤´éƒ¨ ---
        html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <title>äº¤æ˜“é¢„æ¡ˆç¡®è®¤</title>
            {style}
        </head>
        <body>
            <div class="container">
                <h2>Tæ—¥ ({self.t_day.strftime('%Y-%m-%d')}) äº¤æ˜“é¢„æ¡ˆç›˜å‰ç¡®è®¤</h2>
        """

        # --- å¤§ç›˜æƒ…å†µ ---
        yesterday_m_str = f"{market_data['yesterday_m']:.4f}" if not market_data['yesterday_m'].is_nan() else "N/A"
        html += f"""
        <h3>[å¤§ç›˜æƒ…å†µ]</h3>
        <p class="summary">æ˜¨æ—¥Må€¼: <span class="{'red' if market_data.get('yesterday_m', 0) > 0 else 'green'}">{yesterday_m_str}</span></p>
        <table>
            <thead><tr><th>æ—¥æœŸ</th><th>Må€¼</th></tr></thead>
            <tbody>
        """
        for item in reversed(market_data['history_m']):
            m_val_str = f"{item['value']:.4f}" if not item['value'].is_nan() else "N/A"
            html += f"<tr><td>{item['date'].strftime('%Y-%m-%d')}</td><td>{m_val_str}</td></tr>"
        html += "</tbody></table>"

        # --- é€‰è‚¡é¢„æ¡ˆ ---
        html += "<h3>[é€‰è‚¡é¢„æ¡ˆ]</h3>"
        html += """
        <table>
            <thead>
                <tr>
                    <th>æ’å</th>
                    <th>è‚¡ç¥¨ä»£ç </th>
                    <th>è‚¡ç¥¨åç§°</th>
                    <th>å¯æ¥å—å¼€ç›˜åŒºé—´</th>
                    <th>é¢„æœŸæ­¢ç›ˆç‡</th>
                    <th>é¢„æœŸæ­¢æŸç‡</th>
                </tr>
            </thead>
            <tbody>
        """
        for detail in plan_details:
            plan = detail['plan']
            stock_info = detail['stock_info']
            rates = detail['rates']
            tp_rate_str = f"{rates['tp_rate']:.2%}" if not rates['tp_rate'].is_nan() else "N/A"
            sl_rate_str = f"{rates['sl_rate']:.2%}" if not rates['sl_rate'].is_nan() else "N/A"
            html += f"""
            <tr>
                <td>{plan.rank}</td>
                <td>{stock_info.stock_code}</td>
                <td>{stock_info.stock_name}</td>
                <td>{plan.miop:.2f} - {plan.maop:.2f}</td>
                <td class="red">{tp_rate_str}</td>
                <td class="green">{sl_rate_str}</td>
            </tr>
            """
        html += "</tbody></table>"

        # --- å„è‚¡ç¥¨å†å²è¡Œæƒ… ---
        for detail in plan_details:
            stock_info = detail['stock_info']
            history = detail['history']
            html += f"<h4>{stock_info.stock_name} ({stock_info.stock_code}) - è¿‘10æ—¥è¡Œæƒ…</h4>"
            html += """
            <table>
                <thead>
                    <tr>
                        <th>æ—¥æœŸ</th>
                        <th>å¼€ç›˜ä»·</th>
                        <th>æœ€é«˜ä»·</th>
                        <th>æœ€ä½ä»·</th>
                        <th>æ”¶ç›˜ä»·</th>
                        <th>åå¤æƒæ”¶ç›˜</th>
                        <th>æ¶¨å¹…</th>
                    </tr>
                </thead>
                <tbody>
            """
            for item in reversed(history):
                color_class = 'red' if item['change_pct'] > 0 else ('green' if item['change_pct'] < 0 else '')
                html += f"""
                <tr>
                    <td>{item['date'].strftime('%Y-%m-%d')}</td>
                    <td>{item['open']:.2f}</td>
                    <td>{item['high']:.2f}</td>
                    <td>{item['low']:.2f}</td>
                    <td>{item['close']:.2f}</td>
                    <td>{item['hfq_close']:.4f}</td>
                    <td class="{color_class}">{item['change_pct']:.2%}</td>
                </tr>
                """
            html += "</tbody></table>"

        # --- HTMLå°¾éƒ¨ ---
        html += """
                <p class="footer">æœ¬é‚®ä»¶ç”±ç­–ç•¥äº¤æ˜“ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œè¯·åœ¨äº¤æ˜“å‰æœ€ç»ˆç¡®è®¤ã€‚</p>
            </div>
        </body>
        </html>
        """
        return html
    def _find_latest_pending_plan_date(self) -> date | None:
        """ä»Tæ—¥å¼€å§‹å‘å‰å›æº¯ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„ä¸€ä¸ªåŒ…å«å¾…æ‰§è¡Œé¢„æ¡ˆçš„æ—¥æœŸ"""
        # è®¾ç½®ä¸€ä¸ªåˆç†çš„å›æº¯ä¸Šé™ï¼Œä¾‹å¦‚14å¤©
        for i in range(14):
            check_date = self.t_day - timedelta(days=i)
            if DailyTradingPlan.objects.filter(
                plan_date=check_date,
                status=DailyTradingPlan.StatusChoices.PENDING
            ).exists():
                logger.info(f"æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆï¼Œé¢„æ¡ˆç”Ÿæˆæ—¥ä¸º: {check_date}")
                return check_date
        logger.warning(f"åœ¨è¿‡å»14å¤©å†…æœªæ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚")
        return None

####æ–‡ä»¶ç»“æŸ####

####data_manager\service\stock_service.py####
import logging
import datetime
from decimal import Decimal, ROUND_HALF_UP,InvalidOperation
import akshare as ak
import pandas as pd
from django.utils import timezone
from django.db import connection,transaction, DatabaseError

# å¯¼å…¥æ‚¨çš„Djangoæ¨¡å‹
from common.models.stock_info import StockInfo
from common.models.daily_quotes import DailyQuotes
from common.models.factor_definitions import FactorDefinitions
from common.models.daily_factor_values import DailyFactorValues
from common.models.strategy_parameters import StrategyParameters
from common.models.daily_trading_plan import DailyTradingPlan
from common.models.positions import Position
from common.models.trade_log import TradeLog
from common.models.system_log import SystemLog
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# è·å–loggerå®ä¾‹
logger = logging.getLogger(__name__)

# å®šä¹‰æ¨¡å—å¸¸é‡ï¼Œä¾¿äºç»´æŠ¤
MODULE_NAME = 'data_manager'

class StockService:
    """
    å°è£…äº†ä¸è‚¡ç¥¨æ•°æ®ç›¸å…³çš„æœåŠ¡ï¼ŒåŒ…æ‹¬ä»akshareæ›´æ–°æ•°æ®å’Œä»æœ¬åœ°æ•°æ®åº“æŸ¥è¯¢æ•°æ®ã€‚
  
    ä½¿ç”¨ç¤ºä¾‹ (åœ¨Django views.py æˆ– management commandä¸­):
  
    from .services.stock_service import StockService
  
    def my_view(request):
        service = StockService()
      
        # ç¤ºä¾‹1: æ›´æ–°æ‰€æœ‰Aè‚¡ä»Šå¤©çš„è¡Œæƒ…
        service.update_local_a_shares()
      
        # ç¤ºä¾‹2: æ›´æ–°æŒ‡å®šå‡ åªè‚¡ç¥¨æŸæ—¶é—´æ®µçš„è¡Œæƒ…
        codes = ['sh.600519', 'sz.000001']
        service.update_local_a_shares(stock_codes=codes, start_date='2023-01-01', end_date='2023-01-31')
      
        # ç¤ºä¾‹3: æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„åŸºç¡€ä¿¡æ¯
        stock_infos = service.query_stock_info(stock_codes=codes)
      
        # ç¤ºä¾‹4: æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨ä»Šå¤©çš„æ—¥çº¿è¡Œæƒ…
        daily_quotes = service.query_daily_quotes()
    """

    def _log_and_save(self, message: str, level: str = SystemLog.LogLevelChoices.INFO):
        """
        ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œç”¨äºåŒæ—¶å‘æ ‡å‡†loggerå’Œæ•°æ®åº“ç³»ç»Ÿæ—¥å¿—è¡¨å†™å…¥æ—¥å¿—ã€‚
        """
        log_map = {
            SystemLog.LogLevelChoices.INFO: logger.info,
            SystemLog.LogLevelChoices.WARNING: logger.warning,
            SystemLog.LogLevelChoices.ERROR: logger.error,
            SystemLog.LogLevelChoices.CRITICAL: logger.critical,
        }
      
        # æ‰“å°åˆ°æ ‡å‡†æ—¥å¿—
        log_function = log_map.get(level, logger.info)
        log_function(message)
      
        # ä¿å­˜åˆ°æ•°æ®åº“
        # try:
        #     SystemLog.objects.create(
        #         log_level=level,
        #         module_name=MODULE_NAME,
        #         message=message
        #     )
        # except Exception as e:
        #     logger.error(f"æ— æ³•å°†æ—¥å¿—å†™å…¥æ•°æ®åº“: {e}")

    def _save_quotes_df_to_db(self, quotes_df: pd.DataFrame):
        """
        è¾…åŠ©æ–¹æ³•ï¼šå°†ä¸€ä¸ªDataFrameçš„è¡Œæƒ…æ•°æ®é€šè¿‡ update_or_create æ‰¹é‡å­˜å…¥æ•°æ®åº“ã€‚
        æ­¤æ–¹æ³•å…·æœ‰å¹‚ç­‰æ€§ï¼Œé€‚ç”¨äºæ‰€æœ‰æ•°æ®ï¼Œæ— éœ€åŒºåˆ†å†å²å’Œå½“æ—¥ã€‚
        """
        if quotes_df.empty:
            return
 
        # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
        quotes_df.fillna(0, inplace=True)
        quotes_df = quotes_df[(quotes_df['å¼€ç›˜'] > 0) & (quotes_df['æ”¶ç›˜'] > 0) & (quotes_df['æœ€é«˜'] > 0) & (quotes_df['æœ€ä½'] > 0) & (quotes_df['æˆäº¤é‡'] >= 0)]
        if quotes_df.empty:
            self._log_and_save("æ•°æ®æ¸…æ´—åï¼Œå½“å‰æ‰¹æ¬¡æ— æœ‰æ•ˆæ•°æ®å¯å­˜å‚¨ã€‚", level=SystemLog.LogLevelChoices.INFO)
            return
            
        quotes_df['æ—¥æœŸ'] = pd.to_datetime(quotes_df['æ—¥æœŸ']).dt.date
        
        hfq_precision = Decimal('0.0000000001')
        records_to_process = len(quotes_df)
    
        try:
            # å°†æ•´ä¸ªæ‰¹æ¬¡çš„ update_or_create æ“ä½œæ”¾åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­ï¼Œä»¥æé«˜æ€§èƒ½
            with transaction.atomic():
                for _, row in quotes_df.iterrows():
                    try:
                        close_dec = Decimal(str(row['æ”¶ç›˜']))
                        factor_dec = Decimal(str(row['å¤æƒå› å­']))
                        hfq_close_dec = (close_dec * factor_dec).quantize(hfq_precision, rounding=ROUND_HALF_UP)
                        
                        # å¯¹æ¯ä¸€è¡Œæ•°æ®éƒ½æ‰§è¡Œ update_or_create
                        DailyQuotes.objects.update_or_create(
                            stock_code_id=row['stock_code'], 
                            trade_date=row['æ—¥æœŸ'],
                            defaults={
                                'open': Decimal(str(row['å¼€ç›˜'])), 
                                'high': Decimal(str(row['æœ€é«˜'])),
                                'low': Decimal(str(row['æœ€ä½'])), 
                                'close': close_dec,
                                'volume': int(row['æˆäº¤é‡']), 
                                'turnover': Decimal(str(row['æˆäº¤é¢'])),
                                'adjust_factor': factor_dec, 
                                'hfq_close': hfq_close_dec
                            }
                        )
                    except (InvalidOperation, TypeError) as conversion_error:
                        self._log_and_save(f"è·³è¿‡ä¸€æ¡æ•°æ®è½¬æ¢å¤±è´¥çš„è®°å½•: {row['stock_code']} on {row['æ—¥æœŸ']}. Error: {conversion_error}", level=SystemLog.LogLevelChoices.WARNING)
                        continue
            
            self._log_and_save(f"é€šè¿‡ update_or_create æˆåŠŸå¤„ç†äº† {records_to_process} æ¡æ—¥çº¿æ•°æ®ã€‚")
    
        except (DatabaseError, Exception) as e:
            self._log_and_save(f"æ•°æ®æ‰¹é‡å…¥åº“é˜¶æ®µ(update_or_create)å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", level=SystemLog.LogLevelChoices.ERROR)

    def update_local_a_shares(
        self, 
        stock_codes: list[str] = None, 
        start_date: str = None, 
        end_date: str = None
    ):

        """
        1. æ›´æ–°æœ¬åœ°Aè‚¡ä¿¡æ¯ (æœ€ç»ˆç‰ˆï¼šé«˜æ•ˆã€å¥å£®)
        """
        self._log_and_save(f"å¼€å§‹æ‰§è¡ŒAè‚¡æ•°æ®æ›´æ–°ä»»åŠ¡...")
        target_codes=[]
        # --- Part 1: æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ (tb_stock_info) ---
        try:
            self._log_and_save("æ­£åœ¨ä»äº¤æ˜“æ‰€å®˜æ–¹æ•°æ®æºè·å–å…¨é‡Aè‚¡åˆ—è¡¨...")
            
            # 1. é€šè¿‡é«˜æ•ˆã€å¯é çš„æ¥å£ä¸€æ¬¡æ€§è·å–æ‰€æœ‰Aè‚¡ä¿¡æ¯
            # ä¸Šæµ·ä¸»æ¿Aè‚¡
            sh_main_df = ak.stock_info_sh_name_code(symbol="ä¸»æ¿Aè‚¡").copy()
            # ä¸Šæµ·ç§‘åˆ›æ¿
            sh_star_df = ak.stock_info_sh_name_code(symbol="ç§‘åˆ›æ¿").copy()
            # æ·±åœ³Aè‚¡
            sz_a_df = ak.stock_info_sz_name_code(symbol="Aè‚¡åˆ—è¡¨").copy()
 
            # 2. æ•°æ®é¢„å¤„ç†å’Œåˆå¹¶
            # ç»Ÿä¸€åˆ—å
            sh_main_df.rename(columns={'è¯åˆ¸ç®€ç§°': 'stock_name', 'ä¸Šå¸‚æ—¥æœŸ': 'listing_date', 'è¯åˆ¸ä»£ç ': 'code'}, inplace=True)
            sh_star_df.rename(columns={'è¯åˆ¸ç®€ç§°': 'stock_name', 'ä¸Šå¸‚æ—¥æœŸ': 'listing_date', 'è¯åˆ¸ä»£ç ': 'code'}, inplace=True)
            sz_a_df.rename(columns={'Aè‚¡ç®€ç§°': 'stock_name', 'Aè‚¡ä¸Šå¸‚æ—¥æœŸ': 'listing_date', 'Aè‚¡ä»£ç ': 'code'}, inplace=True)
 
            # æ·»åŠ å¸‚åœºå‰ç¼€
            sh_main_df['code'] = 'sh.' + sh_main_df['code']
            sh_star_df['code'] = 'sh.' + sh_star_df['code']
            sz_a_df['code'] = 'sz.' + sz_a_df['code']
 
            # åˆå¹¶ä¸ºä¸€ä¸ªDataFrame
            all_stocks_df = pd.concat([
                sh_main_df[['code', 'stock_name', 'listing_date']],
                sh_star_df[['code', 'stock_name', 'listing_date']],
                sz_a_df[['code', 'stock_name', 'listing_date']]
            ], ignore_index=True)
 
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            all_stocks_df['listing_date'] = pd.to_datetime(all_stocks_df['listing_date']).dt.date
            
            self._log_and_save(f"æˆåŠŸè·å– {len(all_stocks_df)} æ¡Aè‚¡åŸºç¡€ä¿¡æ¯ã€‚")
 
            # 3. é«˜æ•ˆçš„æ‰¹é‡å…¥åº“æ“ä½œ
            with transaction.atomic():
                existing_stocks = StockInfo.objects.in_bulk(field_name='stock_code')
                
                to_create = []
                to_update = []
 
                for _, row in all_stocks_df.iterrows():
                    code = row['code']
                    stock_obj = existing_stocks.get(code)
                    
                    if not stock_obj:
                        # å¦‚æœè‚¡ç¥¨ä¸å­˜åœ¨ï¼Œåˆ™å‡†å¤‡æ–°å»º
                        to_create.append(
                            StockInfo(
                                stock_code=code,
                                stock_name=row['stock_name'],
                                listing_date=row['listing_date'],
                                status=StockInfo.StatusChoices.LISTING
                            )
                        )
                    elif stock_obj.stock_name != row['stock_name']:
                        # å¦‚æœè‚¡ç¥¨å­˜åœ¨ä½†åç§°æœ‰å˜ï¼Œåˆ™å‡†å¤‡æ›´æ–°
                        stock_obj.stock_name = row['stock_name']
                        to_update.append(stock_obj)
 
                # æ‰¹é‡åˆ›å»º
                if to_create:
                    StockInfo.objects.bulk_create(to_create, batch_size=500)
                    self._log_and_save(f"æ‰¹é‡æ–°å¢ {len(to_create)} æ¡è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ã€‚")
                
                # æ‰¹é‡æ›´æ–°
                if to_update:
                    StockInfo.objects.bulk_update(to_update, ['stock_name'], batch_size=500)
                    self._log_and_save(f"æ‰¹é‡æ›´æ–° {len(to_update)} æ¡è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ã€‚")
 
            # å¦‚æœæœªæŒ‡å®š stock_codesï¼Œåˆ™ä½¿ç”¨è·å–åˆ°çš„æ‰€æœ‰ä»£ç è¿›è¡Œä¸‹ä¸€æ­¥
            if not stock_codes or len(stock_codes)==0:
                stock_codes = all_stocks_df['code'].tolist()
            else:
                # å¦‚æœæŒ‡å®šäº†ï¼Œåˆ™åªå¤„ç†æŒ‡å®šçš„ä»£ç 
                stock_codes = [code for code in stock_codes if code in all_stocks_df['code'].values]
            target_codes = stock_codes if stock_codes else all_stocks_df['code'].tolist()
        except Exception as e:
            self._log_and_save(f"æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", level=SystemLog.LogLevelChoices.ERROR)
            return

        # --- Part 2: æ›´æ–°æ—¥çº¿è¡Œæƒ… (ä¸²è¡Œè·å–ã€å†…å­˜æ±‡æ€»ã€æ‰¹é‡å…¥åº“) ---
        self._log_and_save(f"å¼€å§‹ä¸º {len(target_codes)} åªè‚¡ç¥¨ä¸²è¡Œè·å–æ—¥çº¿è¡Œæƒ…...")
        today_str = datetime.date.today().strftime('%Y%m%d')
        start_date_str = datetime.datetime.strptime(start_date, '%Y-%m-%d').strftime('%Y%m%d') if start_date else today_str
        end_date_str = datetime.datetime.strptime(end_date, '%Y-%m-%d').strftime('%Y%m%d') if end_date else today_str
        # å®šä¹‰æ‰¹å¤„ç†å‚æ•°
        batch_size = 50  # æ¯æ‰¹å¤„ç†50åªè‚¡ç¥¨ï¼Œå¯ä»¥æ ¹æ®ä½ çš„æœºå™¨å†…å­˜è°ƒæ•´
        batch_quotes_list = []
        # æ”¹ä¸ºä¸²è¡Œå¾ªç¯
        for i, code in enumerate(target_codes):
            ak_code = code.split('.')[1]
            logger.info(f"è¿›åº¦: [{i+1}/{len(target_codes)}] æ­£åœ¨è·å– {code}...")
            try:
                df_normal = ak.stock_zh_a_hist(symbol=ak_code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="")
                time.sleep(1.6) # å¢åŠ ç¤¼è²Œæ€§å»¶æ—¶ï¼Œé™ä½è¢«å°é£é™©
                df_hfq = ak.stock_zh_a_hist(symbol=ak_code, period="daily", start_date=start_date_str, end_date=end_date_str, adjust="hfq")
                
                if df_normal.empty or df_hfq.empty:
                    continue
 
                df = pd.merge(df_normal, df_hfq[['æ—¥æœŸ', 'æ”¶ç›˜']], on='æ—¥æœŸ', suffixes=('', '_hfq'))
                df['å¤æƒå› å­'] = df.apply(lambda row: row['æ”¶ç›˜_hfq'] / row['æ”¶ç›˜'] if row['æ”¶ç›˜'] and row['æ”¶ç›˜'] != 0 else 0, axis=1)
                df['stock_code'] = code
                batch_quotes_list.append(df)
                
                time.sleep(1.4) # å¢åŠ ç¤¼è²Œæ€§å»¶æ—¶ï¼Œé™ä½è¢«å°é£é™©
 
            except Exception as e:
                self._log_and_save(f"è·å– {code} æ—¥çº¿è¡Œæƒ…å¤±è´¥: {e}", level=SystemLog.LogLevelChoices.WARNING)
                continue
 
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹å¤„ç†å¤§å°ï¼Œæˆ–è€…å·²ç»æ˜¯æœ€åä¸€åªè‚¡ç¥¨
            if (i + 1) % batch_size == 0 or (i + 1) == len(target_codes):
                if not batch_quotes_list:
                    continue # å¦‚æœè¿™ä¸ªæ‰¹æ¬¡æ˜¯ç©ºçš„ï¼Œå°±è·³è¿‡

                self._log_and_save(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}ï¼ŒåŒ…å« {len(batch_quotes_list)} åªè‚¡ç¥¨...")
                
                # 1. åˆå¹¶å½“å‰æ‰¹æ¬¡çš„æ•°æ®
                batch_master_df = pd.concat(batch_quotes_list, ignore_index=True)
                
                # 2. å°†è¿™ä¸ªæ‰¹æ¬¡çš„æ•°æ®å­˜å…¥æ•°æ®åº“
                self._save_quotes_df_to_db(batch_master_df)
                
                # 3. æ¸…ç©ºæ‰¹æ¬¡åˆ—è¡¨ï¼Œé‡Šæ”¾å†…å­˜ï¼Œä¸ºä¸‹ä¸€æ‰¹åšå‡†å¤‡
                batch_quotes_list = []
                self._log_and_save(f"æ‰¹æ¬¡ {i//batch_size + 1} å¤„ç†å®Œæ¯•ï¼Œå†…å­˜å·²é‡Šæ”¾ã€‚")
 
        self._log_and_save("Aè‚¡æ•°æ®æ›´æ–°ä»»åŠ¡å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ã€‚")

    def query_stock_info(self, stock_codes: list[str] = None) -> dict[str, StockInfo]:
        """
        2. æŸ¥è¯¢æœ¬åœ°Aè‚¡åŸºç¡€ä¿¡æ¯
        ç›´æ¥æŸ¥è¯¢ tb_stock_infoã€‚
        """
        queryset = StockInfo.objects.all()
        if stock_codes:
            queryset = queryset.filter(stock_code__in=stock_codes)
      
        return {stock.stock_code: stock for stock in queryset}

    def query_daily_quotes(
        self, 
        stock_codes: list[str] = None, 
        start_date: str = None, 
        end_date: str = None
    ) -> dict[str, list[DailyQuotes]]:
        """
        3. æŸ¥è¯¢æœ¬åœ°Aè‚¡äº¤æ˜“ä¿¡æ¯
        ç›´æ¥æŸ¥è¯¢ tb_daily_quotesã€‚
        """
        # è®¾ç½®é»˜è®¤æ—¥æœŸä¸ºä»Šå¤©
        today = datetime.date.today()
        start_date = start_date or today.strftime('%Y-%m-%d')
        end_date = end_date or today.strftime('%Y-%m-%d')

        # ä½¿ç”¨ select_related ä¼˜åŒ–æŸ¥è¯¢ï¼Œä¸€æ¬¡æ€§è·å–å…³è”çš„ StockInfo å¯¹è±¡
        # ä½¿ç”¨ order_by ç¡®ä¿æ•°æ®æŒ‰è‚¡ç¥¨å’Œæ—¥æœŸæ’åºï¼Œä¾¿äºåç»­åˆ†ç»„
        queryset = DailyQuotes.objects.select_related('stock_code').filter(
            trade_date__gte=start_date,
            trade_date__lte=end_date
        ).order_by('stock_code', 'trade_date')

        if stock_codes:
            queryset = queryset.filter(stock_code__in=stock_codes)
      
        # æ„å»ºè¾“å‡ºå­—å…¸
        result = {}
        for quote in queryset:
            # ä½¿ç”¨ stock_code_id é¿å…å†æ¬¡è®¿é—®æ•°æ®åº“
            # setdefault æ˜¯æ„å»ºè¿™ç§åˆ†ç»„å­—å…¸çš„ä¼˜é›…æ–¹å¼
            result.setdefault(quote.stock_code_id, []).append(quote)
          
        return result

    #æ¸…ç©ºæ‰€æœ‰æ•°æ®
    def clear_all_data(self):
        with connection.cursor() as cursor:
            cursor.execute(f"DELETE FROM tb_daily_factor_values;")
            cursor.execute(f"DELETE FROM tb_daily_quotes;")
            cursor.execute(f"DELETE FROM tb_daily_trading_plan;")
            cursor.execute(f"DELETE FROM tb_factor_definitions;")
            cursor.execute(f"DELETE FROM tb_positions;")
            cursor.execute(f"DELETE FROM tb_stock_info;")
            cursor.execute(f"DELETE FROM tb_strategy_parameters;")
            cursor.execute(f"DELETE FROM tb_system_log;")
            cursor.execute(f"DELETE FROM tb_trade_log;")
####æ–‡ä»¶ç»“æŸ####

####selection_manager\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####selection_manager\admin.py####
from django.contrib import admin

# Register your models here.

####æ–‡ä»¶ç»“æŸ####

####selection_manager\apps.py####
from django.apps import AppConfig


class SelectionManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'selection_manager'

####æ–‡ä»¶ç»“æŸ####

####selection_manager\models.py####
from django.db import models

# Create your models here.

####æ–‡ä»¶ç»“æŸ####

####selection_manager\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####selection_manager\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include
from . import views
urlpatterns = [
    path('initSelectionStratage', views.init_strategy),
    path('runSelection',views.run_selection)
]

####æ–‡ä»¶ç»“æŸ####

####selection_manager\views.py####
from datetime import date,datetime
from django.shortcuts import render
from django.http.response import JsonResponse
from selection_manager.service.selection_service import SelectionService
import json
from django.views.decorators.http import require_http_methods
# Create your views here.
@require_http_methods(["GET"])
def init_strategy(request):
    SelectionService.initialize_strategy()
    result={}
    return JsonResponse(result)
@require_http_methods(["POST"])
def run_selection(request):
    if request.method=='POST':
        body= json.loads(request.body)
        selection_date=datetime.strptime(body['date'], "%Y-%m-%d").date()
        service=SelectionService(selection_date,mode=body['mode'])
        service.run_selection()
        return JsonResponse({
            'type':selection_date,
            'data':json.loads(request.body)
        })
    

####æ–‡ä»¶ç»“æŸ####

####selection_manager\management\commands\prime_market_regime_cache.py####
# selection_manager/management/commands/prime_market_regime_cache.py

import logging
import time
from datetime import date, timedelta

import pandas as pd
from django.core.management.base import BaseCommand
from django.db import transaction
from decimal import Decimal

from common.models import DailyQuotes, StockInfo, DailyFactorValues, StrategyParameters
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE

# é…ç½®æ—¥å¿—
logger = logging.getLogger('prime_market_regime_cache')

# å°è¯•å¯¼å…¥GPUåº“
try:
    import cudf
    import cupy as cp
    GPU_AVAILABLE = True
    logger.info("cuDF å’Œ cuPy åº“å·²æ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ GPU è¿›è¡Œè®¡ç®—ã€‚")
except ImportError:
    GPU_AVAILABLE = False
    logger.warning("æœªæ‰¾åˆ° cuDF æˆ– cuPy åº“ã€‚æ­¤å‘½ä»¤éœ€è¦GPUç¯å¢ƒã€‚è¯·å®‰è£…ç›¸å…³ä¾èµ–åé‡è¯•ã€‚")
    logger.warning("å‚è€ƒå®‰è£…: conda install -c rapidsai -c nvidia -c conda-forge cudf cupy")


class Command(BaseCommand):
    help = 'ä½¿ç”¨GPUé¢„çƒ­å¸‚åœºçŠ¶æ€M(t)çš„å†å²æ•°æ®ç¼“å­˜ï¼Œç”¨äºé¦–æ¬¡è¿è¡Œæˆ–æ•°æ®å›è¡¥ã€‚'

    def add_arguments(self, parser):
        parser.add_argument(
            '--days',
            type=int,
            default=750,
            help='è¦é¢„çƒ­çš„äº¤æ˜“æ—¥å¤©æ•°ï¼Œé»˜è®¤ä¸º750 (çº¦3å¹´)ã€‚'
        )
        parser.add_argument(
            '--end_date',
            type=str,
            # default=date.today().isoformat(),
            default="2023-04-30",
            help='é¢„çƒ­çš„ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©ã€‚æ ¼å¼: YYYY-MM-DD'
        )

    def handle(self, *args, **options):
        if not GPU_AVAILABLE:
            self.stdout.write(self.style.ERROR("GPUç¯å¢ƒä¸å¯ç”¨ï¼Œå‘½ä»¤ç»ˆæ­¢ã€‚"))
            return

        days_to_prime = options['days']
        end_date = date.fromisoformat(options['end_date'])
        
        self.stdout.write(self.style.SUCCESS(f"===== å¼€å§‹M(t)ç¼“å­˜é¢„çƒ­ä»»åŠ¡ (GPUæ¨¡å¼) ====="))
        self.stdout.write(f"é¢„çƒ­å‘¨æœŸ: {days_to_prime} ä¸ªäº¤æ˜“æ—¥, æˆªæ­¢æ—¥æœŸ: {end_date}")
        
        total_start_time = time.time()

        # 1. è·å–æ‰€éœ€å‚æ•°å’Œäº¤æ˜“æ—¥å†
        params = {p.param_name: float(p.param_value) for p in StrategyParameters.objects.filter(param_name__startswith='dynamic_')}
        min_liquidity = params.get('dynamic_min_liquidity', 100000000)
        lookback_new_stock = int(params.get('dynamic_lookback_new_stock', 60))

        trade_dates = list(DailyQuotes.objects.filter(trade_date__lte=end_date)
                           .values_list('trade_date', flat=True).distinct().order_by('-trade_date')[:days_to_prime + 60])
        trade_dates.reverse()

        if not trade_dates:
            self.stdout.write(self.style.ERROR("æ•°æ®åº“ä¸­æ— äº¤æ˜“æ—¥æ•°æ®ï¼Œæ— æ³•é¢„çƒ­ã€‚"))
            return

        # 2. åŠ è½½å…¨å‘¨æœŸæ•°æ®åˆ°Pandas
        self.stdout.write("æ­£åœ¨ä»æ•°æ®åº“åŠ è½½å…¨å‘¨æœŸè¡Œæƒ…æ•°æ®åˆ°å†…å­˜...")
        start_load_time = time.time()
        all_quotes_qs = DailyQuotes.objects.filter(trade_date__in=trade_dates).values(
            'trade_date', 'stock_code_id', 'close', 'turnover', 'hfq_close'
        )
        all_stocks_qs = StockInfo.objects.values('stock_code', 'listing_date', 'stock_name')
        
        df_quotes = pd.DataFrame.from_records(all_quotes_qs)
        df_stocks = pd.DataFrame.from_records(all_stocks_qs)
        
        df_quotes['trade_date'] = pd.to_datetime(df_quotes['trade_date'])
        df_stocks['listing_date'] = pd.to_datetime(df_stocks['listing_date'])
        
        df = pd.merge(df_quotes, df_stocks, left_on='stock_code_id', right_on='stock_code')
        load_duration = time.time() - start_load_time
        self.stdout.write(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•ï¼Œè€—æ—¶: {load_duration:.2f} ç§’ã€‚")

        # 3. æ•°æ®ä¼ è¾“åˆ°GPU
        self.stdout.write("æ­£åœ¨å°†æ•°æ®ä¼ è¾“åˆ°GPUæ˜¾å­˜...")
        start_gpu_transfer_time = time.time()
        gdf = cudf.from_pandas(df)
        gpu_transfer_duration = time.time() - start_gpu_transfer_time
        self.stdout.write(f"æ•°æ®æˆåŠŸä¼ è¾“åˆ°GPUï¼Œè€—æ—¶: {gpu_transfer_duration:.2f} ç§’ã€‚")

        # 4. åœ¨GPUä¸Šè¿›è¡Œè®¡ç®—
        self.stdout.write("æ­£åœ¨GPUä¸Šå¹¶è¡Œè®¡ç®—æ‰€æœ‰æ—¥æœŸçš„M(t)åŸºç¡€æŒ‡æ ‡...")
        start_gpu_calc_time = time.time()
        
        # GPUè®¡ç®—é€»è¾‘
        results = []
        # æˆ‘ä»¬åªå¯¹æœ€è¿‘ `days_to_prime` å¤©è¿›è¡Œè®¡ç®—å’Œä¿å­˜
        for calc_date in pd.to_datetime(trade_dates[-days_to_prime:]):
            # a. å½“æ—¥ç­›é€‰
            gdf_today = gdf[gdf['trade_date'] == calc_date]
            
            # å‰”é™¤ST
            gdf_today = gdf_today[~gdf_today['stock_name'].str.contains('ST')]
            
            # å‰”é™¤æ¬¡æ–°è‚¡
            min_listing_date = calc_date - timedelta(days=lookback_new_stock)
            gdf_today = gdf_today[gdf_today['listing_date'] < min_listing_date]
            
            # å‰”é™¤ä½æµåŠ¨æ€§
            start_liquidity_date = calc_date - timedelta(days=40) # å¤šå–ä¸€äº›æ•°æ®
            gdf_liquidity_period = gdf[(gdf['trade_date'] >= start_liquidity_date) & (gdf['trade_date'] <= calc_date)]
            
            # è·å–æœ€è¿‘20ä¸ªäº¤æ˜“æ—¥
            recent_20_days = gdf_liquidity_period['trade_date'].unique().nlargest(20)
            gdf_liquidity_period = gdf_liquidity_period[gdf_liquidity_period['trade_date'].isin(recent_20_days)]
            
            avg_turnover = gdf_liquidity_period.groupby('stock_code_id')['turnover'].mean()
            liquid_stocks = avg_turnover[avg_turnover >= min_liquidity].index
            
            gdf_today = gdf_today[gdf_today['stock_code_id'].isin(liquid_stocks)]
            
            if gdf_today.empty:
                continue

            # b. è·å–ç”¨äºè®¡ç®—æŒ‡æ ‡çš„å†å²çª—å£æ•°æ®
            start_hist_date = calc_date - timedelta(days=120) # ë„‰ë„‰í•˜ê²Œ 120ì¼
            gdf_hist = gdf[(gdf['trade_date'] >= start_hist_date) & (gdf['trade_date'] <= calc_date)]
            gdf_hist = gdf_hist[gdf_hist['stock_code_id'].isin(gdf_today['stock_code_id'])]

            # c. è®¡ç®—æŒ‡æ ‡
            # M1: åˆ›60æ—¥æ–°é«˜å æ¯”
            gdf_hist_60d = gdf_hist[gdf_hist['trade_date'].isin(gdf_hist['trade_date'].unique().nlargest(60))]
            high60 = gdf_hist_60d.groupby('stock_code_id')['close'].max()
            merged_m1 = gdf_today.merge(high60.rename('high60'), on='stock_code_id')
            m1 = (merged_m1['close'] >= merged_m1['high60']).sum() / len(merged_m1) if len(merged_m1) > 0 else 0

            # M2: MA60ä¹‹ä¸Šå æ¯”
            ma60 = gdf_hist_60d.groupby('stock_code_id')['close'].mean()
            merged_m2 = gdf_today.merge(ma60.rename('ma60'), on='stock_code_id')
            m2 = (merged_m2['close'] > merged_m2['ma60']).sum() / len(merged_m2) if len(merged_m2) > 0 else 0
            
            # M3: 60æ—¥å›æŠ¥ç‡ä¸­ä½æ•°
            date_t_minus_60 = gdf_hist_60d['trade_date'].unique().nsmallest(1).iloc[0]
            close_t = gdf_today[['stock_code_id', 'hfq_close']].set_index('stock_code_id')
            close_t_minus_60 = gdf_hist_60d[gdf_hist_60d['trade_date'] == date_t_minus_60][['stock_code_id', 'hfq_close']].set_index('stock_code_id')
            ret60 = (close_t / close_t_minus_60 - 1).dropna()
            m3 = ret60['hfq_close'].median() if not ret60.empty else 0

            # M4: 20æ—¥å¹³å‡æ³¢åŠ¨ç‡
            gdf_hist_20d = gdf_hist[gdf_hist['trade_date'].isin(gdf_hist['trade_date'].unique().nlargest(20))]
            gdf_hist_20d = gdf_hist_20d.sort_values(by=['stock_code_id', 'trade_date'])
            returns = gdf_hist_20d.groupby('stock_code_id')['hfq_close'].pct_change().dropna()
            vol20 = gdf_hist_20d.merge(returns.rename('returns'), left_index=True, right_index=True).groupby('stock_code_id')['returns'].std()
            m4 = vol20.mean() if not vol20.empty else 0

            results.append({
                'trade_date': calc_date.date(),
                'dynamic_M1_RAW': float(m1),
                'dynamic_M2_RAW': float(m2),
                'dynamic_M3_RAW': float(m3) if m3 is not None else 0.0,
                'dynamic_M4_RAW': float(m4) if m4 is not None else 0.0,
            })
            self.stdout.write(f"  - å®Œæˆæ—¥æœŸ {calc_date.date()} çš„è®¡ç®—ã€‚")

        gpu_calc_duration = time.time() - start_gpu_calc_time
        self.stdout.write(f"GPUè®¡ç®—å®Œæˆï¼Œè€—æ—¶: {gpu_calc_duration:.2f} ç§’ã€‚")

        # 5. ç»“æœæ‰¹é‡å­˜å…¥æ•°æ®åº“
        self.stdout.write("æ­£åœ¨å°†è®¡ç®—ç»“æœæ‰¹é‡å†™å…¥æ•°æ®åº“ç¼“å­˜...")
        start_db_write_time = time.time()
        
        records_to_create = []
        for res in results:
            trade_date_res = res['trade_date']
            for factor_code_suffix, value in res.items():
                if factor_code_suffix == 'trade_date': continue
                if pd.notna(value):
                    records_to_create.append(DailyFactorValues(
                        stock_code_id=MARKET_INDICATOR_CODE,
                        trade_date=trade_date_res,
                        factor_code_id=factor_code_suffix,
                        raw_value=Decimal(str(value))
                    ))
        
        with transaction.atomic():
            # å…ˆåˆ é™¤ï¼Œå†æ’å…¥ï¼Œä¿è¯å¹‚ç­‰æ€§
            dates_in_results = [r['trade_date'] for r in results]
            DailyFactorValues.objects.filter(
                stock_code_id=MARKET_INDICATOR_CODE,
                trade_date__in=dates_in_results
            ).delete()
            DailyFactorValues.objects.bulk_create(records_to_create, batch_size=500)

        db_write_duration = time.time() - start_db_write_time
        self.stdout.write(f"æ•°æ®åº“å†™å…¥å®Œæˆï¼Œå…± {len(records_to_create)} æ¡è®°å½•ï¼Œè€—æ—¶: {db_write_duration:.2f} ç§’ã€‚")

        total_duration = time.time() - total_start_time
        self.stdout.write(self.style.SUCCESS(f"===== M(t)ç¼“å­˜é¢„çƒ­ä»»åŠ¡æˆåŠŸå®Œæˆï¼æ€»è€—æ—¶: {total_duration:.2f} ç§’ ====="))


####æ–‡ä»¶ç»“æŸ####

####selection_manager\service\selection_service.py####
# selection_manager/service/selection_service.py

import logging
from datetime import date, timedelta
from decimal import Decimal

import numpy as np
import pandas as pd
import pandas_ta as ta
from scipy.stats import linregress

from django.db import transaction
from django.utils import timezone

from common.models import (
    StockInfo, DailyQuotes, SystemLog, FactorDefinitions, DailyFactorValues,
    StrategyParameters, DailyTradingPlan
)

# region: å…¨å±€é…ç½®
MODULE_NAME = 'æ—¥ç»ˆé€‰è‚¡ä¸é¢„æ¡ˆæ¨¡å—(åŠ¨æ€ç‰ˆ)'
logger = logging.getLogger(__name__)
MARKET_INDICATOR_CODE = '_MARKET_REGIME_INDICATOR_'
# endregion


class SelectionService:
    """
    T-1æ—¥æ”¶ç›˜åè¿è¡Œçš„åŠ¨æ€è‡ªé€‚åº”é€‰è‚¡ä¸é¢„æ¡ˆç”ŸæˆæœåŠ¡ã€‚
    
    è¯¥æœåŠ¡å®ç°äº† f_dynamic(x, t) é€‰è‚¡è¯„åˆ†å‡½æ•°ï¼Œèƒ½å¤Ÿæ ¹æ®å¸‚åœºçŠ¶æ€ M(t)
    åŠ¨æ€è°ƒæ•´é€‰è‚¡ç­–ç•¥çš„ç»´åº¦æƒé‡ï¼Œä»¥é€‚åº”ä¸åŒçš„å¸‚åœºç¯å¢ƒã€‚
    """

    def __init__(self, trade_date: date, mode: str = 'realtime'):
        """
        åˆå§‹åŒ–é€‰è‚¡æœåŠ¡ã€‚

        :param trade_date: T-1æ—¥ï¼Œå³æ‰§è¡Œè®¡ç®—çš„å½“å¤©æ—¥æœŸã€‚
        :param mode: è¿è¡Œæ¨¡å¼, 'realtime' æˆ– 'backtest'ã€‚
        """
        if mode not in ['realtime', 'backtest']:
            raise ValueError("æ¨¡å¼(mode)å¿…é¡»æ˜¯ 'realtime' æˆ– 'backtest'")

        # --- æ—¥æœŸå¯¹é½é€»è¾‘ ---
        try:
            # æŸ¥è¯¢å°äºç­‰äºè¾“å…¥æ—¥æœŸçš„ã€æœ€æ–°çš„ä¸€ä¸ªäº¤æ˜“æ—¥
            latest_trade_date_obj = DailyQuotes.objects.filter(trade_date__lte=trade_date).latest('trade_date')
            validated_trade_date = latest_trade_date_obj.trade_date
            
            if validated_trade_date != trade_date:
                logger.debug(f"è¾“å…¥æ—¥æœŸ {trade_date} ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œå·²è‡ªåŠ¨æ ¡å‡†ä¸ºæœ€è¿‘çš„äº¤æ˜“æ—¥: {validated_trade_date}")
            
            self.trade_date = validated_trade_date
        except ObjectDoesNotExist:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•æ—©äºæˆ–ç­‰äº trade_date çš„æ•°æ®
            error_msg = f"æ— æ³•åœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°æ—¥æœŸ {trade_date} æˆ–ä¹‹å‰çš„ä»»ä½•äº¤æ˜“æ—¥æ•°æ®ï¼ŒæœåŠ¡æ— æ³•åˆå§‹åŒ–ã€‚"
            logger.error(error_msg)
            raise ValueError(error_msg)
        self.mode = mode
        self.dynamic_params = {}
        self.dynamic_factor_defs = {}
        
        # å¸‚åœºçŠ¶æ€ä¸åŠ¨æ€æƒé‡
        self.market_regime_M = 0.0
        self.dynamic_weights = {}

        # é¢æ¿æ•°æ®
        self.panel_open = None
        self.panel_high = None
        self.panel_low = None
        self.panel_close = None
        self.panel_volume = None
        self.panel_turnover = None
        self.panel_hfq_close = None

        logger.debug(f"--- SelectionService(åŠ¨æ€ç‰ˆ) åˆå§‹åŒ– ---")
        logger.debug(f"äº¤æ˜“æ—¥æœŸ (T-1): {self.trade_date}")
        logger.debug(f"è¿è¡Œæ¨¡å¼: {self.mode}")

    # region: --- 1. ä¸»æµç¨‹ä¸å…¥å£æ–¹æ³• ---

    @staticmethod
    def initialize_strategy():
        """
        åˆå§‹åŒ–åŠ¨æ€ç­–ç•¥æ‰€éœ€çš„å› å­å®šä¹‰å’Œå‚æ•°åˆ°æ•°æ®åº“ã€‚
        è¿™æ˜¯ä¸€ä¸ªå¹‚ç­‰æ“ä½œï¼Œå¯ä»¥é‡å¤è¿è¡Œã€‚
        """
        logger.debug("å¼€å§‹åˆå§‹åŒ–åŠ¨æ€ç­–ç•¥ï¼šé“ºåº•å› å­å®šä¹‰å’Œç­–ç•¥å‚æ•°...")

        # 1. ç¡®ä¿å¸‚åœºæŒ‡æ ‡çš„ç‰¹æ®Šè‚¡ç¥¨ä»£ç å­˜åœ¨
        try:
            StockInfo.objects.get_or_create(
                stock_code=MARKET_INDICATOR_CODE,
                defaults={
                    'stock_name': 'å¸‚åœºçŠ¶æ€æŒ‡æ ‡',
                    'listing_date': date(1990, 1, 1),
                    'status': StockInfo.StatusChoices.LISTING
                }
            )
            logger.debug(f"ç‰¹æ®Šè‚¡ç¥¨ä»£ç  '{MARKET_INDICATOR_CODE}' å·²ç¡®è®¤å­˜åœ¨ã€‚")
        except Exception as e:
            logger.error(f"åˆ›å»ºç‰¹æ®Šè‚¡ç¥¨ä»£ç  '{MARKET_INDICATOR_CODE}' å¤±è´¥: {e}")
            # è¿™æ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œå¦‚æœå¤±è´¥åˆ™ä¸åº”ç»§ç»­
            return

        # 2. å®šä¹‰æ‰€æœ‰å› å­ (åŒ…æ‹¬M(t)ç¼“å­˜å› å­å’Œä¸ªè‚¡å› å­)
        factors_to_define = [
            # M(t) ç¼“å­˜å› å­
            {'factor_code': 'dynamic_M_VALUE', 'factor_name': 'åŠ¨æ€-å¸‚åœºçŠ¶æ€M(t)æœ€ç»ˆå€¼', 'direction': 'positive'},
            {'factor_code': 'dynamic_M1_RAW', 'factor_name': 'åŠ¨æ€-M1åŸå§‹å€¼(æ–°é«˜å æ¯”)', 'direction': 'positive'},
            {'factor_code': 'dynamic_M2_RAW', 'factor_name': 'åŠ¨æ€-M2åŸå§‹å€¼(MA60ä¹‹ä¸Šå æ¯”)', 'direction': 'positive'},
            {'factor_code': 'dynamic_M3_RAW', 'factor_name': 'åŠ¨æ€-M3åŸå§‹å€¼(60æ—¥å›æŠ¥ä¸­ä½æ•°)', 'direction': 'positive'},
            {'factor_code': 'dynamic_M4_RAW', 'factor_name': 'åŠ¨æ€-M4åŸå§‹å€¼(20æ—¥å¹³å‡æ³¢åŠ¨ç‡)', 'direction': 'negative'},
            
            # è¶‹åŠ¿åŠ¨èƒ½ (MT) ç»´åº¦å› å­
            {'factor_code': 'dynamic_MA20_SLOPE', 'factor_name': 'åŠ¨æ€-20æ—¥å‡çº¿æ–œç‡', 'direction': 'positive'},
            {'factor_code': 'dynamic_MA_SCORE', 'factor_name': 'åŠ¨æ€-å‡çº¿æ’åˆ—è¯„åˆ†', 'direction': 'positive'},
            {'factor_code': 'dynamic_ADX_CONFIRM', 'factor_name': 'åŠ¨æ€-ADXè¶‹åŠ¿ç¡®è®¤', 'direction': 'positive'},
            
            # å¼ºåŠ¿çªç ´ (BO) ç»´åº¦å› å­
            {'factor_code': 'dynamic_BREAKOUT_PWR', 'factor_name': 'åŠ¨æ€-çªç ´å¼ºåº¦', 'direction': 'positive'},
            {'factor_code': 'dynamic_VOLUME_SURGE', 'factor_name': 'åŠ¨æ€-æˆäº¤é‡æ¿€å¢', 'direction': 'positive'},
            {'factor_code': 'dynamic_MOM_ACCEL', 'factor_name': 'åŠ¨æ€-åŠ¨èƒ½åŠ é€Ÿåº¦', 'direction': 'positive'},

            # å‡å€¼å›å½’ (MR) ç»´åº¦å› å­
            {'factor_code': 'dynamic_RSI_OS', 'factor_name': 'åŠ¨æ€-çŸ­æœŸè¶…å–(RSI14)', 'direction': 'negative'},
            {'factor_code': 'dynamic_NEG_DEV', 'factor_name': 'åŠ¨æ€-è´Ÿå‘åç¦»åº¦(vs MA60)', 'direction': 'negative'},
            {'factor_code': 'dynamic_BOLL_LB', 'factor_name': 'åŠ¨æ€-å¸ƒæ—ä¸‹è½¨æ”¯æ’‘', 'direction': 'negative'},

            # è´¨é‡é˜²å¾¡ (QD) ç»´åº¦å› å­
            {'factor_code': 'dynamic_LOW_VOL', 'factor_name': 'åŠ¨æ€-ä½æ³¢åŠ¨ç‡(20æ—¥)', 'direction': 'negative'},
            {'factor_code': 'dynamic_MAX_DD', 'factor_name': 'åŠ¨æ€-æœ€å¤§å›æ’¤æ§åˆ¶(60æ—¥)', 'direction': 'negative'},
            {'factor_code': 'dynamic_DOWNSIDE_RISK', 'factor_name': 'åŠ¨æ€-ä¸‹è¡Œé£é™©(60æ—¥)', 'direction': 'negative'},
        ]
        with transaction.atomic():
            for factor_data in factors_to_define:
                FactorDefinitions.objects.update_or_create(
                    factor_code=factor_data['factor_code'],
                    defaults={'factor_name': factor_data['factor_name'], 'direction': factor_data['direction'], 'is_active': True}
                )
        logger.debug(f"æˆåŠŸåˆå§‹åŒ–/æ›´æ–° {len(factors_to_define)} ä¸ªåŠ¨æ€å› å­å®šä¹‰ã€‚")

        # 3. å®šä¹‰æ‰€æœ‰å‚æ•° (ä½¿ç”¨ 'dynamic_' å‰ç¼€)
        parameters_to_define = {
            # M(t) å‚æ•°
            'dynamic_w_m1': {'value': '0.2', 'group': 'M_WEIGHTS', 'desc': 'M(t)æŒ‡æ ‡æƒé‡: M1-åˆ›60æ—¥æ–°é«˜å æ¯”'},
            'dynamic_w_m2': {'value': '0.35', 'group': 'M_WEIGHTS', 'desc': 'M(t)æŒ‡æ ‡æƒé‡: M2-MA60ä¹‹ä¸Šå æ¯”'},
            'dynamic_w_m3': {'value': '0.25', 'group': 'M_WEIGHTS', 'desc': 'M(t)æŒ‡æ ‡æƒé‡: M3-60æ—¥å›æŠ¥ç‡ä¸­ä½æ•°'},
            'dynamic_w_m4': {'value': '0.2', 'group': 'M_WEIGHTS', 'desc': 'M(t)æŒ‡æ ‡æƒé‡: M4-20æ—¥å¹³å‡æ³¢åŠ¨ç‡'},
            'dynamic_m_lookback': {'value': '750', 'group': 'M_PARAMS', 'desc': 'M(t)å†å²å›çœ‹å‘¨æœŸ(çº¦3å¹´)'},

            # åŠ¨æ€æƒé‡ N_i(M(t)) å‚æ•°
            'dynamic_c_MT': {'value': '1.2', 'group': 'N_ATTRACTION', 'desc': 'å¸å¼•åŠ›å‡½æ•°å¼ºåº¦ç³»æ•°: è¶‹åŠ¿åŠ¨èƒ½'},
            'dynamic_c_BO': {'value': '0.9', 'group': 'N_ATTRACTION', 'desc': 'å¸å¼•åŠ›å‡½æ•°å¼ºåº¦ç³»æ•°: å¼ºåŠ¿çªç ´'},
            'dynamic_c_QD': {'value': '1.1', 'group': 'N_ATTRACTION', 'desc': 'å¸å¼•åŠ›å‡½æ•°å¼ºåº¦ç³»æ•°: è´¨é‡é˜²å¾¡'},
            'dynamic_c_MR': {'value': '0.8', 'group': 'N_ATTRACTION', 'desc': 'å¸å¼•åŠ›å‡½æ•°å¼ºåº¦ç³»æ•°: å‡å€¼å›å½’'},
            'dynamic_sigma_MR': {'value': '0.25', 'group': 'N_PARAMS', 'desc': 'å‡å€¼å›å½’ç­–ç•¥é€‚ç”¨èŒƒå›´å®½åº¦'},
            'dynamic_tau': {'value': '0.2', 'group': 'N_PARAMS', 'desc': 'Softmaxæ¸©åº¦ç³»æ•°(æ§åˆ¶åˆ‡æ¢çµæ•åº¦)'},

            # ç»´åº¦å†…éƒ¨å› å­æƒé‡ (k_ij)
            'dynamic_k_MT1': {'value': '0.5', 'group': 'K_WEIGHTS_MT', 'desc': 'è¶‹åŠ¿åŠ¨èƒ½-MA20æ–œç‡æƒé‡'},
            'dynamic_k_MT2': {'value': '0.3', 'group': 'K_WEIGHTS_MT', 'desc': 'è¶‹åŠ¿åŠ¨èƒ½-å‡çº¿æ’åˆ—æƒé‡'},
            'dynamic_k_MT3': {'value': '0.2', 'group': 'K_WEIGHTS_MT', 'desc': 'è¶‹åŠ¿åŠ¨èƒ½-ADXç¡®è®¤æƒé‡'},
            'dynamic_k_BO1': {'value': '0.45', 'group': 'K_WEIGHTS_BO', 'desc': 'å¼ºåŠ¿çªç ´-çªç ´å¼ºåº¦æƒé‡'},
            'dynamic_k_BO2': {'value': '0.35', 'group': 'K_WEIGHTS_BO', 'desc': 'å¼ºåŠ¿çªç ´-æˆäº¤é‡æ¿€å¢æƒé‡'},
            'dynamic_k_BO3': {'value': '0.2', 'group': 'K_WEIGHTS_BO', 'desc': 'å¼ºåŠ¿çªç ´-åŠ¨èƒ½åŠ é€Ÿåº¦æƒé‡'},
            'dynamic_k_MR1': {'value': '0.3', 'group': 'K_WEIGHTS_MR', 'desc': 'å‡å€¼å›å½’-RSIè¶…å–æƒé‡'},
            'dynamic_k_MR2': {'value': '0.5', 'group': 'K_WEIGHTS_MR', 'desc': 'å‡å€¼å›å½’-è´Ÿå‘åç¦»åº¦æƒé‡'},
            'dynamic_k_MR3': {'value': '0.2', 'group': 'K_WEIGHTS_MR', 'desc': 'å‡å€¼å›å½’-å¸ƒæ—ä¸‹è½¨æ”¯æ’‘æƒé‡'},
            'dynamic_k_QD1': {'value': '0.45', 'group': 'K_WEIGHTS_QD', 'desc': 'è´¨é‡é˜²å¾¡-ä½æ³¢åŠ¨ç‡æƒé‡'},
            'dynamic_k_QD2': {'value': '0.35', 'group': 'K_WEIGHTS_QD', 'desc': 'è´¨é‡é˜²å¾¡-æœ€å¤§å›æ’¤æƒé‡'},
            'dynamic_k_QD3': {'value': '0.2', 'group': 'K_WEIGHTS_QD', 'desc': 'è´¨é‡é˜²å¾¡-ä¸‹è¡Œé£é™©æƒé‡'},
            
            # äº¤æ˜“é¢„æ¡ˆå‚æ•°
            # 'dynamic_k_drop': {'value': '0.3', 'group': 'PLAN_PARAMS', 'desc': 'MIOPä½å¼€å®¹å¿ç³»æ•°'},
            # 'dynamic_k_gap': {'value': '0.5', 'group': 'PLAN_PARAMS', 'desc': 'MAOPé«˜å¼€å®¹å¿ç³»æ•°'},
            'dynamic_miopmaop_k_gap_base_mt': {'value': '0.6', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-è¶‹åŠ¿åŠ¨èƒ½-é«˜å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_drop_base_mt': {'value': '0.2', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-è¶‹åŠ¿åŠ¨èƒ½-ä½å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_gap_base_bo': {'value': '1.5', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-å¼ºåŠ¿çªç ´-é«˜å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_drop_base_bo': {'value': '0.1', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-å¼ºåŠ¿çªç ´-ä½å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_gap_base_mr': {'value': '0.05', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-å‡å€¼å›å½’-é«˜å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_drop_base_mr': {'value': '1.8', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-å‡å€¼å›å½’-ä½å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_gap_base_qd': {'value': '0.15', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-è´¨é‡é˜²å¾¡-é«˜å¼€å®¹å¿åº¦'},
            'dynamic_miopmaop_k_drop_base_qd': {'value': '0.15', 'group': 'MIOPMAOP_BASE', 'desc': 'åŠ¨æ€å¼€ç›˜åŒºé—´-è´¨é‡é˜²å¾¡-ä½å¼€å®¹å¿åº¦'},
            
            # ç­›é€‰ä¸è®¡ç®—å‚æ•°
            'dynamic_lookback_new_stock': {'value': '60', 'group': 'FILTERS', 'desc': 'æ¬¡æ–°è‚¡å®šä¹‰å¤©æ•°(è‡ªç„¶æ—¥)'},
            'dynamic_min_liquidity': {'value': '100000000', 'group': 'FILTERS', 'desc': 'æœ€ä½æ—¥å‡æˆäº¤é¢(å…ƒ)'},
            'dynamic_top_n': {'value': '10', 'group': 'SELECTION', 'desc': 'æœ€ç»ˆé€‰å–è‚¡ç¥¨æ•°é‡'},
        }
        with transaction.atomic():
            for name, data in parameters_to_define.items():
                StrategyParameters.objects.update_or_create(
                    param_name=name,
                    defaults={
                        'param_value': Decimal(data['value']),
                        'group_name': data['group'],
                        'description': data['desc']
                    }
                )
        logger.debug(f"æˆåŠŸåˆå§‹åŒ–/æ›´æ–° {len(parameters_to_define)} ä¸ªåŠ¨æ€ç­–ç•¥å‚æ•°ã€‚")
        logger.debug("åŠ¨æ€ç­–ç•¥åˆå§‹åŒ–å®Œæˆã€‚")

    def run_selection(self):
        """
        ä¸€é”®å¯åŠ¨å…¨æµç¨‹çš„å…¥å£æ–¹æ³•ã€‚
        """
        ta.Imports["verbose"] = False
        self._log_to_db('INFO', f"åŠ¨æ€é€‰è‚¡æµç¨‹å¯åŠ¨ã€‚æ¨¡å¼: {self.mode}, æ—¥æœŸ: {self.trade_date}")
        try:
            self._load_dynamic_parameters_and_defs()
            initial_stock_pool = self._initial_screening()
            if not initial_stock_pool:
                self._log_to_db('WARNING', "åˆæ­¥ç­›é€‰åæ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                return

            # æ ¸å¿ƒåŠ¨æ€é€»è¾‘
            self.market_regime_M = self._calculate_market_regime_M(initial_stock_pool)
            self.dynamic_weights = self._calculate_dynamic_weights(self.market_regime_M)
            
            self._load_market_data(initial_stock_pool)
            raw_factors_df = self._calculate_all_dynamic_factors()
            norm_scores_df = self._standardize_factors(raw_factors_df)
            
            dimension_scores_df = self._calculate_dimension_scores(norm_scores_df)
            final_scores = self._calculate_final_dynamic_score(dimension_scores_df, self.dynamic_weights)
            
            trading_plan = self._generate_trading_plan(final_scores,dimension_scores_df)
            if trading_plan.empty:
                self._log_to_db('WARNING', "æœ€ç»ˆæœªç”Ÿæˆä»»ä½•äº¤æ˜“é¢„æ¡ˆã€‚")
                return

            self._save_results(raw_factors_df, norm_scores_df, trading_plan)

            success_msg = f"åŠ¨æ€é€‰è‚¡æµç¨‹æˆåŠŸå®Œæˆã€‚M(t)={self.market_regime_M:.4f}, ç”Ÿæˆ {len(trading_plan)} æ¡äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.debug(success_msg)
            self._log_to_db('INFO', success_msg)

        except Exception as e:
            error_msg = f"åŠ¨æ€é€‰è‚¡æµç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
            logger.critical(error_msg, exc_info=True)
            self._log_to_db('CRITICAL', error_msg)
            raise

    # endregion

    # region: --- 2. æ ¸å¿ƒåŠ¨æ€é€»è¾‘å®ç° ---

    def _calculate_market_regime_M(self, stock_pool: list[str]) -> float:
        """
        è®¡ç®—å¸‚åœºçŠ¶æ€å‡½æ•° M(t)ï¼Œä½¿ç”¨æ•°æ®åº“ç¼“å­˜æœºåˆ¶è¿›è¡Œå¢é‡è®¡ç®—ã€‚
        """
        logger.debug("å¼€å§‹è®¡ç®—å¸‚åœºçŠ¶æ€ M(t)...")
        
        # 1. æ£€æŸ¥å½“æ—¥ç¼“å­˜
        try:
            cached_m = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                trade_date=self.trade_date,
                factor_code_id='dynamic_M_VALUE'
            )
            m_value = float(cached_m.raw_value)
            logger.debug(f"æˆåŠŸä»ç¼“å­˜ä¸­è¯»å–å½“æ—¥ M(t) = {m_value:.4f}")
            return m_value
        except DailyFactorValues.DoesNotExist:
            logger.debug("å½“æ—¥ M(t) ç¼“å­˜æœªå‘½ä¸­ï¼Œå¼€å§‹å¢é‡è®¡ç®—...")

        # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œè¿›è¡Œè®¡ç®—
        lookback_days = int(self.dynamic_params['dynamic_m_lookback'])
        all_trade_dates = self._get_market_trade_dates(lookback_days)
        if not all_trade_dates:
            raise ValueError("æ— æ³•è·å–å†å²äº¤æ˜“æ—¥å†ï¼Œæ— æ³•è®¡ç®—M(t)")

        # 3. è·å–å†å²ç¼“å­˜çš„åŸå§‹æŒ‡æ ‡å€¼
        m_factor_codes = ['dynamic_M1_RAW', 'dynamic_M2_RAW', 'dynamic_M3_RAW', 'dynamic_M4_RAW']
        cached_raw_values_qs = DailyFactorValues.objects.filter(
            stock_code_id=MARKET_INDICATOR_CODE,
            trade_date__in=all_trade_dates,
            factor_code_id__in=m_factor_codes
        ).values('trade_date', 'factor_code_id', 'raw_value')

        cached_df = pd.DataFrame.from_records(cached_raw_values_qs)
        if not cached_df.empty:
            cached_pivot = cached_df.pivot(index='trade_date', columns='factor_code_id', values='raw_value').astype(float)
        else:
            cached_pivot = pd.DataFrame(columns=m_factor_codes)

        # 4. æ‰¾å‡ºéœ€è¦é‡æ–°è®¡ç®—çš„æ—¥æœŸ
        dates_to_calculate = sorted(list(set(all_trade_dates) - set(cached_pivot.index)))
        logger.debug(f"éœ€è¦é‡æ–°è®¡ç®— {len(dates_to_calculate)} å¤©çš„ M(t) åŸºç¡€æŒ‡æ ‡ã€‚")

        # 5. å¯¹ç¼ºå¤±æ—¥æœŸè¿›è¡Œè®¡ç®—
        newly_calculated_data = []
        if dates_to_calculate:
            # åªåŠ è½½è®¡ç®— M(t) æ‰€éœ€çš„æ•°æ®
            self._load_market_data(stock_pool, for_m_calc=True)
            for calc_date in dates_to_calculate:
                m1, m2, m3, m4 = self._calculate_m_indicators_for_date(calc_date)
                newly_calculated_data.append({
                    'trade_date': calc_date,
                    'dynamic_M1_RAW': m1, 'dynamic_M2_RAW': m2,
                    'dynamic_M3_RAW': m3, 'dynamic_M4_RAW': m4
                })
                logger.debug(f"å·²å®Œæˆè®¡ç®—{len(newly_calculated_data)}/ {len(dates_to_calculate)} å¤©")
        
        # 6. åˆå¹¶æ–°æ—§æ•°æ®å¹¶å­˜å…¥ç¼“å­˜
        if newly_calculated_data:
            new_df = pd.DataFrame(newly_calculated_data).set_index('trade_date')
            self._save_m_raw_values_to_cache(new_df)
            # åˆå¹¶åˆ°æ€»çš„DataFrame
            if cached_pivot.empty:
                history_raw_df = new_df.sort_index()
            else:
                history_raw_df = pd.concat([cached_pivot, new_df]).sort_index()
        else:
            history_raw_df = cached_pivot.sort_index()

        # 7. æ ‡å‡†åŒ–å¹¶åˆæˆæœ€ç»ˆ M(t)
        current_raw = history_raw_df.loc[self.trade_date]
        
        m1_norm = self._norm_timeseries(current_raw['dynamic_M1_RAW'], history_raw_df['dynamic_M1_RAW'], 'positive')
        m2_norm = self._norm_timeseries(current_raw['dynamic_M2_RAW'], history_raw_df['dynamic_M2_RAW'], 'positive')
        m3_norm = self._norm_timeseries(current_raw['dynamic_M3_RAW'], history_raw_df['dynamic_M3_RAW'], 'positive')
        m4_norm = self._norm_timeseries(current_raw['dynamic_M4_RAW'], history_raw_df['dynamic_M4_RAW'], 'negative')

        m_t = (
            m1_norm * self.dynamic_params['dynamic_w_m1'] +
            m2_norm * self.dynamic_params['dynamic_w_m2'] +
            m3_norm * self.dynamic_params['dynamic_w_m3'] +
            m4_norm * self.dynamic_params['dynamic_w_m4']
        )
        
        # 8. ç¼“å­˜æœ€ç»ˆçš„ M(t) å€¼
        DailyFactorValues.objects.update_or_create(
            stock_code_id=MARKET_INDICATOR_CODE,
            trade_date=self.trade_date,
            factor_code_id='dynamic_M_VALUE',
            defaults={'raw_value': Decimal(str(m_t)), 'norm_score': Decimal(str(m_t))}
        )
        logger.info(f"M(t) è®¡ç®—å®Œæˆï¼Œå€¼ä¸º: {m_t:.4f}ï¼Œå¹¶å·²å­˜å…¥ç¼“å­˜ã€‚")
        return m_t

    def _calculate_m_indicators_for_date(self, calc_date: date) -> tuple:
        """ä¸ºç‰¹å®šä¸€å¤©è®¡ç®—M(t)çš„å››ä¸ªåŸºç¡€æŒ‡æ ‡åŸå§‹å€¼"""
        # è·å–å½“å¤©çš„é¢æ¿æ•°æ®åˆ‡ç‰‡
        close_slice = self.panel_close.loc[:calc_date]
        hfq_close_slice = self.panel_hfq_close.loc[:calc_date]
        
        if close_slice.empty: return np.nan, np.nan, np.nan, np.nan

        # M1: åˆ›60æ—¥æ–°é«˜å æ¯”
        high60 = hfq_close_slice.rolling(60, min_periods=1).max()
        is_new_high = hfq_close_slice.iloc[-1] == high60.iloc[-1]
        m1 = is_new_high.sum() / is_new_high.count() if is_new_high.count() > 0 else 0

        # M2: MA60ä¹‹ä¸Šå æ¯”
        ma60 = hfq_close_slice.rolling(60, min_periods=1).mean()
        above_ma60 = hfq_close_slice.iloc[-1] > ma60.iloc[-1]
        m2 = above_ma60.sum() / above_ma60.count() if above_ma60.count() > 0 else 0

        # M3: 60æ—¥å›æŠ¥ç‡ä¸­ä½æ•°
        if len(hfq_close_slice) >= 60:
            ret60 = hfq_close_slice.iloc[-1] / hfq_close_slice.iloc[-60] - 1
            m3 = ret60.median()
        else:
            m3 = np.nan

        # M4: 20æ—¥å¹³å‡æ³¢åŠ¨ç‡
        if len(hfq_close_slice) >= 20:
            daily_ret = hfq_close_slice.pct_change(fill_method=None)
            vol20 = daily_ret.rolling(20, min_periods=1).std()
            m4 = vol20.iloc[-1].mean()
        else:
            m4 = np.nan
            
        return m1, m2, m3, m4

    def _norm_timeseries(self, value, history_series, direction):
        """å¯¹æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–"""
        # ä½¿ç”¨TåŠä¹‹å‰çš„æ•°æ®æ¥è®¡ç®—åˆ†ä½æ•°ï¼Œä½œä¸ºTæ—¥çš„è¯„ä»·æ ‡å‡†
        # history_series æ˜¯æŒ‰æ—¶é—´å‡åºæ’åˆ—çš„
        historical_benchmark = history_series
        
        if historical_benchmark.count() < 2: return 0.0 # å¦‚æœå†å²æ•°æ®å¤ªå°‘ï¼Œä¹Ÿæ— æ³•å®šæ ‡
        p1 = historical_benchmark.quantile(0.01)
        p99 = historical_benchmark.quantile(0.99)
        
        if (p99 - p1) < 1e-9: return 0.0
        
        value_prime = np.clip(value, p1, p99)
        
        if direction == 'positive':
            return ((value_prime - p1) / (p99 - p1)) * 2 - 1
        else: # negative
            return ((p99 - value_prime) / (p99 - p1)) * 2 - 1

    def _save_m_raw_values_to_cache(self, df: pd.DataFrame):
        """å°†æ–°è®¡ç®—çš„MæŒ‡æ ‡åŸå§‹å€¼æ‰¹é‡å­˜å…¥æ•°æ®åº“"""
        records = []
        for trade_date, row in df.iterrows():
            for factor_code, raw_value in row.items():
                if pd.notna(raw_value):
                    records.append(DailyFactorValues(
                        stock_code_id=MARKET_INDICATOR_CODE,
                        trade_date=trade_date,
                        factor_code_id=factor_code,
                        raw_value=Decimal(str(raw_value)),
                        norm_score=Decimal(str(raw_value)) # åŸå§‹å€¼ç¼“å­˜ï¼Œnorm_scoreå­—æ®µå¯å¤ç”¨
                    ))
        if records:
            DailyFactorValues.objects.bulk_create(records, ignore_conflicts=True)
            logger.debug(f"æˆåŠŸå°† {len(records)} æ¡M(t)åŸºç¡€æŒ‡æ ‡åŸå§‹å€¼å­˜å…¥ç¼“å­˜ã€‚")

    def _calculate_dynamic_weights(self, M_t: float) -> dict:
        """æ ¹æ®M(t)è®¡ç®—å››ä¸ªç­–ç•¥ç»´åº¦çš„åŠ¨æ€æƒé‡"""
        logger.debug(f"æ ¹æ® M(t)={M_t:.4f} è®¡ç®—åŠ¨æ€æƒé‡...")
        p = self.dynamic_params
        
        # a. è®¡ç®—å„ç»´åº¦å¸å¼•åŠ› A_i
        A_MT = p['dynamic_c_MT'] * M_t
        A_BO = p['dynamic_c_BO'] * M_t
        A_QD = p['dynamic_c_QD'] * (-M_t)
        A_MR = p['dynamic_c_MR'] * np.exp(- (M_t / p['dynamic_sigma_MR'])**2)
        
        # b. é€šè¿‡Softmaxè®¡ç®—æœ€ç»ˆæƒé‡ N_i
        tau = p['dynamic_tau']
        exp_A_MT = np.exp(A_MT / tau)
        exp_A_BO = np.exp(A_BO / tau)
        exp_A_QD = np.exp(A_QD / tau)
        exp_A_MR = np.exp(A_MR / tau)
        
        sum_exp_A = exp_A_MT + exp_A_BO + exp_A_QD + exp_A_MR
        
        weights = {
            'MT': exp_A_MT / sum_exp_A,
            'BO': exp_A_BO / sum_exp_A,
            'QD': exp_A_QD / sum_exp_A,
            'MR': exp_A_MR / sum_exp_A,
        }
        logger.debug(f"åŠ¨æ€æƒé‡è®¡ç®—å®Œæˆ: MT={weights['MT']:.2%}, BO={weights['BO']:.2%}, MR={weights['MR']:.2%}, QD={weights['QD']:.2%}")
        return weights

    def _calculate_dimension_scores(self, norm_scores_df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—å››ä¸ªç­–ç•¥ç»´åº¦çš„å¾—åˆ†"""
        logger.debug("è®¡ç®—å„ç­–ç•¥ç»´åº¦å¾—åˆ†...")
        p = self.dynamic_params
        scores = pd.DataFrame(index=norm_scores_df.index)

        scores['Score_MT'] = (
            norm_scores_df['dynamic_MA20_SLOPE'] * p['dynamic_k_MT1'] +
            norm_scores_df['dynamic_MA_SCORE'] * p['dynamic_k_MT2'] +
            norm_scores_df['dynamic_ADX_CONFIRM'] * p['dynamic_k_MT3']
        )
        scores['Score_BO'] = (
            norm_scores_df['dynamic_BREAKOUT_PWR'] * p['dynamic_k_BO1'] +
            norm_scores_df['dynamic_VOLUME_SURGE'] * p['dynamic_k_BO2'] +
            norm_scores_df['dynamic_MOM_ACCEL'] * p['dynamic_k_BO3']
        )
        scores['Score_MR'] = (
            norm_scores_df['dynamic_RSI_OS'] * p['dynamic_k_MR1'] +
            norm_scores_df['dynamic_NEG_DEV'] * p['dynamic_k_MR2'] +
            norm_scores_df['dynamic_BOLL_LB'] * p['dynamic_k_MR3']
        )
        scores['Score_QD'] = (
            norm_scores_df['dynamic_LOW_VOL'] * p['dynamic_k_QD1'] +
            norm_scores_df['dynamic_MAX_DD'] * p['dynamic_k_QD2'] +
            norm_scores_df['dynamic_DOWNSIDE_RISK'] * p['dynamic_k_QD3']
        )
        return scores

    def _calculate_final_dynamic_score(self, dimension_scores_df: pd.DataFrame, weights: dict) -> pd.Series:
        """è®¡ç®—æœ€ç»ˆçš„ f_dynamic å¾—åˆ†"""
        logger.debug("è®¡ç®—æœ€ç»ˆç»¼åˆå¾—åˆ† f_dynamic(x, t)...")
        final_score = (
            dimension_scores_df['Score_MT'] * weights['MT'] +
            dimension_scores_df['Score_BO'] * weights['BO'] +
            dimension_scores_df['Score_MR'] * weights['MR'] +
            dimension_scores_df['Score_QD'] * weights['QD']
        )
        return final_score.sort_values(ascending=False)

    # endregion

    # region: --- 3. å› å­è®¡ç®— (æ¨¡å—åŒ–) ---

    def _calculate_all_dynamic_factors(self) -> pd.DataFrame:
        """è°ƒåº¦æ‰€æœ‰12ä¸ªå› å­è®¡ç®—æ–¹æ³•"""
        logger.debug("å¼€å§‹è®¡ç®—æ‰€æœ‰åŠ¨æ€å› å­...")
        
        factor_calculators = {
            'dynamic_MA20_SLOPE': self._calc_factor_ma20_slope,
            'dynamic_MA_SCORE': self._calc_factor_ma_score,
            'dynamic_ADX_CONFIRM': self._calc_factor_adx_confirm,
            'dynamic_BREAKOUT_PWR': self._calc_factor_breakout_pwr,
            'dynamic_VOLUME_SURGE': self._calc_factor_volume_surge,
            'dynamic_MOM_ACCEL': self._calc_factor_mom_accel,
            'dynamic_RSI_OS': self._calc_factor_rsi_os,
            'dynamic_NEG_DEV': self._calc_factor_neg_dev,
            'dynamic_BOLL_LB': self._calc_factor_boll_lb,
            'dynamic_LOW_VOL': self._calc_factor_low_vol,
            'dynamic_MAX_DD': self._calc_factor_max_dd,
            'dynamic_DOWNSIDE_RISK': self._calc_factor_downside_risk,
        }
        
        all_factors = {}
        for code, func in factor_calculators.items():
            if code in self.dynamic_factor_defs:
                logger.debug(f"  - è®¡ç®—å› å­: {code}")
                all_factors[code] = func()
        
        raw_factors_df = pd.DataFrame(all_factors)
        original_count = len(raw_factors_df)

        inf_count = np.isinf(raw_factors_df).sum().sum()
        if inf_count > 0:
            logger.debug(f"å‘ç° {inf_count} ä¸ªæ— ç©·å¤§(inf)å€¼ï¼Œå°†æ›¿æ¢ä¸ºNaNè¿›è¡Œå‰”é™¤ã€‚")
            raw_factors_df.replace([np.inf, -np.inf], np.nan, inplace=True)
        # --- æ ¸å¿ƒè°ƒè¯•ä»£ç  ---
        if original_count > 0:
            logger.debug("--- NaN å€¼åˆ†æå¼€å§‹ ---")
            nan_counts = raw_factors_df.isna().sum()
            logger.debug(f"å› å­è®¡ç®—åï¼Œå„å› å­çš„ NaN å€¼æ•°é‡ (æ€»è®¡ {original_count} åªè‚¡ç¥¨):")
            logger.debug("\n" + nan_counts.to_string())
            
            # æ‰¾å‡ºNaNæ•°é‡æœ€å¤šçš„å› å­
            problematic_factors = nan_counts[nan_counts > 0].sort_values(ascending=False)
            if not problematic_factors.empty:
                logger.debug(f"é—®é¢˜å¯èƒ½å‡ºåœ¨ä»¥ä¸‹å› å­ä¸­ï¼Œå®ƒä»¬çš„NaNæ•°é‡è¾ƒå¤š: \n{problematic_factors}")
            else:
                logger.debug("å¤ªæ£’äº†ï¼æ²¡æœ‰ä»»ä½•å› å­äº§ç”ŸNaNã€‚")
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŸä¸€è¡Œå…¨æ˜¯NaN
            all_nan_rows = raw_factors_df.isna().all(axis=1).sum()
            if all_nan_rows > 0:
                logger.debug(f"è­¦å‘Šï¼šæœ‰ {all_nan_rows} åªè‚¡ç¥¨çš„æ‰€æœ‰å› å­å€¼éƒ½ä¸º NaNï¼")
            logger.debug("--- NaN å€¼åˆ†æç»“æŸ ---")
        raw_factors_df.dropna(inplace=True)
        final_count = len(raw_factors_df)
        logger.debug(f"å› å­è®¡ç®—å®Œæˆã€‚å› æ•°æ®ä¸è¶³(NaN)å‰”é™¤äº† {original_count - final_count} åªè‚¡ç¥¨ã€‚å‰©ä½™ {final_count} åªã€‚")
        
        return raw_factors_df

    # --- MT å› å­ ---
    def _calc_factor_ma20_slope(self) -> pd.Series:
        """
        è®¡ç®—20æ—¥å‡çº¿çš„20æ—¥çº¿æ€§å›å½’æ–œç‡ã€‚
        ä½¿ç”¨numpy.linalg.lstsqè¿›è¡Œå‘é‡åŒ–è®¡ç®—ï¼Œé¿å…äº†ä½æ•ˆçš„rolling.apply()ã€‚
        """
        ma20 = self.panel_hfq_close.rolling(20).mean()
        
        # æˆ‘ä»¬åªéœ€è¦æœ€å20ä¸ªMA20å€¼æ¥è®¡ç®—å½“å‰æ–œç‡
        last_20_ma20 = ma20.tail(20)
        
        # å¦‚æœæ•°æ®ä¸è¶³20å¤©ï¼Œåˆ™æ— æ³•è®¡ç®—
        if len(last_20_ma20) < 20:
            # è¿”å›ä¸€ä¸ªå…¨ä¸ºNaNçš„Seriesï¼Œä¿æŒä¸åŸè¾“å‡ºç»“æ„ä¸€è‡´
            return pd.Series(np.nan, index=self.panel_hfq_close.columns)
        # å‡†å¤‡æœ€å°äºŒä¹˜æ³•æ±‚è§£
        # xæ˜¯æ—¶é—´è‡ªå˜é‡ [0, 1, 2, ..., 19]
        x = np.arange(20)
        # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¸¸æ•°é¡¹ï¼Œæ‰€ä»¥æ„å»ºä¸€ä¸ª (20, 2) çš„çŸ©é˜µA
        A = np.vstack([x, np.ones(20)]).T
        
        # yæ˜¯å› å˜é‡ï¼Œå³æ¯ä¸ªè‚¡ç¥¨çš„æœ€å20ä¸ªMA20å€¼
        y = last_20_ma20.values
        
        # np.linalg.lstsq ä¼šä¸ºyçš„æ¯ä¸€åˆ—ï¼ˆæ¯ä¸ªè‚¡ç¥¨ï¼‰è§£å‡º Ax = y ä¸­çš„ x
        # è¿”å›ç»“æœçš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯è§£çš„çŸ©é˜µï¼Œå…¶ä¸­ç¬¬ä¸€è¡Œæ˜¯æ–œç‡(m)ï¼Œç¬¬äºŒè¡Œæ˜¯æˆªè·(c)
        slopes, _ = np.linalg.lstsq(A, y, rcond=None)[0]
        
        # å°†ç»“æœè½¬æ¢å›pandas Series
        return pd.Series(slopes, index=last_20_ma20.columns)

    def _calc_factor_ma_score(self) -> pd.Series:
        close, ma5, ma10, ma20 = (
            self.panel_hfq_close.iloc[-1],
            self.panel_hfq_close.rolling(5).mean().iloc[-1],
            self.panel_hfq_close.rolling(10).mean().iloc[-1],
            self.panel_hfq_close.rolling(20).mean().iloc[-1]
        )
        return (close > ma5).astype(int) + (ma5 > ma10).astype(int) + (ma10 > ma20).astype(int)

    def _calc_factor_adx_confirm(self) -> pd.Series:
        adx_df = self.panel_hfq_close.apply(lambda s: ta.adx(self.panel_high[s.name], self.panel_low[s.name], s, length=14).iloc[-1])
        adx_df = adx_df.T
        condition = (adx_df['ADX_14'] > 20) & (adx_df['DMP_14'] > adx_df['DMN_14'])
        return adx_df['ADX_14'].where(condition, 0)
        

    # --- BO å› å­ ---
    def _calc_factor_breakout_pwr(self) -> pd.Series:
        close = self.panel_hfq_close
        atr14 = self.panel_hfq_close.apply(lambda s: ta.atr(self.panel_high[s.name], self.panel_low[s.name], s, length=14).iloc[-1])
        breakout_level = close.iloc[-60:-1].max()
        return (close.iloc[-1] - breakout_level) / (atr14+ 1e-9)
        

    def _calc_factor_volume_surge(self) -> pd.Series:
        vol = self.panel_volume
        return vol.iloc[-1] / (vol.iloc[-20:-1].mean()+ 1e-9)

    def _calc_factor_mom_accel(self) -> pd.Series:
        """è®¡ç®—åŠ¨èƒ½åŠ é€Ÿåº¦ï¼š(ä»Šæ—¥ROC5 / 11æ—¥å‰ROC5) - 1"""
        # 1. è®¡ç®—æ•´ä¸ªé¢æ¿çš„5æ—¥å˜åŒ–ç‡ (åŠ¨èƒ½)
        roc5 = self.panel_hfq_close.pct_change(5, fill_method=None)
        # 2. ä½¿ç”¨ shift() è·å–11ä¸ªå‘¨æœŸå‰çš„åŠ¨èƒ½å€¼ã€‚è¿™æ‰æ˜¯æ­£ç¡®çš„å‘é‡åŒ–æ“ä½œã€‚
        # shift() ä¼šåœ¨æ¯ä¸ªè‚¡ç¥¨ä»£ç ï¼ˆåˆ—ï¼‰å†…éƒ¨ç‹¬ç«‹è¿›è¡Œæ•°æ®ä¸‹ç§»ã€‚
        roc5_shifted = roc5.shift(11)
        # 3. è®¡ç®—åŠ¨èƒ½åŠ é€Ÿåº¦
        # è¿™ä¸ªè®¡ç®—ç°åœ¨æ˜¯æ­£ç¡®çš„å…ƒç´ å¯¹å…ƒç´ æ“ä½œï¼šæ¯ä¸ªæ ¼å­çš„å€¼é™¤ä»¥å®ƒä¸Šé¢11ä¸ªæ ¼å­çš„å€¼
        acceleration = roc5 / (roc5_shifted + 1e-9) - 1
        # 4. å¦‚æœæ•°æ®é•¿åº¦ä¸è¶³ï¼Œaccelerationçš„å¼€å¤´å‡ è¡Œä¼šæ˜¯NaNï¼Œä½†æœ€åä¸€è¡Œåº”è¯¥æ˜¯æœ‰æ•ˆçš„ã€‚
        # æˆ‘ä»¬è¿”å›æœ€åä¸€è¡Œçš„Serieså³å¯ã€‚
        if acceleration.empty:
            return pd.Series(np.nan, index=self.panel_hfq_close.columns)
        
        return acceleration.iloc[-1]

    # --- MR å› å­ ---
    def _calc_factor_rsi_os(self) -> pd.Series:
        return self.panel_hfq_close.apply(lambda s: ta.rsi(s, length=14).iloc[-1])

    def _calc_factor_neg_dev(self) -> pd.Series:
        ma60 = self.panel_hfq_close.rolling(60).mean().iloc[-1]
        return (self.panel_hfq_close.iloc[-1] - ma60) / (ma60+ 1e-9)

    def _calc_factor_boll_lb(self) -> pd.Series:
        boll_df = self.panel_hfq_close.apply(lambda s: ta.bbands(s, length=20).iloc[-1])
        boll_df = boll_df.T
        return (self.panel_hfq_close.iloc[-1] - boll_df['BBL_20_2.0']) / (boll_df['BBU_20_2.0'] - boll_df['BBL_20_2.0']+ 1e-9)
        
        

    # --- QD å› å­ ---
    def _calc_factor_low_vol(self) -> pd.Series:
        return self.panel_hfq_close.pct_change(fill_method=None).rolling(20, min_periods=2).std().iloc[-1]

    def _calc_factor_max_dd(self) -> pd.Series:
        roll_max = self.panel_hfq_close.rolling(60, min_periods=1).max()
        daily_dd = self.panel_hfq_close / roll_max - 1.0
        return daily_dd.rolling(60, min_periods=1).min().iloc[-1]

    def _calc_factor_downside_risk(self) -> pd.Series:
        returns = self.panel_hfq_close.pct_change(fill_method=None)
        downside_returns = returns.copy()
        downside_returns[downside_returns > 0] = 0
        # æ·»åŠ  min_periods=2
        downside_risk = downside_returns.rolling(60, min_periods=2).std() 
        return downside_risk.iloc[-1]

    # endregion
    
    # region: --- 4. è¾…åŠ©æ–¹æ³• (åŸºæœ¬ä¸æ—§ç‰ˆå…¼å®¹) ---

    def _log_to_db(self, level, message):
        return
        #SystemLog.objects.create(log_level=level, module_name=MODULE_NAME, message=message)

    def _load_dynamic_parameters_and_defs(self):
        logger.debug("åŠ è½½åŠ¨æ€ç­–ç•¥å‚æ•°å’Œå› å­å®šä¹‰...")
        params_qs = StrategyParameters.objects.filter(param_name__startswith='dynamic_')
        self.dynamic_params = {p.param_name: float(p.param_value) for p in params_qs}
        
        defs_qs = FactorDefinitions.objects.filter(is_active=True, factor_code__startswith='dynamic_')
        self.dynamic_factor_defs = {f.factor_code: {'direction': f.direction} for f in defs_qs}
        logger.debug(f"åŠ è½½äº† {len(self.dynamic_params)} ä¸ªåŠ¨æ€å‚æ•°å’Œ {len(self.dynamic_factor_defs)} ä¸ªå¯ç”¨çš„åŠ¨æ€å› å­å®šä¹‰ã€‚")

    def _get_market_trade_dates(self, lookback_period: int) -> list[date]:
        trade_dates = list(
            DailyQuotes.objects
            .filter(trade_date__lte=self.trade_date)
            .values_list('trade_date', flat=True)
            .distinct()
            .order_by('-trade_date')[:lookback_period]
        )
        trade_dates.reverse()
        return trade_dates

    def _initial_screening(self) -> list[str]:
        logger.debug("å¼€å§‹æ‰§è¡Œåˆæ­¥ç­›é€‰...")
        all_stocks = StockInfo.objects.filter(status=StockInfo.StatusChoices.LISTING)
        #è¿‡æ»¤ç§‘åˆ›ç‰ˆã€STã€*ST
        non_st_stocks = all_stocks.exclude(stock_code__contains='.688').exclude(stock_name__startswith='ST').exclude(stock_name__startswith='*ST')
        
        min_listing_date = self.trade_date - timedelta(days=int(self.dynamic_params['dynamic_lookback_new_stock']))
        
        non_new_stocks = non_st_stocks.filter(listing_date__lt=min_listing_date)
        
        stock_pool_codes = list(non_new_stocks.values_list('stock_code', flat=True))
        logger.debug(f"å‰”é™¤ç§‘åˆ›ç‰ˆå’ŒSTå’Œæ¬¡æ–°è‚¡åï¼Œå‰©ä½™ {len(stock_pool_codes)} åªè‚¡ç¥¨ã€‚")

        lookback_days = 20
        start_date = self.trade_date - timedelta(days=lookback_days * 2)
        
        quotes = DailyQuotes.objects.filter(
            stock_code_id__in=stock_pool_codes,
            trade_date__lte=self.trade_date,
            trade_date__gte=start_date
        ).values('stock_code_id', 'trade_date', 'turnover')

        if not quotes:
            logger.warning("åœ¨æµåŠ¨æ€§ç­›é€‰æœŸé—´æœªæ‰¾åˆ°ä»»ä½•è¡Œæƒ…æ•°æ®ã€‚")
            return []

        quotes_df = pd.DataFrame.from_records(quotes)
        recent_trade_dates = sorted(quotes_df['trade_date'].unique())[-lookback_days:]
        quotes_df = quotes_df[quotes_df['trade_date'].isin(recent_trade_dates)]

        avg_turnover = quotes_df.groupby('stock_code_id')['turnover'].mean()
        liquid_stocks = avg_turnover[avg_turnover >= self.dynamic_params['dynamic_min_liquidity']]
        
        final_stock_pool = list(liquid_stocks.index)
        final_stock_pool=stock_pool_codes
        logger.debug(f"å‰”é™¤ä½æµåŠ¨æ€§è‚¡åï¼Œæœ€ç»ˆå‰©ä½™ {len(final_stock_pool)} åªè‚¡ç¥¨è¿›å…¥ç²¾é€‰æ± ã€‚")
        
        return final_stock_pool

    def _load_market_data(self, stock_pool: list[str], for_m_calc: bool = False):
        max_lookback=1000
        if for_m_calc:
            # M(t)æœ¬èº«è¦çœ‹750å¤©å†å²ï¼Œå…¶è®¡ç®—åˆéœ€è¦60å¤©çª—å£ï¼Œæ‰€ä»¥æ€»å…±éœ€è¦çº¦810å¤©
            # ä»æ•°æ®åº“åŠ¨æ€è·å–å‚æ•°ï¼Œé¿å…ç¡¬ç¼–ç 
            m_lookback_param = int(self.dynamic_params.get('dynamic_m_lookback', 750))
            # é¢å¤–å¢åŠ 90å¤©ä½œä¸ºè®¡ç®—Buffer (è¦†ç›–60ä¸ªäº¤æ˜“æ—¥)
            max_lookback = m_lookback_param + 90 
        else:
            # ä¸ªè‚¡å› å­æœ€é•¿å›æº¯60å¤©ï¼Œç»™è¶³bufferåˆ°250å¤©æ˜¯åˆç†çš„
            max_lookback = 250
        logger.debug(f"ç¡®å®šæœ€å¤§æ•°æ®å›æº¯æœŸä¸º {max_lookback} ä¸ªäº¤æ˜“æ—¥ã€‚")

        trade_dates = self._get_market_trade_dates(max_lookback)
        if not trade_dates: raise ValueError("æ— æ³•è·å–å¸‚åœºäº¤æ˜“æ—¥å†ã€‚")
        
        logger.debug(f"æ­£åœ¨åŠ è½½ {len(stock_pool)} åªè‚¡ç¥¨åœ¨ {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥å†…çš„è¡Œæƒ…æ•°æ®...")
        
        quotes_qs = DailyQuotes.objects.filter(
            stock_code_id__in=stock_pool,
            trade_date__in=trade_dates
        ).values('trade_date', 'stock_code_id', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close')
        
        if not quotes_qs: raise ValueError("åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•è‚¡ç¥¨çš„è¡Œæƒ…æ•°æ®ã€‚")

        df = pd.DataFrame.from_records(quotes_qs)
        df['trade_date'] = pd.to_datetime(df['trade_date'])
        
        logger.debug("æ­£åœ¨æ„å»ºé¢æ¿æ•°æ®(Panel Data)...")
        for col in ['open', 'high', 'low', 'close', 'volume', 'turnover', 'hfq_close']:
            panel = df.pivot(index='trade_date', columns='stock_code_id', values=col).astype(float)
            setattr(self, f'panel_{col}', panel)
        logger.debug("é¢æ¿æ•°æ®æ„å»ºå®Œæˆã€‚")

    def _standardize_factors(self, raw_factors_df: pd.DataFrame) -> pd.DataFrame:
        logger.debug("å¼€å§‹å¯¹å› å­å€¼è¿›è¡Œæ ‡å‡†åŒ–...")
        norm_scores_df = pd.DataFrame(index=raw_factors_df.index)
        
        for factor_code, series in raw_factors_df.items():
            direction = self.dynamic_factor_defs[factor_code]['direction']
            p1, p99 = series.quantile(0.01), series.quantile(0.99)
            
            if (p99 - p1) < 1e-9:
                norm_scores_df[factor_code] = 0
                continue
            
            x_prime = series.clip(p1, p99)
            
            if direction == 'positive':
                score = ((x_prime - p1) / (p99 - p1)) * 200 - 100
            else:
                score = ((p99 - x_prime) / (p99 - p1)) * 200 - 100
            
            norm_scores_df[factor_code] = score
            
        logger.debug("å› å­æ ‡å‡†åŒ–å®Œæˆã€‚")
        return norm_scores_df

    def _generate_trading_plan(self, final_scores: pd.Series, dimension_scores: pd.DataFrame) -> pd.DataFrame:
        """
        [V2.1 - Patched] ä¸ºTop Nè‚¡ç¥¨ç”ŸæˆåŠ¨æ€çš„ã€åŸºäºç­–ç•¥DNAçš„äº¤æ˜“é¢„æ¡ˆã€‚
        - ä¿®å¤äº†ATRè®¡ç®—ä¸­æ··åˆä½¿ç”¨å¤æƒä¸ä¸å¤æƒä»·æ ¼çš„ä¸¥é‡BUGã€‚
        - ä¼˜åŒ–äº†ä»£ç å¯è¯»æ€§ã€‚
        """
        logger.debug("å¼€å§‹ç”ŸæˆåŠ¨æ€äº¤æ˜“é¢„æ¡ˆ (V2.1 - Patched)...")
        top_n = int(self.dynamic_params.get('dynamic_top_n', 10))
        top_stocks_scores = final_scores.head(top_n)
        
        if top_stocks_scores.empty:
            return pd.DataFrame()
 
        top_stock_codes = top_stocks_scores.index.tolist()
        
        # æå–Top Nè‚¡ç¥¨çš„ç»´åº¦å¾—åˆ†
        top_dimension_scores = dimension_scores.reindex(top_stock_codes)
 
        # === æ ¸å¿ƒä¿®æ­£ç‚¹åœ¨è¿™é‡Œ ===
        # ä½¿ç”¨ä¸å¤æƒçš„ self.panel_close ä½œä¸º apply çš„ä¸»ä½“ï¼Œç¡®ä¿ lambda ä¸­çš„ 's' æ˜¯ä¸å¤æƒæ”¶ç›˜ä»·åºåˆ—
        logger.debug("æ­£åœ¨åŸºäºä¸å¤æƒä»·æ ¼è®¡ç®—ATR...")
        atr14 = self.panel_close.apply(
            lambda s: ta.atr(
                high=self.panel_high[s.name].astype(float), 
                low=self.panel_low[s.name].astype(float), 
                close=s.astype(float),  # è¿™é‡Œçš„ 's' ç°åœ¨æ˜¯æ­£ç¡®çš„ä¸å¤æƒæ”¶ç›˜ä»·åºåˆ—
                length=14
            ).iloc[-1]
        )
        # === ä¿®æ­£ç»“æŸ ===
 
        # å‡†å¤‡åç»­è®¡ç®—æ‰€éœ€çš„æ•°æ®
        last_close_series = self.panel_close.iloc[-1].reindex(top_stock_codes)
        last_atr_series = atr14.reindex(top_stock_codes)
        p = self.dynamic_params
        
        plans = []
        for stock_code in top_stock_codes:
            # --- æ ¸å¿ƒåŠ¨æ€é€»è¾‘å¼€å§‹ (è¿™éƒ¨åˆ†é€»è¾‘æ˜¯æ­£ç¡®çš„ï¼Œæ— éœ€ä¿®æ”¹) ---
            
            # æ­¥éª¤1: è®¡ç®—å„ç»´åº¦çš„è´¡çŒ®å€¼ (DCV)
            # ... (æ­¤éƒ¨åˆ†é€»è¾‘ä¿æŒä¸å˜)
            dcv = {
                'MT': self.dynamic_weights['MT'] * top_dimension_scores.loc[stock_code, 'Score_MT'],
                'BO': self.dynamic_weights['BO'] * top_dimension_scores.loc[stock_code, 'Score_BO'],
                'MR': self.dynamic_weights['MR'] * top_dimension_scores.loc[stock_code, 'Score_MR'],
                'QD': self.dynamic_weights['QD'] * top_dimension_scores.loc[stock_code, 'Score_QD'],
            }
            
            # æ­¥éª¤2: æå–æ­£å‘è´¡çŒ®å€¼ (PDCV) å¹¶è®¡ç®—ç­–ç•¥DNAæƒé‡ (SSW)
            # ... (æ­¤éƒ¨åˆ†é€»è¾‘ä¿æŒä¸å˜)
            pdcv = {k: max(0, v) for k, v in dcv.items()}
            total_pdcv = sum(pdcv.values())
            
            if total_pdcv <= 1e-9:
                logger.warning(f"è‚¡ç¥¨ {stock_code} ä¿¡å·æ··ä¹± (Total_PDCV <= 0)ï¼Œé‡‡ç”¨ä¿å®ˆçš„QDç­–ç•¥ä½œä¸ºå…¶å¼€ç›˜åŒºé—´ã€‚")
                ssw = {'MT': 0, 'BO': 0, 'MR': 0, 'QD': 1.0}
            else:
                ssw = {k: v / total_pdcv for k, v in pdcv.items()}
 
            # æ­¥éª¤3: åŠ æƒåˆæˆåŠ¨æ€kå€¼
            # ... (æ­¤éƒ¨åˆ†é€»è¾‘ä¿æŒä¸å˜)
            k_gap_dynamic = (
                ssw['MT'] * p['dynamic_miopmaop_k_gap_base_mt'] +
                ssw['BO'] * p['dynamic_miopmaop_k_gap_base_bo'] +
                ssw['MR'] * p['dynamic_miopmaop_k_gap_base_mr'] +
                ssw['QD'] * p['dynamic_miopmaop_k_gap_base_qd']
            )
            k_drop_dynamic = (
                ssw['MT'] * p['dynamic_miopmaop_k_drop_base_mt'] +
                ssw['BO'] * p['dynamic_miopmaop_k_drop_base_bo'] +
                ssw['MR'] * p['dynamic_miopmaop_k_drop_base_mr'] +
                ssw['QD'] * p['dynamic_miopmaop_k_drop_base_qd']
            )
            # --- æ ¸å¿ƒåŠ¨æ€é€»è¾‘ç»“æŸ ---
 
            # è·å–è¯¥è‚¡ç¥¨çš„ä¸å¤æƒæ”¶ç›˜ä»·å’Œæ­£ç¡®çš„ATRå€¼
            close = last_close_series.get(stock_code)
            atr = last_atr_series.get(stock_code)
 
            if pd.isna(close) or pd.isna(atr) or close <= 0:
                logger.warning(f"è‚¡ç¥¨ {stock_code} çš„æ”¶ç›˜ä»·æˆ–ATRæ— æ•ˆ(å¯èƒ½æ•°æ®ä¸è¶³)ï¼Œæ— æ³•ç”Ÿæˆé¢„æ¡ˆã€‚")
                continue
 
            # ä½¿ç”¨ç®€åŒ–çš„å…¬å¼ï¼Œæ›´æ¸…æ™°ä¸”èƒ½é¿å…æµ®ç‚¹ç²¾åº¦é—®é¢˜
            miop = close - k_drop_dynamic * atr
            maop = close + k_gap_dynamic * atr
 
            plans.append({
                'stock_code': stock_code,
                'rank': len(plans) + 1,
                'final_score': top_stocks_scores.get(stock_code),
                'miop': miop,
                'maop': maop
            })
            
            # æ›´æ–°æ—¥å¿—ï¼Œç°åœ¨ATRå€¼ä¼šæ˜¯æ­£å¸¸çš„
            logger.debug(f"é¢„æ¡ˆ: {stock_code}, Rank: {len(plans)}, ATR:{atr:.2f}, "
                        f"SSW(MT/BO/MR/QD):({ssw['MT']:.2f}/{ssw['BO']:.2f}/{ssw['MR']:.2f}/{ssw['QD']:.2f}), "
                        f"k_gap_dyn:{k_gap_dynamic:.2f}, k_drop_dyn:{k_drop_dynamic:.2f}, MIOP:{miop:.2f}, MAOP:{maop:.2f}")
 
        if not plans:
            return pd.DataFrame()
 
        plan_df = pd.DataFrame(plans).dropna(subset=['miop', 'maop'])
        logger.debug("åŠ¨æ€äº¤æ˜“é¢„æ¡ˆç”Ÿæˆå®Œæˆã€‚")
        return plan_df

    @transaction.atomic
    def _save_results(self, raw_factors_df, norm_scores_df, trading_plan_df):
        logger.debug("å¼€å§‹å°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“...")
        
        # 1. ä¿å­˜æ¯æ—¥å› å­å€¼
        factor_values_to_create = []
        for stock_code, row in raw_factors_df.iterrows():
            for factor_code, raw_value in row.items():
                norm_score = norm_scores_df.loc[stock_code, factor_code]
                factor_values_to_create.append(
                    DailyFactorValues(
                        stock_code_id=stock_code, trade_date=self.trade_date,
                        factor_code_id=factor_code, raw_value=Decimal(str(raw_value)),
                        norm_score=Decimal(str(norm_score))
                    )
                )
        DailyFactorValues.objects.bulk_create(factor_values_to_create, ignore_conflicts=True)

        # 2. ä¿å­˜æ¯æ—¥äº¤æ˜“é¢„æ¡ˆ
        plan_date = self.trade_date + timedelta(days=1)
        DailyTradingPlan.objects.filter(plan_date=plan_date).delete()
        
        plans_to_create = []
        for _, row in trading_plan_df.iterrows():
            plans_to_create.append(
                DailyTradingPlan(
                    plan_date=plan_date, stock_code_id=row['stock_code'],
                    rank=row['rank'], final_score=Decimal(str(row['final_score'])),
                    miop=Decimal(str(row['miop'])).quantize(Decimal('0.01')),
                    maop=Decimal(str(row['maop'])).quantize(Decimal('0.01')),
                    status=DailyTradingPlan.StatusChoices.PENDING
                )
            )
        DailyTradingPlan.objects.bulk_create(plans_to_create)
        
        log_message = f"T-1æ—¥({self.trade_date})åŠ¨æ€é€‰è‚¡å®Œæˆ, Tæ—¥({plan_date})é¢„æ¡ˆå¦‚ä¸‹:\n"
        log_message += trading_plan_df.to_string(index=False)
        self._log_to_db('INFO', log_message)
        logger.debug("æ‰€æœ‰ç»“æœå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“ã€‚")

    # endregion

####æ–‡ä»¶ç»“æŸ####

####trade_manager\__init__.py####

####æ–‡ä»¶ç»“æŸ####

####trade_manager\admin.py####
from django.contrib import admin

# Register your models here.

####æ–‡ä»¶ç»“æŸ####

####trade_manager\apps.py####
# trade_manager/apps.py

import os
import sys
from django.apps import AppConfig
import logging

logger = logging.getLogger(__name__)

class TradeManagerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'trade_manager'

    def ready(self):
        # # å…³é”®ä¿®æ­£ï¼šé€šè¿‡æ£€æŸ¥ç¯å¢ƒå˜é‡ RUN_MAIN æ¥é˜²æ­¢è°ƒåº¦å™¨åœ¨é‡è½½ä¸»è¿›ç¨‹ä¸­å¯åŠ¨ä¸¤æ¬¡
        # # è¿™ä¸ªç¯å¢ƒå˜é‡æ˜¯ Django çš„ autoreloader åœ¨å¯åŠ¨å­è¿›ç¨‹æ—¶è®¾ç½®çš„ã€‚
        # # æˆ‘ä»¬åªæƒ³åœ¨è¿è¡Œå®é™…åº”ç”¨çš„å­è¿›ç¨‹ä¸­å¯åŠ¨è°ƒåº¦å™¨ã€‚
        # if os.environ.get('RUN_MAIN'):
        #     logger.info("æ£€æµ‹åˆ° Django åº”ç”¨å·¥ä½œè¿›ç¨‹ï¼Œå‡†å¤‡åˆå§‹åŒ–è°ƒåº¦å™¨...")
        #     from .service import scheduler_service
        #     # ç¡®ä¿è°ƒåº¦å™¨åªå¯åŠ¨ä¸€æ¬¡
        #     if not scheduler_service.scheduler.running:
        #          scheduler_service.start()
        #     else:
        #          logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œï¼Œè·³è¿‡é‡å¤å¯åŠ¨ã€‚")
        # else:
        #     logger.info("æ£€æµ‹åˆ° Django ç®¡ç†æˆ–é‡è½½ä¸»è¿›ç¨‹ï¼Œè·³è¿‡è°ƒåº¦å™¨åˆå§‹åŒ–ã€‚")
        return


####æ–‡ä»¶ç»“æŸ####

####trade_manager\models.py####
from django.db import models

# Create your models here.

####æ–‡ä»¶ç»“æŸ####

####trade_manager\tests.py####
from django.test import TestCase

# Create your tests here.

####æ–‡ä»¶ç»“æŸ####

####trade_manager\urls.py####
"""
URL configuration for autoTrade project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path,include
from . import views
urlpatterns = [
    path('beforeFixRun', views.before_fix_run),
    path('initParam',views.initialize_strategy_parameters),
    path('simulateTrade', views.simulate_trade)
]

####æ–‡ä»¶ç»“æŸ####

####trade_manager\views.py####
from datetime import date,datetime
from django.shortcuts import render
from django.http.response import JsonResponse
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.simulate_trade import SimulateTradeService
import json
from django.views.decorators.http import require_http_methods
# Create your views here.
@require_http_methods(["POST"])
def before_fix_run(request):
    if request.method=='POST':
        body= json.loads(request.body)
        selection_date=datetime.strptime(body['date'], "%Y-%m-%d").date()
        service=BeforeFixService(selection_date)
        service.run()
        return JsonResponse({
            'result':'æˆåŠŸ'
        })
@require_http_methods(["GET"])
def initialize_strategy_parameters(request):
    if request.method=='GET':
        DecisionOrderService.initialize_strategy_parameters()
        return JsonResponse({
            'result':'æˆåŠŸ'
        })

@require_http_methods(["POST"])
def simulate_trade(request):
    if request.method=='POST':
        body= json.loads(request.body)
        start_date=body['startDate']
        end_date=body['endDate']
        service=SimulateTradeService()
        result=service.run_backtest(start_date=start_date,end_date=end_date)
        return JsonResponse(result)
####æ–‡ä»¶ç»“æŸ####

####trade_manager\management\commands\run_backtest.py####
# ==============================================================================
# æ–‡ä»¶ 2/5: trade_manager/management/commands/run_backtest.py (æ–°å¢)
# æè¿°: ç”¨äºä»å‘½ä»¤è¡Œå¯åŠ¨å›æµ‹çš„ Command æ–‡ä»¶ã€‚
# ==============================================================================
from django.core.management.base import BaseCommand, CommandParser
from trade_manager.service.simulate_trade import SimulateTradeService
from decimal import Decimal

class Command(BaseCommand):
    help = 'è¿è¡Œä¸€ä¸ªå®Œæ•´çš„äº¤æ˜“ç­–ç•¥å›æµ‹'

    def add_arguments(self, parser: CommandParser):
        parser.add_argument(
            '--start',
            type=str,
            required=True,
            help='å›æµ‹èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)'
        )
        parser.add_argument(
            '--end',
            type=str,
            required=True,
            help='å›æµ‹ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)'
        )
        parser.add_argument(
            '--capital',
            type=Decimal,
            required=True,
            help='åˆå§‹èµ„é‡‘'
        )

    def handle(self, *args, **options):
        start_date = options['start']
        end_date = options['end']
        initial_capital = options['capital']

        self.stdout.write(self.style.SUCCESS(f'===== å¼€å§‹æ‰§è¡Œå›æµ‹ä»»åŠ¡ ====='))
        self.stdout.write(f'  - èµ·å§‹æ—¥æœŸ: {start_date}')
        self.stdout.write(f'  - ç»“æŸæ—¥æœŸ: {end_date}')
        self.stdout.write(f'  - åˆå§‹èµ„é‡‘: {initial_capital:.2f}')

        try:
            service = SimulateTradeService()
            # æ³¨æ„ï¼šæˆ‘ä»¬å°†æ‰€æœ‰å‚æ•°éƒ½ä¼ é€’ç»™ run_backtest æ–¹æ³•
            result = service.run_backtest(
                start_date=start_date,
                end_date=end_date,
                initial_capital=initial_capital
            )
            
            self.stdout.write(self.style.SUCCESS('\n===== å›æµ‹æ‰§è¡Œå®Œæ¯• ====='))
            self.stdout.write(f'æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡: {result}')

        except Exception as e:
            self.stdout.write(self.style.ERROR(f'å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}'))
            # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¯èƒ½éœ€è¦æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
            raise e


####æ–‡ä»¶ç»“æŸ####

####trade_manager\management\commands\run_scheduler.py####
# trade_manager/management/commands/run_scheduler.py

from django.core.management.base import BaseCommand
from trade_manager.service import scheduler_service
import logging
import time
logger = logging.getLogger(__name__)
class Command(BaseCommand):
    help = 'å¯åŠ¨è‡ªåŠ¨åŒ–äº¤æ˜“çš„ APScheduler è°ƒåº¦å™¨'

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS('æ­£åœ¨å¯åŠ¨è°ƒåº¦å™¨æœåŠ¡...'))
        scheduler_service.start()
        try:
            # è¿™æ˜¯å…³é”®ï¼šè®©ä¸»è¿›ç¨‹è¿›å…¥ä¸€ä¸ªæ— é™å¾ªç¯ï¼Œä»¥é˜²æ­¢è„šæœ¬é€€å‡º
            # è¿™æ ·åå°çš„è°ƒåº¦å™¨çº¿ç¨‹æ‰èƒ½ä¸€ç›´å­˜æ´»
            while True:
                time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œé™ä½CPUå ç”¨
        except (KeyboardInterrupt, SystemExit):
            # å½“æ¥æ”¶åˆ°é€€å‡ºä¿¡å·æ—¶ï¼ˆå¦‚Ctrl+Cæˆ–uWSGIçš„åœæ­¢å‘½ä»¤ï¼‰
            # ä¼˜é›…åœ°å…³é—­è°ƒåº¦å™¨
            logger.info("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å…³é—­è°ƒåº¦å™¨...")
            scheduler_service.scheduler.shutdown()
            logger.info("è°ƒåº¦å™¨å·²æˆåŠŸå…³é—­ã€‚")
            self.stdout.write(self.style.SUCCESS('è°ƒåº¦å™¨æœåŠ¡å·²ä¼˜é›…åœ°åœæ­¢ã€‚'))
        self.stdout.write(self.style.SUCCESS('è°ƒåº¦å™¨æœåŠ¡å·²åœæ­¢ã€‚'))


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\backtest_reporter.py####
# ==============================================================================
# æ–‡ä»¶ 3/5: trade_manager/service/backtest_reporter.py (æ–°å¢)
# æè¿°: è´Ÿè´£ç”Ÿæˆå’Œå‘é€å›æµ‹é‚®ä»¶æŠ¥å‘Šçš„æ¨¡å—ã€‚
# ==============================================================================
import base64
import io
import logging
from datetime import date
from decimal import Decimal
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

import pandas as pd
from django.db import connections

from common.models.backtest_logs import BacktestDailyLog, BacktestOperationLog
from common.models.positions import Position
from data_manager.service.email_handler import EmailHandler

logger = logging.getLogger(__name__)

class BacktestReporter:
    """
    å›æµ‹æŠ¥å‘Šç”Ÿæˆä¸å‘é€å™¨ã€‚
    """
    def __init__(self, schema_name: str, start_date: date, current_date: date, initial_capital: Decimal):
        self.schema_name = schema_name
        self.start_date = start_date
        self.current_date = current_date
        self.initial_capital = initial_capital
        self.email_handler = EmailHandler()
        self.recipients = ['876858298@qq.com']#'850696281@qq.com','285173686@qq.com'
    def _execute_query(self, query: str, params: list = None) -> list[dict]:
        """åœ¨æŒ‡å®š schema ä¸­æ‰§è¡ŒåŸç”Ÿ SQL æŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
        with connections['default'].cursor() as cursor:
            cursor.execute(f'SET search_path TO "{self.schema_name}", public;')
            cursor.execute(query, params or [])
            columns = [col[0] for col in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]

    def _generate_report_data(self) -> dict:
        """å‡†å¤‡é‚®ä»¶æŠ¥å‘Šæ‰€éœ€çš„æ‰€æœ‰æ•°æ®"""
        data = {}

        # 1. å…³é”®æŒ‡æ ‡
        daily_logs = self._execute_query(
            f"SELECT trade_date, total_assets FROM {BacktestDailyLog._meta.db_table} ORDER BY trade_date"
        )
        df_daily = pd.DataFrame(daily_logs)
        df_daily['total_assets'] = df_daily['total_assets'].astype(float)
        
        # èƒœç‡
        sell_ops = self._execute_query(
            f"SELECT exit_reason FROM {BacktestOperationLog._meta.db_table} WHERE direction = 'SELL'"
        )
        if sell_ops:
            total_sells = len(sell_ops)
            profit_sells = sum(1 for op in sell_ops if op['exit_reason'] == 'TAKE_PROFIT')
            data['win_rate'] = profit_sells / total_sells if total_sells > 0 else 0.0
        else:
            data['win_rate'] = 0.0
        
        # æœ€å¤§å›æ’¤
        df_daily['peak'] = df_daily['total_assets'].cummax()
        df_daily['drawdown'] = (df_daily['total_assets'] - df_daily['peak']) / df_daily['peak']
        data['max_drawdown'] = df_daily['drawdown'].min() if not df_daily.empty else 0.0

        # å¹´åŒ–æ”¶ç›Šç‡
        final_assets = float(df_daily['total_assets'].iloc[-1]) if not df_daily.empty else float(self.initial_capital)
        days_passed = (self.current_date - self.start_date).days
        if days_passed > 0:
            data['annualized_return'] = ((final_assets / float(self.initial_capital)) ** (365.0 / days_passed)) - 1
        else:
            data['annualized_return'] = 0.0

        # 2. èµ„é‡‘æ›²çº¿å›¾æ•°æ®
        data['plot_data'] = self._execute_query(
            f"SELECT trade_date, total_assets, market_m_value FROM {BacktestDailyLog._meta.db_table} ORDER BY trade_date"
        )

        # 3. å½“å‰æŒä»“
        data['current_holdings'] = self._execute_query(
            f"""
            SELECT p.stock_code, si.stock_name, p.entry_price, p.quantity, 
                   p.current_take_profit, p.current_stop_loss, dq.close as current_price
            FROM {Position._meta.db_table} p
            JOIN public.tb_stock_info si ON p.stock_code = si.stock_code
            LEFT JOIN public.tb_daily_quotes dq ON p.stock_code = dq.stock_code AND dq.trade_date = %s
            WHERE p.status = 'open'
            """, [self.current_date]
        )
        for h in data['current_holdings']:
            h['profit_rate'] = (h['current_take_profit'] / h['entry_price']) - 1 if h['entry_price'] > 0 else 0
            h['loss_rate'] = 1 - (h['current_stop_loss'] / h['entry_price']) if h['entry_price'] > 0 else 0

        # 4. æ”¶ç›Šæ’å
        all_ops = self._execute_query(f"SELECT stock_code, stock_name, direction, amount FROM {BacktestOperationLog._meta.db_table}")
        profits = {}
        for op in all_ops:
            key = (op['stock_code'], op['stock_name'])
            if op['direction'] == 'BUY':
                profits[key] = profits.get(key, 0) - op['amount']
            else: # SELL
                profits[key] = profits.get(key, 0) + op['amount']
        # æ€»æ”¶ç›Š = å·²å®ç°ç›ˆäº + æœªå®ç°ç›ˆäº
        #        = (å–å‡ºæ€»é¢ - ä¹°å…¥æ€»é¢) + (å½“å‰å¸‚å€¼ - æŒä»“æˆæœ¬)
        #        = (å–å‡ºæ€»é¢) - (å·²å¹³ä»“éƒ¨åˆ†çš„ä¹°å…¥æˆæœ¬) + (å½“å‰å¸‚å€¼)
        # ä¹‹å‰çš„å¾ªç¯å·²ç»è®¡ç®—äº† (å–å‡ºæ€»é¢ - å…¨éƒ¨ä¹°å…¥æˆæœ¬)ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€åŠ ä¸Šå½“å‰å¸‚å€¼å³å¯ã€‚
        for holding in data['current_holdings']:
            key = (holding['stock_code'], holding['stock_name'])
            
            # å¤„ç†å½“å¤©å¯èƒ½æ²¡æœ‰è¡Œæƒ…æ•°æ®çš„æƒ…å†µï¼Œè‹¥æ— å½“å‰ä»·åˆ™æŒ‰å…¥åœºä»·è®¡ç®—ï¼Œæµ®åŠ¨ç›ˆäºä¸º0
            current_price = holding['current_price'] or holding['entry_price']
            
            # è®¡ç®—å½“å‰æŒä»“çš„æ€»å¸‚å€¼
            current_market_value = holding['quantity'] * current_price
            
            # å°†å½“å‰å¸‚å€¼åŠ åˆ°è¯¥è‚¡ç¥¨çš„ç´¯è®¡æ”¶ç›Šä¸­
            profits[key] = profits.get(key, 0) + current_market_value
        profit_list = [{'stock_code': k[0], 'stock_name': k[1], 'profit': v} for k, v in profits.items()]
        data['profit_ranking'] = sorted(profit_list, key=lambda x: x['profit'], reverse=True)

        return data

    def _generate_plot_base64(self, plot_data: list[dict]) -> str:
        if not plot_data:
            return ""
        
        try:
            plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False
        except Exception as e:
            pass
        
        try:
            df = pd.DataFrame(plot_data)
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df['trade_date'] = pd.to_datetime(df['trade_date'])
            df['total_assets'] = pd.to_numeric(df['total_assets'])
            df['market_m_value'] = pd.to_numeric(df['market_m_value'])

            if df.empty:
                return ""

            plt.style.use('seaborn-v0_8-whitegrid')
            fig, ax1 = plt.subplots(figsize=(14, 7))

            # ç»˜åˆ¶ä¸»æ›²çº¿
            ax1.plot(df['trade_date'], df['total_assets'], color='dodgerblue', label='money', linewidth=2)
            ax1.set_xlabel('date', fontsize=12)
            ax1.set_ylabel('money', color='dodgerblue', fontsize=12)
            ax1.tick_params(axis='y', labelcolor='dodgerblue')
            ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))

            # ç»˜åˆ¶å‰¯åæ ‡è½´æ›²çº¿
            ax2 = ax1.twinx()
            ax2.plot(df['trade_date'], df['market_m_value'], color='coral', linestyle='--', label='M', alpha=0.7)
            ax2.set_ylabel('M', color='coral', fontsize=12)
            ax2.tick_params(axis='y', labelcolor='coral')
            ax2.axhline(0, color='grey', linestyle=':', linewidth=1)

            # ======================= ä¸»è¦ä¿®æ”¹ç‚¹ =======================
            # 1. æ›´å¥å£®å’Œç®€åŒ–çš„Xè½´åˆ»åº¦é€»è¾‘
            num_days = (df['trade_date'].max() - df['trade_date'].min()).days
            
            if num_days <= 60:  # 2ä¸ªæœˆä»¥å†…ï¼ŒæŒ‰å‘¨æ˜¾ç¤º
                locator = mdates.WeekdayLocator(byweekday=mdates.MO)
                formatter = mdates.DateFormatter('%m-%d')
            elif num_days <= 365 * 2: # 2å¹´ä»¥å†…ï¼ŒæŒ‰å­£åº¦æ˜¾ç¤º
                locator = mdates.MonthLocator(interval=3)
                formatter = mdates.DateFormatter('%Y-%m')
            elif num_days <= 365 * 5: # 5å¹´ä»¥å†…ï¼ŒæŒ‰åŠå¹´æ˜¾ç¤º
                locator = mdates.MonthLocator(interval=6)
                formatter = mdates.DateFormatter('%Y-%m')
            else:  # è¶…è¿‡5å¹´ï¼ŒæŒ‰å¹´æ˜¾ç¤º
                locator = mdates.YearLocator()
                formatter = mdates.DateFormatter('%Y')
            
            ax1.xaxis.set_major_locator(locator)
            ax1.xaxis.set_major_formatter(formatter)

            # 2. ç§»é™¤ fig.autofmt_xdate()ï¼Œå¹¶æ‰‹åŠ¨è®¾ç½®æ ‡ç­¾æ—‹è½¬ï¼Œé¿å…å†²çª
            plt.setp(ax1.get_xticklabels(), rotation=30, ha='right')
            # ========================================================

            fig.suptitle('Money-M(t)', fontsize=16, weight='bold')
            fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))
            
            # ä½¿ç”¨ tight_layout æ›¿ä»£
            plt.tight_layout(rect=[0, 0, 1, 0.96])

            # ä¿å­˜å›¾åƒåˆ°å†…å­˜
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100)
            plt.close(fig)
            buf.seek(0)
            return base64.b64encode(buf.getvalue()).decode('utf-8')
        finally:
            pass



    def _format_html_content(self, data: dict, plot_base64: str) -> str:
        
        # ======================= ä¿®å¤é¢œè‰²é€»è¾‘ =======================
        # ä¿®å¤ï¼šç›ˆåˆ© (value > 0) ä¸ºç»¿è‰²ï¼ŒäºæŸ (value < 0) ä¸ºçº¢è‰²
        def get_row_style(value):
            if value > 0:
                return 'style="background-color: #e9f5e9; color: #1e7e34;"'  # ç»¿è‰²èƒŒæ™¯ï¼Œæ·±ç»¿è‰²æ–‡å­—
            elif value < 0:
                return 'style="background-color: #fdeaea; color: #c82333;"'  # çº¢è‰²èƒŒæ™¯ï¼Œæ·±çº¢è‰²æ–‡å­—
            else:
                return '' # ä¸­æ€§
        # ==========================================================
        # Part 1: Key Metrics
        html = f"""
        <h2>å…³é”®æŒ‡æ ‡ (æˆªè‡³ {self.current_date.strftime('%Y-%m-%d')})</h2>
        <table class="summary-table">
            <tr>
                <th>èƒœç‡</th><td>{data['win_rate']:.2%}</td>
                <th>æœ€å¤§å›æ’¤</th><td style="color: #c82333;">{data['max_drawdown']:.2%}</td>
                <th>å¹´åŒ–æ”¶ç›Šç‡</th><td>{data['annualized_return']:.2%}</td>
            </tr>
        </table>
        """
        # Part 2: Plot
        html += f"""
        <h2>èµ„é‡‘ä¸Må€¼å˜åŒ–è¶‹åŠ¿</h2>
        <div style="text-align: center;">
            <img src="data:image/png;base64,{plot_base64}" alt="Performance Chart" style="max-width: 100%;">
        </div>
        """
        # Part 3: Current Holdings
        html += "<h2>å½“å‰æŒä»“æƒ…å†µ</h2>"
        if data['current_holdings']:
            html += """
            <table class="data-table">
                <thead><tr><th>è‚¡ç¥¨ä»£ç </th><th>è‚¡ç¥¨åç§°</th><th>å…¥åœºä»·</th><th>å½“å‰ä»·</th><th>æµ®åŠ¨ç›ˆäº</th><th>æ­¢ç›ˆä»·æ ¼</th><th>æ­¢æŸä»·æ ¼</th><th>é¢„è®¾æ­¢ç›ˆç‡</th><th>é¢„è®¾æ­¢æŸç‡</th></tr></thead>
                <tbody>
            """
            for h in data['current_holdings']:
                current_price = h['current_price'] or h['entry_price']
                profit_loss = current_price - h['entry_price']
                profit_loss_rate = (current_price / h['entry_price'] - 1) if h['entry_price'] else 0
                style = get_row_style(profit_loss)
                html += f"""
                <tr {style}>
                    <td>{h['stock_code']}</td>
                    <td>{h['stock_name']}</td>
                    <td>{h['entry_price']:.2f}</td>
                    <td>{current_price:.2f}</td>
                    <td>{profit_loss_rate:.2%}</td>
                    <td>{h['current_take_profit']:.2f}</td>
                    <td>{h['current_stop_loss']:.2f}</td>
                    <td>{h['profit_rate']:.2%}</td>
                    <td>{h['loss_rate']:.2%}</td>
                </tr>
                """
            html += "</tbody></table>"
        else:
            html += "<p>å½“å‰æ— æŒä»“ã€‚</p>"
        # Part 4: Profit Ranking
        html += "<h2>å„è‚¡ç´¯è®¡æ”¶ç›Šæ’å</h2>"
        if data['profit_ranking']:
            html += """
            <table class="data-table">
                <thead><tr><th>æ’å</th><th>è‚¡ç¥¨ä»£ç </th><th>è‚¡ç¥¨åç§°</th><th>ç´¯è®¡æ”¶ç›Š(å…ƒ)</th></tr></thead>
                <tbody>
            """
            for i, p in enumerate(data['profit_ranking'], 1):
                # è¿™é‡Œå¤ç”¨ä¸Šé¢ä¿®æ”¹å¥½çš„é¢œè‰²é€»è¾‘
                style = get_row_style(p['profit'])
                html += f"""
                <tr {style}>
                    <td>{i}</td>
                    <td>{p['stock_code']}</td>
                    <td>{p['stock_name']}</td>
                    <td>{p['profit']:,.2f}</td>
                </tr>
                """
            html += "</tbody></table>"
        else:
            html += "<p>æš‚æ— å·²å¹³ä»“çš„äº¤æ˜“ã€‚</p>"
        # Final HTML structure (ä¿æŒä¸å˜)
        final_html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <title>å›æµ‹æŠ¥å‘Š</title>
            <style>
                body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; margin: 20px; background-color: #f4f7f6; color: #333; }}
                h2 {{ color: #0056b3; border-bottom: 2px solid #e0e0e0; padding-bottom: 8px; margin-top: 30px; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 15px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }}
                th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #ddd; }}
                th {{ background-color: #f8f9fa; }}
                .summary-table th {{ width: 15%; background-color: #e9ecef; }}
                .summary-table td {{ font-weight: bold; font-size: 1.1em; }}
                .data-table tbody tr:hover {{ background-color: #f1f1f1; }}
            </style>
        </head>
        <body>
            <h1>å›æµ‹è¿›åº¦æŠ¥å‘Š: {self.start_date}~{self.current_date}å›æµ‹</h1>
            {html}
        </body>
        </html>
        """
        return final_html

    def send_report(self):
        """ç”Ÿæˆå¹¶å‘é€æŠ¥å‘Šé‚®ä»¶"""
        logger.info(f"[{self.schema_name}] æ­£åœ¨ç”Ÿæˆæˆªè‡³ {self.current_date} çš„å›æµ‹æŠ¥å‘Š...")
        try:
            report_data = self._generate_report_data()
            plot_base64 = self._generate_plot_base64(report_data.get('plot_data', []))
            html_content = self._format_html_content(report_data, plot_base64)
            subject = f"å›æµ‹æŠ¥å‘Š ({self.start_date}~{self.current_date}) - {self.current_date.strftime('%Y-%m-%d')}"
            
            self.email_handler.send_email(
                recipients=self.recipients,
                subject=subject,
                html_content=html_content
            )
            logger.info(f"[{self.start_date}~{self.current_date}] å›æµ‹æŠ¥å‘Šé‚®ä»¶å·²æˆåŠŸå‘é€ã€‚")
        except Exception as e:
            logger.error(f"[{self.start_date}~{self.current_date}] ç”Ÿæˆæˆ–å‘é€å›æµ‹æŠ¥å‘Šæ—¶å¤±è´¥: {e}", exc_info=True)


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\before_fix_service.py####
# trade_manager/service/before_fix_service.py

import logging
from datetime import date, timedelta, datetime
from decimal import Decimal, ROUND_HALF_UP
from django.utils import timezone
from django.db import transaction
from django.db.models import Q

# å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å‹
from common.models import (
    CorporateAction,
    DailyTradingPlan,
    Position,
    DailyQuotes,
    SystemLog
)

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


class BeforeFixService:
    """
    Tæ—¥å¼€ç›˜å‰æ ¡å‡†ä¸é¢„æ¡ˆä¿®æ­£æœåŠ¡ã€‚

    èŒè´£:
    1. æ£€æŸ¥å½“å¤©æ˜¯å¦å·²æˆåŠŸæ‰§è¡Œè¿‡ï¼Œé˜²æ­¢é‡å¤è¿è¡Œã€‚
    2. è·å–Tæ—¥çš„é™¤æƒé™¤æ¯äº‹ä»¶ã€‚
    3. è®¡ç®—å—å½±å“è‚¡ç¥¨çš„ä»·æ ¼è°ƒæ•´æ¯”ç‡ã€‚
    4. æ ¹æ®æ¯”ç‡ä¿®æ­£â€œæ¯æ—¥äº¤æ˜“é¢„æ¡ˆâ€ä¸­çš„MIOPå’ŒMAOPã€‚
    5. æ ¹æ®æ¯”ç‡ä¿®æ­£â€œæŒä»“ä¿¡æ¯â€ä¸­çš„æ­¢ç›ˆæ­¢æŸä»·ã€‚
    6. å¯¹è¿‘æœŸå‘ç”Ÿé…è‚¡çš„è‚¡ç¥¨è¿›è¡Œç‰¹æ®Šé£é™©å¤„ç†ã€‚
    """
    MODULE_NAME = 'ç›˜å‰æ ¡å‡†ä¸é¢„æ¡ˆä¿®æ­£'
    # å¯é…ç½®å‚æ•°
    MAX_PLAN_LOOKBACK_DAYS = 14  # æŸ¥æ‰¾äº¤æ˜“é¢„æ¡ˆçš„æœ€å¤§å›æº¯å¤©æ•°
    RIGHTS_ISSUE_LOOKBACK_DAYS = 30 # é…è‚¡äº‹ä»¶ç‰¹æ®Šå¤„ç†çš„å›æº¯äº¤æ˜“æ—¥æ•°

    def __init__(self, execution_date: date = None):
        """
        åˆå§‹åŒ–æœåŠ¡ã€‚
        :param execution_date: Tæ—¥ï¼Œå³æ‰§è¡Œæ ¡å‡†çš„æ—¥æœŸã€‚å¦‚æœä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºå½“å¤©ã€‚
        """
        self.t_day = execution_date if execution_date else date.today()
        self.t_minus_1_day = None
        self.adjustment_ratios = {} # å­˜å‚¨ {stock_code: ratio}
        logger.debug(f"[{self.MODULE_NAME}] æœåŠ¡åˆå§‹åŒ–ï¼Œç›®æ ‡Tæ—¥: {self.t_day}")

    def _log_to_db(self, level: str, message: str):
        """è¾…åŠ©æ–¹æ³•ï¼šå°†æ—¥å¿—å†™å…¥æ•°æ®åº“"""
        try:
            SystemLog.objects.create(
                log_level=level,
                module_name=self.MODULE_NAME,
                message=message
            )
        except Exception as e:
            logger.error(f"æ— æ³•å°†æ—¥å¿—å†™å…¥æ•°æ®åº“: {e}")

    def _is_trading_day(self, check_date: date) -> bool:
        """æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
        is_trade_day = DailyQuotes.objects.filter(trade_date=check_date).exists()
        logger.info(f"æ£€æŸ¥æ—¥æœŸ {check_date} æ˜¯å¦ä¸ºäº¤æ˜“æ—¥: {'æ˜¯' if is_trade_day else 'å¦'}")
        return is_trade_day

    def _get_last_trading_day(self, from_date: date) -> date | None:
        """è·å–æŒ‡å®šæ—¥æœŸä¹‹å‰çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥"""
        last_day = DailyQuotes.objects.filter(
            trade_date__lt=from_date
        ).order_by('-trade_date').values_list('trade_date', flat=True).first()
        
        if last_day:
            logger.info(f"{from_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ (T-1) æ˜¯: {last_day}")
        else:
            logger.warning(f"æ— æ³•æ‰¾åˆ° {from_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ã€‚")
        return last_day

    def _find_latest_pending_plan_date(self) -> date | None:
        """ä»Tæ—¥å¼€å§‹å‘å‰å›æº¯ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„ä¸€ä¸ªåŒ…å«å¾…æ‰§è¡Œé¢„æ¡ˆçš„æ—¥æœŸ"""
        for i in range(self.MAX_PLAN_LOOKBACK_DAYS):
            check_date = self.t_day - timedelta(days=i)
            if DailyTradingPlan.objects.filter(
                plan_date=check_date,
                status=DailyTradingPlan.StatusChoices.PENDING
            ).exists():
                logger.info(f"æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆï¼Œé¢„æ¡ˆæ—¥æœŸä¸º: {check_date}")
                return check_date
        logger.warning(f"åœ¨è¿‡å» {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…æœªæ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚")
        return None

    def _calculate_adjusted_price(self, t_minus_1_close: Decimal, events: list[CorporateAction]) -> Decimal:
        """
        æ ¸å¿ƒç®—æ³•ï¼šæ ¹æ®äº‹ä»¶åˆ—è¡¨è®¡ç®—é™¤æƒé™¤æ¯å‚è€ƒä»·ã€‚
        å¤„ç†é¡ºåºï¼š1.é™¤æ¯ -> 2.é€/è½¬è‚¡ -> 3.é…è‚¡
        """
        adjusted_price = t_minus_1_close
        
        # æŒ‰äº‹ä»¶ç±»å‹ä¼˜å…ˆçº§æ’åº
        event_priority = {
            CorporateAction.EventType.DIVIDEND: 1,
            CorporateAction.EventType.BONUS: 2,
            CorporateAction.EventType.TRANSFER: 2,
            CorporateAction.EventType.SPLIT: 2,
            CorporateAction.EventType.RIGHTS: 3,
        }
        sorted_events = sorted(events, key=lambda e: event_priority.get(e.event_type, 99))

        for event in sorted_events:
            # 1. ç°é‡‘åˆ†çº¢ (é™¤æ¯)
            if event.event_type == CorporateAction.EventType.DIVIDEND and event.dividend_per_share:
                adjusted_price -= event.dividend_per_share
            
            # 2. é€è‚¡/è½¬å¢è‚¡/å¹¶è‚¡/æ‹†è‚¡ (é™¤æƒ)
            elif event.event_type in [CorporateAction.EventType.BONUS, CorporateAction.EventType.TRANSFER, CorporateAction.EventType.SPLIT]:
                if event.shares_before and event.shares_after and event.shares_after > 0:
                    adjusted_price = adjusted_price * (event.shares_before / event.shares_after)

            # 3. é…è‚¡ (é™¤æƒ) - æ³¨æ„ï¼šæŒ‰éœ€æ±‚ï¼Œæ­¤è®¡ç®—ç»“æœä¸ç”¨äºå¸¸è§„æ ¡å‡†ï¼Œä½†é€»è¾‘ä¿ç•™
            elif event.event_type == CorporateAction.EventType.RIGHTS:
                if event.shares_before and event.shares_after and event.rights_issue_price is not None and event.shares_after > 0:
                    adjusted_price = (event.shares_before * adjusted_price + (event.shares_after - event.shares_before) * event.rights_issue_price) / event.shares_after
        
        return adjusted_price

    @transaction.atomic
    def run(self):
        """æ‰§è¡Œç›˜å‰æ ¡å‡†ä¸ä¿®æ­£çš„ä¸»æµç¨‹"""

        self.t_minus_1_day = self._get_last_trading_day(self.t_day)
        if not self.t_minus_1_day:
            logger.error(f"æ— æ³•ç¡®å®šT-1æ—¥ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
            return

        # a. è·å–Tæ—¥æ‰€æœ‰é™¤æƒé™¤æ¯ä¿¡æ¯
        events_on_t_day = CorporateAction.objects.filter(ex_dividend_date=self.t_day)
        if not events_on_t_day.exists():
            logger.debug(f"Tæ—¥ ({self.t_day}) æ— é™¤æƒé™¤æ¯äº‹ä»¶ï¼Œæ— éœ€æ ¡å‡†ã€‚")
            return

        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„äº‹ä»¶
        events_by_stock = {}
        for event in events_on_t_day:
            events_by_stock.setdefault(event.stock_code, []).append(event)
        
        affected_codes = list(events_by_stock.keys())
        logger.info(f"Tæ—¥å…±æœ‰ {len(affected_codes)} åªè‚¡ç¥¨å‘ç”Ÿè‚¡æƒäº‹ä»¶ã€‚")

        # è·å–è¿™äº›è‚¡ç¥¨åœ¨T-1æ—¥çš„æ”¶ç›˜ä»·
        quotes_qs = DailyQuotes.objects.filter(
            trade_date=self.t_minus_1_day,
            stock_code_id__in=affected_codes
        )
        # ä½¿ç”¨å­—å…¸æ¨å¯¼å¼æ„å»ºæˆ‘ä»¬éœ€è¦çš„æ˜ å°„å…³ç³»
        quotes_t_minus_1 = {quote.stock_code_id: quote for quote in quotes_qs}

        # b. è®¡ç®—ä»·æ ¼è°ƒæ•´æ¯”ç‡
        for stock_code, events in events_by_stock.items():
            if stock_code not in quotes_t_minus_1:
                logger.warning(f"è‚¡ç¥¨ {stock_code} åœ¨T-1æ—¥({self.t_minus_1_day})æ— è¡Œæƒ…æ•°æ®ï¼ˆå¯èƒ½åœç‰Œï¼‰ï¼Œè·³è¿‡æ ¡å‡†ã€‚")
                continue
            
            close_t_minus_1 = quotes_t_minus_1[stock_code].close
            if close_t_minus_1 <= 0:
                logger.warning(f"è‚¡ç¥¨ {stock_code} åœ¨T-1æ—¥æ”¶ç›˜ä»·ä¸º0æˆ–è´Ÿæ•°ï¼Œä¸åˆç†ï¼Œè·³è¿‡æ ¡å‡†ã€‚")
                continue

            adjusted_close = self._calculate_adjusted_price(close_t_minus_1, events)
            ratio = adjusted_close / close_t_minus_1
            self.adjustment_ratios[stock_code] = ratio
            logger.info(f"è‚¡ç¥¨ {stock_code}: T-1æ”¶ç›˜ä»·={close_t_minus_1}, æ ¡å‡†åä»·æ ¼={adjusted_close:.2f}, è°ƒæ•´æ¯”ç‡={ratio:.6f}")

        # c. ä¿®æ­£äº¤æ˜“é¢„æ¡ˆ
        self._process_trading_plans()

        # d. ä¿®æ­£æŒä»“é£æ§
        self._process_positions()

        # e. é…è‚¡äº‹ä»¶ç‰¹æ®Šå¤„ç†
        self._handle_rights_issue_special_case()

        logger.info(f"[{self.MODULE_NAME}] ä»»åŠ¡æˆåŠŸå®Œæˆã€‚å…±å¤„ç† {len(self.adjustment_ratios)} åªè‚¡ç¥¨çš„å¸¸è§„æ ¡å‡†ã€‚")

    def _process_trading_plans(self):
        """ä¿®æ­£äº¤æ˜“é¢„æ¡ˆä¸­çš„MIOPå’ŒMAOP"""
        plan_date_to_fix = self._find_latest_pending_plan_date()
        if not plan_date_to_fix:
            return

        plans_to_fix = DailyTradingPlan.objects.filter(
            plan_date=plan_date_to_fix,
            status=DailyTradingPlan.StatusChoices.PENDING,
            stock_code__in=self.adjustment_ratios.keys()
        )

        plans_to_update = []
        for plan in plans_to_fix:
            ratio = self.adjustment_ratios[plan.stock_code_id]
            original_miop = plan.miop
            original_maop = plan.maop
            
            plan.miop = (original_miop * Decimal(str(ratio))).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            plan.maop = (original_maop * Decimal(str(ratio))).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            
            plans_to_update.append(plan)
            logger.info(f"äº¤æ˜“é¢„æ¡ˆä¿®æ­£: {plan.stock_code}, MIOP: {original_miop}->{plan.miop}, MAOP: {original_maop}->{plan.maop}")

        if plans_to_update:
            DailyTradingPlan.objects.bulk_update(plans_to_update, ['miop', 'maop'])
            logger.info(f"æˆåŠŸæ‰¹é‡æ›´æ–° {len(plans_to_update)} æ¡äº¤æ˜“é¢„æ¡ˆã€‚")

    def _process_positions(self):
        """ä¿®æ­£æŒä»“ä¸­çš„æ­¢ç›ˆæ­¢æŸä»·"""
        positions_to_fix = Position.objects.filter(
            status=Position.StatusChoices.OPEN,
            stock_code__in=self.adjustment_ratios.keys()
        )

        positions_to_update = []
        for pos in positions_to_fix:
            ratio = self.adjustment_ratios[pos.stock_code_id]
            original_sl = pos.current_stop_loss
            original_tp = pos.current_take_profit

            pos.current_stop_loss = (original_sl * Decimal(str(ratio))).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            pos.current_take_profit = (original_tp * Decimal(str(ratio))).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            
            positions_to_update.append(pos)
            logger.info(f"æŒä»“é£æ§ä¿®æ­£: {pos.stock_code}, æ­¢æŸ: {original_sl}->{pos.current_stop_loss}, æ­¢ç›ˆ: {original_tp}->{pos.current_take_profit}")

        if positions_to_update:
            Position.objects.bulk_update(positions_to_update, ['current_stop_loss', 'current_take_profit'])
            logger.info(f"æˆåŠŸæ‰¹é‡æ›´æ–° {len(positions_to_update)} æ¡æŒä»“è®°å½•ã€‚")

    def _handle_rights_issue_special_case(self):
        """å¤„ç†30ä¸ªäº¤æ˜“æ—¥å†…æœ‰é…è‚¡äº‹ä»¶çš„è‚¡ç¥¨"""
        # 1. è·å–è¿‡å»30ä¸ªäº¤æ˜“æ—¥çš„æ—¥æœŸåˆ—è¡¨
        recent_trading_days = list(
            DailyQuotes.objects.filter(trade_date__lte=self.t_day)
            .order_by('-trade_date')
            .values_list('trade_date', flat=True)[:self.RIGHTS_ISSUE_LOOKBACK_DAYS]
        )
        if not recent_trading_days:
            logger.warning("æ— æ³•è·å–æœ€è¿‘äº¤æ˜“æ—¥åˆ—è¡¨ï¼Œè·³è¿‡é…è‚¡ç‰¹æ®Šå¤„ç†ã€‚")
            return

        # 2. æŸ¥æ‰¾åœ¨æ­¤æœŸé—´å‘ç”Ÿé…è‚¡çš„è‚¡ç¥¨
        rights_issue_stocks = list(
            CorporateAction.objects.filter(
                event_type=CorporateAction.EventType.RIGHTS,
                ex_dividend_date__in=recent_trading_days
            ).values_list('stock_code', flat=True).distinct()
        )
        if not rights_issue_stocks:
            logger.info("è¿‘æœŸæ— é…è‚¡äº‹ä»¶ï¼Œæ— éœ€ç‰¹æ®Šå¤„ç†ã€‚")
            return
        
        logger.warning(f"æ£€æµ‹åˆ° {len(rights_issue_stocks)} åªè‚¡ç¥¨è¿‘æœŸæœ‰é…è‚¡äº‹ä»¶: {rights_issue_stocks}ï¼Œå°†è¿›è¡Œé£é™©å‰”é™¤ã€‚")

        # 3. å¤„ç†äº¤æ˜“é¢„æ¡ˆ
        plan_date_to_fix = self._find_latest_pending_plan_date()
        if plan_date_to_fix:
            plans_to_void = DailyTradingPlan.objects.filter(
                plan_date=plan_date_to_fix,
                status=DailyTradingPlan.StatusChoices.PENDING,
                stock_code__in=rights_issue_stocks
            )
            plans_to_update = []
            for plan in plans_to_void:
                plan.miop = Decimal('99999.00')
                plan.maop = Decimal('0.00')
                plans_to_update.append(plan)
            
            if plans_to_update:
                DailyTradingPlan.objects.bulk_update(plans_to_update, ['miop', 'maop'])
                logger.info(f"é…è‚¡é£é™©å¤„ç†ï¼šå°† {len(plans_to_update)} æ¡äº¤æ˜“é¢„æ¡ˆçš„MIOP/MAOPç½®ä¸ºæ— æ•ˆã€‚")

        # 4. å¤„ç†æŒä»“
        positions_to_void = Position.objects.filter(
            status=Position.StatusChoices.OPEN,
            stock_code__in=rights_issue_stocks
        )
        positions_to_update = []
        for pos in positions_to_void:
            pos.current_take_profit = Decimal('0.00')
            pos.current_stop_loss = Decimal('99999.00')
            positions_to_update.append(pos)
        
        if positions_to_update:
            Position.objects.bulk_update(positions_to_update, ['current_take_profit', 'current_stop_loss'])
            logger.info(f"é…è‚¡é£é™©å¤„ç†ï¼šå°† {len(positions_to_update)} æ¡æŒä»“çš„æ­¢ç›ˆ/æ­¢æŸç½®ä¸ºç´§æ€¥é€€å‡ºçŠ¶æ€ã€‚")


# --- å¦‚ä½•åœ¨é¡¹ç›®ä¸­ä½¿ç”¨è¿™ä¸ªæœåŠ¡ ---
# ä½ å¯ä»¥åœ¨ä¸€ä¸ªDjango Management Commandæˆ–è€…å®šæ—¶ä»»åŠ¡ï¼ˆå¦‚Celeryï¼‰ä¸­è°ƒç”¨å®ƒ
#
# from trade_manager.service.before_fix_service import BeforeFixService
#
# def run_daily_premarket_fix():
#     # é»˜è®¤ä½¿ç”¨å½“å¤©æ—¥æœŸ
#     service = BeforeFixService()
#     service.run()
#
# def run_backtest_premarket_fix(some_date):
#     # ä¼ å…¥æŒ‡å®šæ—¥æœŸè¿›è¡Œå›æµ‹
#     service = BeforeFixService(execution_date=some_date)
#     service.run()


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\db_utils.py####
# trade_manager/service/db_utils.py

import contextlib
import logging
import threading
from django.db import connections
from django.db.backends.signals import connection_created

logger = logging.getLogger(__name__)

# ä½¿ç”¨çº¿ç¨‹å±€éƒ¨å­˜å‚¨æ¥å®‰å…¨åœ°åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­ä¼ é€’ schema åç§°
_db_context = threading.local()

def backtest_schema_handler(sender, connection, **kwargs):
    """
    Django `connection_created` ä¿¡å·çš„å¤„ç†å™¨ã€‚
    å½“ä¸€ä¸ªæ–°çš„æ•°æ®åº“è¿æ¥è¢«åˆ›å»ºæ—¶ï¼Œæ­¤å‡½æ•°ä¼šè¢«è°ƒç”¨ã€‚
    å®ƒä¼šæ£€æŸ¥å½“å‰çº¿ç¨‹æ˜¯å¦åœ¨ `use_backtest_schema` ä¸Šä¸‹æ–‡ä¸­ï¼Œ
    å¦‚æœæ˜¯ï¼Œåˆ™ç«‹å³ä¸ºè¿™ä¸ªæ–°è¿æ¥è®¾ç½®æ­£ç¡®çš„ search_pathã€‚
    """
    if hasattr(_db_context, 'schema_name') and _db_context.schema_name:
        schema_name = _db_context.schema_name
        logger.debug(f"æ–°æ•°æ®åº“è¿æ¥åˆ›å»ºï¼Œä¸ºå…¶è®¾ç½® search_path -> {schema_name}, public")
        with connection.cursor() as cursor:
            # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢SQLæ³¨å…¥
            cursor.execute("SET search_path TO %s, public;", [schema_name])

# å°†ä¿¡å·å¤„ç†å™¨è¿æ¥åˆ° `connection_created` ä¿¡å·
# dispatch_uid ç¡®ä¿å³ä½¿ä»£ç è¢«å¤šæ¬¡å¯¼å…¥ï¼Œä¿¡å·å¤„ç†å™¨ä¹Ÿåªè¿æ¥ä¸€æ¬¡
connection_created.connect(backtest_schema_handler, dispatch_uid="set_backtest_search_path")

@contextlib.contextmanager
def use_backtest_schema(schema_name: str):
    """
    ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºåœ¨ç‰¹å®šä»£ç å—å†…å°†æ‰€æœ‰æ•°æ®åº“æ“ä½œé‡å®šå‘åˆ°æŒ‡å®šçš„ schemaã€‚

    ç”¨æ³•:
    with use_backtest_schema('my_backtest_schema'):
        # æ­¤å¤„æ‰€æœ‰çš„ Django ORM æ“ä½œéƒ½ä¼šåœ¨ 'my_backtest_schema' ä¸­è¿›è¡Œ
        MyModel.objects.create(...)
    """
    # è¿›å…¥ with å—æ—¶ï¼Œè®¾ç½®çº¿ç¨‹å±€éƒ¨å˜é‡
    _db_context.schema_name = schema_name
    # å¼ºåˆ¶å…³é—­å½“å‰çº¿ç¨‹çš„ç°æœ‰è¿æ¥ï¼Œä»¥ç¡®ä¿ä¸‹ä¸€ä¸ªæŸ¥è¯¢ä¼šåˆ›å»ºä¸€ä¸ªæ–°è¿æ¥ï¼Œä»è€Œè§¦å‘ä¿¡å·å¤„ç†å™¨
    connections['default'].close()
    try:
        # å°†æ§åˆ¶æƒäº¤è¿˜ç»™ with å—å†…çš„ä»£ç 
        yield
    finally:
        # é€€å‡º with å—æ—¶ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¼‚å¸¸ï¼‰ï¼Œæ¸…ç†çº¿ç¨‹å±€éƒ¨å˜é‡
        if hasattr(_db_context, 'schema_name'):
            del _db_context.schema_name
        # å†æ¬¡å…³é—­è¿æ¥ï¼Œä»¥ä¾¿åç»­æ“ä½œèƒ½æ¢å¤åˆ°é»˜è®¤çš„ search_path
        connections['default'].close()
        logger.debug("å·²é€€å‡ºå›æµ‹ schema ä¸Šä¸‹æ–‡ï¼Œæ¢å¤é»˜è®¤ search_pathã€‚")


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\decision_order_service.py####
# trade_manager/service/decision_order_service.py
# ç‰ˆæœ¬: 2.0 - M(t)é©±åŠ¨çš„åŠ¨æ€é£é™©ç®¡ç†
# æè¿°: æ­¤ç‰ˆæœ¬é‡æ„äº†æ­¢ç›ˆæ­¢æŸè®¡ç®—é€»è¾‘ï¼Œä½¿å…¶ä¸åŠ¨æ€é€‰è‚¡ç­–ç•¥çš„å¸‚åœºçŠ¶æ€åˆ¤æ–­(M(t))ä¿æŒä¸€è‡´ã€‚
#       è§£å†³äº†æ—§ç‰ˆåœ¨éè¶‹åŠ¿è¡Œæƒ…ä¸­æ­¢æŸä»·å¯èƒ½é«˜äºæ­¢ç›ˆä»·çš„ä¸¥é‡é€»è¾‘é—®é¢˜ã€‚

import logging
from datetime import date, timedelta
from decimal import Decimal, ROUND_HALF_UP
import pandas as pd
import pandas_ta as ta

from django.db import transaction
from django.utils import timezone

from common.models import (
    DailyTradingPlan,
    Position,
    TradeLog,
    StrategyParameters,
    DailyQuotes,
    SystemLog,
    DailyFactorValues  # æ–°å¢å¯¼å…¥
)
from .trade_handler import ITradeHandler
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE # æ–°å¢å¯¼å…¥

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class DecisionOrderService:
    """
    å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å— (V2.0 - åŠ¨æ€é£é™©ç‰ˆ)ã€‚

    è¯¥æœåŠ¡è´Ÿè´£åœ¨Tæ—¥å¼€ç›˜åçš„é»„é‡‘æ—¶é—´å†…ï¼Œæ ¹æ®é¢„æ¡ˆã€å®é™…å¼€ç›˜ä»·å’Œè´¦æˆ·çŠ¶æ€ï¼Œ
    åšå‡ºæœ€ç»ˆçš„ä¹°å…¥å†³ç­–ï¼Œå¹¶æ‰§è¡Œä¸‹å•ã€‚å…¶æ ¸å¿ƒç‰¹è‰²æ˜¯ï¼Œåœ¨è®¢å•æˆäº¤åï¼Œ
    èƒ½å¤Ÿæ ¹æ®T-1æ—¥çš„å¸‚åœºçŠ¶æ€M(t)ï¼Œä¸ºæ–°æŒä»“è®¡ç®—åŠ¨æ€çš„ã€è‡ªé€‚åº”çš„æ­¢ç›ˆæ­¢æŸä»·ã€‚
    """
    MODULE_NAME = 'å¼€ç›˜å†³ç­–ä¸ä¸‹å•(åŠ¨æ€é£é™©ç‰ˆ)'
    MAX_PLAN_LOOKBACK_DAYS = 14

    def __init__(self, handler: ITradeHandler, execution_date: date = None):
        """
        åˆå§‹åŒ–æœåŠ¡ã€‚

        :param handler: ä¸€ä¸ªå®ç°äº† ITradeHandler æ¥å£çš„å®ä¾‹ï¼Œç”¨äºä¸äº¤æ˜“ç¯å¢ƒäº¤äº’ã€‚
        :param execution_date: Tæ—¥ï¼Œå³æ‰§è¡Œå†³ç­–çš„æ—¥æœŸã€‚å¦‚æœä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºå½“å¤©ã€‚
        """
        if not isinstance(handler, ITradeHandler):
            raise TypeError("ä¼ å…¥çš„ handler å¿…é¡»æ˜¯ ITradeHandler çš„ä¸€ä¸ªå®ä¾‹ã€‚")
      
        self.handler = handler
        self.execution_date = execution_date if execution_date else date.today()
        self.params = self._load_strategy_parameters()
      
        # æ–°å¢ï¼šç”¨äºå­˜å‚¨å½“æ—¥åŠ¨æ€è®¡ç®—ç»“æœçš„å®ä¾‹å˜é‡
        self.current_max_positions = 0
        self.final_nominal_principal = Decimal('0.0')
 
        # ã€å…¨æ–°ã€‘è°ƒç”¨æ–°çš„åˆå§‹åŒ–å¼•æ“
        self._initialize_position_sizing_engine()
      
        logger.debug(f"[{self.MODULE_NAME}] æœåŠ¡åˆå§‹åŒ–ã€‚æ‰§è¡ŒTæ—¥: {self.execution_date}")
        logger.debug(f"ç­–ç•¥å‚æ•°åŠ è½½æˆåŠŸ: {len(self.params)}ä¸ª")
        logger.debug(f"å½“æ—¥åŠ¨æ€æœ€å¤§æŒä»“æ•°: {self.current_max_positions}")
        logger.debug(f"å½“æ—¥åŠ¨æ€å•ä½åä¹‰æœ¬é‡‘: {self.final_nominal_principal:.2f}")

    def _initialize_position_sizing_engine(self):
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        åœ¨æœåŠ¡åˆå§‹åŒ–æ—¶ï¼Œå®Œæˆæ‰€æœ‰åŸºäºT-1æ—¥M(t)çš„ä»“ä½ sizing è®¡ç®—ã€‚
        """
        try:
            # 1. è·å–T-1äº¤æ˜“æ—¥
            t_minus_1_date = DailyQuotes.objects.filter(trade_date__lt=self.execution_date).latest('trade_date').trade_date
        except DailyQuotes.DoesNotExist:
            logger.error(f"æ— æ³•æ‰¾åˆ° {self.execution_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ŒåŠ¨æ€ä»“ä½ç®¡ç†æ— æ³•å¯åŠ¨ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ã€‚")
            self.current_max_positions = self.params.get('MIN_POSITIONS_COUNT', 1)
            self.final_nominal_principal = Decimal('0.0') # å¯¼è‡´æ— æ³•ä¹°å…¥
            return
 
        # 2. è·å–T-1æ—¥çš„å¸‚åœºçŠ¶æ€M(t)
        market_regime_M = self._get_market_regime_M(t_minus_1_date)
        logger.info(f"è·å–åˆ° T-1 ({t_minus_1_date}) çš„ M(t) = {market_regime_M:.4f}")
 
        # 3. è®¡ç®—å½“æ—¥åŠ¨æ€æœ€å¤§æŒä»“æ•°
        self.current_max_positions = self._calculate_dynamic_max_positions(market_regime_M)
        
        # 4. è®¡ç®—å½“æ—¥åŠ¨æ€å•ä½åä¹‰æœ¬é‡‘
        self.final_nominal_principal = self._calculate_dynamic_nominal_principal(market_regime_M, t_minus_1_date)
 
    def _get_market_regime_M(self, t_minus_1_date: date) -> Decimal:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        ä»æ•°æ®åº“è·å–æŒ‡å®šæ—¥æœŸçš„ M(t) å€¼ã€‚
        """
        try:
            m_value_record = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                trade_date=t_minus_1_date,
                factor_code_id='dynamic_M_VALUE'
            )
            return m_value_record.raw_value
        except DailyFactorValues.DoesNotExist:
            logger.error(f"ä¸¥é‡è­¦å‘Š: æ— æ³•åœ¨ {t_minus_1_date} æ‰¾åˆ°å¸‚åœºçŠ¶æ€M(t)å€¼ï¼å°†ä½¿ç”¨æœ€ä¿å®ˆçš„ä¸­æ€§å€¼0.0è¿›è¡Œè®¡ç®—ã€‚")
            return Decimal('0.0')
 
    def _calculate_dynamic_max_positions(self, M_t: Decimal) -> int:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        æ ¹æ®M(t)è®¡ç®—åŠ¨æ€æœ€å¤§æŒä»“æ•° Current_Max_Positionsã€‚
        """
        S_min_pos = self.params['RISK_ADJ_POS_FLOOR_PCT']
        
        # i. è®¡ç®—æ€»ä»“ä½æ•°é£é™©ç¼©æ”¾å› å­ S_pos(M(t))
        S_pos = S_min_pos + (1 - S_min_pos) * (M_t + 1) / 2
        
        # ii. è®¡ç®—ç†è®ºæœ€å¤§ä»“ä½æ•°
        base_max_pos = self.params['ORIGINAL_MAX_POSITIONS']
        theoretical_max = Decimal(base_max_pos) * S_pos
        
        # iii. å–æ•´å¹¶åº”ç”¨ä¸‹é™
        min_pos_count = self.params['MIN_POSITIONS_COUNT']
        current_max_positions = max(min_pos_count, int(theoretical_max.to_integral_value(rounding='ROUND_FLOOR')))
        
        logger.debug(f"åŠ¨æ€æŒä»“æ•°è®¡ç®—: S_pos={S_pos:.4f}, ç†è´¢æŒä»“={theoretical_max:.2f}, æœ€ç»ˆå–æ•´={current_max_positions}")
        return current_max_positions
 
    def _calculate_dynamic_nominal_principal(self, M_t: Decimal, t_minus_1_date: date) -> Decimal:
        """
        ã€å…¨æ–°æ–¹æ³•ã€‘
        æ ¹æ®M(t)è®¡ç®—åŠ¨æ€å•ä½åä¹‰æœ¬é‡‘ Final_Nominal_Principalã€‚
        """
        # i. è·å–å½“å‰æ€»èµ„äº§
        cash_balance = self.handler.get_available_balance()
        positions_market_value = Decimal('0.0')
        open_positions = Position.objects.filter(status=Position.StatusChoices.OPEN)
        if open_positions.exists():
            for pos in open_positions:
                try:
                    quote = DailyQuotes.objects.get(stock_code_id=pos.stock_code_id, trade_date=t_minus_1_date)
                    positions_market_value += quote.close * pos.quantity
                except DailyQuotes.DoesNotExist:
                    positions_market_value += pos.entry_price * pos.quantity
        
        total_assets = cash_balance + positions_market_value
        logger.debug(f"æ€»èµ„äº§è®¡ç®—: ç°é‡‘{cash_balance:.2f} + æŒä»“å¸‚å€¼{positions_market_value:.2f} = {total_assets:.2f}")
 
        # ii. è®¡ç®—åŸºå‡†å•ä½åä¹‰æœ¬é‡‘
        base_max_pos = self.params['ORIGINAL_MAX_POSITIONS']
        if base_max_pos <= 0: return Decimal('0.0')
        baseline_unit_principal = total_assets / Decimal(base_max_pos)
        
        # iii. è®¡ç®—å•ä½åä¹‰æœ¬é‡‘é£é™©ç¼©æ”¾å› å­ S_cap(M(t))
        S_min_cap = self.params['RISK_ADJ_CAPITAL_FLOOR_PCT']
        S_cap = S_min_cap + (1 - S_min_cap) * (M_t + 1) / 2
        S_cap=1
        # iv. è®¡ç®—åŠ¨æ€è°ƒæ•´åçš„åä¹‰æœ¬é‡‘
        adjusted_unit_principal = baseline_unit_principal * S_cap
        
        logger.debug(f"åŠ¨æ€åä¹‰æœ¬é‡‘è®¡ç®—: åŸºå‡†æœ¬é‡‘={baseline_unit_principal:.2f}, S_cap={S_cap:.4f}, è°ƒæ•´åæœ¬é‡‘={adjusted_unit_principal:.2f}")
        
        # v. ç¡®å®šæœ€ç»ˆä¸‹å•åä¹‰æœ¬é‡‘ - æ³¨æ„ï¼šä¸å¯ç”¨ç°é‡‘çš„æ¯”è¾ƒå°†åœ¨ä¸‹å•æ—¶è¿›è¡Œ
        return adjusted_unit_principal

    def _log_to_db(self, level: str, message: str):
        """è¾…åŠ©æ–¹æ³•ï¼šå°†æ—¥å¿—å†™å…¥æ•°æ®åº“"""
        # åœ¨é«˜é¢‘å›æµ‹ä¸­å¯ä»¥æ³¨é‡Šæ‰æ­¤æ–¹æ³•ä»¥æé«˜æ€§èƒ½
        # SystemLog.objects.create(
        #     log_level=level,
        #     module_name=self.MODULE_NAME,
        #     message=message
        # )
        pass
    def _find_relevant_plan_date(self) -> date | None:
        # 1. è®¡ç®—æŸ¥è¯¢çš„èµ·å§‹æ—¥æœŸ
        start_date = self.execution_date - timedelta(days=self.MAX_PLAN_LOOKBACK_DAYS - 1)
        
        # 2. æ‰§è¡Œä¸€æ¬¡æ•°æ®åº“æŸ¥è¯¢
        latest_plan = DailyTradingPlan.objects.filter(
            plan_date__gte=start_date,  # gte = greater than or equal to (å¤§äºç­‰äº)
            plan_date__lte=self.execution_date, # lte = less than or equal to (å°äºç­‰äº)
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('-plan_date').first() # æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼Œå¹¶å–ç¬¬ä¸€ä¸ª
    
        # 3. å¤„ç†æŸ¥è¯¢ç»“æœ
        if latest_plan:
            found_date = latest_plan.plan_date
            if found_date != self.execution_date:
                logger.info(f"æ‰§è¡Œæ—¥ {self.execution_date} æ— é¢„æ¡ˆï¼Œå›æº¯æ‰¾åˆ°å¾…æ‰§è¡Œé¢„æ¡ˆï¼Œå…¶ç”Ÿæˆæ—¥æœŸä¸º: {found_date}")
            else:
                logger.debug(f"æ‰¾åˆ°å½“å¤© {found_date} çš„å¾…æ‰§è¡Œé¢„æ¡ˆã€‚")
            return found_date
        
        # å¦‚æœæŸ¥è¯¢ç»“æœä¸ºç©º
        logger.warning(f"åœ¨è¿‡å» {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…ï¼ˆä» {self.execution_date} å¼€å§‹å›æº¯ï¼‰æœªæ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚")
        return None
    def _load_strategy_parameters(self) -> dict:
        """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç­–ç•¥å‚æ•°åˆ°å†…å­˜"""
        params = {}
        # å®šä¹‰éœ€è¦åŠ è½½çš„å‚æ•°åŠå…¶é»˜è®¤å€¼
        # æ³¨æ„ï¼šè¿™é‡Œçš„é”®ååº”ä¸ initialize_strategy_parameters ä¸­å®šä¹‰çš„å®Œå…¨ä¸€è‡´
        required_params = {
            # é€šç”¨å‚æ•°
            #'MAX_POSITIONS': '3',
            'MAX_CAPITAL_PER_POSITION': '20000.00',
            'k_slip': '0.002',
            'lookback_atr': '14',
            # æ–°ç‰ˆåŠ¨æ€é£é™©å‚æ•°
            'risk_adj_tp_pct_min': '0.07',
            'risk_adj_tp_pct_max': '0.15',
            'risk_adj_sl_atr_min': '1.2',
            'risk_adj_sl_atr_max': '2.2',
            'risk_adj_max_loss_pct': '0.08',
            # å…¨æ–°åŠ¨æ€ä»“ä½å‚æ•°
            'ORIGINAL_MAX_POSITIONS': '5',
            'MIN_POSITIONS_COUNT': '1',
            'RISK_ADJ_POS_FLOOR_PCT': '0.2',
            'RISK_ADJ_CAPITAL_FLOOR_PCT': '0.5',
        }
      
        db_params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
      
        for key, default_value in required_params.items():
            value = db_params.get(key, Decimal(str(default_value)))
            if key in ['ORIGINAL_MAX_POSITIONS', 'MIN_POSITIONS_COUNT', 'lookback_atr']:
                params[key] = int(value)
            else:
                params[key] = Decimal(str(value))
        return params

    # --- æš´éœ²ç»™å¤–éƒ¨è°ƒåº¦çš„æ ¸å¿ƒå‡½æ•° ---

    def adjust_trading_plan_daily(self):
        """
        å‡½æ•°ä¸€ï¼šæ‰§è¡Œæ¯æ—¥äº¤æ˜“é¢„æ¡ˆå†è°ƒæ•´ (é€»è¾‘ä¸å˜)ã€‚
        """
        logger.debug(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„äº¤æ˜“é¢„æ¡ˆäºŒæ¬¡ç­›é€‰...")
        relevant_plan_date = self._find_relevant_plan_date()
        if not relevant_plan_date:
            msg = f"åœ¨ {self.execution_date} åŠä¹‹å‰ {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.debug(msg)
            self._log_to_db('WARNING', msg)
            return
        plans_today = DailyTradingPlan.objects.filter(
            plan_date=relevant_plan_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')

        if not plans_today.exists():
            msg = f"åœ¨ {self.execution_date} æ²¡æœ‰æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.debug(msg)
            self._log_to_db('WARNING', msg)
            return

        plans_to_cancel = []
        for plan in plans_today:
            try:
                open_price = self.handler.get_opening_price(plan.stock_code_id)
                if open_price <= 0:
                    logger.warning(f"è‚¡ç¥¨ {plan.stock_code_id} å¼€ç›˜ä»·ä¸º0æˆ–æ— æ•ˆï¼Œè§†ä¸ºä¸ç¬¦åˆæ¡ä»¶ã€‚")
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)
                    continue

                if not (plan.miop <= open_price <= plan.maop):
                    msg = (f"é¢„æ¡ˆ {plan.stock_code_id} (Rank:{plan.rank}) å¼€ç›˜ä»· {open_price} "
                           f"ä¸åœ¨åŒºé—´ [{plan.miop}, {plan.maop}] å†…ï¼Œå·²ä½œåºŸã€‚")
                    logger.debug(msg)
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)

            except Exception as e:
                msg = f"è·å– {plan.stock_code_id} å¼€ç›˜ä»·æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œè¯¥é¢„æ¡ˆä½œåºŸã€‚"
                logger.error(msg)
                self._log_to_db('ERROR', msg)
                plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                plans_to_cancel.append(plan)

        if plans_to_cancel:
            with transaction.atomic():
                DailyTradingPlan.objects.bulk_update(plans_to_cancel, ['status'])
            logger.debug(f"æˆåŠŸä½œåºŸ {len(plans_to_cancel)} æ¡ä¸ç¬¦åˆå¼€ç›˜æ¡ä»¶çš„äº¤æ˜“é¢„æ¡ˆã€‚")
        else:
            logger.debug("æ‰€æœ‰å¾…æ‰§è¡Œé¢„æ¡ˆå‡ç¬¦åˆå¼€ç›˜ä»·æ¡ä»¶ã€‚")

    def execute_orders(self):
        """
        å‡½æ•°äºŒï¼šè¿›è¡Œä¸‹å• (é€»è¾‘ä¸å˜)ã€‚
        """
        logger.debug(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„ä¸‹å•æµç¨‹...")

        open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
        # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„å½“æ—¥æœ€å¤§æŒä»“æ•°
        remaining_slots = self.current_max_positions - open_positions_count

        if remaining_slots <= 0:
            msg = f"å½“å‰æŒä»“æ•° {open_positions_count} å·²è¾¾æˆ–è¶…è¿‡å½“æ—¥åŠ¨æ€ä¸Šé™ {self.current_max_positions}ï¼Œä¸è¿›è¡Œä¹°å…¥ã€‚"
            logger.debug(msg)
            self._log_to_db('WARNING', msg)
            return

        relevant_plan_date = self._find_relevant_plan_date()
        if not relevant_plan_date:
            msg = f"åœ¨ {self.execution_date} åŠä¹‹å‰ {self.MAX_PLAN_LOOKBACK_DAYS} å¤©å†…æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆå¯ä¾›ä¸‹å•ã€‚"
            logger.debug(msg)
            self._log_to_db('INFO', msg)
            return

        candidates = DailyTradingPlan.objects.filter(
            plan_date=relevant_plan_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')
 
        if not candidates.exists():
            msg = f"åœ¨ {self.execution_date} æ— ç¬¦åˆæ¡ä»¶çš„ä¹°å…¥æ ‡çš„ã€‚"
            logger.debug(msg)
            self._log_to_db('INFO', msg)
            return

        for candidate in candidates:
            try:
                stock_code = candidate.stock_code_id
                open_price = self.handler.get_opening_price(stock_code)
              
                k_slip = self.params['k_slip']
                limit_price = (open_price * (Decimal('1.0') + k_slip)).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
 
                # è·å–ä¸‹å•æ—¶æœ€ç»ˆçš„åä¹‰æœ¬é‡‘
                available_balance = self.handler.get_available_balance()
                
                # self.final_nominal_principal æ˜¯å·²æŒ‰M(t)è°ƒæ•´è¿‡çš„å€¼
                # å†ç»“åˆç¡¬æ€§é£æ§å’ŒæµåŠ¨æ€§çº¦æŸ
                nominal_principal = min(
                    self.final_nominal_principal, 
                    self.params['MAX_CAPITAL_PER_POSITION'], 
                    available_balance
                )
                
                logger.debug(f"æ ‡çš„ {stock_code}: åŠ¨æ€è°ƒæ•´åæœ¬é‡‘={self.final_nominal_principal:.2f}, "
                             f"å•ä»“ä¸Šé™={self.params['MAX_CAPITAL_PER_POSITION']:.2f}, "
                             f"å¯ç”¨ç°é‡‘={available_balance:.2f}. "
                             f"æœ€ç»ˆåä¹‰æœ¬é‡‘={nominal_principal:.2f}")
 
                if limit_price <= 0:
                    logger.debug(f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„ä¸‹å•é™ä»·æ— æ•ˆï¼ˆ{limit_price}ï¼‰ï¼Œè·³è¿‡ã€‚")
                    continue
 
                shares_to_buy = int(nominal_principal / limit_price)
                quantity = (shares_to_buy // 100) * 100
 
                if quantity < 100:
                    msg = (f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„åä¹‰æœ¬é‡‘ {nominal_principal:.2f} ä¸è¶³ä»¥è´­ä¹°ä¸€æ‰‹ï¼ˆ100è‚¡ï¼‰ã€‚")
                    logger.warning(msg)
                    self._log_to_db('WARNING', msg)
                    continue
 
                msg = (f"ç¡®å®šå”¯ä¸€ä¹°å…¥æ ‡çš„: {candidate.stock_code.stock_name}({stock_code}) (Rank:{candidate.rank})ã€‚ "
                       f"è®¡åˆ’ä»¥é™ä»· {limit_price} ä¹°å…¥ {quantity} è‚¡ã€‚")
                logger.info(msg)
                self._log_to_db('INFO', msg)
              
                self.handler.place_buy_order(stock_code, limit_price, quantity)
              
                candidate.status = DailyTradingPlan.StatusChoices.EXECUTED
                candidate.save()
 
                return
 
            except Exception as e:
                msg = f"å¤„ç†å€™é€‰è‚¡ {candidate.stock_code_id} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
                logger.error(msg, exc_info=True)
                self._log_to_db('CRITICAL', msg)
                continue
 
        logger.debug(f"å·²å°è¯•æ‰€æœ‰ {len(candidates)} ä¸ªå€™é€‰æ ‡çš„ï¼Œå‡æœªæˆåŠŸä¹°å…¥ã€‚")

    def calculate_stop_profit_loss(self, trade_id: int):
        """
        å‡½æ•°ä¸‰ï¼šæ­¢ç›ˆæ­¢æŸåŒºé—´è®¡ç®— (V2.0 é‡æ„ç‰ˆ)ã€‚
        åœ¨è®¢å•æˆäº¤åï¼Œä¸ºæ–°æŒä»“è®¡ç®—å¹¶æ›´æ–°ç”±M(t)é©±åŠ¨çš„åŠ¨æ€æ­¢ç›ˆæ­¢æŸä»·ã€‚
 
        :param trade_id: å·²æˆäº¤çš„ä¹°å…¥äº¤æ˜“åœ¨ tb_trade_log ä¸­çš„å”¯ä¸€IDã€‚
        """
        logger.debug(f"å¼€å§‹ä¸º trade_id={trade_id} è®¡ç®—åŠ¨æ€æ­¢ç›ˆæ­¢æŸåŒºé—´...")
        try:
            with transaction.atomic():
                # 1. è·å–äº¤æ˜“å’ŒæŒä»“ä¿¡æ¯
                trade_log = TradeLog.objects.select_for_update().get(
                    trade_id=trade_id,
                    trade_type=TradeLog.TradeTypeChoices.BUY,
                    status=TradeLog.StatusChoices.FILLED
                )
                position = Position.objects.select_for_update().get(pk=trade_log.position_id)
 
                if position.current_stop_loss > 0 and position.current_take_profit > 0:
                    logger.warning(f"Position ID {position.position_id} ä¼¼ä¹å·²è®¡ç®—è¿‡æ­¢ç›ˆæ­¢æŸï¼Œå°†è·³è¿‡ã€‚")
                    return
 
                stock_code = trade_log.stock_code_id
                aep = trade_log.price
                buy_date = trade_log.trade_datetime.date()
                t_minus_1_date = DailyQuotes.objects.filter(trade_date__lt=buy_date).latest('trade_date').trade_date
              
                # 2. è·å–è®¡ç®—æ‰€éœ€çš„æ ¸å¿ƒæ•°æ®ï¼šM(t) å’Œ ATR
                # 2.1 è·å– T-1 æ—¥çš„å¸‚åœºçŠ¶æ€ M(t)
                try:
                    m_value_record = DailyFactorValues.objects.get(
                        stock_code_id=MARKET_INDICATOR_CODE,
                        trade_date=t_minus_1_date,
                        factor_code_id='dynamic_M_VALUE'
                    )
                    market_regime_M = m_value_record.raw_value
                except DailyFactorValues.DoesNotExist:
                    logger.error(f"æ— æ³•æ‰¾åˆ° {t_minus_1_date} çš„å¸‚åœºçŠ¶æ€M(t)å€¼ï¼å°†ä½¿ç”¨ä¸­æ€§å€¼0.0è¿›è¡Œè®¡ç®—ã€‚")
                    market_regime_M = Decimal('0.0')

                # 2.2 è·å–è®¡ç®— ATR æ‰€éœ€çš„å†å²è¡Œæƒ…
                lookback_days = self.params['lookback_atr'] + 50 # å¢åŠ buffer
                start_date_for_calc = t_minus_1_date - timedelta(days=lookback_days * 2)
 
                quotes_qs = DailyQuotes.objects.filter(
                    stock_code_id=stock_code,
                    trade_date__gte=start_date_for_calc,
                    trade_date__lte=t_minus_1_date
                ).order_by('trade_date')
 
                if len(quotes_qs) < self.params['lookback_atr']:
                    raise ValueError(f"è‚¡ç¥¨ {stock_code} åœ¨ {t_minus_1_date} å‰çš„å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ATRã€‚")
 
                df = pd.DataFrame.from_records(quotes_qs.values('high', 'low', 'close'))
                df = df.astype(float)
 
                atr_series = ta.atr(df['high'], df['low'], df['close'], length=self.params['lookback_atr'])
                atr_14_buy = Decimal(str(atr_series.iloc[-1])) if not atr_series.empty else Decimal('0.0')

                # 3. è®¡ç®—åŠ¨æ€æ­¢ç›ˆä»· g_new(y)
                tp_min = self.params['risk_adj_tp_pct_min']
                tp_max = self.params['risk_adj_tp_pct_max']
                tp_pct = tp_min + (tp_max - tp_min) * (market_regime_M + 1) / 2
                take_profit_price = aep * (1 + tp_pct)

                # 4. è®¡ç®—è‡ªé€‚åº”æ­¢æŸä»· h_new(z)
                # 4.1 è®¡ç®—åŠ¨æ€ATRä¹˜æ•° k_h(M(t))
                kh_min = self.params['risk_adj_sl_atr_min']
                kh_max = self.params['risk_adj_sl_atr_max']
                k_h_dynamic = kh_min + (kh_max - kh_min) * (market_regime_M + 1) / 2
                
                # 4.2 è®¡ç®—åŠ¨æ€æ³¢åŠ¨æ­¢æŸçº¿
                z1_dynamic_atr = aep - k_h_dynamic * atr_14_buy

                # 4.3 è®¡ç®—ç»å¯¹æœ€å¤§äºæŸåº•çº¿
                z2_max_loss = aep * (1 - self.params['risk_adj_max_loss_pct'])
              
                # 4.4 å–æœ€ä¸¥æ ¼çš„æ­¢æŸä½ï¼ˆä»·æ ¼æœ€é«˜è€…ï¼‰
                stop_loss_price = max(z1_dynamic_atr, z2_max_loss)
              
                logger.debug(f"[{stock_code}] æ­¢æŸçº¿æ¯”è¾ƒ (åŸºäºM(t)={market_regime_M:.4f}): "
                            f"åŠ¨æ€ATRæ­¢æŸ(ä¹˜æ•°{k_h_dynamic:.2f})={z1_dynamic_atr:.2f}, "
                            f"ç»å¯¹æœ€å¤§äºæŸ={z2_max_loss:.2f}")
 
                # 5. æ›´æ–°æŒä»“ä¿¡æ¯è¡¨
                position.current_take_profit = take_profit_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                position.current_stop_loss = stop_loss_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                
                # æœ€ç»ˆæ ¡éªŒï¼Œé˜²æ­¢å‡ºç°æç«¯æƒ…å†µ
                if position.current_stop_loss >= position.current_take_profit:
                    logger.critical(f"ä¸¥é‡é€»è¾‘é”™è¯¯ï¼è®¡ç®—åæ­¢æŸä»·({position.current_stop_loss})ä»é«˜äºæˆ–ç­‰äºæ­¢ç›ˆä»·({position.current_take_profit})ã€‚å°†ä½¿ç”¨æœ€å¤§äºæŸåº•çº¿ä½œä¸ºæ­¢æŸã€‚")
                    position.current_stop_loss = z2_max_loss.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)

                position.save(update_fields=['current_take_profit', 'current_stop_loss'])
                loss_pct = (aep - position.current_stop_loss) / aep if aep > 0 else Decimal('0.0')
                msg = (f"æˆåŠŸè®¡ç®—å¹¶æ›´æ–° Position ID {position.position_id} ({stock_code}) çš„åŠ¨æ€é£æ§ä»·æ ¼: "
                       f"è´­å…¥ä»·={aep:.2f}, æ­¢ç›ˆä»·={position.current_take_profit:.2f} (ç›®æ ‡æ”¶ç›Šç‡ {tp_pct:.2%}), "
                       f"æ­¢æŸä»·={position.current_stop_loss:.2f} (æœ€å¤§å®¹å¿äºæŸ {loss_pct:.2%})")
                logger.info(msg)
                self._log_to_db('INFO', msg)
 
        except TradeLog.DoesNotExist:
            logger.error(f"Trade ID {trade_id} ä¸å­˜åœ¨æˆ–ä¸æ»¡è¶³è®¡ç®—æ¡ä»¶ï¼ˆéä¹°å…¥/æœªæˆäº¤ï¼‰ã€‚")
        except Position.DoesNotExist:
            logger.error(f"ä¸ Trade ID {trade_id} å…³è”çš„ Position ä¸å­˜åœ¨ã€‚")
        except Exception as e:
            msg = f"ä¸º Trade ID {trade_id} è®¡ç®—åŠ¨æ€æ­¢ç›ˆæ­¢æŸæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
            logger.critical(msg, exc_info=True)
            self._log_to_db('CRITICAL', msg)
            raise

    # --- å·¥å…·å‡½æ•° ---

    @staticmethod
    def initialize_strategy_parameters():
        """
        å·¥å…·å‡½æ•°ï¼šåˆå§‹åŒ–æœ¬æ¨¡å—æ‰€éœ€çš„ç­–ç•¥å‚æ•°åˆ°æ•°æ®åº“ã€‚
        è¿™æ˜¯ä¸€ä¸ªå¹‚ç­‰æ“ä½œï¼Œå¯ä»¥å®‰å…¨åœ°é‡å¤è¿è¡Œã€‚
        """
        logger.info("å¼€å§‹åˆå§‹åŒ–[å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—-åŠ¨æ€é£é™©ç‰ˆ]çš„ç­–ç•¥å‚æ•°...")

        params_to_define = {
            # é€šç”¨å‚æ•°
            #'MAX_POSITIONS': {'value': '3', 'group': 'POSITION_MGMT', 'desc': 'æœ€å¤§å¯å…·å¤‡çš„æ€»ä»“ä½æ•°'},
            'MAX_CAPITAL_PER_POSITION': {'value': '20000.00', 'group': 'POSITION_MGMT', 'desc': 'æ¯ä»“æœ€å¤§æŠ•å…¥èµ„é‡‘æ•°(å…ƒ)'},
            'k_slip': {'value': '0.002', 'group': 'ORDER_EXEC', 'desc': 'ä¸‹å•æ»‘ç‚¹ç³»æ•°, ç”¨äºè®¡ç®—é™ä»·å•ä»·æ ¼'},
            'lookback_atr': {'value': '14', 'group': 'INDICATORS', 'desc': 'ATRè®¡ç®—å‘¨æœŸ'},
            
            # æ–°ç‰ˆ M(t) é©±åŠ¨çš„åŠ¨æ€é£é™©å‚æ•°
            'risk_adj_tp_pct_min': {'value': '0.07', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å°æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯” (ç†Šå¸‚)'},
            'risk_adj_tp_pct_max': {'value': '0.15', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å¤§æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯” (ç‰›å¸‚)'},
            'risk_adj_sl_atr_min': {'value': '1.2', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å°ATRæ­¢æŸä¹˜æ•° (ç†Šå¸‚)'},
            'risk_adj_sl_atr_max': {'value': '2.2', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-æœ€å¤§ATRæ­¢æŸä¹˜æ•° (ç‰›å¸‚)'},
            'risk_adj_max_loss_pct': {'value': '0.08', 'group': 'RISK_ADJUSTED', 'desc': 'M(t)é©±åŠ¨-ç»å¯¹æœ€å¤§äºæŸç™¾åˆ†æ¯”'},
            # --- å…¨æ–°åŠ¨æ€ä»“ä½ç®¡ç†å‚æ•° ---
            'ORIGINAL_MAX_POSITIONS': {'value': '5', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘ç­–ç•¥åŸºå‡†æœ€å¤§æŒä»“æ•°'},
            'MIN_POSITIONS_COUNT': {'value': '1', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘æœ€å°æŒä»“æ•°ç¡¬ä¸‹é™'},
            'RISK_ADJ_POS_FLOOR_PCT': {'value': '0.1', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘æ€»ä»“ä½æ•°ç¼©æ”¾å› å­çš„ä¸‹é™ S_min_pos (ä¾‹å¦‚0.4ä»£è¡¨æœ€å·®æƒ…å†µæŒæœ‰åŸºå‡†çš„40%)'},
            'RISK_ADJ_CAPITAL_FLOOR_PCT': {'value': '0.6', 'group': 'DYNAMIC_POS_MGMT', 'desc': 'ã€åŠ¨æ€ä»“ä½ã€‘å•ä½åä¹‰æœ¬é‡‘ç¼©æ”¾å› å­çš„ä¸‹é™ S_min_cap (ä¾‹å¦‚0.6ä»£è¡¨æœ€å·®æƒ…å†µæŠ•å…¥åŸºå‡†çš„60%)'}
        }

        with transaction.atomic():
            for name, data in params_to_define.items():
                StrategyParameters.objects.update_or_create(
                    param_name=name,
                    defaults={
                        'param_value': Decimal(data['value']),
                        'group_name': data['group'],
                        'description': data['desc']
                    }
                )
      
        logger.info(f"æˆåŠŸåˆå§‹åŒ–/æ›´æ–° {len(params_to_define)} ä¸ªåŠ¨æ€é£é™©ç­–ç•¥å‚æ•°ã€‚")

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\decision_order_service_old.py####
# trade_manager/service/decision_order_service.py

import logging
from datetime import date, timedelta
from decimal import Decimal, ROUND_HALF_UP
import pandas as pd
import pandas_ta as ta

from django.db import transaction
from django.utils import timezone

from common.models import (
    DailyTradingPlan,
    Position,
    TradeLog,
    StrategyParameters,
    DailyQuotes,
    SystemLog
)
from .trade_handler import ITradeHandler

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class DecisionOrderService:
    """
    å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—ã€‚

    è¯¥æœåŠ¡è´Ÿè´£åœ¨Tæ—¥å¼€ç›˜åçš„é»„é‡‘æ—¶é—´å†…ï¼Œæ ¹æ®é¢„æ¡ˆã€å®é™…å¼€ç›˜ä»·å’Œè´¦æˆ·çŠ¶æ€ï¼Œ
    åšå‡ºæœ€ç»ˆçš„ä¹°å…¥å†³ç­–ï¼Œå¹¶æ‰§è¡Œä¸‹å•ã€‚åŒæ—¶ï¼Œå®ƒä¹Ÿæä¾›äº†åœ¨è®¢å•æˆäº¤åè®¡ç®—
    æ­¢ç›ˆæ­¢æŸåŒºé—´çš„åŠŸèƒ½ã€‚
    """
    MODULE_NAME = 'å¼€ç›˜å†³ç­–ä¸ä¸‹å•'

    def __init__(self, handler: ITradeHandler, execution_date: date = None):
        """
        åˆå§‹åŒ–æœåŠ¡ã€‚

        :param handler: ä¸€ä¸ªå®ç°äº† ITradeHandler æ¥å£çš„å®ä¾‹ï¼Œç”¨äºä¸äº¤æ˜“ç¯å¢ƒäº¤äº’ã€‚
        :param execution_date: Tæ—¥ï¼Œå³æ‰§è¡Œå†³ç­–çš„æ—¥æœŸã€‚å¦‚æœä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºå½“å¤©ã€‚
                               æ­¤å‚æ•°ä¸ºå›æµ‹æ¨¡å—æä¾›äº†è®¾ç½®æ¨¡æ‹Ÿæ—¥æœŸçš„å…¥å£ã€‚
        """
        if not isinstance(handler, ITradeHandler):
            raise TypeError("ä¼ å…¥çš„ handler å¿…é¡»æ˜¯ ITradeHandler çš„ä¸€ä¸ªå®ä¾‹ã€‚")
        
        self.handler = handler
        self.execution_date = execution_date if execution_date else date.today()
        self.params = self._load_strategy_parameters()
        
        logger.debug(f"[{self.MODULE_NAME}] æœåŠ¡åˆå§‹åŒ–ã€‚æ‰§è¡ŒTæ—¥: {self.execution_date}")
        logger.debug(f"ç­–ç•¥å‚æ•°åŠ è½½æˆåŠŸ: {self.params}")

    def _log_to_db(self, level: str, message: str):
        """è¾…åŠ©æ–¹æ³•ï¼šå°†æ—¥å¿—å†™å…¥æ•°æ®åº“"""
        SystemLog.objects.create(
            log_level=level,
            module_name=self.MODULE_NAME,
            message=message
        )

    def _load_strategy_parameters(self) -> dict:
        """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰ç­–ç•¥å‚æ•°åˆ°å†…å­˜"""
        params = {}
        # å®šä¹‰éœ€è¦åŠ è½½çš„å‚æ•°åŠå…¶é»˜è®¤å€¼ï¼Œä»¥é˜²æ•°æ®åº“ä¸­æ²¡æœ‰
        required_params = {
            'MAX_POSITIONS': 2,
            'MAX_CAPITAL_PER_POSITION': 25000.00,
            'k_slip': 0.002,
            'Base_Target': 0.07,
            'k_g1': 1.5,
            'Max_Target': 0.20,
            'k_h1': 2.0,
            'k_h2': 3.0,
            'Max_Loss_Percent': 0.08,
            'lookback_atr': 14,
            'lookback_adx': 14,
            'lookback_ma20': 20,
            'param_adx_threshold': 25
        }
        
        db_params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
        
        for key, default_value in required_params.items():
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„å€¼ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
            value = db_params.get(key, Decimal(str(default_value)))
            # å°†éœ€è¦æ•´æ•°çš„å‚æ•°è½¬æ¢ä¸ºint
            if key in ['MAX_POSITIONS', 'lookback_atr', 'lookback_adx', 'lookback_ma20', 'param_adx_threshold']:
                params[key] = int(value)
            else:
                params[key] = Decimal(str(value))
        return params

    # --- æš´éœ²ç»™å¤–éƒ¨è°ƒåº¦çš„æ ¸å¿ƒå‡½æ•° ---

    def adjust_trading_plan_daily(self):
        """
        å‡½æ•°ä¸€ï¼šæ‰§è¡Œæ¯æ—¥äº¤æ˜“é¢„æ¡ˆå†è°ƒæ•´ã€‚
        æ ¹æ®å®é™…å¼€ç›˜ä»·ä¸å‰©ä½™ä»“ä½è¿›è¡ŒäºŒæ¬¡ç­›é€‰ï¼Œå…³é—­ä¸ä¼šè¢«é€‰æ‹©çš„äº¤æ˜“é¢„æ¡ˆã€‚
        """
        logger.debug(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„äº¤æ˜“é¢„æ¡ˆäºŒæ¬¡ç­›é€‰...")
        
        plans_today = DailyTradingPlan.objects.filter(
            plan_date=self.execution_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')

        if not plans_today.exists():
            msg = f"åœ¨ {self.execution_date} æ²¡æœ‰æ‰¾åˆ°å¾…æ‰§è¡Œçš„äº¤æ˜“é¢„æ¡ˆã€‚"
            logger.warning(msg)
            self._log_to_db('WARNING', msg)
            return

        plans_to_cancel = []
        for plan in plans_today:
            try:
                open_price = self.handler.get_opening_price(plan.stock_code)
                if open_price <= 0:
                    logger.warning(f"è‚¡ç¥¨ {plan.stock_code} å¼€ç›˜ä»·ä¸º0æˆ–æ— æ•ˆï¼Œè§†ä¸ºä¸ç¬¦åˆæ¡ä»¶ã€‚")
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)
                    continue

                if not (plan.miop <= open_price <= plan.maop):
                    msg = (f"é¢„æ¡ˆ {plan.stock_code} (Rank:{plan.rank}) å¼€ç›˜ä»· {open_price} "
                           f"ä¸åœ¨åŒºé—´ [{plan.miop}, {plan.maop}] å†…ï¼Œå·²ä½œåºŸã€‚")
                    logger.debug(msg)
                    plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                    plans_to_cancel.append(plan)

            except Exception as e:
                msg = f"è·å– {plan.stock_code} å¼€ç›˜ä»·æ—¶å‘ç”Ÿé”™è¯¯: {e}ï¼Œè¯¥é¢„æ¡ˆä½œåºŸã€‚"
                logger.error(msg)
                self._log_to_db('ERROR', msg)
                plan.status = DailyTradingPlan.StatusChoices.CANCELLED
                plans_to_cancel.append(plan)

        if plans_to_cancel:
            with transaction.atomic():
                DailyTradingPlan.objects.bulk_update(plans_to_cancel, ['status'])
            logger.info(f"æˆåŠŸä½œåºŸ {len(plans_to_cancel)} æ¡ä¸ç¬¦åˆå¼€ç›˜æ¡ä»¶çš„äº¤æ˜“é¢„æ¡ˆã€‚")
        else:
            logger.info("æ‰€æœ‰å¾…æ‰§è¡Œé¢„æ¡ˆå‡ç¬¦åˆå¼€ç›˜ä»·æ¡ä»¶ã€‚")

    def execute_orders(self):
        """
        å‡½æ•°äºŒï¼šè¿›è¡Œä¸‹å•ã€‚
        è¯»å–é¢„æ¡ˆè¡¨ï¼Œé€‰æ‹©æœ€ä¼˜æ ‡çš„ï¼Œè®¡ç®—ä»“ä½å’Œä»·æ ¼ï¼Œå¹¶è°ƒç”¨å¤„ç†å™¨æ‰§è¡Œä¸‹å•ã€‚
        """
        logger.info(f"å¼€å§‹æ‰§è¡Œ {self.execution_date} çš„ä¸‹å•æµç¨‹...")

        # 1. æ£€æŸ¥å‰©ä½™ä»“ä½
        open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
        remaining_slots = self.params['MAX_POSITIONS'] - open_positions_count

        if remaining_slots <= 0:
            msg = f"å½“å‰æŒä»“æ•° {open_positions_count} å·²è¾¾ä¸Šé™ {self.params['MAX_POSITIONS']}ï¼Œä»Šæ—¥ä¸è¿›è¡Œä¹°å…¥æ“ä½œã€‚"
            logger.warning(msg)
            self._log_to_db('WARNING', msg)
            return

        #2. è·å–æ‰€æœ‰å¾…å¤„ç†çš„å€™é€‰æ ‡çš„
        candidates = DailyTradingPlan.objects.filter(
            plan_date=self.execution_date,
            status=DailyTradingPlan.StatusChoices.PENDING
        ).order_by('rank')
 
        if not candidates.exists():
            msg = f"åœ¨ {self.execution_date} æ— ç¬¦åˆæ¡ä»¶çš„ä¹°å…¥æ ‡çš„ã€‚"
            logger.info(msg)
            self._log_to_db('INFO', msg)
            return

        # 3. éå†æ‰€æœ‰å€™é€‰æ ‡çš„ï¼Œç›´åˆ°æˆåŠŸä¹°å…¥ä¸€ä¸ª
        for candidate in candidates:
            try:
                stock_code = candidate.stock_code
                open_price = self.handler.get_opening_price(stock_code)
                
                # è®¡ç®—ä¸‹å•é™ä»·
                k_slip = self.params['k_slip']
                limit_price = (open_price * (Decimal('1.0') + k_slip)).quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
 
                # è®¡ç®—æœ¬æ¬¡äº¤æ˜“å¯ç”¨èµ„é‡‘
                available_balance = self.handler.get_available_balance()
                capital_per_slot = available_balance / Decimal(remaining_slots)
                nominal_principal = min(capital_per_slot, self.params['MAX_CAPITAL_PER_POSITION'])
 
                # è®¡ç®—è´­å…¥è‚¡æ•°
                if limit_price <= 0:
                    logger.warning(f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„ä¸‹å•é™ä»·æ— æ•ˆï¼ˆ{limit_price}ï¼‰ï¼Œè·³è¿‡ã€‚")
                    continue # å°è¯•ä¸‹ä¸€ä¸ªå€™é€‰
 
                shares_to_buy = int(nominal_principal / limit_price)
                quantity = (shares_to_buy // 100) * 100 # å‘ä¸‹å–æ•´åˆ°100çš„å€æ•°
 
                if quantity < 100:
                    msg = (f"æ ‡çš„ {stock_code}: è®¡ç®—å‡ºçš„åä¹‰æœ¬é‡‘ {nominal_principal:.2f} ä¸è¶³ä»¥è´­ä¹°ä¸€æ‰‹ï¼ˆ100è‚¡ï¼‰ï¼Œ"
                           f"æ‰€éœ€é‡‘é¢çº¦ä¸º {limit_price * 100:.2f}ã€‚æ”¾å¼ƒæœ¬æ¬¡äº¤æ˜“ã€‚")
                    logger.warning(msg)
                    self._log_to_db('WARNING', msg)
                    continue # èµ„é‡‘ä¸è¶³ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå€™é€‰
 
                # 4. æ‰§è¡Œä¸‹å•
                msg = (f"ç¡®å®šå”¯ä¸€ä¹°å…¥æ ‡çš„: {stock_code} (Rank:{candidate.rank})ã€‚ "
                       f"è®¡åˆ’ä»¥é™ä»· {limit_price} ä¹°å…¥ {quantity} è‚¡ã€‚")
                logger.info(msg)
                self._log_to_db('INFO', msg)
                
                self.handler.place_buy_order(stock_code, limit_price, quantity)
                
                # æ ‡è®°é¢„æ¡ˆä¸ºå·²æ‰§è¡Œ
                candidate.status = DailyTradingPlan.StatusChoices.EXECUTED
                candidate.save()
 
                # æˆåŠŸä¹°å…¥åï¼Œç«‹å³é€€å‡ºå‡½æ•°ï¼Œå¤–å±‚å¾ªç¯ä¼šå†³å®šæ˜¯å¦ç»§ç»­ä¹°å…¥ä¸‹ä¸€ä¸ªä»“ä½
                return
 
            except Exception as e:
                msg = f"å¤„ç†å€™é€‰è‚¡ {candidate.stock_code} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"
                logger.error(msg, exc_info=True)
                self._log_to_db('CRITICAL', msg)
                continue # å‘ç”Ÿå¼‚å¸¸ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªå€™é€‰
 
        # å¦‚æœå¾ªç¯æ­£å¸¸ç»“æŸï¼Œè¯´æ˜æ‰€æœ‰å€™é€‰è‚¡éƒ½æ— æ³•ä¹°å…¥
        logger.info(f"å·²å°è¯•æ‰€æœ‰ {len(candidates)} ä¸ªå€™é€‰æ ‡çš„ï¼Œå‡æœªæˆåŠŸä¹°å…¥ã€‚")

    def calculate_stop_profit_loss(self, trade_id: int):
        """
        å‡½æ•°ä¸‰ï¼šæ­¢ç›ˆæ­¢æŸåŒºé—´è®¡ç®— (ä¿®æ­£ç‰ˆ)ã€‚
        åœ¨è®¢å•æˆäº¤åï¼Œä¸ºæ–°æŒä»“è®¡ç®—å¹¶æ›´æ–°åˆå§‹çš„æ­¢ç›ˆæ­¢æŸä»·ã€‚
 
        :param trade_id: å·²æˆäº¤çš„ä¹°å…¥äº¤æ˜“åœ¨ tb_trade_log ä¸­çš„å”¯ä¸€IDã€‚
        """
        logger.info(f"å¼€å§‹ä¸º trade_id={trade_id} è®¡ç®—æ­¢ç›ˆæ­¢æŸåŒºé—´...")
        try:
            with transaction.atomic():
                # 1. è·å–äº¤æ˜“å’ŒæŒä»“ä¿¡æ¯
                trade_log = TradeLog.objects.select_for_update().get(
                    trade_id=trade_id,
                    trade_type=TradeLog.TradeTypeChoices.BUY,
                    status=TradeLog.StatusChoices.FILLED
                )
                position = Position.objects.select_for_update().get(pk=trade_log.position_id)
 
                if position.current_stop_loss > 0:
                    logger.warning(f"Position ID {position.position_id} ä¼¼ä¹å·²è®¡ç®—è¿‡æ­¢ç›ˆæ­¢æŸï¼Œå°†è·³è¿‡ã€‚")
                    return
 
                stock_code = trade_log.stock_code_id
                aep = trade_log.price
                buy_date = trade_log.trade_datetime.date()
                
                # 2. è·å–è®¡ç®—æ‰€éœ€è¡Œæƒ…æ•°æ® (é¿å…æœªæ¥å‡½æ•°)
                lookback_days = self.params['lookback_adx'] + 50
                start_date_for_calc = buy_date - timedelta(days=lookback_days * 2)
                end_date_for_calc = buy_date - timedelta(days=1)
 
                quotes_qs = DailyQuotes.objects.filter(
                    stock_code_id=stock_code,
                    trade_date__gte=start_date_for_calc,
                    trade_date__lte=end_date_for_calc
                ).order_by('trade_date')
 
                if len(quotes_qs) < max(self.params['lookback_atr'], self.params['lookback_adx'], self.params['lookback_ma20']):
                    raise ValueError(f"è‚¡ç¥¨ {stock_code} åœ¨ {end_date_for_calc} å‰çš„å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡ã€‚")
 
                df = pd.DataFrame.from_records(quotes_qs.values('high', 'low', 'close'))
                df = df.astype(float)
 
                # 3. è®¡ç®—æ‰€æœ‰å¿…éœ€æŒ‡æ ‡
                atr_series = ta.atr(df['high'], df['low'], df['close'], length=self.params['lookback_atr'])
                atr_14_buy = Decimal(str(atr_series.iloc[-1]))
 
                ma20_series = ta.sma(df['close'], length=self.params['lookback_ma20'])
                ma20_buy = Decimal(str(ma20_series.iloc[-1]))
 
                adx_df = ta.adx(df['high'], df['low'], df['close'], length=self.params['lookback_adx'])
                adx_14_buy = Decimal(str(adx_df[f'ADX_{self.params["lookback_adx"]}'].iloc[-1]))
 
                # 4. è®¡ç®—æ­¢ç›ˆä»· g(y) - é€»è¾‘ä¸å˜
                profit_margin = min(
                    self.params['Base_Target'] + self.params['k_g1'] * (atr_14_buy / aep),
                    self.params['Max_Target']
                )
                take_profit_price = aep * (Decimal('1.0') + profit_margin)
 
                # 5. è®¡ç®—æ­¢æŸä»· h(z) - ä¸¥æ ¼æŒ‰ç…§éœ€æ±‚æ–‡æ¡£é€»è¾‘
                # 5.1 æ ¹æ®ADXåˆ¤æ–­å¸‚åœºçŠ¶æ€ï¼Œé€‰æ‹©z_final
                adx_threshold = self.params['param_adx_threshold']
                if adx_14_buy > adx_threshold:
                    # è¶‹åŠ¿çŠ¶æ€ï¼Œä½¿ç”¨è¾ƒçª„çš„ATRä¹˜æ•°
                    z_final = aep - self.params['k_h1'] * atr_14_buy
                else:
                    # éœ‡è¡çŠ¶æ€ï¼Œä½¿ç”¨è¾ƒå®½çš„ATRä¹˜æ•°
                    z_final = aep - self.params['k_h2'] * atr_14_buy
 
                # 5.2 è®¡ç®—å…¶ä»–æ­¢æŸçº¿
                z2_technical = ma20_buy
                z3_max_loss = aep * (Decimal('1.0') - self.params['Max_Loss_Percent'])
                
                # 5.3 å–æœ€ä¸¥æ ¼çš„æ­¢æŸä½ï¼ˆä»·æ ¼æœ€é«˜è€…ï¼‰
                stop_loss_price = max(z_final, z2_technical, z3_max_loss)
                
                logger.info(f"[{stock_code}] æ­¢æŸçº¿æ¯”è¾ƒ: è¶‹åŠ¿ä½={z_final:.2f}, æŠ€æœ¯ä½={z2_technical:.2f}, åº•çº¿={z3_max_loss:.2f}")
 
                # 6. æ›´æ–°æŒä»“ä¿¡æ¯è¡¨
                position.current_take_profit = take_profit_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                position.current_stop_loss = stop_loss_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
                position.save(update_fields=['current_take_profit', 'current_stop_loss'])
 
                msg = (f"æˆåŠŸè®¡ç®—å¹¶æ›´æ–° Position ID {position.position_id} ({stock_code}) çš„é£æ§ä»·æ ¼: "
                       f"è´­å…¥ä»·={aep}, æ­¢ç›ˆä»·={position.current_take_profit}, æ­¢ç›ˆç‡={((Decimal('1.0') + profit_margin)*100):.2f}%, æ­¢æŸä»·={position.current_stop_loss}, æ­¢æŸç‡={((position.current_stop_loss/aep)*100):.2f}%")
                logger.info(msg)
                self._log_to_db('INFO', msg)
 
        except TradeLog.DoesNotExist:
            logger.error(f"Trade ID {trade_id} ä¸å­˜åœ¨æˆ–ä¸æ»¡è¶³è®¡ç®—æ¡ä»¶ï¼ˆéä¹°å…¥/æœªæˆäº¤ï¼‰ã€‚")
        except Position.DoesNotExist:
            logger.error(f"ä¸ Trade ID {trade_id} å…³è”çš„ Position ä¸å­˜åœ¨ã€‚")
        except Exception as e:
            msg = f"ä¸º Trade ID {trade_id} è®¡ç®—æ­¢ç›ˆæ­¢æŸæ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}"

    # --- å·¥å…·å‡½æ•° ---

    @staticmethod
    def initialize_strategy_parameters():
        """
        å·¥å…·å‡½æ•°ï¼šåˆå§‹åŒ–æœ¬æ¨¡å—æ‰€éœ€çš„ç­–ç•¥å‚æ•°åˆ°æ•°æ®åº“ã€‚
        è¿™æ˜¯ä¸€ä¸ªå¹‚ç­‰æ“ä½œï¼Œå¯ä»¥å®‰å…¨åœ°é‡å¤è¿è¡Œã€‚
        """
        logger.info("å¼€å§‹åˆå§‹åŒ–[å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—]çš„ç­–ç•¥å‚æ•°...")

        params_to_define = {
            # ä»“ä½ç®¡ç†
            'MAX_POSITIONS': {'value': '2', 'group': 'POSITION_MGMT', 'desc': 'æœ€å¤§å¯å…·å¤‡çš„æ€»ä»“ä½æ•°'},
            'MAX_CAPITAL_PER_POSITION': {'value': '25000.00', 'group': 'POSITION_MGMT', 'desc': 'æ¯ä»“æœ€å¤§æŠ•å…¥èµ„é‡‘æ•°(å…ƒ)'},
            # ä¸‹å•å‚æ•°
            'k_slip': {'value': '0.002', 'group': 'ORDER_EXEC', 'desc': 'ä¸‹å•æ»‘ç‚¹ç³»æ•°, ç”¨äºè®¡ç®—é™ä»·å•ä»·æ ¼'},
            # æ­¢ç›ˆå‚æ•° g(y)
            'Base_Target': {'value': '0.07', 'group': 'TAKE_PROFIT', 'desc': 'åŸºç¡€æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯”'},
            'k_g1': {'value': '1.5', 'group': 'TAKE_PROFIT', 'desc': 'ATRæº¢ä»·ä¹˜æ•°, ç”¨äºåŠ¨æ€è°ƒæ•´æ­¢ç›ˆç›®æ ‡'},
            'Max_Target': {'value': '0.20', 'group': 'TAKE_PROFIT', 'desc': 'æœ€å¤§æ­¢ç›ˆç›®æ ‡ç™¾åˆ†æ¯”ä¸Šé™'},
            # æ­¢æŸå‚æ•° h(z)
            'k_h1': {'value': '2.0', 'group': 'STOP_LOSS', 'desc': 'è¶‹åŠ¿å¸‚ATRæ­¢æŸä¹˜æ•° (ç›˜ä¸­åŠ¨æ€ä½¿ç”¨)'},
            'k_h2': {'value': '3.0', 'group': 'STOP_LOSS', 'desc': 'éœ‡è¡å¸‚ATRæ­¢æŸä¹˜æ•° (ç”¨äºè®¡ç®—åˆå§‹æ­¢æŸ)'},
            'Max_Loss_Percent': {'value': '0.08', 'group': 'STOP_LOSS', 'desc': 'æœ€å¤§å›æ’¤å®¹å¿åº¦(ç»å¯¹äºæŸç™¾åˆ†æ¯”ä¸Šé™)'},
            # æŒ‡æ ‡å‘¨æœŸ
            'lookback_atr': {'value': '14', 'group': 'INDICATORS', 'desc': 'ATRè®¡ç®—å‘¨æœŸ'},
            'lookback_adx': {'value': '14', 'group': 'INDICATORS', 'desc': 'ADXè®¡ç®—å‘¨æœŸ'},
            'lookback_ma20': {'value': '20', 'group': 'INDICATORS', 'desc': 'MA20è®¡ç®—å‘¨æœŸ'},
        }

        with transaction.atomic():
            for name, data in params_to_define.items():
                StrategyParameters.objects.update_or_create(
                    param_name=name,
                    defaults={
                        'param_value': Decimal(data['value']),
                        'group_name': data['group'],
                        'description': data['desc']
                    }
                )
        
        logger.info(f"æˆåŠŸåˆå§‹åŒ–/æ›´æ–° {len(params_to_define)} ä¸ªç­–ç•¥å‚æ•°ã€‚")


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\monitor_exit_service.py####
# trade_manager/service/monitor_exit_service.py

import logging
from datetime import date
from django.utils import timezone
from decimal import Decimal

# å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å‹å’Œæ¥å£
from common.models import Position, TradeLog
from .trade_handler import ITradeHandler

persistent_logger = logging.getLogger(__name__)


class MonitorExitService:
    """
    3.5 - ç›˜ä¸­æŒä»“ç›‘æ§ä¸é€€å‡ºæ¨¡å—

    è¯¥æœåŠ¡è´Ÿè´£åœ¨äº¤æ˜“æ—¶æ®µå†…ï¼Œä»¥å›ºå®šé¢‘ç‡è½®è¯¢ï¼Œç›‘æ§æ‰€æœ‰éå½“æ—¥å»ºä»“çš„æŒä»“ã€‚
    å½“æŒä»“è‚¡ç¥¨çš„å®æ—¶ä»·æ ¼è§¦åŠé¢„è®¾çš„æ­¢ç›ˆæˆ–æ­¢æŸçº¿æ—¶ï¼Œè°ƒç”¨äº¤æ˜“å¤„ç†å™¨æ‰§è¡Œå–å‡ºæ“ä½œã€‚
    """
    MODULE_NAME = 'ç›˜ä¸­æŒä»“ç›‘æ§ä¸é€€å‡º'

    def __init__(self, handler: ITradeHandler,execution_date: date = None):
        """
        åˆå§‹åŒ–ç›‘æ§æœåŠ¡ã€‚

        :param handler: ä¸€ä¸ªå®ç°äº† ITradeHandler æ¥å£çš„å®ä¾‹ï¼Œç”¨äºä¸äº¤æ˜“ç¯å¢ƒäº¤äº’ã€‚
        """
        if not isinstance(handler, ITradeHandler):
            raise TypeError("ä¼ å…¥çš„ handler å¿…é¡»æ˜¯ ITradeHandler çš„ä¸€ä¸ªå®ä¾‹ã€‚")
        
        self.handler = handler
        self.execution_date = execution_date if execution_date else timezone.now().date()
        # ä½¿ç”¨ç‰¹å®šçš„loggerè¿›è¡Œé«˜é¢‘ã€éæŒä¹…åŒ–çš„æ—¥å¿—è®°å½•
        self.logger = persistent_logger

    def monitor_and_exit_positions(self):
        """
        æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æŒä»“ç›‘æ§ä¸é€€å‡ºæ£€æŸ¥ã€‚
        æ­¤å‡½æ•°åº”ç”±ä¸€ä¸ªå®šæ—¶è°ƒåº¦å™¨åœ¨äº¤æ˜“æ—¶æ®µå†…ï¼ˆ09:30:01 - 14:57:00ï¼‰
        ä»¥è®¾å®šçš„é¢‘ç‡åå¤è°ƒç”¨ã€‚
        """
        self.logger.debug(f"[{self.MODULE_NAME}] ä»»åŠ¡å¼€å§‹...")

        # 1. ä»æŒä»“ä¿¡æ¯è¡¨è¯»å–å‡ºentry_datetimeå»ºä»“æˆäº¤æ—¶é—´ä¸ä¸ºä»Šå¤©çš„æŒä»“ä¿¡æ¯
        today = timezone.now().date()
        positions_to_monitor = Position.objects.filter(
            status=Position.StatusChoices.OPEN
        ).exclude(
            entry_datetime__date=self.execution_date
        )

        if not positions_to_monitor.exists():
            self.logger.debug("å½“å‰æ— éœ€è¦ç›‘æ§çš„éš”å¤œæŒä»“ã€‚")
            return

        # 2. å¾ªç¯è°ƒç”¨å¤„ç†å™¨åˆ¤æ–­æ˜¯å¦è¾¾åˆ°äº†æ­¢ç›ˆæ­¢æŸçŠ¶æ€
        for position in positions_to_monitor:
            try:
                # è·å–å®æ—¶ä»·æ ¼
                current_price = self.handler.get_realtime_price(position.stock_code)

                if current_price is None or current_price <= 0:
                    self.logger.debug(f"æ— æ³•è·å– {position.stock_code} çš„æœ‰æ•ˆå®æ—¶ä»·æ ¼ï¼Œè·³è¿‡æœ¬æ¬¡æ£€æŸ¥ã€‚")
                    continue
                
                self.logger.debug(
                    f"ç›‘æ§: {position.stock_code}, "
                    f"å½“å‰ä»·: {current_price}, "
                    f"æ­¢æŸä»·: {position.current_stop_loss}, "
                    f"æ­¢ç›ˆä»·: {position.current_take_profit}"
                )

                # æ£€æŸ¥æ˜¯å¦è§¦å‘æ­¢æŸ
                if current_price <= position.current_stop_loss:
                    msg = (f"è§¦å‘æ­¢æŸæ¡ä»¶! è‚¡ç¥¨: {position.stock_code}, "
                           f"å½“å‰ä»·: {current_price} <= æ­¢æŸä»·: {position.current_stop_loss}ã€‚å‡†å¤‡æ‰§è¡Œå–å‡ºã€‚")
                    persistent_logger.info(msg) # è¿™æ˜¯ä¸€ä¸ªé‡è¦äº‹ä»¶ï¼Œä½¿ç”¨å¯æŒä¹…åŒ–çš„logger
                    self.handler.sell_stock_by_market_price(position, TradeLog.ReasonChoices.STOP_LOSS)
                    # å–å‡ºåï¼Œæ­¤æŒä»“åœ¨ä¸‹ä¸€æ¬¡å¾ªç¯ä¸­å°†ä¸å†è¢«æŸ¥è¯¢åˆ°ï¼Œæ— éœ€ä»å½“å‰å¾ªç¯ä¸­ç§»é™¤

                # æ£€æŸ¥æ˜¯å¦è§¦å‘æ­¢ç›ˆ
                elif current_price >= position.current_take_profit:
                    msg = (f"è§¦å‘æ­¢ç›ˆæ¡ä»¶! è‚¡ç¥¨: {position.stock_code}, "
                           f"å½“å‰ä»·: {current_price} >= æ­¢ç›ˆä»·: {position.current_take_profit}ã€‚å‡†å¤‡æ‰§è¡Œå–å‡ºã€‚")
                    persistent_logger.info(msg) # è¿™æ˜¯ä¸€ä¸ªé‡è¦äº‹ä»¶ï¼Œä½¿ç”¨å¯æŒä¹…åŒ–çš„logger
                    self.handler.sell_stock_by_market_price(position, TradeLog.ReasonChoices.TAKE_PROFIT)

            except Exception as e:
                # æ ¹æ®è¦æ±‚ï¼Œå–å‡ºå¤±è´¥ç­‰å¼‚å¸¸åªåœ¨æ§åˆ¶å°æ‰“å°é”™è¯¯æ—¥å¿—ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å¾ªç¯
                self.logger.error(
                    f"å¤„ç†æŒä»“ {position.position_id} ({position.stock_code}) æ—¶å‘ç”Ÿé”™è¯¯: {e}",
                    exc_info=False # åœ¨é«˜é¢‘åœºæ™¯ä¸‹ï¼Œå¯ä»¥å…³é—­tracebackä»¥ä¿æŒæ—¥å¿—ç®€æ´
                )
                continue
        
        self.logger.debug(f"[{self.MODULE_NAME}] ä»»åŠ¡ç»“æŸã€‚")


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\real_trade_handler.py####
# trade_manager/service/real_trade_handler.py

import logging
import json
from decimal import Decimal, ROUND_HALF_UP
from datetime import date, time, datetime, timedelta

import easytrader
import akshare as ak
from django.db import transaction
from django.utils import timezone

from .trade_handler import ITradeHandler
from common.models import Position, TradeLog, DailyQuotes
from trade_manager.service.decision_order_service import DecisionOrderService
from common.config_loader import config_loader # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®åŠ è½½å™¨

logger = logging.getLogger(__name__)

class ConnectionManager:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(ConnectionManager, cls).__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.user = None
            self.last_connected_date = None
            self.last_refreshed_time = None # æ–°å¢ï¼šä¸Šæ¬¡åˆ·æ–°æ—¶é—´
            self.refresh_interval = timedelta(seconds=5) # æ–°å¢ï¼šåˆ·æ–°é—´éš”
            self.initialized = True
            logger.info("ConnectionManager å·²åˆå§‹åŒ–ã€‚")

    def get_user(self):
        """è·å–æˆ–åˆ›å»ºå½“å¤©çš„ easytrader è¿æ¥ï¼Œå¹¶æŒ‰éœ€åˆ·æ–°"""
        config = config_loader.get('easytrader')
        today = date.today()
        
        if not self.user or self.last_connected_date != today:
            logger.info("å½“å¤©é¦–æ¬¡è¿æ¥æˆ–è¿æ¥å·²å¤±æ•ˆï¼Œæ­£åœ¨é‡æ–°å»ºç«‹ easytrader è¿æ¥...")
            try:
                self._connect(config)
                self.last_connected_date = today
                self.last_refreshed_time = datetime.now()
                logger.info("easytrader è¿æ¥æˆåŠŸã€‚")
            except Exception as e:
                logger.error(f"è¿æ¥ easytrader å¤±è´¥: {e}", exc_info=True)
                self.user = None
                self.last_connected_date = None
                raise
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        if datetime.now() - self.last_refreshed_time > self.refresh_interval:
            logger.info("ä¼šè¯è¶…è¿‡5åˆ†é’Ÿæœªåˆ·æ–°ï¼Œæ‰§è¡Œ user.refresh()...")
            try:
                self.user.refresh()
                self.last_refreshed_time = datetime.now()
                logger.info("user.refresh() æ‰§è¡ŒæˆåŠŸã€‚")
            except Exception as e:
                logger.error(f"æ‰§è¡Œ user.refresh() å¤±è´¥: {e}ï¼Œå°†å°è¯•æ–­å¼€é‡è¿ã€‚")
                self.disconnect() # åˆ·æ–°å¤±è´¥ï¼Œå¯èƒ½è¿æ¥å·²æ–­ï¼Œå¼ºåˆ¶æ–­å¼€
                # ä¸‹æ¬¡è°ƒç”¨ get_user æ—¶ä¼šè‡ªåŠ¨é‡è¿
                raise # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©å½“å‰æ“ä½œå¤±è´¥
        
        return self.user

    def _connect(self, config: dict):
        client_type = config.get('client_type', 'ht_client')
        user_config_path = config.get('user_config_path')
        
        if client_type == 'ht_client':
            self.user = easytrader.use('ht_client')
            self.user.prepare(user_config_path)
        else:
            raise NotImplementedError(f"ä¸æ”¯æŒçš„å®¢æˆ·ç«¯ç±»å‹: {client_type}")

    def disconnect(self):
        if self.user:
            try:
                self.user.exit()
                logger.info("easytrader è¿æ¥å·²æˆåŠŸæ–­å¼€ã€‚")
            except Exception as e:
                logger.error(f"æ–­å¼€ easytrader è¿æ¥æ—¶å‡ºé”™: {e}", exc_info=True)
            finally:
                self.user = None
                self.last_connected_date = None
                self.last_refreshed_time = None

connection_manager = ConnectionManager()

class RealTradeHandler(ITradeHandler):
    COMMISSION_RATE = Decimal('0.00025')
    MIN_COMMISSION = Decimal('5')
    STAMP_DUTY_RATE = Decimal('0.001')

    def __init__(self):
        config = config_loader.get_config()
        self.is_simulation = (config.get('trading_mode') == 'real_simulation_observation')
        logger.info(f"RealTradeHandler åˆå§‹åŒ–ã€‚æ¨¡å¼: {'å®ç›˜æ¨¡æ‹Ÿè§‚æµ‹' if self.is_simulation else 'å®ç›˜äº¤æ˜“'}")

    def _get_user(self):
        return connection_manager.get_user()

    def _api_buy(self, stock_code: str, price: Decimal, quantity: int):
        user = self._get_user()
        ak_code = stock_code.split('.')[-1]
        return user.buy(ak_code, price=float(price), amount=quantity)

    def _api_sell(self, stock_code: str, quantity: int):
        user = self._get_user()
        ak_code = stock_code.split('.')[-1]
        return user.sell(ak_code, amount=quantity)

    def _api_get_orders(self):
        user = self._get_user()
        return user.entrust

    def _api_get_balance(self):
        user = self._get_user()
        return user.balance

    def _api_get_realtime_quote(self, stock_code: str) -> dict:
        ak_code = stock_code.split('.')[-1]
        try:
            df = ak.stock_zh_a_spot_em(symbol=ak_code)
            if not df.empty:
                quote = df.iloc[0]
                return {
                    'open': Decimal(str(quote['ä»Šå¼€'])),
                    'price': Decimal(str(quote['æœ€æ–°ä»·'])),
                }
        except Exception as e:
            logger.warning(f"é€šè¿‡ akshare è·å– {stock_code} å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
        return {}

    def get_opening_price(self, stock_code: str) -> Decimal:
        quote = self._api_get_realtime_quote(stock_code)
        return quote.get('open', Decimal('0.00'))

    def get_realtime_price(self, stock_code: str) -> Decimal | None:
        quote = self._api_get_realtime_quote(stock_code)
        return quote.get('price')

    def get_available_balance(self) -> Decimal:
        if self.is_simulation:
            return Decimal('1000000.00')
        
        balance_info = self._api_get_balance()
        return Decimal(str(balance_info.get('å¯ç”¨é‡‘é¢', '0.00')))

    @transaction.atomic
    def place_buy_order(self, stock_code: str, price: Decimal, quantity: int):
        logger.info(f"å‡†å¤‡ä¸‹å•ä¹°å…¥: {stock_code}, ä»·æ ¼: {price}, æ•°é‡: {quantity}")
        
        entry_datetime = timezone.now()
        position = Position.objects.create(
            stock_code_id=stock_code, entry_datetime=entry_datetime,
            entry_price=price, quantity=quantity,
            current_stop_loss=Decimal('0.00'), current_take_profit=Decimal('0.00'),
            status=Position.StatusChoices.OPEN
        )
        trade_log = TradeLog.objects.create(
            position=position, stock_code_id=stock_code,
            trade_datetime=entry_datetime, trade_type=TradeLog.TradeTypeChoices.BUY,
            order_type=TradeLog.OrderTypeChoices.LIMIT, price=price,
            quantity=quantity, commission=Decimal('0.00'), stamp_duty=Decimal('0.00'),
            reason=TradeLog.ReasonChoices.ENTRY, status=TradeLog.StatusChoices.PENDING
        )

        if self.is_simulation:
            logger.info("[æ¨¡æ‹Ÿæ¨¡å¼] è·³è¿‡çœŸå®APIè°ƒç”¨ï¼Œç›´æ¥æ¨¡æ‹Ÿæˆäº¤ã€‚")
            amount = price * quantity
            commission = max(amount * self.COMMISSION_RATE, self.MIN_COMMISSION)
            trade_log.status = TradeLog.StatusChoices.FILLED
            trade_log.commission = commission.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            trade_log.save()
            
            decision_service = DecisionOrderService(self, execution_date=date.today())
            decision_service.calculate_stop_profit_loss(trade_log.trade_id)
        else:
            try:
                order_result = self._api_buy(stock_code, price, quantity)
                logger.info(f"çœŸå®ä¹°å…¥å§”æ‰˜å·²æäº¤: {order_result}")
                # å…³é”®ï¼šä¿å­˜å§”æ‰˜ç¼–å·
                if order_result and 'entrust_no' in order_result:
                    trade_log.external_order_id = str(order_result['entrust_no'])
                    trade_log.save()
            except Exception as e:
                logger.error(f"æäº¤ä¹°å…¥å§”æ‰˜å¤±è´¥: {e}", exc_info=True)
                trade_log.status = TradeLog.StatusChoices.FAILED
                trade_log.save()
                position.status = Position.StatusChoices.CLOSED
                position.save()

    @transaction.atomic
    def sell_stock_by_market_price(self, position: Position, reason: str):
        logger.info(f"å‡†å¤‡å¸‚ä»·å–å‡º: {position.stock_code_id}, æ•°é‡: {position.quantity}, åŸå› : {reason}")

        trade_log = TradeLog.objects.create(
            position=position, stock_code_id=position.stock_code_id,
            trade_datetime=timezone.now(), trade_type=TradeLog.TradeTypeChoices.SELL,
            order_type=TradeLog.OrderTypeChoices.MARKET, price=Decimal('0.00'),
            quantity=position.quantity, commission=Decimal('0.00'), stamp_duty=Decimal('0.00'),
            reason=reason, status=TradeLog.StatusChoices.PENDING
        )

        if self.is_simulation:
            logger.info("[æ¨¡æ‹Ÿæ¨¡å¼] è·³è¿‡çœŸå®APIè°ƒç”¨ï¼Œç›´æ¥æ¨¡æ‹Ÿæˆäº¤ã€‚")
            try:
                last_quote = DailyQuotes.objects.filter(stock_code_id=position.stock_code_id).latest('trade_date')
                sell_price = last_quote.close
            except DailyQuotes.DoesNotExist:
                sell_price = position.entry_price

            amount = sell_price * position.quantity
            commission = max(amount * self.COMMISSION_RATE, self.MIN_COMMISSION)
            stamp_duty = amount * self.STAMP_DUTY_RATE

            trade_log.status = TradeLog.StatusChoices.FILLED
            trade_log.price = sell_price
            trade_log.commission = commission.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            trade_log.stamp_duty = stamp_duty.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)
            trade_log.save()

            position.status = Position.StatusChoices.CLOSED
            position.save()
        else:
            try:
                order_result = self._api_sell(position.stock_code_id, position.quantity)
                logger.info(f"çœŸå®å–å‡ºå§”æ‰˜å·²æäº¤: {order_result}")
                if order_result and 'entrust_no' in order_result:
                    trade_log.external_order_id = str(order_result['entrust_no'])
                    trade_log.save()
            except Exception as e:
                logger.error(f"æäº¤å–å‡ºå§”æ‰˜å¤±è´¥: {e}", exc_info=True)
                trade_log.status = TradeLog.StatusChoices.FAILED
                trade_log.save()

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\scheduler_service.py####
# trade_manager/service/scheduler_service.py

import logging
import pandas as pd # ä¿®æ­£ï¼šå¯¼å…¥pandas
from datetime import date, timedelta, datetime

import akshare as ak
from apscheduler.schedulers.background import BackgroundScheduler # ä½¿ç”¨BackgroundScheduler
from django.conf import settings
from django.db import transaction
from decimal import Decimal

from selection_manager.service.selection_service import SelectionService
from data_manager.service.corporate_action_service import CorporateActionService
from data_manager.service.stock_service import StockService
from data_manager.service.email_service import EmailNotificationService
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.monitor_exit_service import MonitorExitService
from trade_manager.service.real_trade_handler import RealTradeHandler, connection_manager
from common.models import TradeLog, Position
from common.config_loader import config_loader

logger = logging.getLogger(__name__)

class TradingCalendar:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(TradingCalendar, cls).__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.trade_dates = set()
            self.last_updated = None
            self.initialized = True
            self._update_calendar()

    def _update_calendar(self):
        logger.info("æ­£åœ¨æ›´æ–°äº¤æ˜“æ—¥å†...")
        try:
            df = ak.tool_trade_date_hist_sina()
            self.trade_dates = set(pd.to_datetime(df['trade_date']).dt.date)
            self.last_updated = date.today()
            logger.info(f"äº¤æ˜“æ—¥å†æ›´æ–°æˆåŠŸï¼Œå…±è·å– {len(self.trade_dates)} ä¸ªäº¤æ˜“æ—¥ã€‚")
        except Exception as e:
            logger.error(f"æ›´æ–°äº¤æ˜“æ—¥å†å¤±è´¥: {e}", exc_info=True)

    def is_trading_day(self, check_date: date) -> bool:
        if date.today() != self.last_updated:
            self._update_calendar()
        return check_date in self.trade_dates

trading_calendar = TradingCalendar()

# --- Job Functions ---

def run_job_wrapper(job_func, job_name, *args, **kwargs):
    scheduler_status = config_loader.get('scheduler', {}).get('status')
    if scheduler_status == 'off': return

    logger.info(f"--- [{job_name}] ä»»åŠ¡è§¦å‘ ---")
    if scheduler_status == 'dry_run':
        logger.info(f"[{job_name}] ç©ºè½¬æ¨¡å¼ï¼Œä»»åŠ¡ä»…æ‰“å°æ—¥å¿—ï¼Œä¸æ‰§è¡Œã€‚")
        return
    
    try:
        job_func(*args, **kwargs)
        logger.info(f"--- [{job_name}] ä»»åŠ¡æˆåŠŸæ‰§è¡Œ ---")
    except Exception as e:
        logger.error(f"--- [{job_name}] ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e} ---", exc_info=True)

def daily_check():
    today = date.today()
    if not trading_calendar.is_trading_day(today):
        logger.debug(f"{today} ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä»Šæ—¥ä¸»è¦äº¤æ˜“æµç¨‹ä»»åŠ¡å°†è·³è¿‡ã€‚")
        return False
    return True

def selection_job():
    

    t_minus_1 = date.today() - timedelta(days=1)
    if not trading_calendar.is_trading_day(date.today()):
        logger.info(f"ä»Šæ—¥({date.today()})ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä¸æ‰§è¡Œé€‰è‚¡ä»»åŠ¡ã€‚")
        return
    service = StockService()
    service.update_local_a_shares(start_date=date.today().strftime('%Y-%m-%d'),end_date=date.today().strftime('%Y-%m-%d'))
    service = SelectionService(trade_date=date.today(), mode='realtime')
    service.run_selection()

def premarket_fix_job():
    if not daily_check(): return
    service = BeforeFixService(execution_date=date.today())
    service.run()

def opening_decision_job():
    if not daily_check(): return
    handler = RealTradeHandler()
    service = DecisionOrderService(handler, execution_date=date.today())
    
    logger.info("æ‰§è¡Œäº¤æ˜“é¢„æ¡ˆäºŒæ¬¡ç­›é€‰...")
    service.adjust_trading_plan_daily()
    
    logger.info("å¾ªç¯æ‰§è¡Œä¸‹å•ï¼Œå°è¯•å¡«æ»¡ä»“ä½...")
    max_positions = service.current_max_positions
    logger.info(f"æ ¹æ®M(t)è®¡ç®—ï¼Œå½“æ—¥åŠ¨æ€æœ€å¤§æŒä»“æ•°ä¸º: {max_positions}")

    
    open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
    slots_to_fill = max_positions - open_positions_count
 
    # 3. å¾ªç¯è°ƒç”¨åŒä¸€ä¸ªå®ä¾‹çš„æ–¹æ³•
    for i in range(slots_to_fill):
        logger.info(f"å°è¯•å¡«å……ç¬¬ {i+1}/{slots_to_fill} ä¸ªä»“ä½...")
        service.execute_orders()

def monitoring_job():
    if not daily_check(): return
    handler = RealTradeHandler()
    service = MonitorExitService(handler, execution_date=date.today())
    service.monitor_and_exit_positions()

def update_order_status_job():
    if not daily_check(): return
    handler = RealTradeHandler()
    if handler.is_simulation: return

    pending_trades = TradeLog.objects.filter(status=TradeLog.StatusChoices.PENDING, external_order_id__isnull=False)
    if not pending_trades.exists(): return
    
    try:
        real_orders = handler._api_get_orders()
        if not real_orders: return
        real_orders_map = {str(o['entrust_no']): o for o in real_orders}

        for trade in pending_trades:
            real_order = real_orders_map.get(trade.external_order_id)
            if not real_order: continue
            
            if real_order['order_status'] in ['å·²æˆ', 'å…¨éƒ¨æˆäº¤']:
                with transaction.atomic():
                    trade.status = TradeLog.StatusChoices.FILLED
                    trade.price = Decimal(str(real_order['filled_price']))
                    # æ³¨æ„ï¼šeasytraderè¿”å›çš„ä½£é‡‘å¯èƒ½ä¸å‡†ç¡®ï¼Œè¿™é‡Œä»…ä¸ºç¤ºä¾‹
                    trade.commission = Decimal(str(real_order.get('business_balance', '0.0'))) - Decimal(str(real_order.get('clear_balance', '0.0')))
                    trade.save()

                    if trade.trade_type == 'buy':
                        decision_service = DecisionOrderService(handler, execution_date=date.today())
                        decision_service.calculate_stop_profit_loss(trade.trade_id)
                    else: # sell
                        position = trade.position
                        position.status = Position.StatusChoices.CLOSED
                        position.save()
                logger.info(f"è®¢å• {trade.trade_id} (å§”æ‰˜å·: {trade.external_order_id}) çŠ¶æ€æ›´æ–°ä¸ºå·²æˆäº¤ã€‚")

            elif real_order['order_status'] in ['å·²æ’¤', 'åºŸå•', 'éƒ¨æˆå·²æ’¤']:
                with transaction.atomic():
                    trade.status = TradeLog.StatusChoices.CANCELLED if 'æ’¤' in real_order['order_status'] else TradeLog.StatusChoices.FAILED
                    trade.save()
                    if trade.trade_type == 'buy':
                        position = trade.position
                        position.status = Position.StatusChoices.CLOSED
                        position.save()
                logger.info(f"è®¢å• {trade.trade_id} (å§”æ‰˜å·: {trade.external_order_id}) çŠ¶æ€æ›´æ–°ä¸º {trade.status}ã€‚")

    except Exception as e:
        logger.error(f"æ›´æ–°è®¢å•çŠ¶æ€æ—¶å‡ºé”™: {e}", exc_info=True)

def update_corporate_actions_job():
    today = date.today()
    start_date = today - timedelta(days=30)
    end_date = today + timedelta(days=30)
    service = CorporateActionService()
    service.sync_corporate_actions(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'))

def disconnect_job():
    logger.info("æ‰§è¡Œæ¯æ—¥æ–­å¼€è¿æ¥ä»»åŠ¡...")
    connection_manager.disconnect()

scheduler = BackgroundScheduler(timezone='Asia/Shanghai')


def schedule_intraday_jobs():
    """åœ¨æ¯ä¸ªäº¤æ˜“æ—¥å¼€ç›˜å‰ï¼Œæ·»åŠ å½“å¤©çš„ç›˜ä¸­ç›‘æ§ä»»åŠ¡ã€‚"""
    job_id_monitor = 'intraday_monitoring_job'
    job_id_order_status = 'intraday_order_status_job'
    
    # ä¸ºé˜²æ­¢é‡å¤æ·»åŠ ï¼Œå…ˆå°è¯•ç§»é™¤æ—§çš„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    try:
        scheduler.remove_job(job_id_monitor)
        logger.info(f"æˆåŠŸç§»é™¤æ—§çš„ç›˜ä¸­ç›‘æ§ä»»åŠ¡ (ID: {job_id_monitor})ã€‚")
    except Exception:
        pass # JobNotFoundError, a normal case
    
    try:
        scheduler.remove_job(job_id_order_status)
        logger.info(f"æˆåŠŸç§»é™¤æ—§çš„è®¢å•çŠ¶æ€æ›´æ–°ä»»åŠ¡ (ID: {job_id_order_status})ã€‚")
    except Exception:
        pass
 
    if not daily_check(): return
 
    today_str = date.today().isoformat()
    logger.info(f"æ­£åœ¨ä¸º {today_str} æ·»åŠ ç›˜ä¸­ä»»åŠ¡...")
 
    scheduler.add_job(
        run_job_wrapper, 
        'interval', 
        seconds=5, 
        start_date=f'{today_str} 09:30:01', 
        end_date=f'{today_str} 14:57:00', 
        args=[monitoring_job, 'ç›˜ä¸­ç›‘æ§'],
        id=job_id_monitor, # **ç»™ä»»åŠ¡ä¸€ä¸ªå”¯ä¸€çš„ID**
        replace_existing=True # å¦‚æœIDå·²å­˜åœ¨ï¼Œåˆ™æ›¿æ¢
    )
 
    scheduler.add_job(
        run_job_wrapper, 
        'interval', 
        seconds=10, 
        start_date=f'{today_str} 09:30:00', 
        end_date=f'{today_str} 15:00:00', 
        args=[update_order_status_job, 'æ›´æ–°è®¢å•çŠ¶æ€'],
        id=job_id_order_status, # **ç»™ä»»åŠ¡ä¸€ä¸ªå”¯ä¸€çš„ID**
        replace_existing=True
    )
    logger.info("å½“æ—¥ç›˜ä¸­ä»»åŠ¡å·²æˆåŠŸè°ƒåº¦ã€‚")
 
 
# æ¸…ç†ä»»åŠ¡çš„å‡½æ•°ï¼Œè™½ç„¶ replace_existing=Trueä¹Ÿèƒ½å·¥ä½œï¼Œä½†æ˜¾å¼æ¸…ç†æ›´å¹²å‡€
def cleanup_intraday_jobs():
    """æ”¶ç›˜åæ¸…ç†ï¼Œä»¥é˜²ä¸‡ä¸€ã€‚"""
    try:
        scheduler.remove_job('intraday_monitoring_job')
        scheduler.remove_job('intraday_order_status_job')
        logger.info("å·²æ¸…ç†å½“æ—¥ç›˜ä¸­ä»»åŠ¡ã€‚")
    except Exception:
        pass

# é‚®ä»¶å‘é€ä»»åŠ¡
def email_jobs():
    """æ¯å¤©å‘é€è®¡åˆ’é‚®ä»¶"""
    today = date.today()
    service = EmailNotificationService(today)
    service.runEmailSend()


def start():
    """å¯åŠ¨è°ƒåº¦å™¨çš„ä¸»å‡½æ•°"""
    if config_loader.get('scheduler', {}).get('status') == 'off':
        logger.info("è°ƒåº¦å™¨çŠ¶æ€ä¸º 'off'ï¼Œä¸å¯åŠ¨ã€‚")
        return

    if scheduler.running:
        logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­ã€‚")
        return

    # æ·»åŠ ä»»åŠ¡
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=19, minute=0, args=[selection_job, 'æ—¥ç»ˆé€‰è‚¡'])
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=6, minute=10, args=[premarket_fix_job, 'ç›˜å‰æ ¡å‡†'])
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=6, minute=30, args=[email_jobs, 'é¢„æ¡ˆæ¨é€'])
    #scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=9, minute=25, second=5, args=[opening_decision_job, 'å¼€ç›˜å†³ç­–'])
    
    # --- æ¯æ—¥åŠ¨æ€ä»»åŠ¡çš„è°ƒåº¦å™¨ ---
    # åœ¨æ¯ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜å‰ï¼ˆä¾‹å¦‚9:00ï¼‰å®‰æ’å¥½å½“å¤©çš„ç›˜ä¸­ä»»åŠ¡
    #scheduler.add_job(schedule_intraday_jobs, 'cron', day='*', hour=9, minute=0)
    #åœ¨æ”¶ç›˜åæ¸…ç†
    #scheduler.add_job(cleanup_intraday_jobs, 'cron', day='*', hour=15, minute=5)
    
    # æ•°æ®å’Œè¿æ¥ç®¡ç†ä»»åŠ¡
    scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=6, minute=0, args=[update_corporate_actions_job, 'æ›´æ–°é™¤æƒé™¤æ¯'])
    #scheduler.add_job(run_job_wrapper, 'cron', day='*', hour=15, minute=30, args=[disconnect_job, 'æ–­å¼€è¿æ¥'])
    # today_str = date.today().isoformat()
    # scheduler.add_job(
    #     run_job_wrapper, 
    #     'interval', 
    #     seconds=10, 
    #     start_date=f'{today_str} 07:30:00', 
    #     end_date=f'{today_str} 19:30:00',
    #     args=[update_order_status_job, 'æ›´æ–°è®¢å•çŠ¶æ€'],
    #     id='job_id_order_status', # **ç»™ä»»åŠ¡ä¸€ä¸ªå”¯ä¸€çš„ID**
    #     replace_existing=True
    # )
    logger.info("APScheduler å·²é…ç½®å®Œæˆï¼Œå‡†å¤‡åœ¨åå°å¯åŠ¨...")
    scheduler.start()

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\simulate_trade.py####
# ==============================================================================
# æ–‡ä»¶ 4/5: trade_manager/service/simulate_trade.py (ä¿®æ”¹)
# æè¿°: æ ¸å¿ƒå›æµ‹æœåŠ¡ï¼Œé›†æˆæ—¥å¿—è®°å½•å’Œé‚®ä»¶å‘é€ã€‚
# ==============================================================================
# trade_manager/service/simulate_trade.py

import logging
from datetime import date, timedelta, datetime
from decimal import Decimal
import numpy as np
import pandas as pd
from django.db import connections, transaction
from django.core.management import call_command

# å†…éƒ¨æ¨¡å—å¯¼å…¥
from common.models import (
    DailyFactorValues, DailyTradingPlan, Position, TradeLog, SystemLog,
    StrategyParameters, DailyQuotes, CorporateAction
)
# æ–°å¢å¯¼å…¥
from common.models.backtest_logs import BacktestDailyLog, BacktestOperationLog 
from selection_manager.service.selection_service import SelectionService, MARKET_INDICATOR_CODE
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.monitor_exit_service import MonitorExitService
from .simulate_trade_handler import SimulateTradeHandler
from .db_utils import use_backtest_schema
from .backtest_reporter import BacktestReporter # æ–°å¢å¯¼å…¥

logger = logging.getLogger(__name__)

class SimulateTradeService:
    """
    å›æµ‹å®æ–½æœåŠ¡ (V3 - é›†æˆæ—¥å¿—ä¸æŠ¥å‘Š)ã€‚
    """
    COMMISSION_RATE = Decimal('0.0002854')
    MIN_COMMISSION = Decimal('5')
    STAMP_DUTY_RATE = Decimal('0.001')
    SELL_SLIPPAGE_RATE = Decimal('0.002')

    def __init__(self):
        self.start_date: date = None
        self.end_date: date = None
        self.current_date: date = None
        self.initial_capital = Decimal('0.0')
        self.cash_balance = Decimal('0.0')
        self.portfolio_history = []
        self.last_buy_trade_id = None
        self.backtest_run_id: str = None # æ–°å¢ï¼šå›æµ‹å”¯ä¸€ID

    def _setup_backtest_schema(self, schema_name: str, initial_capital: Decimal):
        logger.info(f"--- 1. åœ¨ Schema '{schema_name}' ä¸­å‡†å¤‡å›æµ‹ç¯å¢ƒ ---")
        
        logger.info("æ­£åœ¨æ–° Schema ä¸­åˆ›å»ºè¡¨ç»“æ„ (æ‰§è¡Œ migrate)...")
        with connections['default'].cursor() as cursor:
            logger.info(f"ä¸´æ—¶éš”ç¦» search_path åˆ° '{schema_name}' ä»¥ä¾¿è¿è¡Œ migrate å‘½ä»¤ã€‚")
            cursor.execute(f'SET search_path TO "{schema_name}";')
            
            logger.info("æ­£åœ¨æ–° Schema ä¸­åˆ›å»ºè¡¨ç»“æ„ (æ‰§è¡Œ migrate)...")
            # åœ¨è¿™ä¸ªéš”ç¦»çš„ç¯å¢ƒä¸‹ï¼Œmigrate çœ‹ä¸åˆ° public.django_migrationsï¼Œå› æ­¤ä¼šåˆ›å»ºæ‰€æœ‰è¡¨ã€‚
            call_command('migrate')
            logger.info("è¡¨ç»“æ„åˆ›å»ºå®Œæˆã€‚")

        tables_to_copy = [
            'tb_stock_info', 'tb_daily_quotes', 'tb_corporate_actions',
            'tb_factor_definitions', 'tb_strategy_parameters', 
            'tb_daily_factor_values','tb_daily_trading_plan'
        ]
        
        logger.info(f"å‡†å¤‡ä» 'public' schema å¤åˆ¶åŸºç¡€æ•°æ®åˆ° '{schema_name}'...")
        with transaction.atomic(), connections['default'].cursor() as cursor:
            cursor.execute(f'SET search_path TO "{schema_name}";')
            for table_name in tables_to_copy:
                logger.info(f"  - æ­£åœ¨å¤„ç†è¡¨: {table_name}")
                # 1. åŒºåˆ†å¹¶è·å– "æ™®é€šç´¢å¼•" å’Œ "çº¦æŸ"
                # =========================================================================
                # 1a. è·å–æ™®é€šç´¢å¼• (ä¸åŒ…æ‹¬ç”± UNIQUE æˆ– PRIMARY KEY çº¦æŸåˆ›å»ºçš„ç´¢å¼•)
                logger.info(f"    - æ­£åœ¨è·å– '{table_name}' çš„æ™®é€šç´¢å¼•...")
                cursor.execute("""
                    SELECT indexdef
                    FROM pg_indexes
                    WHERE schemaname = %s AND tablename = %s
                    AND indexname NOT IN (
                        SELECT conname FROM pg_constraint WHERE conrelid = %s::regclass
                    );
                """, [schema_name, table_name, f'"{schema_name}"."{table_name}"'])
                plain_indexes_to_recreate = [row[0] for row in cursor.fetchall()]
                # 1b. è·å–çº¦æŸ (å¤–é”®å’Œå”¯ä¸€çº¦æŸ)
                logger.info(f"    - æ­£åœ¨è·å– '{table_name}' çš„å¤–é”®å’Œå”¯ä¸€çº¦æŸ...")
                cursor.execute("""
                    SELECT 'ALTER TABLE ' || quote_ident(conrelid::regclass::text) || ' ADD CONSTRAINT ' || quote_ident(conname) || ' ' || pg_get_constraintdef(oid)
                    FROM pg_constraint
                    WHERE contype IN ('f', 'u') AND conrelid = %s::regclass;
                """, [f'"{schema_name}"."{table_name}"'])
                constraints_to_recreate = [row[0] for row in cursor.fetchall()]
                # 2. åˆ é™¤ç´¢å¼•å’Œçº¦æŸ (åˆ é™¤çº¦æŸä¼šè‡ªåŠ¨åˆ é™¤å…¶åº•å±‚ç´¢å¼•)
                # =========================================================================
                # 2a. åˆ é™¤çº¦æŸ
                for const_def in constraints_to_recreate:
                    const_name = const_def.split('ADD CONSTRAINT ')[1].split(' ')[0]
                    logger.info(f"      - åˆ é™¤çº¦æŸ: {const_name}")
                    cursor.execute(f'ALTER TABLE "{table_name}" DROP CONSTRAINT IF EXISTS {const_name};')
                
                # 2b. åˆ é™¤æ™®é€šç´¢å¼•
                for index_def in plain_indexes_to_recreate:
                    # ä» "CREATE INDEX index_name ON ..." ä¸­æå– index_name
                    try:
                        index_name = index_def.split(' ')[2]
                        logger.info(f"      - åˆ é™¤ç´¢å¼•: {index_name}")
                        cursor.execute(f'DROP INDEX IF EXISTS "{index_name}";')
                    except IndexError:
                        logger.warning(f"æ— æ³•ä» '{index_def}' è§£æç´¢å¼•åç§°ï¼Œè·³è¿‡åˆ é™¤ã€‚")
                # 3. é«˜æ•ˆå¤åˆ¶æ•°æ® (ç°åœ¨éå¸¸å¿«)
                # =========================================================================
                logger.info(f"    - æ­£åœ¨ä» public.{table_name} å¤åˆ¶æ•°æ®...")
                sql = f'INSERT INTO "{table_name}" SELECT * FROM public."{table_name}";'
                cursor.execute(sql)
                logger.info(f"    - æ•°æ®å¤åˆ¶å®Œæˆã€‚")
                # 4. é‡å»ºç´¢å¼•å’Œçº¦æŸ
                # =========================================================================
                logger.info(f"    - æ­£åœ¨é‡å»º '{table_name}' çš„ç´¢å¼•å’Œçº¦æŸ...")
                # 4a. é‡å»ºæ™®é€šç´¢å¼•
                for index_def in plain_indexes_to_recreate:
                    logger.info(f"      - é‡å»ºç´¢å¼•: {index_def}")
                    cursor.execute(index_def)
                
                # 4b. é‡å»ºçº¦æŸ (è¿™ä¼šè‡ªåŠ¨é‡å»ºå®ƒä»¬çš„åº•å±‚ç´¢å¼•)
                for const_def in constraints_to_recreate:
                    logger.info(f"      - é‡å»ºçº¦æŸ: {const_def}")
                    cursor.execute(const_def)

                # =========================================================================
                # 5. é‡ç½®è‡ªå¢ä¸»é”®åºåˆ— (è§£å†³ä¸»é”®å†²çªçš„å…³é”®)
                # =========================================================================
                # è‡ªåŠ¨æŸ¥æ‰¾å¹¶æ›´æ–°å½“å‰è¡¨çš„è‡ªå¢åºåˆ—
                find_serial_sql = """
                    SELECT 
                        a.attname, 
                        pg_get_serial_sequence(
                            quote_ident(n.nspname) || '.' || quote_ident(c.relname), 
                            a.attname
                        )
                    FROM 
                        pg_class c
                    JOIN 
                        pg_attribute a ON a.attrelid = c.oid
                    JOIN 
                        pg_namespace n ON c.relnamespace = n.oid -- é€šè¿‡namespace OIDå…³è”
                    WHERE 
                        n.nspname = %s      -- å‚æ•°1: schemaçš„åç§°
                        AND c.relname = %s  -- å‚æ•°2: è¡¨çš„åç§°
                        AND a.attnum > 0 
                        AND NOT a.attisdropped
                        AND pg_get_serial_sequence(quote_ident(n.nspname) || '.' || quote_ident(c.relname), a.attname) IS NOT NULL;
                """
                cursor.execute(find_serial_sql, [schema_name, table_name])
                serial_columns = cursor.fetchall()

                for column_name, sequence_name in serial_columns:
                    logger.info(f"    - å‘ç°è‡ªå¢åˆ— '{column_name}'ï¼Œæ­£åœ¨é‡ç½®å…¶åºåˆ— '{sequence_name}'...")
                    
                    # å°†åºåˆ—çš„ä¸‹ä¸€ä¸ªå€¼è®¾ç½®ä¸º (è¡¨ä¸­è¯¥åˆ—çš„æœ€å¤§å€¼ + 1)ï¼Œå¦‚æœè¡¨ä¸ºç©ºåˆ™è®¾ç½®ä¸º1
                    update_sequence_sql = f"""
                        SELECT setval(
                            '{sequence_name}', 
                            COALESCE((SELECT MAX("{column_name}") FROM "{table_name}"), 0) + 1, 
                            true
                        )
                    """
                    cursor.execute(update_sequence_sql)
                    logger.info(f"    - åºåˆ— '{sequence_name}' å·²æ›´æ–°ã€‚")

                
        logger.info("åŸºç¡€æ•°æ®å¤åˆ¶å®Œæˆã€‚")
        # with connections['default'].cursor() as cursor:
        #     for table_name in tables_to_copy:
        #         logger.info(f"  - æ­£åœ¨å¤åˆ¶è¡¨: {table_name}")
        #         sql = f'INSERT INTO "{schema_name}"."{table_name}" SELECT * FROM public."{table_name}";'
        #         cursor.execute(sql)
        # logger.info("åŸºç¡€æ•°æ®å¤åˆ¶å®Œæˆã€‚")

        self.initial_capital = initial_capital
        self.cash_balance = self.initial_capital
        logger.info(f"åˆå§‹èµ„é‡‘å·²è®¾å®šä¸º: {self.initial_capital:.2f}")

    def run_backtest(self, start_date: str, end_date: str, initial_capital: Decimal) -> dict:
        self.start_date = date.fromisoformat(start_date)
        self.end_date = date.fromisoformat(end_date)
        self.backtest_run_id = f"backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"ä¸ºæœ¬æ¬¡å›æµ‹åˆ›å»ºä¸´æ—¶ Schema: {self.backtest_run_id}")

        try:
            with connections['default'].cursor() as cursor:
                cursor.execute(f'CREATE SCHEMA IF NOT EXISTS "{self.backtest_run_id}";')

            with use_backtest_schema(self.backtest_run_id):
                self._setup_backtest_schema(self.backtest_run_id, initial_capital)

                handler = SimulateTradeHandler(self)
                trading_days = self._get_trading_days()
                if not trading_days:
                    logger.error("åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•äº¤æ˜“æ—¥ï¼Œå›æµ‹ç»ˆæ­¢ã€‚")
                    return {}

                logger.info(f"--- 2. å¼€å§‹æ—¥åº¦å›æµ‹å¾ªç¯ ({len(trading_days)}å¤©) ---")
                
                last_sent_month = None # ç”¨äºé‚®ä»¶è§¦å‘

                for i, current_day in enumerate(trading_days):
                    self.current_date = current_day
                    logger.info(f"\n{'='*20} æ¨¡æ‹Ÿæ—¥: {self.current_date} ({i+1}/{len(trading_days)}) {'='*20}")


                    logger.info("-> [Tæ—¥ ç›˜å‰æ ¡å‡†] ...")
                    before_fix_service = BeforeFixService(execution_date=self.current_date)
                    before_fix_service.run()
                    
                    self._handle_dividends()

                    logger.info("-> [Tæ—¥ å¼€ç›˜å†³ç­–ä¸ä¹°å…¥] ...")
                    decision_order_service = DecisionOrderService(handler=handler, execution_date=self.current_date)
                    decision_order_service.adjust_trading_plan_daily()
                    
                    while True:
                        open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
                        max_pos = decision_order_service.current_max_positions
                        if open_positions_count >= max_pos: break
                        
                        self.last_buy_trade_id = None
                        decision_order_service.execute_orders()
                        
                        if self.last_buy_trade_id:
                            decision_order_service.calculate_stop_profit_loss(self.last_buy_trade_id)
                            # åœ¨æ­¢ç›ˆæ­¢æŸè®¡ç®—å®Œæ¯•åï¼Œè·å–æ›´æ–°åçš„æŒä»“å¯¹è±¡
                            trade_log = TradeLog.objects.get(pk=self.last_buy_trade_id)
                            position = trade_log.position
                            # ç°åœ¨æ‰è°ƒç”¨æ—¥å¿—è®°å½•å‡½æ•°ï¼Œæ­¤æ—¶ position å¯¹è±¡å·²åŒ…å«æ­£ç¡®çš„æ­¢ç›ˆæ­¢æŸä»·
                            handler._record_buy_operation(position)
                        else:
                            break

                    monitor_exit_service = MonitorExitService(handler=handler, execution_date=self.current_date)
                    logger.info("-> [Tæ—¥ ç›˜ä¸­ç›‘æ§] æ¨¡æ‹Ÿä»·æ ¼è·Œè‡³æœ€ä½ç‚¹...")
                    handler.current_price_node = 'LOW'
                    monitor_exit_service.monitor_and_exit_positions()
                    logger.info("-> [Tæ—¥ ç›˜ä¸­ç›‘æ§] æ¨¡æ‹Ÿä»·æ ¼æ¶¨è‡³æœ€é«˜ç‚¹...")
                    handler.current_price_node = 'HIGH'
                    monitor_exit_service.monitor_and_exit_positions()

                    


                    logger.info(f"-> [Tæ—¥ ç›˜åé€‰è‚¡] åŸºäº {self.current_date} çš„æ•°æ®ä¸ºä¸‹ä¸€äº¤æ˜“æ—¥åšå‡†å¤‡...")
                    selection_service = SelectionService(trade_date=self.current_date, mode='backtest')
                    selection_service.run_selection()
                    
                    self._record_daily_log()

                    # --- é‚®ä»¶å‘é€é€»è¾‘ ---
                    is_last_day = (i == len(trading_days) - 1)
                    current_month = current_day.month
                    send_mail_flag = False

                    if is_last_day:
                        send_mail_flag = True
                        logger.info("å›æµ‹ç»“æŸï¼Œè§¦å‘æœ€ç»ˆé‚®ä»¶æŠ¥å‘Šã€‚")
                    elif last_sent_month is not None and current_month != last_sent_month:
                        send_mail_flag = True
                        logger.info(f"æœˆä»½ä» {last_sent_month} å˜ä¸º {current_month}ï¼Œè§¦å‘æœˆåº¦é‚®ä»¶æŠ¥å‘Šã€‚")
                    
                    if send_mail_flag:
                        reporter = BacktestReporter(
                            schema_name=self.backtest_run_id,
                            start_date=self.start_date,
                            current_date=self.current_date,
                            initial_capital=self.initial_capital
                        )
                        reporter.send_report()
                    
                    last_sent_month = current_month
                    # --- é‚®ä»¶å‘é€é€»è¾‘ç»“æŸ ---

                logger.info("--- 3. å›æµ‹å¾ªç¯ç»“æŸ ---")
                return self._calculate_performance_metrics()

        except Exception as e:
            logger.critical(f"å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            return {"error": str(e)}

    def _get_trading_days(self) -> list[date]:
        dates = DailyQuotes.objects.filter(
            trade_date__gte=self.start_date,
            trade_date__lte=self.end_date
        ).values_list('trade_date', flat=True).distinct().order_by('trade_date')
        return list(dates)

    def _handle_dividends(self):
        dividend_events = CorporateAction.objects.filter(
            ex_dividend_date=self.current_date, event_type=CorporateAction.EventType.DIVIDEND
        )
        if not dividend_events.exists(): return

        events_by_stock = {}
        for event in dividend_events:
            events_by_stock.setdefault(event.stock_code, []).append(event)
        
        open_positions = Position.objects.filter(
            stock_code_id__in=events_by_stock.keys(), status=Position.StatusChoices.OPEN
        )
        for pos in open_positions:
            for event in events_by_stock.get(pos.stock_code_id, []):
                dividend_amount = event.dividend_per_share * pos.quantity
                self.cash_balance += dividend_amount
                logger.info(f"é™¤æ¯äº‹ä»¶: æŒä»“ID {pos.position_id} ({pos.stock_code_id}) è·å¾—åˆ†çº¢ {dividend_amount:.2f}")

    def _record_daily_log(self):
        open_positions = Position.objects.filter(status=Position.StatusChoices.OPEN)
        market_value = Decimal('0.0')
        for pos in open_positions:
            try:
                quote = DailyQuotes.objects.get(stock_code_id=pos.stock_code_id, trade_date=self.current_date)
                market_value += quote.close * pos.quantity
            except DailyQuotes.DoesNotExist:
                market_value += pos.entry_price * pos.quantity
        
        total_assets = self.cash_balance + market_value

        try:
            m_value_obj = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                factor_code_id='dynamic_M_VALUE',
                trade_date=self.current_date
            )
            m_value = m_value_obj.raw_value
        except DailyFactorValues.DoesNotExist:
            m_value = None

        BacktestDailyLog.objects.create(
            backtest_run_id=self.backtest_run_id,
            trade_date=self.current_date,
            total_assets=total_assets,
            cash=self.cash_balance,
            holdings_value=market_value,
            market_m_value=m_value
        )
        logger.info(f"--- æ—¥ç»ˆç»“ç®— ({self.current_date}) ---")
        logger.info(f"ç°é‡‘: {self.cash_balance:.2f}, æŒä»“å¸‚å€¼: {market_value:.2f}, æ€»èµ„äº§: {total_assets:.2f}, Må€¼: {m_value}")

    def _calculate_performance_metrics(self) -> dict:
        logger.info("--- 4. è®¡ç®—å›æµ‹æ€§èƒ½æŒ‡æ ‡ ---")
        daily_logs = BacktestDailyLog.objects.filter(backtest_run_id=self.backtest_run_id).order_by('trade_date')
        if not daily_logs.exists():
            return {}

        df = pd.DataFrame(list(daily_logs.values('total_assets')))
        df['total_assets'] = df['total_assets'].astype(float)
        
        final_value = df['total_assets'].iloc[-1]
        total_return_rate = (final_value / float(self.initial_capital)) - 1
        
        total_days = (self.end_date - self.start_date).days
        if total_days > 0:
            annualized_return = ((final_value / float(self.initial_capital)) ** (365.0 / total_days)) - 1
        else:
            annualized_return = 0.0

        df['peak'] = df['total_assets'].cummax()
        df['drawdown'] = (df['total_assets'] - df['peak']) / df['peak']
        max_drawdown = df['drawdown'].min()

        result = {
            'total_return_rate': f"{total_return_rate:.2%}",
            'annualized_return': f"{annualized_return:.2%}",
            'max_drawdown': f"{max_drawdown:.2%}"
        }
        logger.info(f"æœ€ç»ˆå›æµ‹ç»“æœ: {result}")
        return result


####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\simulate_trade_handler.py####
# ==============================================================================
# æ–‡ä»¶ 5/5: trade_manager/service/simulate_trade_handler.py (ä¿®æ”¹)
# æè¿°: æ¨¡æ‹Ÿäº¤æ˜“å¤„ç†å™¨ï¼Œé›†æˆæ“ä½œæ—¥å¿—è®°å½•ã€‚
# ==============================================================================
# trade_manager/service/simulate_trade_handler.py

import logging
from datetime import time, timedelta
from decimal import Decimal, ROUND_HALF_UP
from datetime import date, timedelta, datetime
from django.db import transaction
from django.utils import timezone

from .trade_handler import ITradeHandler
from common.models import Position, TradeLog, DailyQuotes, StockInfo, DailyFactorValues
from common.models.backtest_logs import BacktestOperationLog # æ–°å¢å¯¼å…¥
from selection_manager.service.selection_service import MARKET_INDICATOR_CODE # æ–°å¢å¯¼å…¥

from typing import TYPE_CHECKING, Literal
if TYPE_CHECKING:
    from .simulate_trade import SimulateTradeService

logger = logging.getLogger(__name__)

class SimulateTradeHandler(ITradeHandler):
    """
    æ¨¡æ‹Ÿäº¤æ˜“å¤„ç†å™¨ (SimulateTradeHandler) - é›†æˆæ“ä½œæ—¥å¿—ã€‚
    """

    def __init__(self, service: 'SimulateTradeService'):
        self.service = service
        self.current_price_node: Literal['OPEN', 'LOW', 'HIGH', 'CLOSE'] = 'CLOSE'

    def get_opening_price(self, stock_code: str) -> Decimal:
        try:
            quote = DailyQuotes.objects.get(
                stock_code_id=stock_code,
                trade_date=self.service.current_date
            )
            return quote.open
        except DailyQuotes.DoesNotExist:
            logger.warning(f"[å›æµ‹] æ— æ³•åœ¨ {self.service.current_date} æ‰¾åˆ° {stock_code} çš„è¡Œæƒ…æ•°æ®ï¼Œè¿”å›0ã€‚")
            return Decimal('0.00')

    def get_realtime_price(self, stock_code: str) -> Decimal | None:
        try:
            quote = DailyQuotes.objects.get(
                stock_code_id=stock_code,
                trade_date=self.service.current_date
            )
            if self.current_price_node == 'LOW':
                return quote.low
            elif self.current_price_node == 'HIGH':
                return quote.high
            else:
                return quote.close
        except DailyQuotes.DoesNotExist:
            return None

    def get_available_balance(self) -> Decimal:
        return self.service.cash_balance

    @transaction.atomic
    def place_buy_order(self, stock_code: str, price: Decimal, quantity: int) -> None:
        amount = price * quantity
        commission = max(amount * self.service.COMMISSION_RATE, self.service.MIN_COMMISSION)
        total_cost = amount + commission

        if self.service.cash_balance < total_cost:
            raise ValueError(f"èµ„é‡‘ä¸è¶³ï¼")

        self.service.cash_balance -= total_cost
        logger.info(f"[å›æµ‹] ä¹°å…¥ {stock_code} {quantity}è‚¡ @{price:.2f}, èŠ±è´¹: {amount:.2f}, ç°é‡‘ä½™é¢: {self.service.cash_balance:.2f}")

        entry_time = time(9, 30, 1)
        entry_datetime = timezone.make_aware(timezone.datetime.combine(self.service.current_date, entry_time))

        new_position = Position.objects.create(
            stock_code_id=stock_code, entry_datetime=entry_datetime, entry_price=price,
            quantity=quantity, status=Position.StatusChoices.OPEN,
            current_stop_loss=Decimal('0.00'), current_take_profit=Decimal('0.00')
        )

        trade_log = TradeLog.objects.create(
            position=new_position, stock_code_id=stock_code, trade_datetime=entry_datetime,
            trade_type=TradeLog.TradeTypeChoices.BUY, order_type=TradeLog.OrderTypeChoices.LIMIT,
            price=price, quantity=quantity, commission=commission,
            reason=TradeLog.ReasonChoices.ENTRY, status=TradeLog.StatusChoices.FILLED
        )
        
        self.service.last_buy_trade_id = trade_log.trade_id

        

    @transaction.atomic
    def sell_stock_by_market_price(self, position: Position, reason: str) -> None:
        if reason == TradeLog.ReasonChoices.STOP_LOSS:
            #æœ‰å¯èƒ½è§¦å‘æ­¢æŸæ˜¯å› ä¸ºé…è‚¡æŠŠæ­¢æŸé‡‘é¢æ”¹åˆ°äº†999999ï¼Œæ‰€ä»¥æ­¢æŸé‡‘é¢åº”è¯¥å–å¼€ç›˜ä»·å’Œæ­¢æŸä»·æ›´ä½çš„é‚£ä¸ª
            base_sell_price = self.get_opening_price(position.stock_code_id)
            trigger_price=min(base_sell_price,position.current_stop_loss)
        else: # TAKE_PROFIT
            trigger_price = position.current_take_profit

        sell_price = (trigger_price * (Decimal('1.0') - self.service.SELL_SLIPPAGE_RATE))
        sell_price = sell_price.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)

        amount = sell_price * position.quantity
        commission = max(amount * self.service.COMMISSION_RATE, self.service.MIN_COMMISSION)
        stamp_duty = amount * self.service.STAMP_DUTY_RATE
        net_income = amount - commission - stamp_duty

        self.service.cash_balance += net_income
        logger.info(f"[å›æµ‹] å–å‡º {position.stock_code_id} {position.quantity}è‚¡ @{sell_price:.2f}, ç°é‡‘ä½™é¢: {self.service.cash_balance:.2f}")

        position.status = Position.StatusChoices.CLOSED
        position.save()

        sell_time = time(14, 57, 0)
        sell_datetime = timezone.make_aware(timezone.datetime.combine(self.service.current_date, sell_time))

        TradeLog.objects.create(
            position=position, stock_code_id=position.stock_code_id, trade_datetime=sell_datetime,
            trade_type=TradeLog.TradeTypeChoices.SELL, order_type=TradeLog.OrderTypeChoices.MARKET,
            price=sell_price, quantity=position.quantity, commission=commission,
            stamp_duty=stamp_duty, reason=reason, status=TradeLog.StatusChoices.FILLED
        )
        
        # --- æ–°å¢: è®°å½•å–å‡ºæ“ä½œæ—¥å¿— ---
        self._record_sell_operation(position, sell_price, reason)
        
    def _get_t_minus_1_date(self) -> date:
        """å®‰å…¨åœ°è·å–T-1äº¤æ˜“æ—¥"""
        try:
            return DailyQuotes.objects.filter(trade_date__lt=self.service.current_date).latest('trade_date').trade_date
        except DailyQuotes.DoesNotExist:
            logger.warning(f"æ— æ³•æ‰¾åˆ° {self.service.current_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥ã€‚")
            return self.service.current_date - timedelta(days=1)

    def _record_buy_operation(self, position: Position):
        t_minus_1 = self._get_t_minus_1_date()
        
        # è·å–Må€¼
        try:
            m_value_obj = DailyFactorValues.objects.get(
                stock_code_id=MARKET_INDICATOR_CODE,
                factor_code_id='dynamic_M_VALUE',
                trade_date=t_minus_1
            )
            m_value = m_value_obj.raw_value
        except DailyFactorValues.DoesNotExist:
            m_value = None
        
        # è·å–å› å­å¾—åˆ†
        # æ­¥éª¤1: å…ˆè·å–è¯¥è‚¡ç¥¨å½“å¤©çš„æ‰€æœ‰å› å­å€¼
        all_factor_scores_qs = DailyFactorValues.objects.filter(
            stock_code_id=position.stock_code_id,
            trade_date=t_minus_1
        )
        
        # æ­¥éª¤2: åœ¨ Python å±‚é¢è¿›è¡Œè¿‡æ»¤å’Œæ ¼å¼åŒ–
        scores_list = []
        for f in all_factor_scores_qs:
            scores_list.append(f"{f.factor_code_id}:{f.norm_score:.2f}")
        scores_str = "|".join(scores_list)
        
        # è·å–æ­¢ç›ˆæ­¢æŸç‡ (åœ¨è°ƒç”¨æ­¤å‡½æ•°æ—¶ï¼ŒPositionåº”å·²è¢«æ›´æ–°)
        profit_rate = (position.current_take_profit / position.entry_price) - 1 if position.entry_price > 0 else 0
        loss_rate = 1 - (position.current_stop_loss / position.entry_price) if position.entry_price > 0 else 0

        BacktestOperationLog.objects.create(
            backtest_run_id=self.service.backtest_run_id,
            position_id_ref=position.position_id,
            stock_code=position.stock_code_id,
            stock_name=position.stock_code.stock_name,
            trade_date=self.service.current_date,
            direction=BacktestOperationLog.Direction.BUY,
            exit_reason=None,
            profit_rate=profit_rate,
            loss_rate=loss_rate,
            buy_date_m_value=m_value,
            factor_scores=scores_str,
            price=position.entry_price,
            quantity=position.quantity,
            amount=position.entry_price * position.quantity
        )
        logger.debug(f"å·²è®°å½•ä¹°å…¥æ“ä½œæ—¥å¿— for Position ID: {position.position_id}")
        
    def _record_sell_operation(self, position: Position, sell_price: Decimal, reason: str):
        # åæŸ¥ä¹°å…¥è®°å½•
        try:
            buy_op = BacktestOperationLog.objects.get(
                backtest_run_id=self.service.backtest_run_id,
                position_id_ref=position.position_id,
                direction=BacktestOperationLog.Direction.BUY
            )
            m_value = buy_op.buy_date_m_value
            scores_str = buy_op.factor_scores
            profit_rate = buy_op.profit_rate
            loss_rate = buy_op.loss_rate
        except BacktestOperationLog.DoesNotExist:
            logger.error(f"ä¸¥é‡é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ° Position ID {position.position_id} å¯¹åº”çš„ä¹°å…¥æ“ä½œæ—¥å¿—ï¼")
            m_value, scores_str, profit_rate, loss_rate = None, "", None, None

        exit_reason_for_log = None
        if reason == TradeLog.ReasonChoices.TAKE_PROFIT:
            exit_reason_for_log = BacktestOperationLog.ExitReason.TAKE_PROFIT
        elif reason == TradeLog.ReasonChoices.STOP_LOSS:
            exit_reason_for_log = BacktestOperationLog.ExitReason.STOP_LOSS

        BacktestOperationLog.objects.create(
            backtest_run_id=self.service.backtest_run_id,
            position_id_ref=position.position_id,
            stock_code=position.stock_code_id,
            stock_name=position.stock_code.stock_name,
            trade_date=self.service.current_date,
            direction=BacktestOperationLog.Direction.SELL,
            exit_reason=exit_reason_for_log,
            profit_rate=profit_rate,
            loss_rate=loss_rate,
            buy_date_m_value=m_value,
            factor_scores=scores_str,
            price=sell_price,
            quantity=position.quantity,
            amount=sell_price * position.quantity
        )
        logger.debug(f"å·²è®°å½•å–å‡ºæ“ä½œæ—¥å¿— for Position ID: {position.position_id}")

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\simulate_trade_old.py####
# trade_manager/service/simulate_trade.py

import logging
import shutil
import os
from datetime import date, timedelta
from decimal import Decimal, ROUND_HALF_UP
import numpy as np
import pandas as pd
import time
from django.conf import settings
from django.db import connections, transaction
import sqlite3
from common.models import (
    DailyFactorValues, DailyTradingPlan, Position, TradeLog, SystemLog,
    StrategyParameters, DailyQuotes, CorporateAction
)
from selection_manager.service.selection_service import SelectionService
from trade_manager.service.before_fix_service import BeforeFixService
from trade_manager.service.decision_order_service import DecisionOrderService
from trade_manager.service.monitor_exit_service import MonitorExitService
from .simulate_trade_handler import SimulateTradeHandler

logger = logging.getLogger(__name__)

class SimulateTradeService:
    """
    å›æµ‹å®æ–½æœåŠ¡ã€‚
    """
    COMMISSION_RATE = Decimal('0.0002854')
    MIN_COMMISSION = Decimal('5')
    STAMP_DUTY_RATE = Decimal('0.001')
    SELL_SLIPPAGE_RATE = Decimal('0.002')
    ANNUAL_RISK_FREE_RATE = Decimal('0.015')
    TRADING_DAYS_PER_YEAR = 252

    def __init__(self):
        self.start_date: date = None
        self.end_date: date = None
        self.current_date: date = None
        self.initial_capital = Decimal('0.0')
        self.cash_balance = Decimal('0.0')
        self.portfolio_history = []
        self.last_buy_trade_id = None
        self.original_db_config = None
    def _load_db_to_memory(self, source_db_path: str):
        """
        ã€ä¼˜åŒ–ç‰ˆã€‘ä½¿ç”¨ SQLite Backup API é«˜æ•ˆåœ°å°†ç£ç›˜æ•°æ®åº“åŠ è½½åˆ°å†…å­˜ã€‚
        """
        logger.info(f"å¼€å§‹å°†æ•°æ®ä» {source_db_path} åŠ è½½åˆ°å†…å­˜ (ä½¿ç”¨ Backup API)...")
        start_time = time.time()
        
        # 1. åˆ›å»ºä¸€ä¸ªåˆ°æºæ–‡ä»¶æ•°æ®åº“çš„ç›´æ¥è¿æ¥ (åªè¯»)
        try:
            source_conn = sqlite3.connect(f'file:{source_db_path}?mode=ro', uri=True)
        except sqlite3.OperationalError as e:
            logger.error(f"æ— æ³•ä»¥åªè¯»æ¨¡å¼æ‰“å¼€æºæ•°æ®åº“ {source_db_path}: {e}")
            raise
 
        # 2. è·å–åˆ°Djangoç®¡ç†çš„å†…å­˜æ•°æ®åº“çš„åº•å±‚è¿æ¥
        mem_conn = connections['default'].connection
 
        try:
            # 3. ã€æ ¸å¿ƒä¼˜åŒ–ã€‘ä½¿ç”¨ backup æ–¹æ³•
            #    å®ƒä¼šä»¥æœ€æœ‰æ•ˆçš„æ–¹å¼ï¼ˆé€šå¸¸æ˜¯æŒ‰æ•°æ®é¡µï¼‰å°†æºæ•°æ®åº“å†…å®¹å¤åˆ¶åˆ°ç›®æ ‡æ•°æ®åº“
            source_conn.backup(mem_conn)
            
            duration = time.time() - start_time
            logger.info(f"æ•°æ®æˆåŠŸåŠ è½½åˆ°å†…å­˜æ•°æ®åº“ï¼Œè€—æ—¶: {duration:.2f} ç§’ã€‚")
 
        except Exception as e:
            logger.error(f"ä½¿ç”¨ Backup API åŠ è½½æ•°æ®åˆ°å†…å­˜æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise
        finally:
            # 4. å…³é—­è¿æ¥
            source_conn.close()
            # mem_conn ä¸éœ€è¦æˆ‘ä»¬æ‰‹åŠ¨å…³é—­ï¼ŒDjangoä¼šç®¡ç†å®ƒ
 
    def _setup_environment(self):
        """
        ä¿®æ­£ç‰ˆï¼šè°ƒæ•´äº†æ“ä½œé¡ºåºï¼Œå…ˆåŠ è½½æ•°æ®ï¼Œå†æ‰§è¡ŒORMæ“ä½œã€‚
        """
        logger.info("--- 1. å‡†å¤‡å›æµ‹ç¯å¢ƒ (å†…å­˜æ¨¡å¼) ---")
        
        base_dir = settings.BASE_DIR
        source_db = os.path.join(base_dir, 'mainDB.sqlite3')
        
        # 1. å…³é—­æ‰€æœ‰ç°æœ‰è¿æ¥
        connections.close_all()
        
        # 2. ä¿å­˜åŸå§‹é…ç½®ï¼Œå¹¶å°† 'default' æ•°æ®åº“é‡å®šå‘åˆ°å†…å­˜
        self.original_db_config = settings.DATABASES['default'].copy()
        settings.DATABASES['default']['NAME'] = ':memory:'
        logger.info("å·²å°† 'default' æ•°æ®åº“è¿æ¥é‡å®šå‘åˆ° :memory:")
 
        # 3. ç¡®ä¿Djangoå»ºç«‹åˆ°æ–°å†…å­˜æ•°æ®åº“çš„è¿æ¥
        #    è¿™ä¸€æ­¥è‡³å…³é‡è¦ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªç©ºçš„å†…å­˜æ•°æ®åº“å®ä¾‹
        connections['default'].ensure_connection()
        
        # 4. ã€æ ¸å¿ƒä¿®æ­£ã€‘ç«‹å³å°†ç£ç›˜æ•°æ®åŠ è½½åˆ°å†…å­˜æ•°æ®åº“ä¸­
        #    æ­¤æ—¶ï¼Œå†…å­˜æ•°æ®åº“ä»ç©ºå˜æˆäº† mainDB.sqlite3 çš„ä¸€ä¸ªå®Œæ•´å…‹éš†
        self._load_db_to_memory(source_db)
 
        # 5. ã€é¡ºåºè°ƒæ•´ã€‘ç°åœ¨å†…å­˜æ•°æ®åº“æ˜¯å®Œæ•´çš„äº†ï¼Œå¯ä»¥å®‰å…¨åœ°æ‰§è¡Œä»»ä½•Django ORMæ“ä½œ
        

        #DailyFactorValues, DailyTradingPlan,
        # æ¸…ç©ºå›æµ‹è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿæ•°æ®çš„è¡¨
        tables_to_clear = [
             Position,
            TradeLog, SystemLog
        ]
        # ä½¿ç”¨ transaction.atomic() æ¥ä¿è¯æ“ä½œçš„åŸå­æ€§
        with transaction.atomic():
            for model in tables_to_clear:
                # ç°åœ¨ model.objects.all() å¯ä»¥æ­£å¸¸å·¥ä½œäº†
                model.objects.all().delete()
                logger.info(f"å·²æ¸…ç©ºè¡¨: {model._meta.db_table}")
 
        # è¯»å–ç­–ç•¥å‚æ•°
        # ç°åœ¨ StrategyParameters.objects.all() ä¹Ÿå¯ä»¥æ­£å¸¸å·¥ä½œäº†
        params = {p.param_name: p.param_value for p in StrategyParameters.objects.all()}
        max_positions = int(params.get('MAX_POSITIONS', Decimal('5')))
        max_capital_per_pos = params.get('MAX_CAPITAL_PER_POSITION', Decimal('10000'))
        self.initial_capital = Decimal(max_positions) * max_capital_per_pos
        self.initial_capital=150000
        self.cash_balance = self.initial_capital
        logger.info(f"åˆå§‹èµ„é‡‘å·²è®¾å®šä¸º: {self.initial_capital:.2f}")
 
    def _cleanup_environment(self):
        """åœ¨å›æµ‹ç»“æŸåæ¢å¤åŸå§‹æ•°æ®åº“é…ç½®"""
        if self.original_db_config:
            connections.close_all()
            settings.DATABASES['default'] = self.original_db_config
            # å†…å­˜æ•°æ®åº“çš„è¿æ¥å…³é—­åï¼Œå…¶å†…å®¹ä¼šè‡ªåŠ¨é”€æ¯ï¼Œæ— éœ€æ‰‹åŠ¨åˆ é™¤æ–‡ä»¶
            logger.info("å·²æ¢å¤ 'default' æ•°æ®åº“è¿æ¥åˆ°åŸå§‹é…ç½®ï¼Œå†…å­˜æ•°æ®åº“å·²é‡Šæ”¾ã€‚")
    def _get_trading_days(self) -> list[date]:
        dates = DailyQuotes.objects.filter(
            trade_date__gte=self.start_date,
            trade_date__lte=self.end_date
        ).values_list('trade_date', flat=True).distinct().order_by('trade_date')
        return list(dates)

    def _calculate_daily_portfolio_value(self):
        open_positions = Position.objects.filter(status=Position.StatusChoices.OPEN)
        market_value = Decimal('0.0')
        for pos in open_positions:
            try:
                quote = DailyQuotes.objects.get(
                    stock_code_id=pos.stock_code_id,
                    trade_date=self.current_date
                )
                market_value += quote.close * pos.quantity
            except DailyQuotes.DoesNotExist:
                market_value += pos.entry_price * pos.quantity
        
        total_value = self.cash_balance + market_value
        self.portfolio_history.append({
            'date': self.current_date,
            'total_value': total_value
        })
        logger.info(f"--- æ—¥ç»ˆç»“ç®— ({self.current_date}) ---")
        logger.info(f"ç°é‡‘: {self.cash_balance:.2f}, æŒä»“å¸‚å€¼: {market_value:.2f}, æ€»èµ„äº§: {total_value:.2f}")

    def _calculate_performance_metrics(self) -> dict:
        logger.info("--- 4. è®¡ç®—å›æµ‹æ€§èƒ½æŒ‡æ ‡ ---")
        if not self.portfolio_history:
            return {}

        df = pd.DataFrame(self.portfolio_history)
        df['total_value'] = df['total_value'].astype(float)
        df['daily_return'] = df['total_value'].pct_change().fillna(0)
        
        final_value = float(df['total_value'].iloc[-1])
        total_return_amount = final_value - float(self.initial_capital)
        total_return_rate = (final_value / float(self.initial_capital)) - 1

        mean_daily_return = df['daily_return'].mean()
        std_daily_return = df['daily_return'].std()
        
        if std_daily_return == 0 or np.isnan(std_daily_return):
            sharpe_ratio = 0.0
        else:
            daily_risk_free_rate = (1 + self.ANNUAL_RISK_FREE_RATE) ** Decimal(1/self.TRADING_DAYS_PER_YEAR) - 1
            sharpe_ratio = (mean_daily_return - float(daily_risk_free_rate)) / std_daily_return
            sharpe_ratio *= np.sqrt(self.TRADING_DAYS_PER_YEAR)

        result = {
            'total_return_amount': round(total_return_amount, 2),
            'total_return_rate': round(total_return_rate, 4),
            'sharpe_ratio': round(float(sharpe_ratio), 4)
        }
        logger.info(f"å›æµ‹ç»“æœ: {result}")
        return result

    def run_backtest(self, start_date: str, end_date: str) -> dict:
        try:
            self.start_date = date.fromisoformat(start_date)
            self.end_date = date.fromisoformat(end_date)

            self._setup_environment()

            handler = SimulateTradeHandler(self)
            
            trading_days = self._get_trading_days()
            if not trading_days:
                logger.error("åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•äº¤æ˜“æ—¥ï¼Œå›æµ‹ç»ˆæ­¢ã€‚")
                return {}

            baseline_date = trading_days[0] - timedelta(days=1)
            self.portfolio_history.append({'date': baseline_date, 'total_value': self.initial_capital})

            logger.info(f"--- 2. å¼€å§‹æ—¥åº¦å›æµ‹å¾ªç¯ ({len(trading_days)}å¤©) ---")
            for i, current_day in enumerate(trading_days):
                self.current_date = current_day
                logger.info(f"\n{'='*20} æ¨¡æ‹Ÿæ—¥: {self.current_date} ({i+1}/{len(trading_days)}) {'='*20}")

                prev_trading_day = trading_days[i-1] if i > 0 else None
                if prev_trading_day:
                    logger.info(f"-> [T-1 é€‰è‚¡] åŸºäº {prev_trading_day} çš„æ•°æ®...")
                    selection_service = SelectionService(trade_date=prev_trading_day, mode='backtest')
                    selection_service.run_selection()

                logger.info("-> [Tæ—¥ ç›˜å‰æ ¡å‡†] ...")
                before_fix_service = BeforeFixService(execution_date=self.current_date)
                before_fix_service.run()
                
                dividend_events = CorporateAction.objects.filter(
                    ex_dividend_date=self.current_date, event_type=CorporateAction.EventType.DIVIDEND
                )
                # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼Œæé«˜æ•ˆç‡
                events_by_stock = {}
                for event in dividend_events:
                    events_by_stock.setdefault(event.stock_code, []).append(event)

                if events_by_stock:
                    # è·å–æ‰€æœ‰å¯èƒ½å—å½±å“çš„æŒä»“
                    open_positions_for_dividend = Position.objects.filter(
                        stock_code_id__in=events_by_stock.keys(),
                        status=Position.StatusChoices.OPEN
                    )
                    
                    for pos in open_positions_for_dividend:
                        # æ‰¾åˆ°è¯¥è‚¡ç¥¨å¯¹åº”çš„æ‰€æœ‰åˆ†çº¢äº‹ä»¶ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
                        stock_events = events_by_stock.get(pos.stock_code_id, [])
                        for event in stock_events:
                            dividend_amount = event.dividend_per_share * pos.quantity
                            self.cash_balance += dividend_amount
                            logger.info(f"é™¤æ¯äº‹ä»¶: æŒä»“ID {pos.position_id} ({pos.stock_code_id}) è·å¾—åˆ†çº¢ {dividend_amount:.2f}ï¼Œç°é‡‘ä½™é¢æ›´æ–°ä¸º {self.cash_balance:.2f}")



                logger.info("-> [Tæ—¥ å¼€ç›˜å†³ç­–ä¸ä¹°å…¥] ...")
                decision_order_service = DecisionOrderService(handler=handler, execution_date=self.current_date)
                decision_order_service.adjust_trading_plan_daily()
                
                while True:
                    open_positions_count = Position.objects.filter(status=Position.StatusChoices.OPEN).count()
                    max_pos = decision_order_service.current_max_positions
                    if open_positions_count >= max_pos:
                        break
                    
                    self.last_buy_trade_id = None
                    decision_order_service.execute_orders()
                    
                    if self.last_buy_trade_id:
                        decision_order_service.calculate_stop_profit_loss(self.last_buy_trade_id)
                    else:
                        break

                # å…³é”®ä¿®å¤ï¼šåœ¨å¾ªç¯å†…å®ä¾‹åŒ– MonitorExitService å¹¶ä¼ å…¥æ—¥æœŸ
                monitor_exit_service = MonitorExitService(handler=handler, execution_date=self.current_date)

                logger.info("-> [Tæ—¥ ç›˜ä¸­ç›‘æ§] æ¨¡æ‹Ÿä»·æ ¼è·Œè‡³æœ€ä½ç‚¹...")
                handler.current_price_node = 'LOW'
                monitor_exit_service.monitor_and_exit_positions()

                logger.info("-> [Tæ—¥ ç›˜ä¸­ç›‘æ§] æ¨¡æ‹Ÿä»·æ ¼æ¶¨è‡³æœ€é«˜ç‚¹...")
                handler.current_price_node = 'HIGH'
                monitor_exit_service.monitor_and_exit_positions()

                self._calculate_daily_portfolio_value()

            logger.info("--- 3. å›æµ‹å¾ªç¯ç»“æŸ ---")
            return self._calculate_performance_metrics()
        
        finally:
            # ç¡®ä¿æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½æ¸…ç†ç¯å¢ƒ
            self._cleanup_environment()

####æ–‡ä»¶ç»“æŸ####

####trade_manager\service\trade_handler.py####
# trade_manager/service/trade_handler.py

from abc import ABC, abstractmethod
from decimal import Decimal
from django.db import transaction
from django.utils import timezone
# ä¸ºäº†ç±»å‹æç¤ºï¼Œæˆ‘ä»¬å¯ä»¥ä» common.models å¯¼å…¥ Position å’Œ TradeLog
# æ³¨æ„ï¼šä¸ºäº†é¿å…å¾ªç¯å¯¼å…¥ï¼Œé€šå¸¸åœ¨å®ç°ç±»ä¸­è¿›è¡Œå®é™…å¯¼å…¥ï¼Œè¿™é‡Œä»…ä¸ºç±»å‹æç¤º
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from common.models import Position, TradeLog



class ITradeHandler(ABC):
    """
    äº¤æ˜“å¤„ç†å™¨æŠ½è±¡åŸºç±» (Abstract Base Class)ã€‚

    è¯¥æ¥å£å®šä¹‰äº†å¼€ç›˜å†³ç­–ä¸ä¸‹å•æ¨¡å—æ‰€éœ€çš„æ‰€æœ‰å¤–éƒ¨äº¤äº’è¡Œä¸ºã€‚
    é€šè¿‡ä¾èµ–æ­¤æŠ½è±¡æ¥å£è€Œéå…·ä½“å®ç°ï¼Œ`DecisionOrderService` å¯ä»¥ä¸ä¸åŒçš„
    äº¤æ˜“ç¯å¢ƒï¼ˆå¦‚çœŸå®äº¤æ˜“æ¥å£ã€å›æµ‹å¼•æ“ï¼‰è§£è€¦ã€‚

    - å¯¹äºçœŸå®äº¤æ˜“ï¼Œå®ç°ç±»å°†é€šè¿‡APIä¸åˆ¸å•†æœåŠ¡å™¨äº¤äº’ã€‚
    - å¯¹äºå›æµ‹ï¼Œå®ç°ç±»å°†æ¨¡æ‹Ÿè¿™äº›äº¤äº’ï¼Œä¾‹å¦‚ä»å†å²æ•°æ®ä¸­è¯»å–å¼€ç›˜ä»·ã€
      æ¨¡æ‹Ÿè®¢å•æˆäº¤ã€å¹¶ç®¡ç†ä¸€ä¸ªè™šæ‹Ÿè´¦æˆ·çš„ä½™é¢ã€‚
    """

    @abstractmethod
    def get_opening_price(self, stock_code: str) -> Decimal:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æ‰§è¡Œæ—¥çš„å®é™…å¼€ç›˜ä»·ã€‚

        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼ä¸ tb_stock_info è¡¨ä¸€è‡´ (å¦‚ 'sh.600000')ã€‚
        :return: å½“æ—¥çš„å¼€ç›˜ä»·ã€‚å¦‚æœæ— æ³•è·å–ï¼ˆä¾‹å¦‚åœç‰Œï¼‰ï¼Œåº”å¼•å‘å¼‚å¸¸æˆ–è¿”å›ä¸€ä¸ªå¯è¯†åˆ«çš„é”™è¯¯å€¼ï¼ˆå¦‚Decimal('0.00')ï¼‰ã€‚
        """
        pass

    @abstractmethod
    def place_buy_order(self, stock_code: str, price: Decimal, quantity: int) -> None:
        """
        æäº¤ä¸€ä¸ªä¹°å…¥è®¢å•ã€‚

        æ­¤æ–¹æ³•çš„å®ç°è€…è´Ÿè´£å¤„ç†ä¸äº¤æ˜“ç³»ç»Ÿçš„æ‰€æœ‰äº¤äº’ã€‚æ ¹æ®éœ€æ±‚ï¼Œæ­¤æ–¹æ³•
        åœ¨æ‰§è¡Œæ—¶ï¼Œéœ€è¦å®Œæˆä»¥ä¸‹æ•°æ®åº“æ“ä½œï¼š
        1. åœ¨ `tb_positions` è¡¨ä¸­æ’å…¥ä¸€æ¡æ–°çš„æŒä»“è®°å½•ï¼Œå…¶ä¸­æ‰€æœ‰éç©ºå­—æ®µ
           ï¼ˆå¦‚ current_stop_loss, current_take_profitï¼‰å¯ä½¿ç”¨å“¨å…µå€¼ï¼ˆå¦‚-1ï¼‰å¡«å……ï¼Œ
           ç­‰å¾…åç»­çš„æ­¢ç›ˆæ­¢æŸè®¡ç®—ä»»åŠ¡æ¥æ›´æ–°ã€‚
        2. åœ¨ `tb_trade_log` è¡¨ä¸­æ’å…¥ä¸€æ¡å¯¹åº”çš„äº¤æ˜“è®°å½•ï¼Œåˆå§‹çŠ¶æ€åº”ä¸º
           'pending'ã€‚

        :param stock_code: è‚¡ç¥¨ä»£ç ã€‚
        :param price: é¢„æœŸçš„ä¹°å…¥é™ä»·ã€‚
        :param quantity: è®¡åˆ’ä¹°å…¥çš„è‚¡æ•°ï¼ˆå¿…é¡»æ˜¯100çš„æ•´æ•°å€ï¼‰ã€‚
        :return: æ— è¿”å›å€¼ã€‚
        """
        pass

    @abstractmethod
    def get_available_balance(self) -> Decimal:
        """
        æŸ¥è¯¢å½“å‰è´¦æˆ·çš„å¯ç”¨èµ„é‡‘ä½™é¢ã€‚

        :return: å¯ç”¨äºäº¤æ˜“çš„ç°é‡‘ä½™é¢ã€‚
        """
        pass

    
    @abstractmethod
    def get_realtime_price(self, stock_code: str) -> Decimal | None:
        """
        è·å–ä¸€åªè‚¡ç¥¨çš„å®æ—¶ä»·æ ¼ã€‚
 
        :param stock_code: è‚¡ç¥¨ä»£ç ï¼Œæ ¼å¼å¦‚ 'sh.600000'ã€‚
        :return: è¯¥è‚¡ç¥¨æ­¤æ—¶æ­¤åˆ»çš„å¸‚åœºä»· (Decimalç±»å‹)ã€‚å¦‚æœè·å–å¤±è´¥ï¼ˆå¦‚ç½‘ç»œé—®é¢˜ã€è‚¡ç¥¨åœç‰Œï¼‰ï¼Œ
                 åº”è¿”å› Noneï¼Œä»¥ä¾¿è°ƒç”¨æ–¹è¿›è¡Œé”™è¯¯å¤„ç†ã€‚
        """
        pass
 
    @abstractmethod
    def sell_stock_by_market_price(self, position: 'Position', reason: str) -> None:
        """
        ä»¥å¸‚ä»·å•å…¨é‡å–å‡ºæŒ‡å®šçš„æŒä»“ã€‚
 
        æ­¤æ–¹æ³•çš„å…·ä½“å®ç°éœ€è¦å®Œæˆä¸€ä¸ªåŸå­æ€§çš„æ“ä½œæµç¨‹ï¼š
        1. è°ƒç”¨äº¤æ˜“APIï¼Œä»¥å¸‚ä»·å•å–å‡º `position.quantity` æ•°é‡çš„ `position.stock_code`ã€‚
        2. **åœ¨APIè°ƒç”¨æˆåŠŸè¿”å›æˆäº¤å›æŠ¥å**ï¼Œæ‰§è¡Œä»¥ä¸‹æ•°æ®åº“æ“ä½œï¼š
           a. **æ›´æ–°æŒä»“è¡¨ (tb_positions)**: å°†ä¼ å…¥çš„ `position` å¯¹è±¡çš„çŠ¶æ€æ›´æ–°ä¸º 'closed'ã€‚
              `position.status = Position.StatusChoices.CLOSED`
              `position.save()`
           b. **æ’å…¥äº¤æ˜“è®°å½• (tb_trade_log)**: åˆ›å»ºä¸€æ¡æ–°çš„å–å‡ºè®°å½•ã€‚
              - `position`: å…³è”åˆ°æ­¤æŒä»“ã€‚
              - `stock_code`: è‚¡ç¥¨ä»£ç ã€‚
              - `trade_datetime`: äº¤æ˜“çš„å®é™…æˆäº¤æ—¶é—´ã€‚
              - `trade_type`: 'sell'ã€‚
              - `order_type`: 'market'ã€‚
              - `quantity`: å®é™…æˆäº¤æ•°é‡ã€‚
              - `price`: å®é™…çš„æˆäº¤å‡ä»·ã€‚ä»æˆäº¤å›æŠ¥ä¸­è·å–ã€‚å¦‚æœæ— æ³•ç«‹å³è·å–ï¼Œ
                                            åˆ™ä½¿ç”¨ -1 ä½œä¸ºå ä½ç¬¦ï¼Œç­‰å¾…åç»­ä»»åŠ¡å›è¡¥ã€‚
              - `commission`, `stamp_duty`: ä»æˆäº¤å›æŠ¥ä¸­è·å–ã€‚å¦‚æœæ— æ³•ç«‹å³è·å–ï¼Œ
                                            åˆ™ä½¿ç”¨ -1 ä½œä¸ºå ä½ç¬¦ï¼Œç­‰å¾…åç»­ä»»åŠ¡å›è¡¥ã€‚
              - `reason`: ä½¿ç”¨ä¼ å…¥çš„ `reason` å‚æ•° ('take_profit' æˆ– 'stop_loss')ã€‚
              - `status`: 'filled' (å·²æˆäº¤)ã€‚
        3. æ•´ä¸ªæ•°æ®åº“æ›´æ–°è¿‡ç¨‹åº”è¯¥è¢«åŒ…è£¹åœ¨ä¸€ä¸ªäº‹åŠ¡ä¸­ (`transaction.atomic`)ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚
 
        :param position: è¦å–å‡ºçš„æŒä»“å¯¹è±¡ (common.models.positions.Position)ã€‚
                         è¯¥å¯¹è±¡åŒ…å«äº†æŒä»“IDã€è‚¡ç¥¨ä»£ç ã€æŒä»“æ•°é‡ç­‰æ‰€æœ‰å¿…è¦ä¿¡æ¯ã€‚
        :param reason: å–å‡ºåŸå› çš„å­—ç¬¦ä¸²ï¼Œå¦‚ 'take_profit' æˆ– 'stop_loss'ã€‚
                       è¿™ä¸ªå€¼å°†ç”¨äºå¡«å……äº¤æ˜“è®°å½•è¡¨çš„ `reason` å­—æ®µã€‚
        :return: æ— è¿”å›å€¼ã€‚å¦‚æœæ‰§è¡Œå¤±è´¥ï¼ˆå¦‚APIè°ƒç”¨å¤±è´¥ã€è‚¡ç¥¨è·Œåœæ— æ³•å–å‡ºï¼‰ï¼Œ
                 åº”åœ¨æ–¹æ³•å†…éƒ¨å¤„ç†å¼‚å¸¸ï¼ˆå¦‚è®°å½•æ—¥å¿—ï¼‰ï¼Œå¹¶å‘ä¸Šå±‚è°ƒç”¨è€…ï¼ˆMonitorExitServiceï¼‰
                 æŠ›å‡ºå¼‚å¸¸æˆ–é€šè¿‡å…¶ä»–æ–¹å¼é€šçŸ¥å¤±è´¥ï¼Œä»¥ä¾¿ä¸Šå±‚å†³å®šæ˜¯å¦é‡è¯•ã€‚
        """
        pass
####æ–‡ä»¶ç»“æŸ####
